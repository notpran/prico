(function () {
  'use strict';

  /**
   * Utility module to work with key-value stores.
   *
   * @module map
   */

  /**
   * Creates a new Map instance.
   *
   * @function
   * @return {Map<any, any>}
   *
   * @function
   */
  const create$6 = () => new Map();

  /**
   * Copy a Map object into a fresh Map object.
   *
   * @function
   * @template K,V
   * @param {Map<K,V>} m
   * @return {Map<K,V>}
   */
  const copy = m => {
    const r = create$6();
    m.forEach((v, k) => { r.set(k, v); });
    return r
  };

  /**
   * Get map property. Create T if property is undefined and set T on map.
   *
   * ```js
   * const listeners = map.setIfUndefined(events, 'eventName', set.create)
   * listeners.add(listener)
   * ```
   *
   * @function
   * @template {Map<any, any>} MAP
   * @template {MAP extends Map<any,infer V> ? function():V : unknown} CF
   * @param {MAP} map
   * @param {MAP extends Map<infer K,any> ? K : unknown} key
   * @param {CF} createT
   * @return {ReturnType<CF>}
   */
  const setIfUndefined = (map, key, createT) => {
    let set = map.get(key);
    if (set === undefined) {
      map.set(key, set = createT());
    }
    return set
  };

  /**
   * Creates an Array and populates it with the content of all key-value pairs using the `f(value, key)` function.
   *
   * @function
   * @template K
   * @template V
   * @template R
   * @param {Map<K,V>} m
   * @param {function(V,K):R} f
   * @return {Array<R>}
   */
  const map$2 = (m, f) => {
    const res = [];
    for (const [key, value] of m) {
      res.push(f(value, key));
    }
    return res
  };

  /**
   * Tests whether any key-value pairs pass the test implemented by `f(value, key)`.
   *
   * @todo should rename to some - similarly to Array.some
   *
   * @function
   * @template K
   * @template V
   * @param {Map<K,V>} m
   * @param {function(V,K):boolean} f
   * @return {boolean}
   */
  const any = (m, f) => {
    for (const [key, value] of m) {
      if (f(value, key)) {
        return true
      }
    }
    return false
  };

  /**
   * Utility module to work with sets.
   *
   * @module set
   */

  const create$5 = () => new Set();

  /**
   * Utility module to work with Arrays.
   *
   * @module array
   */

  /**
   * Return the last element of an array. The element must exist
   *
   * @template L
   * @param {ArrayLike<L>} arr
   * @return {L}
   */
  const last = arr => arr[arr.length - 1];

  /**
   * Append elements from src to dest
   *
   * @template M
   * @param {Array<M>} dest
   * @param {Array<M>} src
   */
  const appendTo = (dest, src) => {
    for (let i = 0; i < src.length; i++) {
      dest.push(src[i]);
    }
  };

  /**
   * Transforms something array-like to an actual Array.
   *
   * @function
   * @template T
   * @param {ArrayLike<T>|Iterable<T>} arraylike
   * @return {T}
   */
  const from$2 = Array.from;

  /**
   * True iff condition holds on some element in the Array.
   *
   * @function
   * @template S
   * @template {ArrayLike<S>} ARR
   * @param {ARR} arr
   * @param {function(S, number, ARR):boolean} f
   * @return {boolean}
   */
  const some$1 = (arr, f) => {
    for (let i = 0; i < arr.length; i++) {
      if (f(arr[i], i, arr)) {
        return true
      }
    }
    return false
  };

  const isArray = Array.isArray;

  /**
   * Observable class prototype.
   *
   * @module observable
   */

  /**
   * Handles named events.
   * @experimental
   *
   * This is basically a (better typed) duplicate of Observable, which will replace Observable in the
   * next release.
   *
   * @template {{[key in keyof EVENTS]: function(...any):void}} EVENTS
   */
  class ObservableV2 {
    constructor () {
      /**
       * Some desc.
       * @type {Map<string, Set<any>>}
       */
      this._observers = create$6();
    }

    /**
     * @template {keyof EVENTS & string} NAME
     * @param {NAME} name
     * @param {EVENTS[NAME]} f
     */
    on (name, f) {
      setIfUndefined(this._observers, /** @type {string} */ (name), create$5).add(f);
      return f
    }

    /**
     * @template {keyof EVENTS & string} NAME
     * @param {NAME} name
     * @param {EVENTS[NAME]} f
     */
    once (name, f) {
      /**
       * @param  {...any} args
       */
      const _f = (...args) => {
        this.off(name, /** @type {any} */ (_f));
        f(...args);
      };
      this.on(name, /** @type {any} */ (_f));
    }

    /**
     * @template {keyof EVENTS & string} NAME
     * @param {NAME} name
     * @param {EVENTS[NAME]} f
     */
    off (name, f) {
      const observers = this._observers.get(name);
      if (observers !== undefined) {
        observers.delete(f);
        if (observers.size === 0) {
          this._observers.delete(name);
        }
      }
    }

    /**
     * Emit a named event. All registered event listeners that listen to the
     * specified name will receive the event.
     *
     * @todo This should catch exceptions
     *
     * @template {keyof EVENTS & string} NAME
     * @param {NAME} name The event name.
     * @param {Parameters<EVENTS[NAME]>} args The arguments that are applied to the event listener.
     */
    emit (name, args) {
      // copy all listeners to an array first to make sure that no event is emitted to listeners that are subscribed while the event handler is called.
      return from$2((this._observers.get(name) || create$6()).values()).forEach(f => f(...args))
    }

    destroy () {
      this._observers = create$6();
    }
  }
  /* c8 ignore end */

  /**
   * Common Math expressions.
   *
   * @module math
   */

  const floor = Math.floor;
  const ceil = Math.ceil;
  const abs = Math.abs;
  const round = Math.round;
  const log10 = Math.log10;

  /**
   * @function
   * @param {number} a
   * @param {number} b
   * @return {number} The sum of a and b
   */
  const add = (a, b) => a + b;

  /**
   * @function
   * @param {number} a
   * @param {number} b
   * @return {number} The smaller element of a and b
   */
  const min = (a, b) => a < b ? a : b;

  /**
   * @function
   * @param {number} a
   * @param {number} b
   * @return {number} The bigger element of a and b
   */
  const max = (a, b) => a > b ? a : b;
  /**
   * Base 10 exponential function. Returns the value of 10 raised to the power of pow.
   *
   * @param {number} exp
   * @return {number}
   */
  const exp10 = exp => Math.pow(10, exp);

  /**
   * @param {number} n
   * @return {boolean} Wether n is negative. This function also differentiates between -0 and +0
   */
  const isNegativeZero = n => n !== 0 ? n < 0 : 1 / n < 0;

  /* eslint-env browser */

  /**
   * Binary data constants.
   *
   * @module binary
   */

  /**
   * n-th bit activated.
   *
   * @type {number}
   */
  const BIT1 = 1;
  const BIT2 = 2;
  const BIT3 = 4;
  const BIT4 = 8;
  const BIT6 = 32;
  const BIT7 = 64;
  const BIT8 = 128;
  const BITS5 = 31;
  const BITS6 = 63;
  const BITS7 = 127;
  const BITS8 = 255;
  /**
   * @type {number}
   */
  const BITS31 = 0x7FFFFFFF;
  /**
   * @type {number}
   */
  const BITS32 = 0xFFFFFFFF;

  /**
   * Utility helpers for working with numbers.
   *
   * @module number
   */

  const MAX_SAFE_INTEGER = Number.MAX_SAFE_INTEGER;

  /* c8 ignore next */
  const isInteger = Number.isInteger || (num => typeof num === 'number' && isFinite(num) && floor(num) === num);

  /**
   * @param {string} s
   * @return {string}
   */
  const toLowerCase = s => s.toLowerCase();

  const trimLeftRegex = /^\s*/g;

  /**
   * @param {string} s
   * @return {string}
   */
  const trimLeft = s => s.replace(trimLeftRegex, '');

  const fromCamelCaseRegex = /([A-Z])/g;

  /**
   * @param {string} s
   * @param {string} separator
   * @return {string}
   */
  const fromCamelCase = (s, separator) => trimLeft(s.replace(fromCamelCaseRegex, match => `${separator}${toLowerCase(match)}`));

  /**
   * @param {string} str
   * @return {Uint8Array}
   */
  const _encodeUtf8Polyfill = str => {
    const encodedString = unescape(encodeURIComponent(str));
    const len = encodedString.length;
    const buf = new Uint8Array(len);
    for (let i = 0; i < len; i++) {
      buf[i] = /** @type {number} */ (encodedString.codePointAt(i));
    }
    return buf
  };

  /* c8 ignore next */
  const utf8TextEncoder = /** @type {TextEncoder} */ (typeof TextEncoder !== 'undefined' ? new TextEncoder() : null);

  /**
   * @param {string} str
   * @return {Uint8Array}
   */
  const _encodeUtf8Native = str => utf8TextEncoder.encode(str);

  /**
   * @param {string} str
   * @return {Uint8Array}
   */
  /* c8 ignore next */
  const encodeUtf8 = utf8TextEncoder ? _encodeUtf8Native : _encodeUtf8Polyfill;

  /* c8 ignore next */
  let utf8TextDecoder = typeof TextDecoder === 'undefined' ? null : new TextDecoder('utf-8', { fatal: true, ignoreBOM: true });

  /* c8 ignore start */
  if (utf8TextDecoder && utf8TextDecoder.decode(new Uint8Array()).length === 1) {
    // Safari doesn't handle BOM correctly.
    // This fixes a bug in Safari 13.0.5 where it produces a BOM the first time it is called.
    // utf8TextDecoder.decode(new Uint8Array()).length === 1 on the first call and
    // utf8TextDecoder.decode(new Uint8Array()).length === 1 on the second call
    // Another issue is that from then on no BOM chars are recognized anymore
    /* c8 ignore next */
    utf8TextDecoder = null;
  }

  /**
   * Efficient schema-less binary encoding with support for variable length encoding.
   *
   * Use [lib0/encoding] with [lib0/decoding]. Every encoding function has a corresponding decoding function.
   *
   * Encodes numbers in little-endian order (least to most significant byte order)
   * and is compatible with Golang's binary encoding (https://golang.org/pkg/encoding/binary/)
   * which is also used in Protocol Buffers.
   *
   * ```js
   * // encoding step
   * const encoder = encoding.createEncoder()
   * encoding.writeVarUint(encoder, 256)
   * encoding.writeVarString(encoder, 'Hello world!')
   * const buf = encoding.toUint8Array(encoder)
   * ```
   *
   * ```js
   * // decoding step
   * const decoder = decoding.createDecoder(buf)
   * decoding.readVarUint(decoder) // => 256
   * decoding.readVarString(decoder) // => 'Hello world!'
   * decoding.hasContent(decoder) // => false - all data is read
   * ```
   *
   * @module encoding
   */

  /**
   * A BinaryEncoder handles the encoding to an Uint8Array.
   */
  class Encoder {
    constructor () {
      this.cpos = 0;
      this.cbuf = new Uint8Array(100);
      /**
       * @type {Array<Uint8Array>}
       */
      this.bufs = [];
    }
  }

  /**
   * @function
   * @return {Encoder}
   */
  const createEncoder = () => new Encoder();

  /**
   * @param {function(Encoder):void} f
   */
  const encode = (f) => {
    const encoder = createEncoder();
    f(encoder);
    return toUint8Array(encoder)
  };

  /**
   * The current length of the encoded data.
   *
   * @function
   * @param {Encoder} encoder
   * @return {number}
   */
  const length$1 = encoder => {
    let len = encoder.cpos;
    for (let i = 0; i < encoder.bufs.length; i++) {
      len += encoder.bufs[i].length;
    }
    return len
  };

  /**
   * Transform to Uint8Array.
   *
   * @function
   * @param {Encoder} encoder
   * @return {Uint8Array} The created ArrayBuffer.
   */
  const toUint8Array = encoder => {
    const uint8arr = new Uint8Array(length$1(encoder));
    let curPos = 0;
    for (let i = 0; i < encoder.bufs.length; i++) {
      const d = encoder.bufs[i];
      uint8arr.set(d, curPos);
      curPos += d.length;
    }
    uint8arr.set(new Uint8Array(encoder.cbuf.buffer, 0, encoder.cpos), curPos);
    return uint8arr
  };

  /**
   * Verify that it is possible to write `len` bytes wtihout checking. If
   * necessary, a new Buffer with the required length is attached.
   *
   * @param {Encoder} encoder
   * @param {number} len
   */
  const verifyLen = (encoder, len) => {
    const bufferLen = encoder.cbuf.length;
    if (bufferLen - encoder.cpos < len) {
      encoder.bufs.push(new Uint8Array(encoder.cbuf.buffer, 0, encoder.cpos));
      encoder.cbuf = new Uint8Array(max(bufferLen, len) * 2);
      encoder.cpos = 0;
    }
  };

  /**
   * Write one byte to the encoder.
   *
   * @function
   * @param {Encoder} encoder
   * @param {number} num The byte that is to be encoded.
   */
  const write$1 = (encoder, num) => {
    const bufferLen = encoder.cbuf.length;
    if (encoder.cpos === bufferLen) {
      encoder.bufs.push(encoder.cbuf);
      encoder.cbuf = new Uint8Array(bufferLen * 2);
      encoder.cpos = 0;
    }
    encoder.cbuf[encoder.cpos++] = num;
  };

  /**
   * Write one byte as an unsigned integer.
   *
   * @function
   * @param {Encoder} encoder
   * @param {number} num The number that is to be encoded.
   */
  const writeUint8 = write$1;

  /**
   * Write a variable length unsigned integer. Max encodable integer is 2^53.
   *
   * @function
   * @param {Encoder} encoder
   * @param {number} num The number that is to be encoded.
   */
  const writeVarUint = (encoder, num) => {
    while (num > BITS7) {
      write$1(encoder, BIT8 | (BITS7 & num));
      num = floor(num / 128); // shift >>> 7
    }
    write$1(encoder, BITS7 & num);
  };

  /**
   * Write a variable length integer.
   *
   * We use the 7th bit instead for signaling that this is a negative number.
   *
   * @function
   * @param {Encoder} encoder
   * @param {number} num The number that is to be encoded.
   */
  const writeVarInt = (encoder, num) => {
    const isNegative = isNegativeZero(num);
    if (isNegative) {
      num = -num;
    }
    //             |- whether to continue reading         |- whether is negative     |- number
    write$1(encoder, (num > BITS6 ? BIT8 : 0) | (isNegative ? BIT7 : 0) | (BITS6 & num));
    num = floor(num / 64); // shift >>> 6
    // We don't need to consider the case of num === 0 so we can use a different
    // pattern here than above.
    while (num > 0) {
      write$1(encoder, (num > BITS7 ? BIT8 : 0) | (BITS7 & num));
      num = floor(num / 128); // shift >>> 7
    }
  };

  /**
   * A cache to store strings temporarily
   */
  const _strBuffer = new Uint8Array(30000);
  const _maxStrBSize = _strBuffer.length / 3;

  /**
   * Write a variable length string.
   *
   * @function
   * @param {Encoder} encoder
   * @param {String} str The string that is to be encoded.
   */
  const _writeVarStringNative = (encoder, str) => {
    if (str.length < _maxStrBSize) {
      // We can encode the string into the existing buffer
      /* c8 ignore next */
      const written = utf8TextEncoder.encodeInto(str, _strBuffer).written || 0;
      writeVarUint(encoder, written);
      for (let i = 0; i < written; i++) {
        write$1(encoder, _strBuffer[i]);
      }
    } else {
      writeVarUint8Array(encoder, encodeUtf8(str));
    }
  };

  /**
   * Write a variable length string.
   *
   * @function
   * @param {Encoder} encoder
   * @param {String} str The string that is to be encoded.
   */
  const _writeVarStringPolyfill = (encoder, str) => {
    const encodedString = unescape(encodeURIComponent(str));
    const len = encodedString.length;
    writeVarUint(encoder, len);
    for (let i = 0; i < len; i++) {
      write$1(encoder, /** @type {number} */ (encodedString.codePointAt(i)));
    }
  };

  /**
   * Write a variable length string.
   *
   * @function
   * @param {Encoder} encoder
   * @param {String} str The string that is to be encoded.
   */
  /* c8 ignore next */
  const writeVarString = (utf8TextEncoder && /** @type {any} */ (utf8TextEncoder).encodeInto) ? _writeVarStringNative : _writeVarStringPolyfill;

  /**
   * Append fixed-length Uint8Array to the encoder.
   *
   * @function
   * @param {Encoder} encoder
   * @param {Uint8Array} uint8Array
   */
  const writeUint8Array = (encoder, uint8Array) => {
    const bufferLen = encoder.cbuf.length;
    const cpos = encoder.cpos;
    const leftCopyLen = min(bufferLen - cpos, uint8Array.length);
    const rightCopyLen = uint8Array.length - leftCopyLen;
    encoder.cbuf.set(uint8Array.subarray(0, leftCopyLen), cpos);
    encoder.cpos += leftCopyLen;
    if (rightCopyLen > 0) {
      // Still something to write, write right half..
      // Append new buffer
      encoder.bufs.push(encoder.cbuf);
      // must have at least size of remaining buffer
      encoder.cbuf = new Uint8Array(max(bufferLen * 2, rightCopyLen));
      // copy array
      encoder.cbuf.set(uint8Array.subarray(leftCopyLen));
      encoder.cpos = rightCopyLen;
    }
  };

  /**
   * Append an Uint8Array to Encoder.
   *
   * @function
   * @param {Encoder} encoder
   * @param {Uint8Array} uint8Array
   */
  const writeVarUint8Array = (encoder, uint8Array) => {
    writeVarUint(encoder, uint8Array.byteLength);
    writeUint8Array(encoder, uint8Array);
  };

  /**
   * Create an DataView of the next `len` bytes. Use it to write data after
   * calling this function.
   *
   * ```js
   * // write float32 using DataView
   * const dv = writeOnDataView(encoder, 4)
   * dv.setFloat32(0, 1.1)
   * // read float32 using DataView
   * const dv = readFromDataView(encoder, 4)
   * dv.getFloat32(0) // => 1.100000023841858 (leaving it to the reader to find out why this is the correct result)
   * ```
   *
   * @param {Encoder} encoder
   * @param {number} len
   * @return {DataView}
   */
  const writeOnDataView = (encoder, len) => {
    verifyLen(encoder, len);
    const dview = new DataView(encoder.cbuf.buffer, encoder.cpos, len);
    encoder.cpos += len;
    return dview
  };

  /**
   * @param {Encoder} encoder
   * @param {number} num
   */
  const writeFloat32 = (encoder, num) => writeOnDataView(encoder, 4).setFloat32(0, num, false);

  /**
   * @param {Encoder} encoder
   * @param {number} num
   */
  const writeFloat64 = (encoder, num) => writeOnDataView(encoder, 8).setFloat64(0, num, false);

  /**
   * @param {Encoder} encoder
   * @param {bigint} num
   */
  const writeBigInt64 = (encoder, num) => /** @type {any} */ (writeOnDataView(encoder, 8)).setBigInt64(0, num, false);

  const floatTestBed = new DataView(new ArrayBuffer(4));
  /**
   * Check if a number can be encoded as a 32 bit float.
   *
   * @param {number} num
   * @return {boolean}
   */
  const isFloat32 = num => {
    floatTestBed.setFloat32(0, num);
    return floatTestBed.getFloat32(0) === num
  };

  /**
   * Encode data with efficient binary format.
   *
   * Differences to JSON:
   * • Transforms data to a binary format (not to a string)
   * • Encodes undefined, NaN, and ArrayBuffer (these can't be represented in JSON)
   * • Numbers are efficiently encoded either as a variable length integer, as a
   *   32 bit float, as a 64 bit float, or as a 64 bit bigint.
   *
   * Encoding table:
   *
   * | Data Type           | Prefix   | Encoding Method    | Comment |
   * | ------------------- | -------- | ------------------ | ------- |
   * | undefined           | 127      |                    | Functions, symbol, and everything that cannot be identified is encoded as undefined |
   * | null                | 126      |                    | |
   * | integer             | 125      | writeVarInt        | Only encodes 32 bit signed integers |
   * | float32             | 124      | writeFloat32       | |
   * | float64             | 123      | writeFloat64       | |
   * | bigint              | 122      | writeBigInt64      | |
   * | boolean (false)     | 121      |                    | True and false are different data types so we save the following byte |
   * | boolean (true)      | 120      |                    | - 0b01111000 so the last bit determines whether true or false |
   * | string              | 119      | writeVarString     | |
   * | object<string,any>  | 118      | custom             | Writes {length} then {length} key-value pairs |
   * | array<any>          | 117      | custom             | Writes {length} then {length} json values |
   * | Uint8Array          | 116      | writeVarUint8Array | We use Uint8Array for any kind of binary data |
   *
   * Reasons for the decreasing prefix:
   * We need the first bit for extendability (later we may want to encode the
   * prefix with writeVarUint). The remaining 7 bits are divided as follows:
   * [0-30]   the beginning of the data range is used for custom purposes
   *          (defined by the function that uses this library)
   * [31-127] the end of the data range is used for data encoding by
   *          lib0/encoding.js
   *
   * @param {Encoder} encoder
   * @param {undefined|null|number|bigint|boolean|string|Object<string,any>|Array<any>|Uint8Array} data
   */
  const writeAny = (encoder, data) => {
    switch (typeof data) {
      case 'string':
        // TYPE 119: STRING
        write$1(encoder, 119);
        writeVarString(encoder, data);
        break
      case 'number':
        if (isInteger(data) && abs(data) <= BITS31) {
          // TYPE 125: INTEGER
          write$1(encoder, 125);
          writeVarInt(encoder, data);
        } else if (isFloat32(data)) {
          // TYPE 124: FLOAT32
          write$1(encoder, 124);
          writeFloat32(encoder, data);
        } else {
          // TYPE 123: FLOAT64
          write$1(encoder, 123);
          writeFloat64(encoder, data);
        }
        break
      case 'bigint':
        // TYPE 122: BigInt
        write$1(encoder, 122);
        writeBigInt64(encoder, data);
        break
      case 'object':
        if (data === null) {
          // TYPE 126: null
          write$1(encoder, 126);
        } else if (isArray(data)) {
          // TYPE 117: Array
          write$1(encoder, 117);
          writeVarUint(encoder, data.length);
          for (let i = 0; i < data.length; i++) {
            writeAny(encoder, data[i]);
          }
        } else if (data instanceof Uint8Array) {
          // TYPE 116: ArrayBuffer
          write$1(encoder, 116);
          writeVarUint8Array(encoder, data);
        } else {
          // TYPE 118: Object
          write$1(encoder, 118);
          const keys = Object.keys(data);
          writeVarUint(encoder, keys.length);
          for (let i = 0; i < keys.length; i++) {
            const key = keys[i];
            writeVarString(encoder, key);
            writeAny(encoder, data[key]);
          }
        }
        break
      case 'boolean':
        // TYPE 120/121: boolean (true/false)
        write$1(encoder, data ? 120 : 121);
        break
      default:
        // TYPE 127: undefined
        write$1(encoder, 127);
    }
  };

  /**
   * Now come a few stateful encoder that have their own classes.
   */

  /**
   * Basic Run Length Encoder - a basic compression implementation.
   *
   * Encodes [1,1,1,7] to [1,3,7,1] (3 times 1, 1 time 7). This encoder might do more harm than good if there are a lot of values that are not repeated.
   *
   * It was originally used for image compression. Cool .. article http://csbruce.com/cbm/transactor/pdfs/trans_v7_i06.pdf
   *
   * @note T must not be null!
   *
   * @template T
   */
  class RleEncoder extends Encoder {
    /**
     * @param {function(Encoder, T):void} writer
     */
    constructor (writer) {
      super();
      /**
       * The writer
       */
      this.w = writer;
      /**
       * Current state
       * @type {T|null}
       */
      this.s = null;
      this.count = 0;
    }

    /**
     * @param {T} v
     */
    write (v) {
      if (this.s === v) {
        this.count++;
      } else {
        if (this.count > 0) {
          // flush counter, unless this is the first value (count = 0)
          writeVarUint(this, this.count - 1); // since count is always > 0, we can decrement by one. non-standard encoding ftw
        }
        this.count = 1;
        // write first value
        this.w(this, v);
        this.s = v;
      }
    }
  }

  /**
   * @param {UintOptRleEncoder} encoder
   */
  const flushUintOptRleEncoder = encoder => {
    if (encoder.count > 0) {
      // flush counter, unless this is the first value (count = 0)
      // case 1: just a single value. set sign to positive
      // case 2: write several values. set sign to negative to indicate that there is a length coming
      writeVarInt(encoder.encoder, encoder.count === 1 ? encoder.s : -encoder.s);
      if (encoder.count > 1) {
        writeVarUint(encoder.encoder, encoder.count - 2); // since count is always > 1, we can decrement by one. non-standard encoding ftw
      }
    }
  };

  /**
   * Optimized Rle encoder that does not suffer from the mentioned problem of the basic Rle encoder.
   *
   * Internally uses VarInt encoder to write unsigned integers. If the input occurs multiple times, we write
   * write it as a negative number. The UintOptRleDecoder then understands that it needs to read a count.
   *
   * Encodes [1,2,3,3,3] as [1,2,-3,3] (once 1, once 2, three times 3)
   */
  class UintOptRleEncoder {
    constructor () {
      this.encoder = new Encoder();
      /**
       * @type {number}
       */
      this.s = 0;
      this.count = 0;
    }

    /**
     * @param {number} v
     */
    write (v) {
      if (this.s === v) {
        this.count++;
      } else {
        flushUintOptRleEncoder(this);
        this.count = 1;
        this.s = v;
      }
    }

    /**
     * Flush the encoded state and transform this to a Uint8Array.
     *
     * Note that this should only be called once.
     */
    toUint8Array () {
      flushUintOptRleEncoder(this);
      return toUint8Array(this.encoder)
    }
  }

  /**
   * @param {IntDiffOptRleEncoder} encoder
   */
  const flushIntDiffOptRleEncoder = encoder => {
    if (encoder.count > 0) {
      //          31 bit making up the diff | wether to write the counter
      // const encodedDiff = encoder.diff << 1 | (encoder.count === 1 ? 0 : 1)
      const encodedDiff = encoder.diff * 2 + (encoder.count === 1 ? 0 : 1);
      // flush counter, unless this is the first value (count = 0)
      // case 1: just a single value. set first bit to positive
      // case 2: write several values. set first bit to negative to indicate that there is a length coming
      writeVarInt(encoder.encoder, encodedDiff);
      if (encoder.count > 1) {
        writeVarUint(encoder.encoder, encoder.count - 2); // since count is always > 1, we can decrement by one. non-standard encoding ftw
      }
    }
  };

  /**
   * A combination of the IntDiffEncoder and the UintOptRleEncoder.
   *
   * The count approach is similar to the UintDiffOptRleEncoder, but instead of using the negative bitflag, it encodes
   * in the LSB whether a count is to be read. Therefore this Encoder only supports 31 bit integers!
   *
   * Encodes [1, 2, 3, 2] as [3, 1, 6, -1] (more specifically [(1 << 1) | 1, (3 << 0) | 0, -1])
   *
   * Internally uses variable length encoding. Contrary to normal UintVar encoding, the first byte contains:
   * * 1 bit that denotes whether the next value is a count (LSB)
   * * 1 bit that denotes whether this value is negative (MSB - 1)
   * * 1 bit that denotes whether to continue reading the variable length integer (MSB)
   *
   * Therefore, only five bits remain to encode diff ranges.
   *
   * Use this Encoder only when appropriate. In most cases, this is probably a bad idea.
   */
  class IntDiffOptRleEncoder {
    constructor () {
      this.encoder = new Encoder();
      /**
       * @type {number}
       */
      this.s = 0;
      this.count = 0;
      this.diff = 0;
    }

    /**
     * @param {number} v
     */
    write (v) {
      if (this.diff === v - this.s) {
        this.s = v;
        this.count++;
      } else {
        flushIntDiffOptRleEncoder(this);
        this.count = 1;
        this.diff = v - this.s;
        this.s = v;
      }
    }

    /**
     * Flush the encoded state and transform this to a Uint8Array.
     *
     * Note that this should only be called once.
     */
    toUint8Array () {
      flushIntDiffOptRleEncoder(this);
      return toUint8Array(this.encoder)
    }
  }

  /**
   * Optimized String Encoder.
   *
   * Encoding many small strings in a simple Encoder is not very efficient. The function call to decode a string takes some time and creates references that must be eventually deleted.
   * In practice, when decoding several million small strings, the GC will kick in more and more often to collect orphaned string objects (or maybe there is another reason?).
   *
   * This string encoder solves the above problem. All strings are concatenated and written as a single string using a single encoding call.
   *
   * The lengths are encoded using a UintOptRleEncoder.
   */
  class StringEncoder {
    constructor () {
      /**
       * @type {Array<string>}
       */
      this.sarr = [];
      this.s = '';
      this.lensE = new UintOptRleEncoder();
    }

    /**
     * @param {string} string
     */
    write (string) {
      this.s += string;
      if (this.s.length > 19) {
        this.sarr.push(this.s);
        this.s = '';
      }
      this.lensE.write(string.length);
    }

    toUint8Array () {
      const encoder = new Encoder();
      this.sarr.push(this.s);
      this.s = '';
      writeVarString(encoder, this.sarr.join(''));
      writeUint8Array(encoder, this.lensE.toUint8Array());
      return toUint8Array(encoder)
    }
  }

  /**
   * Error helpers.
   *
   * @module error
   */

  /**
   * @param {string} s
   * @return {Error}
   */
  /* c8 ignore next */
  const create$4 = s => new Error(s);

  /**
   * @throws {Error}
   * @return {never}
   */
  /* c8 ignore next 3 */
  const methodUnimplemented = () => {
    throw create$4('Method unimplemented')
  };

  /**
   * @throws {Error}
   * @return {never}
   */
  /* c8 ignore next 3 */
  const unexpectedCase = () => {
    throw create$4('Unexpected case')
  };

  /**
   * Efficient schema-less binary decoding with support for variable length encoding.
   *
   * Use [lib0/decoding] with [lib0/encoding]. Every encoding function has a corresponding decoding function.
   *
   * Encodes numbers in little-endian order (least to most significant byte order)
   * and is compatible with Golang's binary encoding (https://golang.org/pkg/encoding/binary/)
   * which is also used in Protocol Buffers.
   *
   * ```js
   * // encoding step
   * const encoder = encoding.createEncoder()
   * encoding.writeVarUint(encoder, 256)
   * encoding.writeVarString(encoder, 'Hello world!')
   * const buf = encoding.toUint8Array(encoder)
   * ```
   *
   * ```js
   * // decoding step
   * const decoder = decoding.createDecoder(buf)
   * decoding.readVarUint(decoder) // => 256
   * decoding.readVarString(decoder) // => 'Hello world!'
   * decoding.hasContent(decoder) // => false - all data is read
   * ```
   *
   * @module decoding
   */

  const errorUnexpectedEndOfArray = create$4('Unexpected end of array');
  const errorIntegerOutOfRange = create$4('Integer out of Range');

  /**
   * A Decoder handles the decoding of an Uint8Array.
   */
  class Decoder {
    /**
     * @param {Uint8Array} uint8Array Binary data to decode
     */
    constructor (uint8Array) {
      /**
       * Decoding target.
       *
       * @type {Uint8Array}
       */
      this.arr = uint8Array;
      /**
       * Current decoding position.
       *
       * @type {number}
       */
      this.pos = 0;
    }
  }

  /**
   * @function
   * @param {Uint8Array} uint8Array
   * @return {Decoder}
   */
  const createDecoder = uint8Array => new Decoder(uint8Array);

  /**
   * @function
   * @param {Decoder} decoder
   * @return {boolean}
   */
  const hasContent = decoder => decoder.pos !== decoder.arr.length;

  /**
   * Create an Uint8Array view of the next `len` bytes and advance the position by `len`.
   *
   * Important: The Uint8Array still points to the underlying ArrayBuffer. Make sure to discard the result as soon as possible to prevent any memory leaks.
   *            Use `buffer.copyUint8Array` to copy the result into a new Uint8Array.
   *
   * @function
   * @param {Decoder} decoder The decoder instance
   * @param {number} len The length of bytes to read
   * @return {Uint8Array}
   */
  const readUint8Array = (decoder, len) => {
    const view = new Uint8Array(decoder.arr.buffer, decoder.pos + decoder.arr.byteOffset, len);
    decoder.pos += len;
    return view
  };

  /**
   * Read variable length Uint8Array.
   *
   * Important: The Uint8Array still points to the underlying ArrayBuffer. Make sure to discard the result as soon as possible to prevent any memory leaks.
   *            Use `buffer.copyUint8Array` to copy the result into a new Uint8Array.
   *
   * @function
   * @param {Decoder} decoder
   * @return {Uint8Array}
   */
  const readVarUint8Array = decoder => readUint8Array(decoder, readVarUint(decoder));

  /**
   * Read one byte as unsigned integer.
   * @function
   * @param {Decoder} decoder The decoder instance
   * @return {number} Unsigned 8-bit integer
   */
  const readUint8 = decoder => decoder.arr[decoder.pos++];

  /**
   * Read unsigned integer (32bit) with variable length.
   * 1/8th of the storage is used as encoding overhead.
   *  * numbers < 2^7 is stored in one bytlength
   *  * numbers < 2^14 is stored in two bylength
   *
   * @function
   * @param {Decoder} decoder
   * @return {number} An unsigned integer.length
   */
  const readVarUint = decoder => {
    let num = 0;
    let mult = 1;
    const len = decoder.arr.length;
    while (decoder.pos < len) {
      const r = decoder.arr[decoder.pos++];
      // num = num | ((r & binary.BITS7) << len)
      num = num + (r & BITS7) * mult; // shift $r << (7*#iterations) and add it to num
      mult *= 128; // next iteration, shift 7 "more" to the left
      if (r < BIT8) {
        return num
      }
      /* c8 ignore start */
      if (num > MAX_SAFE_INTEGER) {
        throw errorIntegerOutOfRange
      }
      /* c8 ignore stop */
    }
    throw errorUnexpectedEndOfArray
  };

  /**
   * Read signed integer (32bit) with variable length.
   * 1/8th of the storage is used as encoding overhead.
   *  * numbers < 2^7 is stored in one bytlength
   *  * numbers < 2^14 is stored in two bylength
   * @todo This should probably create the inverse ~num if number is negative - but this would be a breaking change.
   *
   * @function
   * @param {Decoder} decoder
   * @return {number} An unsigned integer.length
   */
  const readVarInt = decoder => {
    let r = decoder.arr[decoder.pos++];
    let num = r & BITS6;
    let mult = 64;
    const sign = (r & BIT7) > 0 ? -1 : 1;
    if ((r & BIT8) === 0) {
      // don't continue reading
      return sign * num
    }
    const len = decoder.arr.length;
    while (decoder.pos < len) {
      r = decoder.arr[decoder.pos++];
      // num = num | ((r & binary.BITS7) << len)
      num = num + (r & BITS7) * mult;
      mult *= 128;
      if (r < BIT8) {
        return sign * num
      }
      /* c8 ignore start */
      if (num > MAX_SAFE_INTEGER) {
        throw errorIntegerOutOfRange
      }
      /* c8 ignore stop */
    }
    throw errorUnexpectedEndOfArray
  };

  /**
   * We don't test this function anymore as we use native decoding/encoding by default now.
   * Better not modify this anymore..
   *
   * Transforming utf8 to a string is pretty expensive. The code performs 10x better
   * when String.fromCodePoint is fed with all characters as arguments.
   * But most environments have a maximum number of arguments per functions.
   * For effiency reasons we apply a maximum of 10000 characters at once.
   *
   * @function
   * @param {Decoder} decoder
   * @return {String} The read String.
   */
  /* c8 ignore start */
  const _readVarStringPolyfill = decoder => {
    let remainingLen = readVarUint(decoder);
    if (remainingLen === 0) {
      return ''
    } else {
      let encodedString = String.fromCodePoint(readUint8(decoder)); // remember to decrease remainingLen
      if (--remainingLen < 100) { // do not create a Uint8Array for small strings
        while (remainingLen--) {
          encodedString += String.fromCodePoint(readUint8(decoder));
        }
      } else {
        while (remainingLen > 0) {
          const nextLen = remainingLen < 10000 ? remainingLen : 10000;
          // this is dangerous, we create a fresh array view from the existing buffer
          const bytes = decoder.arr.subarray(decoder.pos, decoder.pos + nextLen);
          decoder.pos += nextLen;
          // Starting with ES5.1 we can supply a generic array-like object as arguments
          encodedString += String.fromCodePoint.apply(null, /** @type {any} */ (bytes));
          remainingLen -= nextLen;
        }
      }
      return decodeURIComponent(escape(encodedString))
    }
  };
  /* c8 ignore stop */

  /**
   * @function
   * @param {Decoder} decoder
   * @return {String} The read String
   */
  const _readVarStringNative = decoder =>
    /** @type any */ (utf8TextDecoder).decode(readVarUint8Array(decoder));

  /**
   * Read string of variable length
   * * varUint is used to store the length of the string
   *
   * @function
   * @param {Decoder} decoder
   * @return {String} The read String
   *
   */
  /* c8 ignore next */
  const readVarString = utf8TextDecoder ? _readVarStringNative : _readVarStringPolyfill;

  /**
   * @param {Decoder} decoder
   * @param {number} len
   * @return {DataView}
   */
  const readFromDataView = (decoder, len) => {
    const dv = new DataView(decoder.arr.buffer, decoder.arr.byteOffset + decoder.pos, len);
    decoder.pos += len;
    return dv
  };

  /**
   * @param {Decoder} decoder
   */
  const readFloat32 = decoder => readFromDataView(decoder, 4).getFloat32(0, false);

  /**
   * @param {Decoder} decoder
   */
  const readFloat64 = decoder => readFromDataView(decoder, 8).getFloat64(0, false);

  /**
   * @param {Decoder} decoder
   */
  const readBigInt64 = decoder => /** @type {any} */ (readFromDataView(decoder, 8)).getBigInt64(0, false);

  /**
   * @type {Array<function(Decoder):any>}
   */
  const readAnyLookupTable = [
    decoder => undefined, // CASE 127: undefined
    decoder => null, // CASE 126: null
    readVarInt, // CASE 125: integer
    readFloat32, // CASE 124: float32
    readFloat64, // CASE 123: float64
    readBigInt64, // CASE 122: bigint
    decoder => false, // CASE 121: boolean (false)
    decoder => true, // CASE 120: boolean (true)
    readVarString, // CASE 119: string
    decoder => { // CASE 118: object<string,any>
      const len = readVarUint(decoder);
      /**
       * @type {Object<string,any>}
       */
      const obj = {};
      for (let i = 0; i < len; i++) {
        const key = readVarString(decoder);
        obj[key] = readAny(decoder);
      }
      return obj
    },
    decoder => { // CASE 117: array<any>
      const len = readVarUint(decoder);
      const arr = [];
      for (let i = 0; i < len; i++) {
        arr.push(readAny(decoder));
      }
      return arr
    },
    readVarUint8Array // CASE 116: Uint8Array
  ];

  /**
   * @param {Decoder} decoder
   */
  const readAny = decoder => readAnyLookupTable[127 - readUint8(decoder)](decoder);

  /**
   * T must not be null.
   *
   * @template T
   */
  class RleDecoder extends Decoder {
    /**
     * @param {Uint8Array} uint8Array
     * @param {function(Decoder):T} reader
     */
    constructor (uint8Array, reader) {
      super(uint8Array);
      /**
       * The reader
       */
      this.reader = reader;
      /**
       * Current state
       * @type {T|null}
       */
      this.s = null;
      this.count = 0;
    }

    read () {
      if (this.count === 0) {
        this.s = this.reader(this);
        if (hasContent(this)) {
          this.count = readVarUint(this) + 1; // see encoder implementation for the reason why this is incremented
        } else {
          this.count = -1; // read the current value forever
        }
      }
      this.count--;
      return /** @type {T} */ (this.s)
    }
  }

  class UintOptRleDecoder extends Decoder {
    /**
     * @param {Uint8Array} uint8Array
     */
    constructor (uint8Array) {
      super(uint8Array);
      /**
       * @type {number}
       */
      this.s = 0;
      this.count = 0;
    }

    read () {
      if (this.count === 0) {
        this.s = readVarInt(this);
        // if the sign is negative, we read the count too, otherwise count is 1
        const isNegative = isNegativeZero(this.s);
        this.count = 1;
        if (isNegative) {
          this.s = -this.s;
          this.count = readVarUint(this) + 2;
        }
      }
      this.count--;
      return /** @type {number} */ (this.s)
    }
  }

  class IntDiffOptRleDecoder extends Decoder {
    /**
     * @param {Uint8Array} uint8Array
     */
    constructor (uint8Array) {
      super(uint8Array);
      /**
       * @type {number}
       */
      this.s = 0;
      this.count = 0;
      this.diff = 0;
    }

    /**
     * @return {number}
     */
    read () {
      if (this.count === 0) {
        const diff = readVarInt(this);
        // if the first bit is set, we read more data
        const hasCount = diff & 1;
        this.diff = floor(diff / 2); // shift >> 1
        this.count = 1;
        if (hasCount) {
          this.count = readVarUint(this) + 2;
        }
      }
      this.s += this.diff;
      this.count--;
      return this.s
    }
  }

  class StringDecoder$2 {
    /**
     * @param {Uint8Array} uint8Array
     */
    constructor (uint8Array) {
      this.decoder = new UintOptRleDecoder(uint8Array);
      this.str = readVarString(this.decoder);
      /**
       * @type {number}
       */
      this.spos = 0;
    }

    /**
     * @return {string}
     */
    read () {
      const end = this.spos + this.decoder.read();
      const res = this.str.slice(this.spos, end);
      this.spos = end;
      return res
    }
  }

  /* eslint-env browser */
  const getRandomValues = crypto.getRandomValues.bind(crypto);

  /**
   * Isomorphic module for true random numbers / buffers / uuids.
   *
   * Attention: falls back to Math.random if the browser does not support crypto.
   *
   * @module random
   */

  const uint32 = () => getRandomValues(new Uint32Array(1))[0];

  // @ts-ignore
  const uuidv4Template = [1e7] + -1e3 + -4e3 + -8e3 + -1e11;

  /**
   * @return {string}
   */
  const uuidv4 = () => uuidv4Template.replace(/[018]/g, /** @param {number} c */ c =>
    (c ^ uint32() & 15 >> c / 4).toString(16)
  );

  /**
   * Utility module to convert metric values.
   *
   * @module metric
   */

  const prefixUp = ['', 'k', 'M', 'G', 'T', 'P', 'E', 'Z', 'Y'];
  const prefixDown = ['', 'm', 'μ', 'n', 'p', 'f', 'a', 'z', 'y'];

  /**
   * Calculate the metric prefix for a number. Assumes E.g. `prefix(1000) = { n: 1, prefix: 'k' }`
   *
   * @param {number} n
   * @param {number} [baseMultiplier] Multiplier of the base (10^(3*baseMultiplier)). E.g. `convert(time, -3)` if time is already in milli seconds
   * @return {{n:number,prefix:string}}
   */
  const prefix = (n, baseMultiplier = 0) => {
    const nPow = n === 0 ? 0 : log10(n);
    let mult = 0;
    while (nPow < mult * 3 && baseMultiplier > -8) {
      baseMultiplier--;
      mult--;
    }
    while (nPow >= 3 + mult * 3 && baseMultiplier < 8) {
      baseMultiplier++;
      mult++;
    }
    const prefix = baseMultiplier < 0 ? prefixDown[-baseMultiplier] : prefixUp[baseMultiplier];
    return {
      n: round((mult > 0 ? n / exp10(mult * 3) : n * exp10(mult * -3)) * 1e12) / 1e12,
      prefix
    }
  };

  /**
   * Utility module to work with time.
   *
   * @module time
   */

  /**
   * Return current unix time.
   *
   * @return {number}
   */
  const getUnixTime = Date.now;

  /**
   * Transform time (in ms) to a human readable format. E.g. 1100 => 1.1s. 60s => 1min. .001 => 10μs.
   *
   * @param {number} d duration in milliseconds
   * @return {string} humanized approximation of time
   */
  const humanizeDuration = d => {
    if (d < 60000) {
      const p = prefix(d, -1);
      return round(p.n * 100) / 100 + p.prefix + 's'
    }
    d = floor(d / 1000);
    const seconds = d % 60;
    const minutes = floor(d / 60) % 60;
    const hours = floor(d / 3600) % 24;
    const days = floor(d / 86400);
    if (days > 0) {
      return days + 'd' + ((hours > 0 || minutes > 30) ? ' ' + (minutes > 30 ? hours + 1 : hours) + 'h' : '')
    }
    if (hours > 0) {
      /* c8 ignore next */
      return hours + 'h' + ((minutes > 0 || seconds > 30) ? ' ' + (seconds > 30 ? minutes + 1 : minutes) + 'min' : '')
    }
    return minutes + 'min' + (seconds > 0 ? ' ' + seconds + 's' : '')
  };

  /**
   * Utility helpers to work with promises.
   *
   * @module promise
   */

  /**
   * @template T
   * @callback PromiseResolve
   * @param {T|PromiseLike<T>} [result]
   */

  /**
   * @template T
   * @param {function(PromiseResolve<T>,function(Error):void):any} f
   * @return {Promise<T>}
   */
  const create$3 = f => /** @type {Promise<T>} */ (new Promise(f));

  /**
   * `Promise.all` wait for all promises in the array to resolve and return the result
   * @template {unknown[] | []} PS
   *
   * @param {PS} ps
   * @return {Promise<{ -readonly [P in keyof PS]: Awaited<PS[P]> }>}
   */
  Promise.all.bind(Promise);

  /**
   * @template T
   * @param {T|void} res
   * @return {Promise<T|void>}
   */
  const resolve = res => Promise.resolve(res);

  /**
   * Checks if an object is a promise using ducktyping.
   *
   * Promises are often polyfilled, so it makes sense to add some additional guarantees if the user of this
   * library has some insane environment where global Promise objects are overwritten.
   *
   * @param {any} p
   * @return {boolean}
   */
  const isPromise = p => p instanceof Promise || (p && p.then && p.catch && p.finally);

  var commonjsGlobal = typeof globalThis !== 'undefined' ? globalThis : typeof window !== 'undefined' ? window : typeof global !== 'undefined' ? global : typeof self !== 'undefined' ? self : {};

  function createCommonjsModule(fn, basedir, module) {
  	return module = {
  	  path: basedir,
  	  exports: {},
  	  require: function (path, base) {
        return commonjsRequire(path, (base === undefined || base === null) ? module.path : base);
      }
  	}, fn(module, module.exports), module.exports;
  }

  function commonjsRequire () {
  	throw new Error('Dynamic requires are not currently supported by @rollup/plugin-commonjs');
  }

  var byteLength_1 = byteLength;
  var toByteArray_1 = toByteArray;
  var fromByteArray_1 = fromByteArray;

  var lookup$1 = [];
  var revLookup = [];
  var Arr = typeof Uint8Array !== 'undefined' ? Uint8Array : Array;

  var code = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/';
  for (var i = 0, len = code.length; i < len; ++i) {
    lookup$1[i] = code[i];
    revLookup[code.charCodeAt(i)] = i;
  }

  // Support decoding URL-safe base64 strings, as Node.js does.
  // See: https://en.wikipedia.org/wiki/Base64#URL_applications
  revLookup['-'.charCodeAt(0)] = 62;
  revLookup['_'.charCodeAt(0)] = 63;

  function getLens (b64) {
    var len = b64.length;

    if (len % 4 > 0) {
      throw new Error('Invalid string. Length must be a multiple of 4')
    }

    // Trim off extra bytes after placeholder bytes are found
    // See: https://github.com/beatgammit/base64-js/issues/42
    var validLen = b64.indexOf('=');
    if (validLen === -1) validLen = len;

    var placeHoldersLen = validLen === len
      ? 0
      : 4 - (validLen % 4);

    return [validLen, placeHoldersLen]
  }

  // base64 is 4/3 + up to two characters of the original data
  function byteLength (b64) {
    var lens = getLens(b64);
    var validLen = lens[0];
    var placeHoldersLen = lens[1];
    return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen
  }

  function _byteLength (b64, validLen, placeHoldersLen) {
    return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen
  }

  function toByteArray (b64) {
    var tmp;
    var lens = getLens(b64);
    var validLen = lens[0];
    var placeHoldersLen = lens[1];

    var arr = new Arr(_byteLength(b64, validLen, placeHoldersLen));

    var curByte = 0;

    // if there are placeholders, only get up to the last complete 4 chars
    var len = placeHoldersLen > 0
      ? validLen - 4
      : validLen;

    var i;
    for (i = 0; i < len; i += 4) {
      tmp =
        (revLookup[b64.charCodeAt(i)] << 18) |
        (revLookup[b64.charCodeAt(i + 1)] << 12) |
        (revLookup[b64.charCodeAt(i + 2)] << 6) |
        revLookup[b64.charCodeAt(i + 3)];
      arr[curByte++] = (tmp >> 16) & 0xFF;
      arr[curByte++] = (tmp >> 8) & 0xFF;
      arr[curByte++] = tmp & 0xFF;
    }

    if (placeHoldersLen === 2) {
      tmp =
        (revLookup[b64.charCodeAt(i)] << 2) |
        (revLookup[b64.charCodeAt(i + 1)] >> 4);
      arr[curByte++] = tmp & 0xFF;
    }

    if (placeHoldersLen === 1) {
      tmp =
        (revLookup[b64.charCodeAt(i)] << 10) |
        (revLookup[b64.charCodeAt(i + 1)] << 4) |
        (revLookup[b64.charCodeAt(i + 2)] >> 2);
      arr[curByte++] = (tmp >> 8) & 0xFF;
      arr[curByte++] = tmp & 0xFF;
    }

    return arr
  }

  function tripletToBase64 (num) {
    return lookup$1[num >> 18 & 0x3F] +
      lookup$1[num >> 12 & 0x3F] +
      lookup$1[num >> 6 & 0x3F] +
      lookup$1[num & 0x3F]
  }

  function encodeChunk (uint8, start, end) {
    var tmp;
    var output = [];
    for (var i = start; i < end; i += 3) {
      tmp =
        ((uint8[i] << 16) & 0xFF0000) +
        ((uint8[i + 1] << 8) & 0xFF00) +
        (uint8[i + 2] & 0xFF);
      output.push(tripletToBase64(tmp));
    }
    return output.join('')
  }

  function fromByteArray (uint8) {
    var tmp;
    var len = uint8.length;
    var extraBytes = len % 3; // if we have 1 byte left, pad 2 bytes
    var parts = [];
    var maxChunkLength = 16383; // must be multiple of 3

    // go through the array every three bytes, we'll deal with trailing stuff later
    for (var i = 0, len2 = len - extraBytes; i < len2; i += maxChunkLength) {
      parts.push(encodeChunk(uint8, i, (i + maxChunkLength) > len2 ? len2 : (i + maxChunkLength)));
    }

    // pad the end with zeros, but make sure to not forget the extra bytes
    if (extraBytes === 1) {
      tmp = uint8[len - 1];
      parts.push(
        lookup$1[tmp >> 2] +
        lookup$1[(tmp << 4) & 0x3F] +
        '=='
      );
    } else if (extraBytes === 2) {
      tmp = (uint8[len - 2] << 8) + uint8[len - 1];
      parts.push(
        lookup$1[tmp >> 10] +
        lookup$1[(tmp >> 4) & 0x3F] +
        lookup$1[(tmp << 2) & 0x3F] +
        '='
      );
    }

    return parts.join('')
  }

  var base64Js = {
  	byteLength: byteLength_1,
  	toByteArray: toByteArray_1,
  	fromByteArray: fromByteArray_1
  };

  /*! ieee754. BSD-3-Clause License. Feross Aboukhadijeh <https://feross.org/opensource> */
  var read = function (buffer, offset, isLE, mLen, nBytes) {
    var e, m;
    var eLen = (nBytes * 8) - mLen - 1;
    var eMax = (1 << eLen) - 1;
    var eBias = eMax >> 1;
    var nBits = -7;
    var i = isLE ? (nBytes - 1) : 0;
    var d = isLE ? -1 : 1;
    var s = buffer[offset + i];

    i += d;

    e = s & ((1 << (-nBits)) - 1);
    s >>= (-nBits);
    nBits += eLen;
    for (; nBits > 0; e = (e * 256) + buffer[offset + i], i += d, nBits -= 8) {}

    m = e & ((1 << (-nBits)) - 1);
    e >>= (-nBits);
    nBits += mLen;
    for (; nBits > 0; m = (m * 256) + buffer[offset + i], i += d, nBits -= 8) {}

    if (e === 0) {
      e = 1 - eBias;
    } else if (e === eMax) {
      return m ? NaN : ((s ? -1 : 1) * Infinity)
    } else {
      m = m + Math.pow(2, mLen);
      e = e - eBias;
    }
    return (s ? -1 : 1) * m * Math.pow(2, e - mLen)
  };

  var write = function (buffer, value, offset, isLE, mLen, nBytes) {
    var e, m, c;
    var eLen = (nBytes * 8) - mLen - 1;
    var eMax = (1 << eLen) - 1;
    var eBias = eMax >> 1;
    var rt = (mLen === 23 ? Math.pow(2, -24) - Math.pow(2, -77) : 0);
    var i = isLE ? 0 : (nBytes - 1);
    var d = isLE ? 1 : -1;
    var s = value < 0 || (value === 0 && 1 / value < 0) ? 1 : 0;

    value = Math.abs(value);

    if (isNaN(value) || value === Infinity) {
      m = isNaN(value) ? 1 : 0;
      e = eMax;
    } else {
      e = Math.floor(Math.log(value) / Math.LN2);
      if (value * (c = Math.pow(2, -e)) < 1) {
        e--;
        c *= 2;
      }
      if (e + eBias >= 1) {
        value += rt / c;
      } else {
        value += rt * Math.pow(2, 1 - eBias);
      }
      if (value * c >= 2) {
        e++;
        c /= 2;
      }

      if (e + eBias >= eMax) {
        m = 0;
        e = eMax;
      } else if (e + eBias >= 1) {
        m = ((value * c) - 1) * Math.pow(2, mLen);
        e = e + eBias;
      } else {
        m = value * Math.pow(2, eBias - 1) * Math.pow(2, mLen);
        e = 0;
      }
    }

    for (; mLen >= 8; buffer[offset + i] = m & 0xff, i += d, m /= 256, mLen -= 8) {}

    e = (e << mLen) | m;
    eLen += mLen;
    for (; eLen > 0; buffer[offset + i] = e & 0xff, i += d, e /= 256, eLen -= 8) {}

    buffer[offset + i - d] |= s * 128;
  };

  var ieee754 = {
  	read: read,
  	write: write
  };

  var buffer$1 = createCommonjsModule(function (module, exports) {



  const customInspectSymbol =
    (typeof Symbol === 'function' && typeof Symbol['for'] === 'function') // eslint-disable-line dot-notation
      ? Symbol['for']('nodejs.util.inspect.custom') // eslint-disable-line dot-notation
      : null;

  exports.Buffer = Buffer;
  exports.SlowBuffer = SlowBuffer;
  exports.INSPECT_MAX_BYTES = 50;

  const K_MAX_LENGTH = 0x7fffffff;
  exports.kMaxLength = K_MAX_LENGTH;

  /**
   * If `Buffer.TYPED_ARRAY_SUPPORT`:
   *   === true    Use Uint8Array implementation (fastest)
   *   === false   Print warning and recommend using `buffer` v4.x which has an Object
   *               implementation (most compatible, even IE6)
   *
   * Browsers that support typed arrays are IE 10+, Firefox 4+, Chrome 7+, Safari 5.1+,
   * Opera 11.6+, iOS 4.2+.
   *
   * We report that the browser does not support typed arrays if the are not subclassable
   * using __proto__. Firefox 4-29 lacks support for adding new properties to `Uint8Array`
   * (See: https://bugzilla.mozilla.org/show_bug.cgi?id=695438). IE 10 lacks support
   * for __proto__ and has a buggy typed array implementation.
   */
  Buffer.TYPED_ARRAY_SUPPORT = typedArraySupport();

  if (!Buffer.TYPED_ARRAY_SUPPORT && typeof console !== 'undefined' &&
      typeof console.error === 'function') {
    console.error(
      'This browser lacks typed array (Uint8Array) support which is required by ' +
      '`buffer` v5.x. Use `buffer` v4.x if you require old browser support.'
    );
  }

  function typedArraySupport () {
    // Can typed array instances can be augmented?
    try {
      const arr = new Uint8Array(1);
      const proto = { foo: function () { return 42 } };
      Object.setPrototypeOf(proto, Uint8Array.prototype);
      Object.setPrototypeOf(arr, proto);
      return arr.foo() === 42
    } catch (e) {
      return false
    }
  }

  Object.defineProperty(Buffer.prototype, 'parent', {
    enumerable: true,
    get: function () {
      if (!Buffer.isBuffer(this)) return undefined
      return this.buffer
    }
  });

  Object.defineProperty(Buffer.prototype, 'offset', {
    enumerable: true,
    get: function () {
      if (!Buffer.isBuffer(this)) return undefined
      return this.byteOffset
    }
  });

  function createBuffer (length) {
    if (length > K_MAX_LENGTH) {
      throw new RangeError('The value "' + length + '" is invalid for option "size"')
    }
    // Return an augmented `Uint8Array` instance
    const buf = new Uint8Array(length);
    Object.setPrototypeOf(buf, Buffer.prototype);
    return buf
  }

  /**
   * The Buffer constructor returns instances of `Uint8Array` that have their
   * prototype changed to `Buffer.prototype`. Furthermore, `Buffer` is a subclass of
   * `Uint8Array`, so the returned instances will have all the node `Buffer` methods
   * and the `Uint8Array` methods. Square bracket notation works as expected -- it
   * returns a single octet.
   *
   * The `Uint8Array` prototype remains unmodified.
   */

  function Buffer (arg, encodingOrOffset, length) {
    // Common case.
    if (typeof arg === 'number') {
      if (typeof encodingOrOffset === 'string') {
        throw new TypeError(
          'The "string" argument must be of type string. Received type number'
        )
      }
      return allocUnsafe(arg)
    }
    return from(arg, encodingOrOffset, length)
  }

  Buffer.poolSize = 8192; // not used by this implementation

  function from (value, encodingOrOffset, length) {
    if (typeof value === 'string') {
      return fromString(value, encodingOrOffset)
    }

    if (ArrayBuffer.isView(value)) {
      return fromArrayView(value)
    }

    if (value == null) {
      throw new TypeError(
        'The first argument must be one of type string, Buffer, ArrayBuffer, Array, ' +
        'or Array-like Object. Received type ' + (typeof value)
      )
    }

    if (isInstance(value, ArrayBuffer) ||
        (value && isInstance(value.buffer, ArrayBuffer))) {
      return fromArrayBuffer(value, encodingOrOffset, length)
    }

    if (typeof SharedArrayBuffer !== 'undefined' &&
        (isInstance(value, SharedArrayBuffer) ||
        (value && isInstance(value.buffer, SharedArrayBuffer)))) {
      return fromArrayBuffer(value, encodingOrOffset, length)
    }

    if (typeof value === 'number') {
      throw new TypeError(
        'The "value" argument must not be of type number. Received type number'
      )
    }

    const valueOf = value.valueOf && value.valueOf();
    if (valueOf != null && valueOf !== value) {
      return Buffer.from(valueOf, encodingOrOffset, length)
    }

    const b = fromObject(value);
    if (b) return b

    if (typeof Symbol !== 'undefined' && Symbol.toPrimitive != null &&
        typeof value[Symbol.toPrimitive] === 'function') {
      return Buffer.from(value[Symbol.toPrimitive]('string'), encodingOrOffset, length)
    }

    throw new TypeError(
      'The first argument must be one of type string, Buffer, ArrayBuffer, Array, ' +
      'or Array-like Object. Received type ' + (typeof value)
    )
  }

  /**
   * Functionally equivalent to Buffer(arg, encoding) but throws a TypeError
   * if value is a number.
   * Buffer.from(str[, encoding])
   * Buffer.from(array)
   * Buffer.from(buffer)
   * Buffer.from(arrayBuffer[, byteOffset[, length]])
   **/
  Buffer.from = function (value, encodingOrOffset, length) {
    return from(value, encodingOrOffset, length)
  };

  // Note: Change prototype *after* Buffer.from is defined to workaround Chrome bug:
  // https://github.com/feross/buffer/pull/148
  Object.setPrototypeOf(Buffer.prototype, Uint8Array.prototype);
  Object.setPrototypeOf(Buffer, Uint8Array);

  function assertSize (size) {
    if (typeof size !== 'number') {
      throw new TypeError('"size" argument must be of type number')
    } else if (size < 0) {
      throw new RangeError('The value "' + size + '" is invalid for option "size"')
    }
  }

  function alloc (size, fill, encoding) {
    assertSize(size);
    if (size <= 0) {
      return createBuffer(size)
    }
    if (fill !== undefined) {
      // Only pay attention to encoding if it's a string. This
      // prevents accidentally sending in a number that would
      // be interpreted as a start offset.
      return typeof encoding === 'string'
        ? createBuffer(size).fill(fill, encoding)
        : createBuffer(size).fill(fill)
    }
    return createBuffer(size)
  }

  /**
   * Creates a new filled Buffer instance.
   * alloc(size[, fill[, encoding]])
   **/
  Buffer.alloc = function (size, fill, encoding) {
    return alloc(size, fill, encoding)
  };

  function allocUnsafe (size) {
    assertSize(size);
    return createBuffer(size < 0 ? 0 : checked(size) | 0)
  }

  /**
   * Equivalent to Buffer(num), by default creates a non-zero-filled Buffer instance.
   * */
  Buffer.allocUnsafe = function (size) {
    return allocUnsafe(size)
  };
  /**
   * Equivalent to SlowBuffer(num), by default creates a non-zero-filled Buffer instance.
   */
  Buffer.allocUnsafeSlow = function (size) {
    return allocUnsafe(size)
  };

  function fromString (string, encoding) {
    if (typeof encoding !== 'string' || encoding === '') {
      encoding = 'utf8';
    }

    if (!Buffer.isEncoding(encoding)) {
      throw new TypeError('Unknown encoding: ' + encoding)
    }

    const length = byteLength(string, encoding) | 0;
    let buf = createBuffer(length);

    const actual = buf.write(string, encoding);

    if (actual !== length) {
      // Writing a hex string, for example, that contains invalid characters will
      // cause everything after the first invalid character to be ignored. (e.g.
      // 'abxxcd' will be treated as 'ab')
      buf = buf.slice(0, actual);
    }

    return buf
  }

  function fromArrayLike (array) {
    const length = array.length < 0 ? 0 : checked(array.length) | 0;
    const buf = createBuffer(length);
    for (let i = 0; i < length; i += 1) {
      buf[i] = array[i] & 255;
    }
    return buf
  }

  function fromArrayView (arrayView) {
    if (isInstance(arrayView, Uint8Array)) {
      const copy = new Uint8Array(arrayView);
      return fromArrayBuffer(copy.buffer, copy.byteOffset, copy.byteLength)
    }
    return fromArrayLike(arrayView)
  }

  function fromArrayBuffer (array, byteOffset, length) {
    if (byteOffset < 0 || array.byteLength < byteOffset) {
      throw new RangeError('"offset" is outside of buffer bounds')
    }

    if (array.byteLength < byteOffset + (length || 0)) {
      throw new RangeError('"length" is outside of buffer bounds')
    }

    let buf;
    if (byteOffset === undefined && length === undefined) {
      buf = new Uint8Array(array);
    } else if (length === undefined) {
      buf = new Uint8Array(array, byteOffset);
    } else {
      buf = new Uint8Array(array, byteOffset, length);
    }

    // Return an augmented `Uint8Array` instance
    Object.setPrototypeOf(buf, Buffer.prototype);

    return buf
  }

  function fromObject (obj) {
    if (Buffer.isBuffer(obj)) {
      const len = checked(obj.length) | 0;
      const buf = createBuffer(len);

      if (buf.length === 0) {
        return buf
      }

      obj.copy(buf, 0, 0, len);
      return buf
    }

    if (obj.length !== undefined) {
      if (typeof obj.length !== 'number' || numberIsNaN(obj.length)) {
        return createBuffer(0)
      }
      return fromArrayLike(obj)
    }

    if (obj.type === 'Buffer' && Array.isArray(obj.data)) {
      return fromArrayLike(obj.data)
    }
  }

  function checked (length) {
    // Note: cannot use `length < K_MAX_LENGTH` here because that fails when
    // length is NaN (which is otherwise coerced to zero.)
    if (length >= K_MAX_LENGTH) {
      throw new RangeError('Attempt to allocate Buffer larger than maximum ' +
                           'size: 0x' + K_MAX_LENGTH.toString(16) + ' bytes')
    }
    return length | 0
  }

  function SlowBuffer (length) {
    if (+length != length) { // eslint-disable-line eqeqeq
      length = 0;
    }
    return Buffer.alloc(+length)
  }

  Buffer.isBuffer = function isBuffer (b) {
    return b != null && b._isBuffer === true &&
      b !== Buffer.prototype // so Buffer.isBuffer(Buffer.prototype) will be false
  };

  Buffer.compare = function compare (a, b) {
    if (isInstance(a, Uint8Array)) a = Buffer.from(a, a.offset, a.byteLength);
    if (isInstance(b, Uint8Array)) b = Buffer.from(b, b.offset, b.byteLength);
    if (!Buffer.isBuffer(a) || !Buffer.isBuffer(b)) {
      throw new TypeError(
        'The "buf1", "buf2" arguments must be one of type Buffer or Uint8Array'
      )
    }

    if (a === b) return 0

    let x = a.length;
    let y = b.length;

    for (let i = 0, len = Math.min(x, y); i < len; ++i) {
      if (a[i] !== b[i]) {
        x = a[i];
        y = b[i];
        break
      }
    }

    if (x < y) return -1
    if (y < x) return 1
    return 0
  };

  Buffer.isEncoding = function isEncoding (encoding) {
    switch (String(encoding).toLowerCase()) {
      case 'hex':
      case 'utf8':
      case 'utf-8':
      case 'ascii':
      case 'latin1':
      case 'binary':
      case 'base64':
      case 'ucs2':
      case 'ucs-2':
      case 'utf16le':
      case 'utf-16le':
        return true
      default:
        return false
    }
  };

  Buffer.concat = function concat (list, length) {
    if (!Array.isArray(list)) {
      throw new TypeError('"list" argument must be an Array of Buffers')
    }

    if (list.length === 0) {
      return Buffer.alloc(0)
    }

    let i;
    if (length === undefined) {
      length = 0;
      for (i = 0; i < list.length; ++i) {
        length += list[i].length;
      }
    }

    const buffer = Buffer.allocUnsafe(length);
    let pos = 0;
    for (i = 0; i < list.length; ++i) {
      let buf = list[i];
      if (isInstance(buf, Uint8Array)) {
        if (pos + buf.length > buffer.length) {
          if (!Buffer.isBuffer(buf)) buf = Buffer.from(buf);
          buf.copy(buffer, pos);
        } else {
          Uint8Array.prototype.set.call(
            buffer,
            buf,
            pos
          );
        }
      } else if (!Buffer.isBuffer(buf)) {
        throw new TypeError('"list" argument must be an Array of Buffers')
      } else {
        buf.copy(buffer, pos);
      }
      pos += buf.length;
    }
    return buffer
  };

  function byteLength (string, encoding) {
    if (Buffer.isBuffer(string)) {
      return string.length
    }
    if (ArrayBuffer.isView(string) || isInstance(string, ArrayBuffer)) {
      return string.byteLength
    }
    if (typeof string !== 'string') {
      throw new TypeError(
        'The "string" argument must be one of type string, Buffer, or ArrayBuffer. ' +
        'Received type ' + typeof string
      )
    }

    const len = string.length;
    const mustMatch = (arguments.length > 2 && arguments[2] === true);
    if (!mustMatch && len === 0) return 0

    // Use a for loop to avoid recursion
    let loweredCase = false;
    for (;;) {
      switch (encoding) {
        case 'ascii':
        case 'latin1':
        case 'binary':
          return len
        case 'utf8':
        case 'utf-8':
          return utf8ToBytes(string).length
        case 'ucs2':
        case 'ucs-2':
        case 'utf16le':
        case 'utf-16le':
          return len * 2
        case 'hex':
          return len >>> 1
        case 'base64':
          return base64ToBytes(string).length
        default:
          if (loweredCase) {
            return mustMatch ? -1 : utf8ToBytes(string).length // assume utf8
          }
          encoding = ('' + encoding).toLowerCase();
          loweredCase = true;
      }
    }
  }
  Buffer.byteLength = byteLength;

  function slowToString (encoding, start, end) {
    let loweredCase = false;

    // No need to verify that "this.length <= MAX_UINT32" since it's a read-only
    // property of a typed array.

    // This behaves neither like String nor Uint8Array in that we set start/end
    // to their upper/lower bounds if the value passed is out of range.
    // undefined is handled specially as per ECMA-262 6th Edition,
    // Section 13.3.3.7 Runtime Semantics: KeyedBindingInitialization.
    if (start === undefined || start < 0) {
      start = 0;
    }
    // Return early if start > this.length. Done here to prevent potential uint32
    // coercion fail below.
    if (start > this.length) {
      return ''
    }

    if (end === undefined || end > this.length) {
      end = this.length;
    }

    if (end <= 0) {
      return ''
    }

    // Force coercion to uint32. This will also coerce falsey/NaN values to 0.
    end >>>= 0;
    start >>>= 0;

    if (end <= start) {
      return ''
    }

    if (!encoding) encoding = 'utf8';

    while (true) {
      switch (encoding) {
        case 'hex':
          return hexSlice(this, start, end)

        case 'utf8':
        case 'utf-8':
          return utf8Slice(this, start, end)

        case 'ascii':
          return asciiSlice(this, start, end)

        case 'latin1':
        case 'binary':
          return latin1Slice(this, start, end)

        case 'base64':
          return base64Slice(this, start, end)

        case 'ucs2':
        case 'ucs-2':
        case 'utf16le':
        case 'utf-16le':
          return utf16leSlice(this, start, end)

        default:
          if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)
          encoding = (encoding + '').toLowerCase();
          loweredCase = true;
      }
    }
  }

  // This property is used by `Buffer.isBuffer` (and the `is-buffer` npm package)
  // to detect a Buffer instance. It's not possible to use `instanceof Buffer`
  // reliably in a browserify context because there could be multiple different
  // copies of the 'buffer' package in use. This method works even for Buffer
  // instances that were created from another copy of the `buffer` package.
  // See: https://github.com/feross/buffer/issues/154
  Buffer.prototype._isBuffer = true;

  function swap (b, n, m) {
    const i = b[n];
    b[n] = b[m];
    b[m] = i;
  }

  Buffer.prototype.swap16 = function swap16 () {
    const len = this.length;
    if (len % 2 !== 0) {
      throw new RangeError('Buffer size must be a multiple of 16-bits')
    }
    for (let i = 0; i < len; i += 2) {
      swap(this, i, i + 1);
    }
    return this
  };

  Buffer.prototype.swap32 = function swap32 () {
    const len = this.length;
    if (len % 4 !== 0) {
      throw new RangeError('Buffer size must be a multiple of 32-bits')
    }
    for (let i = 0; i < len; i += 4) {
      swap(this, i, i + 3);
      swap(this, i + 1, i + 2);
    }
    return this
  };

  Buffer.prototype.swap64 = function swap64 () {
    const len = this.length;
    if (len % 8 !== 0) {
      throw new RangeError('Buffer size must be a multiple of 64-bits')
    }
    for (let i = 0; i < len; i += 8) {
      swap(this, i, i + 7);
      swap(this, i + 1, i + 6);
      swap(this, i + 2, i + 5);
      swap(this, i + 3, i + 4);
    }
    return this
  };

  Buffer.prototype.toString = function toString () {
    const length = this.length;
    if (length === 0) return ''
    if (arguments.length === 0) return utf8Slice(this, 0, length)
    return slowToString.apply(this, arguments)
  };

  Buffer.prototype.toLocaleString = Buffer.prototype.toString;

  Buffer.prototype.equals = function equals (b) {
    if (!Buffer.isBuffer(b)) throw new TypeError('Argument must be a Buffer')
    if (this === b) return true
    return Buffer.compare(this, b) === 0
  };

  Buffer.prototype.inspect = function inspect () {
    let str = '';
    const max = exports.INSPECT_MAX_BYTES;
    str = this.toString('hex', 0, max).replace(/(.{2})/g, '$1 ').trim();
    if (this.length > max) str += ' ... ';
    return '<Buffer ' + str + '>'
  };
  if (customInspectSymbol) {
    Buffer.prototype[customInspectSymbol] = Buffer.prototype.inspect;
  }

  Buffer.prototype.compare = function compare (target, start, end, thisStart, thisEnd) {
    if (isInstance(target, Uint8Array)) {
      target = Buffer.from(target, target.offset, target.byteLength);
    }
    if (!Buffer.isBuffer(target)) {
      throw new TypeError(
        'The "target" argument must be one of type Buffer or Uint8Array. ' +
        'Received type ' + (typeof target)
      )
    }

    if (start === undefined) {
      start = 0;
    }
    if (end === undefined) {
      end = target ? target.length : 0;
    }
    if (thisStart === undefined) {
      thisStart = 0;
    }
    if (thisEnd === undefined) {
      thisEnd = this.length;
    }

    if (start < 0 || end > target.length || thisStart < 0 || thisEnd > this.length) {
      throw new RangeError('out of range index')
    }

    if (thisStart >= thisEnd && start >= end) {
      return 0
    }
    if (thisStart >= thisEnd) {
      return -1
    }
    if (start >= end) {
      return 1
    }

    start >>>= 0;
    end >>>= 0;
    thisStart >>>= 0;
    thisEnd >>>= 0;

    if (this === target) return 0

    let x = thisEnd - thisStart;
    let y = end - start;
    const len = Math.min(x, y);

    const thisCopy = this.slice(thisStart, thisEnd);
    const targetCopy = target.slice(start, end);

    for (let i = 0; i < len; ++i) {
      if (thisCopy[i] !== targetCopy[i]) {
        x = thisCopy[i];
        y = targetCopy[i];
        break
      }
    }

    if (x < y) return -1
    if (y < x) return 1
    return 0
  };

  // Finds either the first index of `val` in `buffer` at offset >= `byteOffset`,
  // OR the last index of `val` in `buffer` at offset <= `byteOffset`.
  //
  // Arguments:
  // - buffer - a Buffer to search
  // - val - a string, Buffer, or number
  // - byteOffset - an index into `buffer`; will be clamped to an int32
  // - encoding - an optional encoding, relevant is val is a string
  // - dir - true for indexOf, false for lastIndexOf
  function bidirectionalIndexOf (buffer, val, byteOffset, encoding, dir) {
    // Empty buffer means no match
    if (buffer.length === 0) return -1

    // Normalize byteOffset
    if (typeof byteOffset === 'string') {
      encoding = byteOffset;
      byteOffset = 0;
    } else if (byteOffset > 0x7fffffff) {
      byteOffset = 0x7fffffff;
    } else if (byteOffset < -0x80000000) {
      byteOffset = -0x80000000;
    }
    byteOffset = +byteOffset; // Coerce to Number.
    if (numberIsNaN(byteOffset)) {
      // byteOffset: it it's undefined, null, NaN, "foo", etc, search whole buffer
      byteOffset = dir ? 0 : (buffer.length - 1);
    }

    // Normalize byteOffset: negative offsets start from the end of the buffer
    if (byteOffset < 0) byteOffset = buffer.length + byteOffset;
    if (byteOffset >= buffer.length) {
      if (dir) return -1
      else byteOffset = buffer.length - 1;
    } else if (byteOffset < 0) {
      if (dir) byteOffset = 0;
      else return -1
    }

    // Normalize val
    if (typeof val === 'string') {
      val = Buffer.from(val, encoding);
    }

    // Finally, search either indexOf (if dir is true) or lastIndexOf
    if (Buffer.isBuffer(val)) {
      // Special case: looking for empty string/buffer always fails
      if (val.length === 0) {
        return -1
      }
      return arrayIndexOf(buffer, val, byteOffset, encoding, dir)
    } else if (typeof val === 'number') {
      val = val & 0xFF; // Search for a byte value [0-255]
      if (typeof Uint8Array.prototype.indexOf === 'function') {
        if (dir) {
          return Uint8Array.prototype.indexOf.call(buffer, val, byteOffset)
        } else {
          return Uint8Array.prototype.lastIndexOf.call(buffer, val, byteOffset)
        }
      }
      return arrayIndexOf(buffer, [val], byteOffset, encoding, dir)
    }

    throw new TypeError('val must be string, number or Buffer')
  }

  function arrayIndexOf (arr, val, byteOffset, encoding, dir) {
    let indexSize = 1;
    let arrLength = arr.length;
    let valLength = val.length;

    if (encoding !== undefined) {
      encoding = String(encoding).toLowerCase();
      if (encoding === 'ucs2' || encoding === 'ucs-2' ||
          encoding === 'utf16le' || encoding === 'utf-16le') {
        if (arr.length < 2 || val.length < 2) {
          return -1
        }
        indexSize = 2;
        arrLength /= 2;
        valLength /= 2;
        byteOffset /= 2;
      }
    }

    function read (buf, i) {
      if (indexSize === 1) {
        return buf[i]
      } else {
        return buf.readUInt16BE(i * indexSize)
      }
    }

    let i;
    if (dir) {
      let foundIndex = -1;
      for (i = byteOffset; i < arrLength; i++) {
        if (read(arr, i) === read(val, foundIndex === -1 ? 0 : i - foundIndex)) {
          if (foundIndex === -1) foundIndex = i;
          if (i - foundIndex + 1 === valLength) return foundIndex * indexSize
        } else {
          if (foundIndex !== -1) i -= i - foundIndex;
          foundIndex = -1;
        }
      }
    } else {
      if (byteOffset + valLength > arrLength) byteOffset = arrLength - valLength;
      for (i = byteOffset; i >= 0; i--) {
        let found = true;
        for (let j = 0; j < valLength; j++) {
          if (read(arr, i + j) !== read(val, j)) {
            found = false;
            break
          }
        }
        if (found) return i
      }
    }

    return -1
  }

  Buffer.prototype.includes = function includes (val, byteOffset, encoding) {
    return this.indexOf(val, byteOffset, encoding) !== -1
  };

  Buffer.prototype.indexOf = function indexOf (val, byteOffset, encoding) {
    return bidirectionalIndexOf(this, val, byteOffset, encoding, true)
  };

  Buffer.prototype.lastIndexOf = function lastIndexOf (val, byteOffset, encoding) {
    return bidirectionalIndexOf(this, val, byteOffset, encoding, false)
  };

  function hexWrite (buf, string, offset, length) {
    offset = Number(offset) || 0;
    const remaining = buf.length - offset;
    if (!length) {
      length = remaining;
    } else {
      length = Number(length);
      if (length > remaining) {
        length = remaining;
      }
    }

    const strLen = string.length;

    if (length > strLen / 2) {
      length = strLen / 2;
    }
    let i;
    for (i = 0; i < length; ++i) {
      const parsed = parseInt(string.substr(i * 2, 2), 16);
      if (numberIsNaN(parsed)) return i
      buf[offset + i] = parsed;
    }
    return i
  }

  function utf8Write (buf, string, offset, length) {
    return blitBuffer(utf8ToBytes(string, buf.length - offset), buf, offset, length)
  }

  function asciiWrite (buf, string, offset, length) {
    return blitBuffer(asciiToBytes(string), buf, offset, length)
  }

  function base64Write (buf, string, offset, length) {
    return blitBuffer(base64ToBytes(string), buf, offset, length)
  }

  function ucs2Write (buf, string, offset, length) {
    return blitBuffer(utf16leToBytes(string, buf.length - offset), buf, offset, length)
  }

  Buffer.prototype.write = function write (string, offset, length, encoding) {
    // Buffer#write(string)
    if (offset === undefined) {
      encoding = 'utf8';
      length = this.length;
      offset = 0;
    // Buffer#write(string, encoding)
    } else if (length === undefined && typeof offset === 'string') {
      encoding = offset;
      length = this.length;
      offset = 0;
    // Buffer#write(string, offset[, length][, encoding])
    } else if (isFinite(offset)) {
      offset = offset >>> 0;
      if (isFinite(length)) {
        length = length >>> 0;
        if (encoding === undefined) encoding = 'utf8';
      } else {
        encoding = length;
        length = undefined;
      }
    } else {
      throw new Error(
        'Buffer.write(string, encoding, offset[, length]) is no longer supported'
      )
    }

    const remaining = this.length - offset;
    if (length === undefined || length > remaining) length = remaining;

    if ((string.length > 0 && (length < 0 || offset < 0)) || offset > this.length) {
      throw new RangeError('Attempt to write outside buffer bounds')
    }

    if (!encoding) encoding = 'utf8';

    let loweredCase = false;
    for (;;) {
      switch (encoding) {
        case 'hex':
          return hexWrite(this, string, offset, length)

        case 'utf8':
        case 'utf-8':
          return utf8Write(this, string, offset, length)

        case 'ascii':
        case 'latin1':
        case 'binary':
          return asciiWrite(this, string, offset, length)

        case 'base64':
          // Warning: maxLength not taken into account in base64Write
          return base64Write(this, string, offset, length)

        case 'ucs2':
        case 'ucs-2':
        case 'utf16le':
        case 'utf-16le':
          return ucs2Write(this, string, offset, length)

        default:
          if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)
          encoding = ('' + encoding).toLowerCase();
          loweredCase = true;
      }
    }
  };

  Buffer.prototype.toJSON = function toJSON () {
    return {
      type: 'Buffer',
      data: Array.prototype.slice.call(this._arr || this, 0)
    }
  };

  function base64Slice (buf, start, end) {
    if (start === 0 && end === buf.length) {
      return base64Js.fromByteArray(buf)
    } else {
      return base64Js.fromByteArray(buf.slice(start, end))
    }
  }

  function utf8Slice (buf, start, end) {
    end = Math.min(buf.length, end);
    const res = [];

    let i = start;
    while (i < end) {
      const firstByte = buf[i];
      let codePoint = null;
      let bytesPerSequence = (firstByte > 0xEF)
        ? 4
        : (firstByte > 0xDF)
            ? 3
            : (firstByte > 0xBF)
                ? 2
                : 1;

      if (i + bytesPerSequence <= end) {
        let secondByte, thirdByte, fourthByte, tempCodePoint;

        switch (bytesPerSequence) {
          case 1:
            if (firstByte < 0x80) {
              codePoint = firstByte;
            }
            break
          case 2:
            secondByte = buf[i + 1];
            if ((secondByte & 0xC0) === 0x80) {
              tempCodePoint = (firstByte & 0x1F) << 0x6 | (secondByte & 0x3F);
              if (tempCodePoint > 0x7F) {
                codePoint = tempCodePoint;
              }
            }
            break
          case 3:
            secondByte = buf[i + 1];
            thirdByte = buf[i + 2];
            if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80) {
              tempCodePoint = (firstByte & 0xF) << 0xC | (secondByte & 0x3F) << 0x6 | (thirdByte & 0x3F);
              if (tempCodePoint > 0x7FF && (tempCodePoint < 0xD800 || tempCodePoint > 0xDFFF)) {
                codePoint = tempCodePoint;
              }
            }
            break
          case 4:
            secondByte = buf[i + 1];
            thirdByte = buf[i + 2];
            fourthByte = buf[i + 3];
            if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80 && (fourthByte & 0xC0) === 0x80) {
              tempCodePoint = (firstByte & 0xF) << 0x12 | (secondByte & 0x3F) << 0xC | (thirdByte & 0x3F) << 0x6 | (fourthByte & 0x3F);
              if (tempCodePoint > 0xFFFF && tempCodePoint < 0x110000) {
                codePoint = tempCodePoint;
              }
            }
        }
      }

      if (codePoint === null) {
        // we did not generate a valid codePoint so insert a
        // replacement char (U+FFFD) and advance only 1 byte
        codePoint = 0xFFFD;
        bytesPerSequence = 1;
      } else if (codePoint > 0xFFFF) {
        // encode to utf16 (surrogate pair dance)
        codePoint -= 0x10000;
        res.push(codePoint >>> 10 & 0x3FF | 0xD800);
        codePoint = 0xDC00 | codePoint & 0x3FF;
      }

      res.push(codePoint);
      i += bytesPerSequence;
    }

    return decodeCodePointsArray(res)
  }

  // Based on http://stackoverflow.com/a/22747272/680742, the browser with
  // the lowest limit is Chrome, with 0x10000 args.
  // We go 1 magnitude less, for safety
  const MAX_ARGUMENTS_LENGTH = 0x1000;

  function decodeCodePointsArray (codePoints) {
    const len = codePoints.length;
    if (len <= MAX_ARGUMENTS_LENGTH) {
      return String.fromCharCode.apply(String, codePoints) // avoid extra slice()
    }

    // Decode in chunks to avoid "call stack size exceeded".
    let res = '';
    let i = 0;
    while (i < len) {
      res += String.fromCharCode.apply(
        String,
        codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH)
      );
    }
    return res
  }

  function asciiSlice (buf, start, end) {
    let ret = '';
    end = Math.min(buf.length, end);

    for (let i = start; i < end; ++i) {
      ret += String.fromCharCode(buf[i] & 0x7F);
    }
    return ret
  }

  function latin1Slice (buf, start, end) {
    let ret = '';
    end = Math.min(buf.length, end);

    for (let i = start; i < end; ++i) {
      ret += String.fromCharCode(buf[i]);
    }
    return ret
  }

  function hexSlice (buf, start, end) {
    const len = buf.length;

    if (!start || start < 0) start = 0;
    if (!end || end < 0 || end > len) end = len;

    let out = '';
    for (let i = start; i < end; ++i) {
      out += hexSliceLookupTable[buf[i]];
    }
    return out
  }

  function utf16leSlice (buf, start, end) {
    const bytes = buf.slice(start, end);
    let res = '';
    // If bytes.length is odd, the last 8 bits must be ignored (same as node.js)
    for (let i = 0; i < bytes.length - 1; i += 2) {
      res += String.fromCharCode(bytes[i] + (bytes[i + 1] * 256));
    }
    return res
  }

  Buffer.prototype.slice = function slice (start, end) {
    const len = this.length;
    start = ~~start;
    end = end === undefined ? len : ~~end;

    if (start < 0) {
      start += len;
      if (start < 0) start = 0;
    } else if (start > len) {
      start = len;
    }

    if (end < 0) {
      end += len;
      if (end < 0) end = 0;
    } else if (end > len) {
      end = len;
    }

    if (end < start) end = start;

    const newBuf = this.subarray(start, end);
    // Return an augmented `Uint8Array` instance
    Object.setPrototypeOf(newBuf, Buffer.prototype);

    return newBuf
  };

  /*
   * Need to make sure that buffer isn't trying to write out of bounds.
   */
  function checkOffset (offset, ext, length) {
    if ((offset % 1) !== 0 || offset < 0) throw new RangeError('offset is not uint')
    if (offset + ext > length) throw new RangeError('Trying to access beyond buffer length')
  }

  Buffer.prototype.readUintLE =
  Buffer.prototype.readUIntLE = function readUIntLE (offset, byteLength, noAssert) {
    offset = offset >>> 0;
    byteLength = byteLength >>> 0;
    if (!noAssert) checkOffset(offset, byteLength, this.length);

    let val = this[offset];
    let mul = 1;
    let i = 0;
    while (++i < byteLength && (mul *= 0x100)) {
      val += this[offset + i] * mul;
    }

    return val
  };

  Buffer.prototype.readUintBE =
  Buffer.prototype.readUIntBE = function readUIntBE (offset, byteLength, noAssert) {
    offset = offset >>> 0;
    byteLength = byteLength >>> 0;
    if (!noAssert) {
      checkOffset(offset, byteLength, this.length);
    }

    let val = this[offset + --byteLength];
    let mul = 1;
    while (byteLength > 0 && (mul *= 0x100)) {
      val += this[offset + --byteLength] * mul;
    }

    return val
  };

  Buffer.prototype.readUint8 =
  Buffer.prototype.readUInt8 = function readUInt8 (offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 1, this.length);
    return this[offset]
  };

  Buffer.prototype.readUint16LE =
  Buffer.prototype.readUInt16LE = function readUInt16LE (offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 2, this.length);
    return this[offset] | (this[offset + 1] << 8)
  };

  Buffer.prototype.readUint16BE =
  Buffer.prototype.readUInt16BE = function readUInt16BE (offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 2, this.length);
    return (this[offset] << 8) | this[offset + 1]
  };

  Buffer.prototype.readUint32LE =
  Buffer.prototype.readUInt32LE = function readUInt32LE (offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 4, this.length);

    return ((this[offset]) |
        (this[offset + 1] << 8) |
        (this[offset + 2] << 16)) +
        (this[offset + 3] * 0x1000000)
  };

  Buffer.prototype.readUint32BE =
  Buffer.prototype.readUInt32BE = function readUInt32BE (offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 4, this.length);

    return (this[offset] * 0x1000000) +
      ((this[offset + 1] << 16) |
      (this[offset + 2] << 8) |
      this[offset + 3])
  };

  Buffer.prototype.readBigUInt64LE = defineBigIntMethod(function readBigUInt64LE (offset) {
    offset = offset >>> 0;
    validateNumber(offset, 'offset');
    const first = this[offset];
    const last = this[offset + 7];
    if (first === undefined || last === undefined) {
      boundsError(offset, this.length - 8);
    }

    const lo = first +
      this[++offset] * 2 ** 8 +
      this[++offset] * 2 ** 16 +
      this[++offset] * 2 ** 24;

    const hi = this[++offset] +
      this[++offset] * 2 ** 8 +
      this[++offset] * 2 ** 16 +
      last * 2 ** 24;

    return BigInt(lo) + (BigInt(hi) << BigInt(32))
  });

  Buffer.prototype.readBigUInt64BE = defineBigIntMethod(function readBigUInt64BE (offset) {
    offset = offset >>> 0;
    validateNumber(offset, 'offset');
    const first = this[offset];
    const last = this[offset + 7];
    if (first === undefined || last === undefined) {
      boundsError(offset, this.length - 8);
    }

    const hi = first * 2 ** 24 +
      this[++offset] * 2 ** 16 +
      this[++offset] * 2 ** 8 +
      this[++offset];

    const lo = this[++offset] * 2 ** 24 +
      this[++offset] * 2 ** 16 +
      this[++offset] * 2 ** 8 +
      last;

    return (BigInt(hi) << BigInt(32)) + BigInt(lo)
  });

  Buffer.prototype.readIntLE = function readIntLE (offset, byteLength, noAssert) {
    offset = offset >>> 0;
    byteLength = byteLength >>> 0;
    if (!noAssert) checkOffset(offset, byteLength, this.length);

    let val = this[offset];
    let mul = 1;
    let i = 0;
    while (++i < byteLength && (mul *= 0x100)) {
      val += this[offset + i] * mul;
    }
    mul *= 0x80;

    if (val >= mul) val -= Math.pow(2, 8 * byteLength);

    return val
  };

  Buffer.prototype.readIntBE = function readIntBE (offset, byteLength, noAssert) {
    offset = offset >>> 0;
    byteLength = byteLength >>> 0;
    if (!noAssert) checkOffset(offset, byteLength, this.length);

    let i = byteLength;
    let mul = 1;
    let val = this[offset + --i];
    while (i > 0 && (mul *= 0x100)) {
      val += this[offset + --i] * mul;
    }
    mul *= 0x80;

    if (val >= mul) val -= Math.pow(2, 8 * byteLength);

    return val
  };

  Buffer.prototype.readInt8 = function readInt8 (offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 1, this.length);
    if (!(this[offset] & 0x80)) return (this[offset])
    return ((0xff - this[offset] + 1) * -1)
  };

  Buffer.prototype.readInt16LE = function readInt16LE (offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 2, this.length);
    const val = this[offset] | (this[offset + 1] << 8);
    return (val & 0x8000) ? val | 0xFFFF0000 : val
  };

  Buffer.prototype.readInt16BE = function readInt16BE (offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 2, this.length);
    const val = this[offset + 1] | (this[offset] << 8);
    return (val & 0x8000) ? val | 0xFFFF0000 : val
  };

  Buffer.prototype.readInt32LE = function readInt32LE (offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 4, this.length);

    return (this[offset]) |
      (this[offset + 1] << 8) |
      (this[offset + 2] << 16) |
      (this[offset + 3] << 24)
  };

  Buffer.prototype.readInt32BE = function readInt32BE (offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 4, this.length);

    return (this[offset] << 24) |
      (this[offset + 1] << 16) |
      (this[offset + 2] << 8) |
      (this[offset + 3])
  };

  Buffer.prototype.readBigInt64LE = defineBigIntMethod(function readBigInt64LE (offset) {
    offset = offset >>> 0;
    validateNumber(offset, 'offset');
    const first = this[offset];
    const last = this[offset + 7];
    if (first === undefined || last === undefined) {
      boundsError(offset, this.length - 8);
    }

    const val = this[offset + 4] +
      this[offset + 5] * 2 ** 8 +
      this[offset + 6] * 2 ** 16 +
      (last << 24); // Overflow

    return (BigInt(val) << BigInt(32)) +
      BigInt(first +
      this[++offset] * 2 ** 8 +
      this[++offset] * 2 ** 16 +
      this[++offset] * 2 ** 24)
  });

  Buffer.prototype.readBigInt64BE = defineBigIntMethod(function readBigInt64BE (offset) {
    offset = offset >>> 0;
    validateNumber(offset, 'offset');
    const first = this[offset];
    const last = this[offset + 7];
    if (first === undefined || last === undefined) {
      boundsError(offset, this.length - 8);
    }

    const val = (first << 24) + // Overflow
      this[++offset] * 2 ** 16 +
      this[++offset] * 2 ** 8 +
      this[++offset];

    return (BigInt(val) << BigInt(32)) +
      BigInt(this[++offset] * 2 ** 24 +
      this[++offset] * 2 ** 16 +
      this[++offset] * 2 ** 8 +
      last)
  });

  Buffer.prototype.readFloatLE = function readFloatLE (offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 4, this.length);
    return ieee754.read(this, offset, true, 23, 4)
  };

  Buffer.prototype.readFloatBE = function readFloatBE (offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 4, this.length);
    return ieee754.read(this, offset, false, 23, 4)
  };

  Buffer.prototype.readDoubleLE = function readDoubleLE (offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 8, this.length);
    return ieee754.read(this, offset, true, 52, 8)
  };

  Buffer.prototype.readDoubleBE = function readDoubleBE (offset, noAssert) {
    offset = offset >>> 0;
    if (!noAssert) checkOffset(offset, 8, this.length);
    return ieee754.read(this, offset, false, 52, 8)
  };

  function checkInt (buf, value, offset, ext, max, min) {
    if (!Buffer.isBuffer(buf)) throw new TypeError('"buffer" argument must be a Buffer instance')
    if (value > max || value < min) throw new RangeError('"value" argument is out of bounds')
    if (offset + ext > buf.length) throw new RangeError('Index out of range')
  }

  Buffer.prototype.writeUintLE =
  Buffer.prototype.writeUIntLE = function writeUIntLE (value, offset, byteLength, noAssert) {
    value = +value;
    offset = offset >>> 0;
    byteLength = byteLength >>> 0;
    if (!noAssert) {
      const maxBytes = Math.pow(2, 8 * byteLength) - 1;
      checkInt(this, value, offset, byteLength, maxBytes, 0);
    }

    let mul = 1;
    let i = 0;
    this[offset] = value & 0xFF;
    while (++i < byteLength && (mul *= 0x100)) {
      this[offset + i] = (value / mul) & 0xFF;
    }

    return offset + byteLength
  };

  Buffer.prototype.writeUintBE =
  Buffer.prototype.writeUIntBE = function writeUIntBE (value, offset, byteLength, noAssert) {
    value = +value;
    offset = offset >>> 0;
    byteLength = byteLength >>> 0;
    if (!noAssert) {
      const maxBytes = Math.pow(2, 8 * byteLength) - 1;
      checkInt(this, value, offset, byteLength, maxBytes, 0);
    }

    let i = byteLength - 1;
    let mul = 1;
    this[offset + i] = value & 0xFF;
    while (--i >= 0 && (mul *= 0x100)) {
      this[offset + i] = (value / mul) & 0xFF;
    }

    return offset + byteLength
  };

  Buffer.prototype.writeUint8 =
  Buffer.prototype.writeUInt8 = function writeUInt8 (value, offset, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) checkInt(this, value, offset, 1, 0xff, 0);
    this[offset] = (value & 0xff);
    return offset + 1
  };

  Buffer.prototype.writeUint16LE =
  Buffer.prototype.writeUInt16LE = function writeUInt16LE (value, offset, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0);
    this[offset] = (value & 0xff);
    this[offset + 1] = (value >>> 8);
    return offset + 2
  };

  Buffer.prototype.writeUint16BE =
  Buffer.prototype.writeUInt16BE = function writeUInt16BE (value, offset, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0);
    this[offset] = (value >>> 8);
    this[offset + 1] = (value & 0xff);
    return offset + 2
  };

  Buffer.prototype.writeUint32LE =
  Buffer.prototype.writeUInt32LE = function writeUInt32LE (value, offset, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0);
    this[offset + 3] = (value >>> 24);
    this[offset + 2] = (value >>> 16);
    this[offset + 1] = (value >>> 8);
    this[offset] = (value & 0xff);
    return offset + 4
  };

  Buffer.prototype.writeUint32BE =
  Buffer.prototype.writeUInt32BE = function writeUInt32BE (value, offset, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0);
    this[offset] = (value >>> 24);
    this[offset + 1] = (value >>> 16);
    this[offset + 2] = (value >>> 8);
    this[offset + 3] = (value & 0xff);
    return offset + 4
  };

  function wrtBigUInt64LE (buf, value, offset, min, max) {
    checkIntBI(value, min, max, buf, offset, 7);

    let lo = Number(value & BigInt(0xffffffff));
    buf[offset++] = lo;
    lo = lo >> 8;
    buf[offset++] = lo;
    lo = lo >> 8;
    buf[offset++] = lo;
    lo = lo >> 8;
    buf[offset++] = lo;
    let hi = Number(value >> BigInt(32) & BigInt(0xffffffff));
    buf[offset++] = hi;
    hi = hi >> 8;
    buf[offset++] = hi;
    hi = hi >> 8;
    buf[offset++] = hi;
    hi = hi >> 8;
    buf[offset++] = hi;
    return offset
  }

  function wrtBigUInt64BE (buf, value, offset, min, max) {
    checkIntBI(value, min, max, buf, offset, 7);

    let lo = Number(value & BigInt(0xffffffff));
    buf[offset + 7] = lo;
    lo = lo >> 8;
    buf[offset + 6] = lo;
    lo = lo >> 8;
    buf[offset + 5] = lo;
    lo = lo >> 8;
    buf[offset + 4] = lo;
    let hi = Number(value >> BigInt(32) & BigInt(0xffffffff));
    buf[offset + 3] = hi;
    hi = hi >> 8;
    buf[offset + 2] = hi;
    hi = hi >> 8;
    buf[offset + 1] = hi;
    hi = hi >> 8;
    buf[offset] = hi;
    return offset + 8
  }

  Buffer.prototype.writeBigUInt64LE = defineBigIntMethod(function writeBigUInt64LE (value, offset = 0) {
    return wrtBigUInt64LE(this, value, offset, BigInt(0), BigInt('0xffffffffffffffff'))
  });

  Buffer.prototype.writeBigUInt64BE = defineBigIntMethod(function writeBigUInt64BE (value, offset = 0) {
    return wrtBigUInt64BE(this, value, offset, BigInt(0), BigInt('0xffffffffffffffff'))
  });

  Buffer.prototype.writeIntLE = function writeIntLE (value, offset, byteLength, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) {
      const limit = Math.pow(2, (8 * byteLength) - 1);

      checkInt(this, value, offset, byteLength, limit - 1, -limit);
    }

    let i = 0;
    let mul = 1;
    let sub = 0;
    this[offset] = value & 0xFF;
    while (++i < byteLength && (mul *= 0x100)) {
      if (value < 0 && sub === 0 && this[offset + i - 1] !== 0) {
        sub = 1;
      }
      this[offset + i] = ((value / mul) >> 0) - sub & 0xFF;
    }

    return offset + byteLength
  };

  Buffer.prototype.writeIntBE = function writeIntBE (value, offset, byteLength, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) {
      const limit = Math.pow(2, (8 * byteLength) - 1);

      checkInt(this, value, offset, byteLength, limit - 1, -limit);
    }

    let i = byteLength - 1;
    let mul = 1;
    let sub = 0;
    this[offset + i] = value & 0xFF;
    while (--i >= 0 && (mul *= 0x100)) {
      if (value < 0 && sub === 0 && this[offset + i + 1] !== 0) {
        sub = 1;
      }
      this[offset + i] = ((value / mul) >> 0) - sub & 0xFF;
    }

    return offset + byteLength
  };

  Buffer.prototype.writeInt8 = function writeInt8 (value, offset, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) checkInt(this, value, offset, 1, 0x7f, -0x80);
    if (value < 0) value = 0xff + value + 1;
    this[offset] = (value & 0xff);
    return offset + 1
  };

  Buffer.prototype.writeInt16LE = function writeInt16LE (value, offset, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000);
    this[offset] = (value & 0xff);
    this[offset + 1] = (value >>> 8);
    return offset + 2
  };

  Buffer.prototype.writeInt16BE = function writeInt16BE (value, offset, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000);
    this[offset] = (value >>> 8);
    this[offset + 1] = (value & 0xff);
    return offset + 2
  };

  Buffer.prototype.writeInt32LE = function writeInt32LE (value, offset, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000);
    this[offset] = (value & 0xff);
    this[offset + 1] = (value >>> 8);
    this[offset + 2] = (value >>> 16);
    this[offset + 3] = (value >>> 24);
    return offset + 4
  };

  Buffer.prototype.writeInt32BE = function writeInt32BE (value, offset, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000);
    if (value < 0) value = 0xffffffff + value + 1;
    this[offset] = (value >>> 24);
    this[offset + 1] = (value >>> 16);
    this[offset + 2] = (value >>> 8);
    this[offset + 3] = (value & 0xff);
    return offset + 4
  };

  Buffer.prototype.writeBigInt64LE = defineBigIntMethod(function writeBigInt64LE (value, offset = 0) {
    return wrtBigUInt64LE(this, value, offset, -BigInt('0x8000000000000000'), BigInt('0x7fffffffffffffff'))
  });

  Buffer.prototype.writeBigInt64BE = defineBigIntMethod(function writeBigInt64BE (value, offset = 0) {
    return wrtBigUInt64BE(this, value, offset, -BigInt('0x8000000000000000'), BigInt('0x7fffffffffffffff'))
  });

  function checkIEEE754 (buf, value, offset, ext, max, min) {
    if (offset + ext > buf.length) throw new RangeError('Index out of range')
    if (offset < 0) throw new RangeError('Index out of range')
  }

  function writeFloat (buf, value, offset, littleEndian, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) {
      checkIEEE754(buf, value, offset, 4);
    }
    ieee754.write(buf, value, offset, littleEndian, 23, 4);
    return offset + 4
  }

  Buffer.prototype.writeFloatLE = function writeFloatLE (value, offset, noAssert) {
    return writeFloat(this, value, offset, true, noAssert)
  };

  Buffer.prototype.writeFloatBE = function writeFloatBE (value, offset, noAssert) {
    return writeFloat(this, value, offset, false, noAssert)
  };

  function writeDouble (buf, value, offset, littleEndian, noAssert) {
    value = +value;
    offset = offset >>> 0;
    if (!noAssert) {
      checkIEEE754(buf, value, offset, 8);
    }
    ieee754.write(buf, value, offset, littleEndian, 52, 8);
    return offset + 8
  }

  Buffer.prototype.writeDoubleLE = function writeDoubleLE (value, offset, noAssert) {
    return writeDouble(this, value, offset, true, noAssert)
  };

  Buffer.prototype.writeDoubleBE = function writeDoubleBE (value, offset, noAssert) {
    return writeDouble(this, value, offset, false, noAssert)
  };

  // copy(targetBuffer, targetStart=0, sourceStart=0, sourceEnd=buffer.length)
  Buffer.prototype.copy = function copy (target, targetStart, start, end) {
    if (!Buffer.isBuffer(target)) throw new TypeError('argument should be a Buffer')
    if (!start) start = 0;
    if (!end && end !== 0) end = this.length;
    if (targetStart >= target.length) targetStart = target.length;
    if (!targetStart) targetStart = 0;
    if (end > 0 && end < start) end = start;

    // Copy 0 bytes; we're done
    if (end === start) return 0
    if (target.length === 0 || this.length === 0) return 0

    // Fatal error conditions
    if (targetStart < 0) {
      throw new RangeError('targetStart out of bounds')
    }
    if (start < 0 || start >= this.length) throw new RangeError('Index out of range')
    if (end < 0) throw new RangeError('sourceEnd out of bounds')

    // Are we oob?
    if (end > this.length) end = this.length;
    if (target.length - targetStart < end - start) {
      end = target.length - targetStart + start;
    }

    const len = end - start;

    if (this === target && typeof Uint8Array.prototype.copyWithin === 'function') {
      // Use built-in when available, missing from IE11
      this.copyWithin(targetStart, start, end);
    } else {
      Uint8Array.prototype.set.call(
        target,
        this.subarray(start, end),
        targetStart
      );
    }

    return len
  };

  // Usage:
  //    buffer.fill(number[, offset[, end]])
  //    buffer.fill(buffer[, offset[, end]])
  //    buffer.fill(string[, offset[, end]][, encoding])
  Buffer.prototype.fill = function fill (val, start, end, encoding) {
    // Handle string cases:
    if (typeof val === 'string') {
      if (typeof start === 'string') {
        encoding = start;
        start = 0;
        end = this.length;
      } else if (typeof end === 'string') {
        encoding = end;
        end = this.length;
      }
      if (encoding !== undefined && typeof encoding !== 'string') {
        throw new TypeError('encoding must be a string')
      }
      if (typeof encoding === 'string' && !Buffer.isEncoding(encoding)) {
        throw new TypeError('Unknown encoding: ' + encoding)
      }
      if (val.length === 1) {
        const code = val.charCodeAt(0);
        if ((encoding === 'utf8' && code < 128) ||
            encoding === 'latin1') {
          // Fast path: If `val` fits into a single byte, use that numeric value.
          val = code;
        }
      }
    } else if (typeof val === 'number') {
      val = val & 255;
    } else if (typeof val === 'boolean') {
      val = Number(val);
    }

    // Invalid ranges are not set to a default, so can range check early.
    if (start < 0 || this.length < start || this.length < end) {
      throw new RangeError('Out of range index')
    }

    if (end <= start) {
      return this
    }

    start = start >>> 0;
    end = end === undefined ? this.length : end >>> 0;

    if (!val) val = 0;

    let i;
    if (typeof val === 'number') {
      for (i = start; i < end; ++i) {
        this[i] = val;
      }
    } else {
      const bytes = Buffer.isBuffer(val)
        ? val
        : Buffer.from(val, encoding);
      const len = bytes.length;
      if (len === 0) {
        throw new TypeError('The value "' + val +
          '" is invalid for argument "value"')
      }
      for (i = 0; i < end - start; ++i) {
        this[i + start] = bytes[i % len];
      }
    }

    return this
  };

  // CUSTOM ERRORS
  // =============

  // Simplified versions from Node, changed for Buffer-only usage
  const errors = {};
  function E (sym, getMessage, Base) {
    errors[sym] = class NodeError extends Base {
      constructor () {
        super();

        Object.defineProperty(this, 'message', {
          value: getMessage.apply(this, arguments),
          writable: true,
          configurable: true
        });

        // Add the error code to the name to include it in the stack trace.
        this.name = `${this.name} [${sym}]`;
        // Access the stack to generate the error message including the error code
        // from the name.
        this.stack; // eslint-disable-line no-unused-expressions
        // Reset the name to the actual name.
        delete this.name;
      }

      get code () {
        return sym
      }

      set code (value) {
        Object.defineProperty(this, 'code', {
          configurable: true,
          enumerable: true,
          value,
          writable: true
        });
      }

      toString () {
        return `${this.name} [${sym}]: ${this.message}`
      }
    };
  }

  E('ERR_BUFFER_OUT_OF_BOUNDS',
    function (name) {
      if (name) {
        return `${name} is outside of buffer bounds`
      }

      return 'Attempt to access memory outside buffer bounds'
    }, RangeError);
  E('ERR_INVALID_ARG_TYPE',
    function (name, actual) {
      return `The "${name}" argument must be of type number. Received type ${typeof actual}`
    }, TypeError);
  E('ERR_OUT_OF_RANGE',
    function (str, range, input) {
      let msg = `The value of "${str}" is out of range.`;
      let received = input;
      if (Number.isInteger(input) && Math.abs(input) > 2 ** 32) {
        received = addNumericalSeparator(String(input));
      } else if (typeof input === 'bigint') {
        received = String(input);
        if (input > BigInt(2) ** BigInt(32) || input < -(BigInt(2) ** BigInt(32))) {
          received = addNumericalSeparator(received);
        }
        received += 'n';
      }
      msg += ` It must be ${range}. Received ${received}`;
      return msg
    }, RangeError);

  function addNumericalSeparator (val) {
    let res = '';
    let i = val.length;
    const start = val[0] === '-' ? 1 : 0;
    for (; i >= start + 4; i -= 3) {
      res = `_${val.slice(i - 3, i)}${res}`;
    }
    return `${val.slice(0, i)}${res}`
  }

  // CHECK FUNCTIONS
  // ===============

  function checkBounds (buf, offset, byteLength) {
    validateNumber(offset, 'offset');
    if (buf[offset] === undefined || buf[offset + byteLength] === undefined) {
      boundsError(offset, buf.length - (byteLength + 1));
    }
  }

  function checkIntBI (value, min, max, buf, offset, byteLength) {
    if (value > max || value < min) {
      const n = typeof min === 'bigint' ? 'n' : '';
      let range;
      if (byteLength > 3) {
        if (min === 0 || min === BigInt(0)) {
          range = `>= 0${n} and < 2${n} ** ${(byteLength + 1) * 8}${n}`;
        } else {
          range = `>= -(2${n} ** ${(byteLength + 1) * 8 - 1}${n}) and < 2 ** ` +
                  `${(byteLength + 1) * 8 - 1}${n}`;
        }
      } else {
        range = `>= ${min}${n} and <= ${max}${n}`;
      }
      throw new errors.ERR_OUT_OF_RANGE('value', range, value)
    }
    checkBounds(buf, offset, byteLength);
  }

  function validateNumber (value, name) {
    if (typeof value !== 'number') {
      throw new errors.ERR_INVALID_ARG_TYPE(name, 'number', value)
    }
  }

  function boundsError (value, length, type) {
    if (Math.floor(value) !== value) {
      validateNumber(value, type);
      throw new errors.ERR_OUT_OF_RANGE(type || 'offset', 'an integer', value)
    }

    if (length < 0) {
      throw new errors.ERR_BUFFER_OUT_OF_BOUNDS()
    }

    throw new errors.ERR_OUT_OF_RANGE(type || 'offset',
                                      `>= ${type ? 1 : 0} and <= ${length}`,
                                      value)
  }

  // HELPER FUNCTIONS
  // ================

  const INVALID_BASE64_RE = /[^+/0-9A-Za-z-_]/g;

  function base64clean (str) {
    // Node takes equal signs as end of the Base64 encoding
    str = str.split('=')[0];
    // Node strips out invalid characters like \n and \t from the string, base64-js does not
    str = str.trim().replace(INVALID_BASE64_RE, '');
    // Node converts strings with length < 2 to ''
    if (str.length < 2) return ''
    // Node allows for non-padded base64 strings (missing trailing ===), base64-js does not
    while (str.length % 4 !== 0) {
      str = str + '=';
    }
    return str
  }

  function utf8ToBytes (string, units) {
    units = units || Infinity;
    let codePoint;
    const length = string.length;
    let leadSurrogate = null;
    const bytes = [];

    for (let i = 0; i < length; ++i) {
      codePoint = string.charCodeAt(i);

      // is surrogate component
      if (codePoint > 0xD7FF && codePoint < 0xE000) {
        // last char was a lead
        if (!leadSurrogate) {
          // no lead yet
          if (codePoint > 0xDBFF) {
            // unexpected trail
            if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD);
            continue
          } else if (i + 1 === length) {
            // unpaired lead
            if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD);
            continue
          }

          // valid lead
          leadSurrogate = codePoint;

          continue
        }

        // 2 leads in a row
        if (codePoint < 0xDC00) {
          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD);
          leadSurrogate = codePoint;
          continue
        }

        // valid surrogate pair
        codePoint = (leadSurrogate - 0xD800 << 10 | codePoint - 0xDC00) + 0x10000;
      } else if (leadSurrogate) {
        // valid bmp char, but last char was a lead
        if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD);
      }

      leadSurrogate = null;

      // encode utf8
      if (codePoint < 0x80) {
        if ((units -= 1) < 0) break
        bytes.push(codePoint);
      } else if (codePoint < 0x800) {
        if ((units -= 2) < 0) break
        bytes.push(
          codePoint >> 0x6 | 0xC0,
          codePoint & 0x3F | 0x80
        );
      } else if (codePoint < 0x10000) {
        if ((units -= 3) < 0) break
        bytes.push(
          codePoint >> 0xC | 0xE0,
          codePoint >> 0x6 & 0x3F | 0x80,
          codePoint & 0x3F | 0x80
        );
      } else if (codePoint < 0x110000) {
        if ((units -= 4) < 0) break
        bytes.push(
          codePoint >> 0x12 | 0xF0,
          codePoint >> 0xC & 0x3F | 0x80,
          codePoint >> 0x6 & 0x3F | 0x80,
          codePoint & 0x3F | 0x80
        );
      } else {
        throw new Error('Invalid code point')
      }
    }

    return bytes
  }

  function asciiToBytes (str) {
    const byteArray = [];
    for (let i = 0; i < str.length; ++i) {
      // Node's code seems to be doing this and not & 0x7F..
      byteArray.push(str.charCodeAt(i) & 0xFF);
    }
    return byteArray
  }

  function utf16leToBytes (str, units) {
    let c, hi, lo;
    const byteArray = [];
    for (let i = 0; i < str.length; ++i) {
      if ((units -= 2) < 0) break

      c = str.charCodeAt(i);
      hi = c >> 8;
      lo = c % 256;
      byteArray.push(lo);
      byteArray.push(hi);
    }

    return byteArray
  }

  function base64ToBytes (str) {
    return base64Js.toByteArray(base64clean(str))
  }

  function blitBuffer (src, dst, offset, length) {
    let i;
    for (i = 0; i < length; ++i) {
      if ((i + offset >= dst.length) || (i >= src.length)) break
      dst[i + offset] = src[i];
    }
    return i
  }

  // ArrayBuffer or Uint8Array objects from other contexts (i.e. iframes) do not pass
  // the `instanceof` check but they should be treated as of that type.
  // See: https://github.com/feross/buffer/issues/166
  function isInstance (obj, type) {
    return obj instanceof type ||
      (obj != null && obj.constructor != null && obj.constructor.name != null &&
        obj.constructor.name === type.name)
  }
  function numberIsNaN (obj) {
    // For IE11 support
    return obj !== obj // eslint-disable-line no-self-compare
  }

  // Create lookup table for `toString('hex')`
  // See: https://github.com/feross/buffer/issues/219
  const hexSliceLookupTable = (function () {
    const alphabet = '0123456789abcdef';
    const table = new Array(256);
    for (let i = 0; i < 16; ++i) {
      const i16 = i * 16;
      for (let j = 0; j < 16; ++j) {
        table[i16 + j] = alphabet[i] + alphabet[j];
      }
    }
    return table
  })();

  // Return not function with Error if BigInt not supported
  function defineBigIntMethod (fn) {
    return typeof BigInt === 'undefined' ? BufferBigIntNotDefined : fn
  }

  function BufferBigIntNotDefined () {
    throw new Error('BigInt not supported')
  }
  });

  var browser$2 = createCommonjsModule(function (module) {
  // shim for using process in browser
  var process = module.exports = {};

  // cached from whatever global is present so that test runners that stub it
  // don't break things.  But we need to wrap it in a try catch in case it is
  // wrapped in strict mode code which doesn't define any globals.  It's inside a
  // function because try/catches deoptimize in certain engines.

  var cachedSetTimeout;
  var cachedClearTimeout;

  function defaultSetTimout() {
      throw new Error('setTimeout has not been defined');
  }
  function defaultClearTimeout () {
      throw new Error('clearTimeout has not been defined');
  }
  (function () {
      try {
          if (typeof setTimeout === 'function') {
              cachedSetTimeout = setTimeout;
          } else {
              cachedSetTimeout = defaultSetTimout;
          }
      } catch (e) {
          cachedSetTimeout = defaultSetTimout;
      }
      try {
          if (typeof clearTimeout === 'function') {
              cachedClearTimeout = clearTimeout;
          } else {
              cachedClearTimeout = defaultClearTimeout;
          }
      } catch (e) {
          cachedClearTimeout = defaultClearTimeout;
      }
  } ());
  function runTimeout(fun) {
      if (cachedSetTimeout === setTimeout) {
          //normal enviroments in sane situations
          return setTimeout(fun, 0);
      }
      // if setTimeout wasn't available but was latter defined
      if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {
          cachedSetTimeout = setTimeout;
          return setTimeout(fun, 0);
      }
      try {
          // when when somebody has screwed with setTimeout but no I.E. maddness
          return cachedSetTimeout(fun, 0);
      } catch(e){
          try {
              // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally
              return cachedSetTimeout.call(null, fun, 0);
          } catch(e){
              // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error
              return cachedSetTimeout.call(this, fun, 0);
          }
      }


  }
  function runClearTimeout(marker) {
      if (cachedClearTimeout === clearTimeout) {
          //normal enviroments in sane situations
          return clearTimeout(marker);
      }
      // if clearTimeout wasn't available but was latter defined
      if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {
          cachedClearTimeout = clearTimeout;
          return clearTimeout(marker);
      }
      try {
          // when when somebody has screwed with setTimeout but no I.E. maddness
          return cachedClearTimeout(marker);
      } catch (e){
          try {
              // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally
              return cachedClearTimeout.call(null, marker);
          } catch (e){
              // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.
              // Some versions of I.E. have different rules for clearTimeout vs setTimeout
              return cachedClearTimeout.call(this, marker);
          }
      }



  }
  var queue = [];
  var draining = false;
  var currentQueue;
  var queueIndex = -1;

  function cleanUpNextTick() {
      if (!draining || !currentQueue) {
          return;
      }
      draining = false;
      if (currentQueue.length) {
          queue = currentQueue.concat(queue);
      } else {
          queueIndex = -1;
      }
      if (queue.length) {
          drainQueue();
      }
  }

  function drainQueue() {
      if (draining) {
          return;
      }
      var timeout = runTimeout(cleanUpNextTick);
      draining = true;

      var len = queue.length;
      while(len) {
          currentQueue = queue;
          queue = [];
          while (++queueIndex < len) {
              if (currentQueue) {
                  currentQueue[queueIndex].run();
              }
          }
          queueIndex = -1;
          len = queue.length;
      }
      currentQueue = null;
      draining = false;
      runClearTimeout(timeout);
  }

  process.nextTick = function (fun) {
      var args = new Array(arguments.length - 1);
      if (arguments.length > 1) {
          for (var i = 1; i < arguments.length; i++) {
              args[i - 1] = arguments[i];
          }
      }
      queue.push(new Item(fun, args));
      if (queue.length === 1 && !draining) {
          runTimeout(drainQueue);
      }
  };

  // v8 likes predictible objects
  function Item(fun, array) {
      this.fun = fun;
      this.array = array;
  }
  Item.prototype.run = function () {
      this.fun.apply(null, this.array);
  };
  process.title = 'browser';
  process.browser = true;
  process.env = {};
  process.argv = [];
  process.version = ''; // empty string to avoid regexp issues
  process.versions = {};

  function noop() {}

  process.on = noop;
  process.addListener = noop;
  process.once = noop;
  process.off = noop;
  process.removeListener = noop;
  process.removeAllListeners = noop;
  process.emit = noop;
  process.prependListener = noop;
  process.prependOnceListener = noop;

  process.listeners = function (name) { return [] };

  process.binding = function (name) {
      throw new Error('process.binding is not supported');
  };

  process.cwd = function () { return '/' };
  process.chdir = function (dir) {
      throw new Error('process.chdir is not supported');
  };
  process.umask = function() { return 0; };
  });

  /**
   * Often used conditions.
   *
   * @module conditions
   */

  /**
   * @template T
   * @param {T|null|undefined} v
   * @return {T|null}
   */
  /* c8 ignore next */
  const undefinedToNull = v => v === undefined ? null : v;

  /* eslint-env browser */

  /**
   * Isomorphic variable storage.
   *
   * Uses LocalStorage in the browser and falls back to in-memory storage.
   *
   * @module storage
   */

  /* c8 ignore start */
  class VarStoragePolyfill {
    constructor () {
      this.map = new Map();
    }

    /**
     * @param {string} key
     * @param {any} newValue
     */
    setItem (key, newValue) {
      this.map.set(key, newValue);
    }

    /**
     * @param {string} key
     */
    getItem (key) {
      return this.map.get(key)
    }
  }
  /* c8 ignore stop */

  /**
   * @type {any}
   */
  let _localStorage = new VarStoragePolyfill();
  let usePolyfill = true;

  /* c8 ignore start */
  try {
    // if the same-origin rule is violated, accessing localStorage might thrown an error
    if (typeof localStorage !== 'undefined' && localStorage) {
      _localStorage = localStorage;
      usePolyfill = false;
    }
  } catch (e) { }
  /* c8 ignore stop */

  /**
   * This is basically localStorage in browser, or a polyfill in nodejs
   */
  /* c8 ignore next */
  const varStorage = _localStorage;

  /**
   * Utility functions for working with EcmaScript objects.
   *
   * @module object
   */

  /**
   * Object.assign
   */
  const assign = Object.assign;

  /**
   * @param {Object<string,any>} obj
   */
  const keys = Object.keys;

  /**
   * @template V
   * @param {{[k:string]:V}} obj
   * @param {function(V,string):any} f
   */
  const forEach$2 = (obj, f) => {
    for (const key in obj) {
      f(obj[key], key);
    }
  };

  /**
   * @todo implement mapToArray & map
   *
   * @template R
   * @param {Object<string,any>} obj
   * @param {function(any,string):R} f
   * @return {Array<R>}
   */
  const map$1 = (obj, f) => {
    const results = [];
    for (const key in obj) {
      results.push(f(obj[key], key));
    }
    return results
  };

  /**
   * @deprecated use object.size instead
   * @param {Object<string,any>} obj
   * @return {number}
   */
  const length = obj => keys(obj).length;

  /**
   * @param {Object<string,any>} obj
   * @return {number}
   */
  const size = obj => keys(obj).length;

  /**
   * @param {Object|undefined} obj
   */
  const isEmpty = obj => {
    // eslint-disable-next-line
    for (const _k in obj) {
      return false
    }
    return true
  };

  /**
   * @param {Object<string,any>} obj
   * @param {function(any,string):boolean} f
   * @return {boolean}
   */
  const every$1 = (obj, f) => {
    for (const key in obj) {
      if (!f(obj[key], key)) {
        return false
      }
    }
    return true
  };

  /**
   * Calls `Object.prototype.hasOwnProperty`.
   *
   * @param {any} obj
   * @param {string|symbol} key
   * @return {boolean}
   */
  const hasProperty = (obj, key) => Object.prototype.hasOwnProperty.call(obj, key);

  /**
   * @param {Object<string,any>} a
   * @param {Object<string,any>} b
   * @return {boolean}
   */
  const equalFlat = (a, b) => a === b || (size(a) === size(b) && every$1(a, (val, key) => (val !== undefined || hasProperty(b, key)) && b[key] === val));

  /**
   * Make an object immutable. This hurts performance and is usually not needed if you perform good
   * coding practices.
   */
  const freeze = Object.freeze;

  /**
   * Make an object and all its children immutable.
   * This *really* hurts performance and is usually not needed if you perform good coding practices.
   *
   * @template {any} T
   * @param {T} o
   * @return {Readonly<T>}
   */
  const deepFreeze = (o) => {
    for (const key in o) {
      const c = o[key];
      if (typeof c === 'object' || typeof c === 'function') {
        deepFreeze(o[key]);
      }
    }
    return freeze(o)
  };

  /**
   * Common functions and function call helpers.
   *
   * @module function
   */

  /**
   * Calls all functions in `fs` with args. Only throws after all functions were called.
   *
   * @param {Array<function>} fs
   * @param {Array<any>} args
   */
  const callAll = (fs, args, i = 0) => {
    try {
      for (; i < fs.length; i++) {
        fs[i](...args);
      }
    } finally {
      if (i < fs.length) {
        callAll(fs, args, i + 1);
      }
    }
  };

  /**
   * @template A
   *
   * @param {A} a
   * @return {A}
   */
  const id = a => a;

  /**
   * @template V
   * @template {V} OPTS
   *
   * @param {V} value
   * @param {Array<OPTS>} options
   */
  // @ts-ignore
  const isOneOf = (value, options) => options.includes(value);

  /* c8 ignore next 2 */
  // @ts-ignore
  const isNode = typeof browser$2 !== 'undefined' && browser$2.release && /node|io\.js/.test(browser$2.release.name) && Object.prototype.toString.call(typeof browser$2 !== 'undefined' ? browser$2 : 0) === '[object process]';

  /* c8 ignore next */
  const isBrowser = typeof window !== 'undefined' && typeof document !== 'undefined' && !isNode;
  /* c8 ignore next 3 */
  typeof navigator !== 'undefined'
    ? /Mac/.test(navigator.platform)
    : false;

  /**
   * @type {Map<string,string>}
   */
  let params;

  /* c8 ignore start */
  const computeParams = () => {
    if (params === undefined) {
      if (isNode) {
        params = create$6();
        const pargs = browser$2.argv;
        let currParamName = null;
        for (let i = 0; i < pargs.length; i++) {
          const parg = pargs[i];
          if (parg[0] === '-') {
            if (currParamName !== null) {
              params.set(currParamName, '');
            }
            currParamName = parg;
          } else {
            if (currParamName !== null) {
              params.set(currParamName, parg);
              currParamName = null;
            }
          }
        }
        if (currParamName !== null) {
          params.set(currParamName, '');
        }
        // in ReactNative for example this would not be true (unless connected to the Remote Debugger)
      } else if (typeof location === 'object') {
        params = create$6(); // eslint-disable-next-line no-undef
        (location.search || '?').slice(1).split('&').forEach((kv) => {
          if (kv.length !== 0) {
            const [key, value] = kv.split('=');
            params.set(`--${fromCamelCase(key, '-')}`, value);
            params.set(`-${fromCamelCase(key, '-')}`, value);
          }
        });
      } else {
        params = create$6();
      }
    }
    return params
  };
  /* c8 ignore stop */

  /**
   * @param {string} name
   * @return {boolean}
   */
  /* c8 ignore next */
  const hasParam = (name) => computeParams().has(name);

  /**
   * @param {string} name
   * @param {string} defaultVal
   * @return {string}
   */
  /* c8 ignore next 2 */
  const getParam = (name, defaultVal) =>
    computeParams().get(name) || defaultVal;

  /**
   * @param {string} name
   * @return {string|null}
   */
  /* c8 ignore next 4 */
  const getVariable = (name) =>
    isNode
      ? undefinedToNull(browser$2.env[name.toUpperCase().replaceAll('-', '_')])
      : undefinedToNull(varStorage.getItem(name));

  /**
   * @param {string} name
   * @return {boolean}
   */
  /* c8 ignore next 2 */
  const hasConf = (name) =>
    hasParam('--' + name) || getVariable(name) !== null;

  /* c8 ignore next */
  hasConf('production');

  /* c8 ignore next 2 */
  const forceColor = isNode &&
    isOneOf(browser$2.env.FORCE_COLOR, ['true', '1', '2']);

  /* c8 ignore start */
  /**
   * Color is enabled by default if the terminal supports it.
   *
   * Explicitly enable color using `--color` parameter
   * Disable color using `--no-color` parameter or using `NO_COLOR=1` environment variable.
   * `FORCE_COLOR=1` enables color and takes precedence over all.
   */
  const supportsColor = forceColor || (
    !hasParam('--no-colors') && // @todo deprecate --no-colors
    !hasConf('no-color') &&
    (!isNode || browser$2.stdout.isTTY) && (
      !isNode ||
      hasParam('--color') ||
      getVariable('COLORTERM') !== null ||
      (getVariable('TERM') || '').includes('color')
    )
  );
  /* c8 ignore stop */

  /**
   * @param {number} len
   */
  const createUint8ArrayFromLen = len => new Uint8Array(len);

  /**
   * Copy the content of an Uint8Array view to a new ArrayBuffer.
   *
   * @param {Uint8Array} uint8Array
   * @return {Uint8Array}
   */
  const copyUint8Array = uint8Array => {
    const newBuf = createUint8ArrayFromLen(uint8Array.byteLength);
    newBuf.set(uint8Array);
    return newBuf
  };

  /**
   * Encode anything as a UInt8Array. It's a pun on typescripts's `any` type.
   * See encoding.writeAny for more information.
   *
   * @param {any} data
   * @return {Uint8Array}
   */
  const encodeAny = data =>
    encode(encoder => writeAny(encoder, data));

  /**
   * Decode an any-encoded value.
   *
   * @param {Uint8Array} buf
   * @return {any}
   */
  const decodeAny = buf => readAny(createDecoder(buf));

  /**
   * Working with value pairs.
   *
   * @module pair
   */

  /**
   * @template L,R
   */
  class Pair {
    /**
     * @param {L} left
     * @param {R} right
     */
    constructor (left, right) {
      this.left = left;
      this.right = right;
    }
  }

  /**
   * @template L,R
   * @param {L} left
   * @param {R} right
   * @return {Pair<L,R>}
   */
  const create$2 = (left, right) => new Pair(left, right);

  /**
   * @template L,R
   * @param {Array<Pair<L,R>>} arr
   * @param {function(L, R):any} f
   */
  const forEach$1 = (arr, f) => arr.forEach(p => f(p.left, p.right));

  /* eslint-env browser */

  /* c8 ignore start */
  /**
   * @type {Document}
   */
  const doc = /** @type {Document} */ (typeof document !== 'undefined' ? document : {});

  /**
   * @param {string} name
   * @return {HTMLElement}
   */
  const createElement = name => doc.createElement(name);

  /**
   * @return {DocumentFragment}
   */
  const createDocumentFragment = () => doc.createDocumentFragment();

  /**
   * @param {string} text
   * @return {Text}
   */
  const createTextNode = text => doc.createTextNode(text);

  /** @type {DOMParser} */ (typeof DOMParser !== 'undefined' ? new DOMParser() : null);

  /**
   * @param {Element} el
   * @param {Array<pair.Pair<string,string|boolean>>} attrs Array of key-value pairs
   * @return {Element}
   */
  const setAttributes = (el, attrs) => {
    forEach$1(attrs, (key, value) => {
      if (value === false) {
        el.removeAttribute(key);
      } else if (value === true) {
        el.setAttribute(key, '');
      } else {
        // @ts-ignore
        el.setAttribute(key, value);
      }
    });
    return el
  };

  /**
   * @param {Array<Node>|HTMLCollection} children
   * @return {DocumentFragment}
   */
  const fragment = children => {
    const fragment = createDocumentFragment();
    for (let i = 0; i < children.length; i++) {
      appendChild(fragment, children[i]);
    }
    return fragment
  };

  /**
   * @param {Element} parent
   * @param {Array<Node>} nodes
   * @return {Element}
   */
  const append = (parent, nodes) => {
    appendChild(parent, fragment(nodes));
    return parent
  };

  /**
   * @param {EventTarget} el
   * @param {string} name
   * @param {EventListener} f
   */
  const addEventListener = (el, name, f) => el.addEventListener(name, f);

  /**
   * @param {string} name
   * @param {Array<pair.Pair<string,string>|pair.Pair<string,boolean>>} attrs Array of key-value pairs
   * @param {Array<Node>} children
   * @return {Element}
   */
  const element = (name, attrs = [], children = []) =>
    append(setAttributes(createElement(name), attrs), children);

  /**
   * @param {string} t
   * @return {Text}
   */
  const text = createTextNode;

  /**
   * @param {Map<string,string>} m
   * @return {string}
   */
  const mapToStyleString = m => map$2(m, (value, key) => `${key}:${value};`).join('');

  /**
   * @param {Node} parent
   * @param {Node} child
   * @return {Node}
   */
  const appendChild = (parent, child) => parent.appendChild(child);

  doc.ELEMENT_NODE;
  doc.TEXT_NODE;
  doc.CDATA_SECTION_NODE;
  doc.COMMENT_NODE;
  doc.DOCUMENT_NODE;
  doc.DOCUMENT_TYPE_NODE;
  doc.DOCUMENT_FRAGMENT_NODE;
  /* c8 ignore stop */

  /**
   * JSON utility functions.
   *
   * @module json
   */

  /**
   * Transform JavaScript object to JSON.
   *
   * @param {any} object
   * @return {string}
   */
  const stringify = JSON.stringify;

  /* global requestIdleCallback, requestAnimationFrame, cancelIdleCallback, cancelAnimationFrame */

  /**
   * Utility module to work with EcmaScript's event loop.
   *
   * @module eventloop
   */

  /**
   * @type {Array<function>}
   */
  let queue = [];

  const _runQueue = () => {
    for (let i = 0; i < queue.length; i++) {
      queue[i]();
    }
    queue = [];
  };

  /**
   * @param {function():void} f
   */
  const enqueue = f => {
    queue.push(f);
    if (queue.length === 1) {
      setTimeout(_runQueue, 0);
    }
  };

  /**
   * Utility module to work with EcmaScript Symbols.
   *
   * @module symbol
   */

  /**
   * Return fresh symbol.
   *
   * @return {Symbol}
   */
  const create$1 = Symbol;

  const BOLD = create$1();
  const UNBOLD = create$1();
  const BLUE = create$1();
  const GREY = create$1();
  const GREEN = create$1();
  const RED = create$1();
  const PURPLE = create$1();
  const ORANGE = create$1();
  const UNCOLOR = create$1();

  /* c8 ignore start */
  /**
   * @param {Array<undefined|string|Symbol|Object|number|function():any>} args
   * @return {Array<string|object|number|undefined>}
   */
  const computeNoColorLoggingArgs = args => {
    if (args.length === 1 && args[0]?.constructor === Function) {
      args = /** @type {Array<string|Symbol|Object|number>} */ (/** @type {[function]} */ (args)[0]());
    }
    const strBuilder = [];
    const logArgs = [];
    // try with formatting until we find something unsupported
    let i = 0;
    for (; i < args.length; i++) {
      const arg = args[i];
      if (arg === undefined) {
        break
      } else if (arg.constructor === String || arg.constructor === Number) {
        strBuilder.push(arg);
      } else if (arg.constructor === Object) {
        break
      }
    }
    if (i > 0) {
      // create logArgs with what we have so far
      logArgs.push(strBuilder.join(''));
    }
    // append the rest
    for (; i < args.length; i++) {
      const arg = args[i];
      if (!(arg instanceof Symbol)) {
        logArgs.push(arg);
      }
    }
    return logArgs
  };
  /* c8 ignore stop */

  /**
   * Isomorphic logging module with support for colors!
   *
   * @module logging
   */

  /**
   * @type {Object<Symbol,pair.Pair<string,string>>}
   */
  const _browserStyleMap = {
    [BOLD]: create$2('font-weight', 'bold'),
    [UNBOLD]: create$2('font-weight', 'normal'),
    [BLUE]: create$2('color', 'blue'),
    [GREEN]: create$2('color', 'green'),
    [GREY]: create$2('color', 'grey'),
    [RED]: create$2('color', 'red'),
    [PURPLE]: create$2('color', 'purple'),
    [ORANGE]: create$2('color', 'orange'), // not well supported in chrome when debugging node with inspector - TODO: deprecate
    [UNCOLOR]: create$2('color', 'black')
  };

  /**
   * @param {Array<string|Symbol|Object|number|function():any>} args
   * @return {Array<string|object|number>}
   */
  /* c8 ignore start */
  const computeBrowserLoggingArgs = (args) => {
    if (args.length === 1 && args[0]?.constructor === Function) {
      args = /** @type {Array<string|Symbol|Object|number>} */ (/** @type {[function]} */ (args)[0]());
    }
    const strBuilder = [];
    const styles = [];
    const currentStyle = create$6();
    /**
     * @type {Array<string|Object|number>}
     */
    let logArgs = [];
    // try with formatting until we find something unsupported
    let i = 0;
    for (; i < args.length; i++) {
      const arg = args[i];
      // @ts-ignore
      const style = _browserStyleMap[arg];
      if (style !== undefined) {
        currentStyle.set(style.left, style.right);
      } else {
        if (arg === undefined) {
          break
        }
        if (arg.constructor === String || arg.constructor === Number) {
          const style = mapToStyleString(currentStyle);
          if (i > 0 || style.length > 0) {
            strBuilder.push('%c' + arg);
            styles.push(style);
          } else {
            strBuilder.push(arg);
          }
        } else {
          break
        }
      }
    }
    if (i > 0) {
      // create logArgs with what we have so far
      logArgs = styles;
      logArgs.unshift(strBuilder.join(''));
    }
    // append the rest
    for (; i < args.length; i++) {
      const arg = args[i];
      if (!(arg instanceof Symbol)) {
        logArgs.push(arg);
      }
    }
    return logArgs
  };
  /* c8 ignore stop */

  /* c8 ignore start */
  const computeLoggingArgs = supportsColor
    ? computeBrowserLoggingArgs
    : computeNoColorLoggingArgs;
  /* c8 ignore stop */

  /**
   * @param {Array<string|Symbol|Object|number>} args
   */
  const print = (...args) => {
    console.log(...computeLoggingArgs(args));
    /* c8 ignore next */
    vconsoles.forEach((vc) => vc.print(args));
  };

  /* c8 ignore start */
  /**
   * @param {Array<string|Symbol|Object|number>} args
   */
  const warn = (...args) => {
    console.warn(...computeLoggingArgs(args));
    args.unshift(ORANGE);
    vconsoles.forEach((vc) => vc.print(args));
  };
  /* c8 ignore stop */

  /**
   * @param {Error} err
   */
  /* c8 ignore start */
  const printError = (err) => {
    console.error(err);
    vconsoles.forEach((vc) => vc.printError(err));
  };
  /* c8 ignore stop */

  /**
   * @param {string} url image location
   * @param {number} height height of the image in pixel
   */
  /* c8 ignore start */
  const printImg = (url, height) => {
    if (isBrowser) {
      console.log(
        '%c                      ',
        `font-size: ${height}px; background-size: contain; background-repeat: no-repeat; background-image: url(${url})`
      );
      // console.log('%c                ', `font-size: ${height}x; background: url(${url}) no-repeat;`)
    }
    vconsoles.forEach((vc) => vc.printImg(url, height));
  };
  /* c8 ignore stop */

  /**
   * @param {string} base64
   * @param {number} height
   */
  /* c8 ignore next 2 */
  const printImgBase64 = (base64, height) =>
    printImg(`data:image/gif;base64,${base64}`, height);

  /**
   * @param {Array<string|Symbol|Object|number>} args
   */
  const group = (...args) => {
    console.group(...computeLoggingArgs(args));
    /* c8 ignore next */
    vconsoles.forEach((vc) => vc.group(args));
  };

  /**
   * @param {Array<string|Symbol|Object|number>} args
   */
  const groupCollapsed = (...args) => {
    console.groupCollapsed(...computeLoggingArgs(args));
    /* c8 ignore next */
    vconsoles.forEach((vc) => vc.groupCollapsed(args));
  };

  const groupEnd = () => {
    console.groupEnd();
    /* c8 ignore next */
    vconsoles.forEach((vc) => vc.groupEnd());
  };

  const vconsoles = create$5();

  /**
   * @param {Array<string|Symbol|Object|number>} args
   * @return {Array<Element>}
   */
  /* c8 ignore start */
  const _computeLineSpans = (args) => {
    const spans = [];
    const currentStyle = new Map();
    // try with formatting until we find something unsupported
    let i = 0;
    for (; i < args.length; i++) {
      let arg = args[i];
      // @ts-ignore
      const style = _browserStyleMap[arg];
      if (style !== undefined) {
        currentStyle.set(style.left, style.right);
      } else {
        if (arg === undefined) {
          arg = 'undefined ';
        }
        if (arg.constructor === String || arg.constructor === Number) {
          // @ts-ignore
          const span = element('span', [
            create$2('style', mapToStyleString(currentStyle))
          ], [text(arg.toString())]);
          if (span.innerHTML === '') {
            span.innerHTML = '&nbsp;';
          }
          spans.push(span);
        } else {
          break
        }
      }
    }
    // append the rest
    for (; i < args.length; i++) {
      let content = args[i];
      if (!(content instanceof Symbol)) {
        if (content.constructor !== String && content.constructor !== Number) {
          content = ' ' + stringify(content) + ' ';
        }
        spans.push(
          element('span', [], [text(/** @type {string} */ (content))])
        );
      }
    }
    return spans
  };
  /* c8 ignore stop */

  const lineStyle =
    'font-family:monospace;border-bottom:1px solid #e2e2e2;padding:2px;';

  /* c8 ignore start */
  class VConsole {
    /**
     * @param {Element} dom
     */
    constructor (dom) {
      this.dom = dom;
      /**
       * @type {Element}
       */
      this.ccontainer = this.dom;
      this.depth = 0;
      vconsoles.add(this);
    }

    /**
     * @param {Array<string|Symbol|Object|number>} args
     * @param {boolean} collapsed
     */
    group (args, collapsed = false) {
      enqueue(() => {
        const triangleDown = element('span', [
          create$2('hidden', collapsed),
          create$2('style', 'color:grey;font-size:120%;')
        ], [text('▼')]);
        const triangleRight = element('span', [
          create$2('hidden', !collapsed),
          create$2('style', 'color:grey;font-size:125%;')
        ], [text('▶')]);
        const content = element(
          'div',
          [create$2(
            'style',
            `${lineStyle};padding-left:${this.depth * 10}px`
          )],
          [triangleDown, triangleRight, text(' ')].concat(
            _computeLineSpans(args)
          )
        );
        const nextContainer = element('div', [
          create$2('hidden', collapsed)
        ]);
        const nextLine = element('div', [], [content, nextContainer]);
        append(this.ccontainer, [nextLine]);
        this.ccontainer = nextContainer;
        this.depth++;
        // when header is clicked, collapse/uncollapse container
        addEventListener(content, 'click', (_event) => {
          nextContainer.toggleAttribute('hidden');
          triangleDown.toggleAttribute('hidden');
          triangleRight.toggleAttribute('hidden');
        });
      });
    }

    /**
     * @param {Array<string|Symbol|Object|number>} args
     */
    groupCollapsed (args) {
      this.group(args, true);
    }

    groupEnd () {
      enqueue(() => {
        if (this.depth > 0) {
          this.depth--;
          // @ts-ignore
          this.ccontainer = this.ccontainer.parentElement.parentElement;
        }
      });
    }

    /**
     * @param {Array<string|Symbol|Object|number>} args
     */
    print (args) {
      enqueue(() => {
        append(this.ccontainer, [
          element('div', [
            create$2(
              'style',
              `${lineStyle};padding-left:${this.depth * 10}px`
            )
          ], _computeLineSpans(args))
        ]);
      });
    }

    /**
     * @param {Error} err
     */
    printError (err) {
      this.print([RED, BOLD, err.toString()]);
    }

    /**
     * @param {string} url
     * @param {number} height
     */
    printImg (url, height) {
      enqueue(() => {
        append(this.ccontainer, [
          element('img', [
            create$2('src', url),
            create$2('height', `${round(height * 1.5)}px`)
          ])
        ]);
      });
    }

    /**
     * @param {Node} node
     */
    printDom (node) {
      enqueue(() => {
        append(this.ccontainer, [node]);
      });
    }

    destroy () {
      enqueue(() => {
        vconsoles.delete(this);
      });
    }
  }
  /* c8 ignore stop */

  /**
   * @param {Element} dom
   */
  /* c8 ignore next */
  const createVConsole = (dom) => new VConsole(dom);

  /**
   * Utility module to create and manipulate Iterators.
   *
   * @module iterator
   */

  /**
   * @template T
   * @param {function():IteratorResult<T>} next
   * @return {IterableIterator<T>}
   */
  const createIterator = next => ({
    /**
     * @return {IterableIterator<T>}
     */
    [Symbol.iterator] () {
      return this
    },
    // @ts-ignore
    next
  });

  /**
   * @template T
   * @param {Iterator<T>} iterator
   * @param {function(T):boolean} filter
   */
  const iteratorFilter = (iterator, filter) => createIterator(() => {
    let res;
    do {
      res = iterator.next();
    } while (!res.done && !filter(res.value))
    return res
  });

  /**
   * @template T,M
   * @param {Iterator<T>} iterator
   * @param {function(T):M} fmap
   */
  const iteratorMap = (iterator, fmap) => createIterator(() => {
    const { done, value } = iterator.next();
    return { done, value: done ? undefined : fmap(value) }
  });

  /**
   * This is an abstract interface that all Connectors should implement to keep them interchangeable.
   *
   * @note This interface is experimental and it is not advised to actually inherit this class.
   *       It just serves as typing information.
   *
   * @extends {ObservableV2<any>}
   */
  class AbstractConnector extends ObservableV2 {
    /**
     * @param {Doc} ydoc
     * @param {any} awareness
     */
    constructor (ydoc, awareness) {
      super();
      this.doc = ydoc;
      this.awareness = awareness;
    }
  }

  class DeleteItem {
    /**
     * @param {number} clock
     * @param {number} len
     */
    constructor (clock, len) {
      /**
       * @type {number}
       */
      this.clock = clock;
      /**
       * @type {number}
       */
      this.len = len;
    }
  }

  /**
   * We no longer maintain a DeleteStore. DeleteSet is a temporary object that is created when needed.
   * - When created in a transaction, it must only be accessed after sorting, and merging
   *   - This DeleteSet is send to other clients
   * - We do not create a DeleteSet when we send a sync message. The DeleteSet message is created directly from StructStore
   * - We read a DeleteSet as part of a sync/update message. In this case the DeleteSet is already sorted and merged.
   */
  class DeleteSet {
    constructor () {
      /**
       * @type {Map<number,Array<DeleteItem>>}
       */
      this.clients = new Map();
    }
  }

  /**
   * Iterate over all structs that the DeleteSet gc's.
   *
   * @param {Transaction} transaction
   * @param {DeleteSet} ds
   * @param {function(GC|Item):void} f
   *
   * @function
   */
  const iterateDeletedStructs = (transaction, ds, f) =>
    ds.clients.forEach((deletes, clientid) => {
      const structs = /** @type {Array<GC|Item>} */ (transaction.doc.store.clients.get(clientid));
      if (structs != null) {
        const lastStruct = structs[structs.length - 1];
        const clockState = lastStruct.id.clock + lastStruct.length;
        for (let i = 0, del = deletes[i]; i < deletes.length && del.clock < clockState; del = deletes[++i]) {
          iterateStructs(transaction, structs, del.clock, del.len, f);
        }
      }
    });

  /**
   * @param {Array<DeleteItem>} dis
   * @param {number} clock
   * @return {number|null}
   *
   * @private
   * @function
   */
  const findIndexDS = (dis, clock) => {
    let left = 0;
    let right = dis.length - 1;
    while (left <= right) {
      const midindex = floor((left + right) / 2);
      const mid = dis[midindex];
      const midclock = mid.clock;
      if (midclock <= clock) {
        if (clock < midclock + mid.len) {
          return midindex
        }
        left = midindex + 1;
      } else {
        right = midindex - 1;
      }
    }
    return null
  };

  /**
   * @param {DeleteSet} ds
   * @param {ID} id
   * @return {boolean}
   *
   * @private
   * @function
   */
  const isDeleted = (ds, id) => {
    const dis = ds.clients.get(id.client);
    return dis !== undefined && findIndexDS(dis, id.clock) !== null
  };

  /**
   * @param {DeleteSet} ds
   *
   * @private
   * @function
   */
  const sortAndMergeDeleteSet = ds => {
    ds.clients.forEach(dels => {
      dels.sort((a, b) => a.clock - b.clock);
      // merge items without filtering or splicing the array
      // i is the current pointer
      // j refers to the current insert position for the pointed item
      // try to merge dels[i] into dels[j-1] or set dels[j]=dels[i]
      let i, j;
      for (i = 1, j = 1; i < dels.length; i++) {
        const left = dels[j - 1];
        const right = dels[i];
        if (left.clock + left.len >= right.clock) {
          left.len = max(left.len, right.clock + right.len - left.clock);
        } else {
          if (j < i) {
            dels[j] = right;
          }
          j++;
        }
      }
      dels.length = j;
    });
  };

  /**
   * @param {Array<DeleteSet>} dss
   * @return {DeleteSet} A fresh DeleteSet
   */
  const mergeDeleteSets = dss => {
    const merged = new DeleteSet();
    for (let dssI = 0; dssI < dss.length; dssI++) {
      dss[dssI].clients.forEach((delsLeft, client) => {
        if (!merged.clients.has(client)) {
          // Write all missing keys from current ds and all following.
          // If merged already contains `client` current ds has already been added.
          /**
           * @type {Array<DeleteItem>}
           */
          const dels = delsLeft.slice();
          for (let i = dssI + 1; i < dss.length; i++) {
            appendTo(dels, dss[i].clients.get(client) || []);
          }
          merged.clients.set(client, dels);
        }
      });
    }
    sortAndMergeDeleteSet(merged);
    return merged
  };

  /**
   * @param {DeleteSet} ds
   * @param {number} client
   * @param {number} clock
   * @param {number} length
   *
   * @private
   * @function
   */
  const addToDeleteSet = (ds, client, clock, length) => {
    setIfUndefined(ds.clients, client, () => /** @type {Array<DeleteItem>} */ ([])).push(new DeleteItem(clock, length));
  };

  const createDeleteSet = () => new DeleteSet();

  /**
   * @param {StructStore} ss
   * @return {DeleteSet} Merged and sorted DeleteSet
   *
   * @private
   * @function
   */
  const createDeleteSetFromStructStore = ss => {
    const ds = createDeleteSet();
    ss.clients.forEach((structs, client) => {
      /**
       * @type {Array<DeleteItem>}
       */
      const dsitems = [];
      for (let i = 0; i < structs.length; i++) {
        const struct = structs[i];
        if (struct.deleted) {
          const clock = struct.id.clock;
          let len = struct.length;
          if (i + 1 < structs.length) {
            for (let next = structs[i + 1]; i + 1 < structs.length && next.deleted; next = structs[++i + 1]) {
              len += next.length;
            }
          }
          dsitems.push(new DeleteItem(clock, len));
        }
      }
      if (dsitems.length > 0) {
        ds.clients.set(client, dsitems);
      }
    });
    return ds
  };

  /**
   * @param {DSEncoderV1 | DSEncoderV2} encoder
   * @param {DeleteSet} ds
   *
   * @private
   * @function
   */
  const writeDeleteSet = (encoder, ds) => {
    writeVarUint(encoder.restEncoder, ds.clients.size);

    // Ensure that the delete set is written in a deterministic order
    from$2(ds.clients.entries())
      .sort((a, b) => b[0] - a[0])
      .forEach(([client, dsitems]) => {
        encoder.resetDsCurVal();
        writeVarUint(encoder.restEncoder, client);
        const len = dsitems.length;
        writeVarUint(encoder.restEncoder, len);
        for (let i = 0; i < len; i++) {
          const item = dsitems[i];
          encoder.writeDsClock(item.clock);
          encoder.writeDsLen(item.len);
        }
      });
  };

  /**
   * @param {DSDecoderV1 | DSDecoderV2} decoder
   * @return {DeleteSet}
   *
   * @private
   * @function
   */
  const readDeleteSet = decoder => {
    const ds = new DeleteSet();
    const numClients = readVarUint(decoder.restDecoder);
    for (let i = 0; i < numClients; i++) {
      decoder.resetDsCurVal();
      const client = readVarUint(decoder.restDecoder);
      const numberOfDeletes = readVarUint(decoder.restDecoder);
      if (numberOfDeletes > 0) {
        const dsField = setIfUndefined(ds.clients, client, () => /** @type {Array<DeleteItem>} */ ([]));
        for (let i = 0; i < numberOfDeletes; i++) {
          dsField.push(new DeleteItem(decoder.readDsClock(), decoder.readDsLen()));
        }
      }
    }
    return ds
  };

  /**
   * @todo YDecoder also contains references to String and other Decoders. Would make sense to exchange YDecoder.toUint8Array for YDecoder.DsToUint8Array()..
   */

  /**
   * @param {DSDecoderV1 | DSDecoderV2} decoder
   * @param {Transaction} transaction
   * @param {StructStore} store
   * @return {Uint8Array|null} Returns a v2 update containing all deletes that couldn't be applied yet; or null if all deletes were applied successfully.
   *
   * @private
   * @function
   */
  const readAndApplyDeleteSet = (decoder, transaction, store) => {
    const unappliedDS = new DeleteSet();
    const numClients = readVarUint(decoder.restDecoder);
    for (let i = 0; i < numClients; i++) {
      decoder.resetDsCurVal();
      const client = readVarUint(decoder.restDecoder);
      const numberOfDeletes = readVarUint(decoder.restDecoder);
      const structs = store.clients.get(client) || [];
      const state = getState(store, client);
      for (let i = 0; i < numberOfDeletes; i++) {
        const clock = decoder.readDsClock();
        const clockEnd = clock + decoder.readDsLen();
        if (clock < state) {
          if (state < clockEnd) {
            addToDeleteSet(unappliedDS, client, state, clockEnd - state);
          }
          let index = findIndexSS(structs, clock);
          /**
           * We can ignore the case of GC and Delete structs, because we are going to skip them
           * @type {Item}
           */
          // @ts-ignore
          let struct = structs[index];
          // split the first item if necessary
          if (!struct.deleted && struct.id.clock < clock) {
            structs.splice(index + 1, 0, splitItem(transaction, struct, clock - struct.id.clock));
            index++; // increase we now want to use the next struct
          }
          while (index < structs.length) {
            // @ts-ignore
            struct = structs[index++];
            if (struct.id.clock < clockEnd) {
              if (!struct.deleted) {
                if (clockEnd < struct.id.clock + struct.length) {
                  structs.splice(index, 0, splitItem(transaction, struct, clockEnd - struct.id.clock));
                }
                struct.delete(transaction);
              }
            } else {
              break
            }
          }
        } else {
          addToDeleteSet(unappliedDS, client, clock, clockEnd - clock);
        }
      }
    }
    if (unappliedDS.clients.size > 0) {
      const ds = new UpdateEncoderV2();
      writeVarUint(ds.restEncoder, 0); // encode 0 structs
      writeDeleteSet(ds, unappliedDS);
      return ds.toUint8Array()
    }
    return null
  };

  /**
   * @module Y
   */


  const generateNewClientId = uint32;

  /**
   * @typedef {Object} DocOpts
   * @property {boolean} [DocOpts.gc=true] Disable garbage collection (default: gc=true)
   * @property {function(Item):boolean} [DocOpts.gcFilter] Will be called before an Item is garbage collected. Return false to keep the Item.
   * @property {string} [DocOpts.guid] Define a globally unique identifier for this document
   * @property {string | null} [DocOpts.collectionid] Associate this document with a collection. This only plays a role if your provider has a concept of collection.
   * @property {any} [DocOpts.meta] Any kind of meta information you want to associate with this document. If this is a subdocument, remote peers will store the meta information as well.
   * @property {boolean} [DocOpts.autoLoad] If a subdocument, automatically load document. If this is a subdocument, remote peers will load the document as well automatically.
   * @property {boolean} [DocOpts.shouldLoad] Whether the document should be synced by the provider now. This is toggled to true when you call ydoc.load()
   */

  /**
   * @typedef {Object} DocEvents
   * @property {function(Doc):void} DocEvents.destroy
   * @property {function(Doc):void} DocEvents.load
   * @property {function(boolean, Doc):void} DocEvents.sync
   * @property {function(Uint8Array, any, Doc, Transaction):void} DocEvents.update
   * @property {function(Uint8Array, any, Doc, Transaction):void} DocEvents.updateV2
   * @property {function(Doc):void} DocEvents.beforeAllTransactions
   * @property {function(Transaction, Doc):void} DocEvents.beforeTransaction
   * @property {function(Transaction, Doc):void} DocEvents.beforeObserverCalls
   * @property {function(Transaction, Doc):void} DocEvents.afterTransaction
   * @property {function(Transaction, Doc):void} DocEvents.afterTransactionCleanup
   * @property {function(Doc, Array<Transaction>):void} DocEvents.afterAllTransactions
   * @property {function({ loaded: Set<Doc>, added: Set<Doc>, removed: Set<Doc> }, Doc, Transaction):void} DocEvents.subdocs
   */

  /**
   * A Yjs instance handles the state of shared data.
   * @extends ObservableV2<DocEvents>
   */
  class Doc extends ObservableV2 {
    /**
     * @param {DocOpts} opts configuration
     */
    constructor ({ guid = uuidv4(), collectionid = null, gc = true, gcFilter = () => true, meta = null, autoLoad = false, shouldLoad = true } = {}) {
      super();
      this.gc = gc;
      this.gcFilter = gcFilter;
      this.clientID = generateNewClientId();
      this.guid = guid;
      this.collectionid = collectionid;
      /**
       * @type {Map<string, AbstractType<YEvent<any>>>}
       */
      this.share = new Map();
      this.store = new StructStore();
      /**
       * @type {Transaction | null}
       */
      this._transaction = null;
      /**
       * @type {Array<Transaction>}
       */
      this._transactionCleanups = [];
      /**
       * @type {Set<Doc>}
       */
      this.subdocs = new Set();
      /**
       * If this document is a subdocument - a document integrated into another document - then _item is defined.
       * @type {Item?}
       */
      this._item = null;
      this.shouldLoad = shouldLoad;
      this.autoLoad = autoLoad;
      this.meta = meta;
      /**
       * This is set to true when the persistence provider loaded the document from the database or when the `sync` event fires.
       * Note that not all providers implement this feature. Provider authors are encouraged to fire the `load` event when the doc content is loaded from the database.
       *
       * @type {boolean}
       */
      this.isLoaded = false;
      /**
       * This is set to true when the connection provider has successfully synced with a backend.
       * Note that when using peer-to-peer providers this event may not provide very useful.
       * Also note that not all providers implement this feature. Provider authors are encouraged to fire
       * the `sync` event when the doc has been synced (with `true` as a parameter) or if connection is
       * lost (with false as a parameter).
       */
      this.isSynced = false;
      this.isDestroyed = false;
      /**
       * Promise that resolves once the document has been loaded from a persistence provider.
       */
      this.whenLoaded = create$3(resolve => {
        this.on('load', () => {
          this.isLoaded = true;
          resolve(this);
        });
      });
      const provideSyncedPromise = () => create$3(resolve => {
        /**
         * @param {boolean} isSynced
         */
        const eventHandler = (isSynced) => {
          if (isSynced === undefined || isSynced === true) {
            this.off('sync', eventHandler);
            resolve();
          }
        };
        this.on('sync', eventHandler);
      });
      this.on('sync', isSynced => {
        if (isSynced === false && this.isSynced) {
          this.whenSynced = provideSyncedPromise();
        }
        this.isSynced = isSynced === undefined || isSynced === true;
        if (this.isSynced && !this.isLoaded) {
          this.emit('load', [this]);
        }
      });
      /**
       * Promise that resolves once the document has been synced with a backend.
       * This promise is recreated when the connection is lost.
       * Note the documentation about the `isSynced` property.
       */
      this.whenSynced = provideSyncedPromise();
    }

    /**
     * Notify the parent document that you request to load data into this subdocument (if it is a subdocument).
     *
     * `load()` might be used in the future to request any provider to load the most current data.
     *
     * It is safe to call `load()` multiple times.
     */
    load () {
      const item = this._item;
      if (item !== null && !this.shouldLoad) {
        transact(/** @type {any} */ (item.parent).doc, transaction => {
          transaction.subdocsLoaded.add(this);
        }, null, true);
      }
      this.shouldLoad = true;
    }

    getSubdocs () {
      return this.subdocs
    }

    getSubdocGuids () {
      return new Set(from$2(this.subdocs).map(doc => doc.guid))
    }

    /**
     * Changes that happen inside of a transaction are bundled. This means that
     * the observer fires _after_ the transaction is finished and that all changes
     * that happened inside of the transaction are sent as one message to the
     * other peers.
     *
     * @template T
     * @param {function(Transaction):T} f The function that should be executed as a transaction
     * @param {any} [origin] Origin of who started the transaction. Will be stored on transaction.origin
     * @return T
     *
     * @public
     */
    transact (f, origin = null) {
      return transact(this, f, origin)
    }

    /**
     * Define a shared data type.
     *
     * Multiple calls of `ydoc.get(name, TypeConstructor)` yield the same result
     * and do not overwrite each other. I.e.
     * `ydoc.get(name, Y.Array) === ydoc.get(name, Y.Array)`
     *
     * After this method is called, the type is also available on `ydoc.share.get(name)`.
     *
     * *Best Practices:*
     * Define all types right after the Y.Doc instance is created and store them in a separate object.
     * Also use the typed methods `getText(name)`, `getArray(name)`, ..
     *
     * @template {typeof AbstractType<any>} Type
     * @example
     *   const ydoc = new Y.Doc(..)
     *   const appState = {
     *     document: ydoc.getText('document')
     *     comments: ydoc.getArray('comments')
     *   }
     *
     * @param {string} name
     * @param {Type} TypeConstructor The constructor of the type definition. E.g. Y.Text, Y.Array, Y.Map, ...
     * @return {InstanceType<Type>} The created type. Constructed with TypeConstructor
     *
     * @public
     */
    get (name, TypeConstructor = /** @type {any} */ (AbstractType)) {
      const type = setIfUndefined(this.share, name, () => {
        // @ts-ignore
        const t = new TypeConstructor();
        t._integrate(this, null);
        return t
      });
      const Constr = type.constructor;
      if (TypeConstructor !== AbstractType && Constr !== TypeConstructor) {
        if (Constr === AbstractType) {
          // @ts-ignore
          const t = new TypeConstructor();
          t._map = type._map;
          type._map.forEach(/** @param {Item?} n */ n => {
            for (; n !== null; n = n.left) {
              // @ts-ignore
              n.parent = t;
            }
          });
          t._start = type._start;
          for (let n = t._start; n !== null; n = n.right) {
            n.parent = t;
          }
          t._length = type._length;
          this.share.set(name, t);
          t._integrate(this, null);
          return /** @type {InstanceType<Type>} */ (t)
        } else {
          throw new Error(`Type with the name ${name} has already been defined with a different constructor`)
        }
      }
      return /** @type {InstanceType<Type>} */ (type)
    }

    /**
     * @template T
     * @param {string} [name]
     * @return {YArray<T>}
     *
     * @public
     */
    getArray (name = '') {
      return /** @type {YArray<T>} */ (this.get(name, YArray))
    }

    /**
     * @param {string} [name]
     * @return {YText}
     *
     * @public
     */
    getText (name = '') {
      return this.get(name, YText)
    }

    /**
     * @template T
     * @param {string} [name]
     * @return {YMap<T>}
     *
     * @public
     */
    getMap (name = '') {
      return /** @type {YMap<T>} */ (this.get(name, YMap))
    }

    /**
     * @param {string} [name]
     * @return {YXmlElement}
     *
     * @public
     */
    getXmlElement (name = '') {
      return /** @type {YXmlElement<{[key:string]:string}>} */ (this.get(name, YXmlElement))
    }

    /**
     * @param {string} [name]
     * @return {YXmlFragment}
     *
     * @public
     */
    getXmlFragment (name = '') {
      return this.get(name, YXmlFragment)
    }

    /**
     * Converts the entire document into a js object, recursively traversing each yjs type
     * Doesn't log types that have not been defined (using ydoc.getType(..)).
     *
     * @deprecated Do not use this method and rather call toJSON directly on the shared types.
     *
     * @return {Object<string, any>}
     */
    toJSON () {
      /**
       * @type {Object<string, any>}
       */
      const doc = {};

      this.share.forEach((value, key) => {
        doc[key] = value.toJSON();
      });

      return doc
    }

    /**
     * Emit `destroy` event and unregister all event handlers.
     */
    destroy () {
      this.isDestroyed = true;
      from$2(this.subdocs).forEach(subdoc => subdoc.destroy());
      const item = this._item;
      if (item !== null) {
        this._item = null;
        const content = /** @type {ContentDoc} */ (item.content);
        content.doc = new Doc({ guid: this.guid, ...content.opts, shouldLoad: false });
        content.doc._item = item;
        transact(/** @type {any} */ (item).parent.doc, transaction => {
          const doc = content.doc;
          if (!item.deleted) {
            transaction.subdocsAdded.add(doc);
          }
          transaction.subdocsRemoved.add(this);
        }, null, true);
      }
      // @ts-ignore
      this.emit('destroyed', [true]); // DEPRECATED!
      this.emit('destroy', [this]);
      super.destroy();
    }
  }

  class DSDecoderV1 {
    /**
     * @param {decoding.Decoder} decoder
     */
    constructor (decoder) {
      this.restDecoder = decoder;
    }

    resetDsCurVal () {
      // nop
    }

    /**
     * @return {number}
     */
    readDsClock () {
      return readVarUint(this.restDecoder)
    }

    /**
     * @return {number}
     */
    readDsLen () {
      return readVarUint(this.restDecoder)
    }
  }

  class UpdateDecoderV1 extends DSDecoderV1 {
    /**
     * @return {ID}
     */
    readLeftID () {
      return createID(readVarUint(this.restDecoder), readVarUint(this.restDecoder))
    }

    /**
     * @return {ID}
     */
    readRightID () {
      return createID(readVarUint(this.restDecoder), readVarUint(this.restDecoder))
    }

    /**
     * Read the next client id.
     * Use this in favor of readID whenever possible to reduce the number of objects created.
     */
    readClient () {
      return readVarUint(this.restDecoder)
    }

    /**
     * @return {number} info An unsigned 8-bit integer
     */
    readInfo () {
      return readUint8(this.restDecoder)
    }

    /**
     * @return {string}
     */
    readString () {
      return readVarString(this.restDecoder)
    }

    /**
     * @return {boolean} isKey
     */
    readParentInfo () {
      return readVarUint(this.restDecoder) === 1
    }

    /**
     * @return {number} info An unsigned 8-bit integer
     */
    readTypeRef () {
      return readVarUint(this.restDecoder)
    }

    /**
     * Write len of a struct - well suited for Opt RLE encoder.
     *
     * @return {number} len
     */
    readLen () {
      return readVarUint(this.restDecoder)
    }

    /**
     * @return {any}
     */
    readAny () {
      return readAny(this.restDecoder)
    }

    /**
     * @return {Uint8Array}
     */
    readBuf () {
      return copyUint8Array(readVarUint8Array(this.restDecoder))
    }

    /**
     * Legacy implementation uses JSON parse. We use any-decoding in v2.
     *
     * @return {any}
     */
    readJSON () {
      return JSON.parse(readVarString(this.restDecoder))
    }

    /**
     * @return {string}
     */
    readKey () {
      return readVarString(this.restDecoder)
    }
  }

  class DSDecoderV2 {
    /**
     * @param {decoding.Decoder} decoder
     */
    constructor (decoder) {
      /**
       * @private
       */
      this.dsCurrVal = 0;
      this.restDecoder = decoder;
    }

    resetDsCurVal () {
      this.dsCurrVal = 0;
    }

    /**
     * @return {number}
     */
    readDsClock () {
      this.dsCurrVal += readVarUint(this.restDecoder);
      return this.dsCurrVal
    }

    /**
     * @return {number}
     */
    readDsLen () {
      const diff = readVarUint(this.restDecoder) + 1;
      this.dsCurrVal += diff;
      return diff
    }
  }

  class UpdateDecoderV2 extends DSDecoderV2 {
    /**
     * @param {decoding.Decoder} decoder
     */
    constructor (decoder) {
      super(decoder);
      /**
       * List of cached keys. If the keys[id] does not exist, we read a new key
       * from stringEncoder and push it to keys.
       *
       * @type {Array<string>}
       */
      this.keys = [];
      readVarUint(decoder); // read feature flag - currently unused
      this.keyClockDecoder = new IntDiffOptRleDecoder(readVarUint8Array(decoder));
      this.clientDecoder = new UintOptRleDecoder(readVarUint8Array(decoder));
      this.leftClockDecoder = new IntDiffOptRleDecoder(readVarUint8Array(decoder));
      this.rightClockDecoder = new IntDiffOptRleDecoder(readVarUint8Array(decoder));
      this.infoDecoder = new RleDecoder(readVarUint8Array(decoder), readUint8);
      this.stringDecoder = new StringDecoder$2(readVarUint8Array(decoder));
      this.parentInfoDecoder = new RleDecoder(readVarUint8Array(decoder), readUint8);
      this.typeRefDecoder = new UintOptRleDecoder(readVarUint8Array(decoder));
      this.lenDecoder = new UintOptRleDecoder(readVarUint8Array(decoder));
    }

    /**
     * @return {ID}
     */
    readLeftID () {
      return new ID(this.clientDecoder.read(), this.leftClockDecoder.read())
    }

    /**
     * @return {ID}
     */
    readRightID () {
      return new ID(this.clientDecoder.read(), this.rightClockDecoder.read())
    }

    /**
     * Read the next client id.
     * Use this in favor of readID whenever possible to reduce the number of objects created.
     */
    readClient () {
      return this.clientDecoder.read()
    }

    /**
     * @return {number} info An unsigned 8-bit integer
     */
    readInfo () {
      return /** @type {number} */ (this.infoDecoder.read())
    }

    /**
     * @return {string}
     */
    readString () {
      return this.stringDecoder.read()
    }

    /**
     * @return {boolean}
     */
    readParentInfo () {
      return this.parentInfoDecoder.read() === 1
    }

    /**
     * @return {number} An unsigned 8-bit integer
     */
    readTypeRef () {
      return this.typeRefDecoder.read()
    }

    /**
     * Write len of a struct - well suited for Opt RLE encoder.
     *
     * @return {number}
     */
    readLen () {
      return this.lenDecoder.read()
    }

    /**
     * @return {any}
     */
    readAny () {
      return readAny(this.restDecoder)
    }

    /**
     * @return {Uint8Array}
     */
    readBuf () {
      return readVarUint8Array(this.restDecoder)
    }

    /**
     * This is mainly here for legacy purposes.
     *
     * Initial we incoded objects using JSON. Now we use the much faster lib0/any-encoder. This method mainly exists for legacy purposes for the v1 encoder.
     *
     * @return {any}
     */
    readJSON () {
      return readAny(this.restDecoder)
    }

    /**
     * @return {string}
     */
    readKey () {
      const keyClock = this.keyClockDecoder.read();
      if (keyClock < this.keys.length) {
        return this.keys[keyClock]
      } else {
        const key = this.stringDecoder.read();
        this.keys.push(key);
        return key
      }
    }
  }

  class DSEncoderV1 {
    constructor () {
      this.restEncoder = createEncoder();
    }

    toUint8Array () {
      return toUint8Array(this.restEncoder)
    }

    resetDsCurVal () {
      // nop
    }

    /**
     * @param {number} clock
     */
    writeDsClock (clock) {
      writeVarUint(this.restEncoder, clock);
    }

    /**
     * @param {number} len
     */
    writeDsLen (len) {
      writeVarUint(this.restEncoder, len);
    }
  }

  class UpdateEncoderV1 extends DSEncoderV1 {
    /**
     * @param {ID} id
     */
    writeLeftID (id) {
      writeVarUint(this.restEncoder, id.client);
      writeVarUint(this.restEncoder, id.clock);
    }

    /**
     * @param {ID} id
     */
    writeRightID (id) {
      writeVarUint(this.restEncoder, id.client);
      writeVarUint(this.restEncoder, id.clock);
    }

    /**
     * Use writeClient and writeClock instead of writeID if possible.
     * @param {number} client
     */
    writeClient (client) {
      writeVarUint(this.restEncoder, client);
    }

    /**
     * @param {number} info An unsigned 8-bit integer
     */
    writeInfo (info) {
      writeUint8(this.restEncoder, info);
    }

    /**
     * @param {string} s
     */
    writeString (s) {
      writeVarString(this.restEncoder, s);
    }

    /**
     * @param {boolean} isYKey
     */
    writeParentInfo (isYKey) {
      writeVarUint(this.restEncoder, isYKey ? 1 : 0);
    }

    /**
     * @param {number} info An unsigned 8-bit integer
     */
    writeTypeRef (info) {
      writeVarUint(this.restEncoder, info);
    }

    /**
     * Write len of a struct - well suited for Opt RLE encoder.
     *
     * @param {number} len
     */
    writeLen (len) {
      writeVarUint(this.restEncoder, len);
    }

    /**
     * @param {any} any
     */
    writeAny (any) {
      writeAny(this.restEncoder, any);
    }

    /**
     * @param {Uint8Array} buf
     */
    writeBuf (buf) {
      writeVarUint8Array(this.restEncoder, buf);
    }

    /**
     * @param {any} embed
     */
    writeJSON (embed) {
      writeVarString(this.restEncoder, JSON.stringify(embed));
    }

    /**
     * @param {string} key
     */
    writeKey (key) {
      writeVarString(this.restEncoder, key);
    }
  }

  class DSEncoderV2 {
    constructor () {
      this.restEncoder = createEncoder(); // encodes all the rest / non-optimized
      this.dsCurrVal = 0;
    }

    toUint8Array () {
      return toUint8Array(this.restEncoder)
    }

    resetDsCurVal () {
      this.dsCurrVal = 0;
    }

    /**
     * @param {number} clock
     */
    writeDsClock (clock) {
      const diff = clock - this.dsCurrVal;
      this.dsCurrVal = clock;
      writeVarUint(this.restEncoder, diff);
    }

    /**
     * @param {number} len
     */
    writeDsLen (len) {
      if (len === 0) {
        unexpectedCase();
      }
      writeVarUint(this.restEncoder, len - 1);
      this.dsCurrVal += len;
    }
  }

  class UpdateEncoderV2 extends DSEncoderV2 {
    constructor () {
      super();
      /**
       * @type {Map<string,number>}
       */
      this.keyMap = new Map();
      /**
       * Refers to the next unique key-identifier to me used.
       * See writeKey method for more information.
       *
       * @type {number}
       */
      this.keyClock = 0;
      this.keyClockEncoder = new IntDiffOptRleEncoder();
      this.clientEncoder = new UintOptRleEncoder();
      this.leftClockEncoder = new IntDiffOptRleEncoder();
      this.rightClockEncoder = new IntDiffOptRleEncoder();
      this.infoEncoder = new RleEncoder(writeUint8);
      this.stringEncoder = new StringEncoder();
      this.parentInfoEncoder = new RleEncoder(writeUint8);
      this.typeRefEncoder = new UintOptRleEncoder();
      this.lenEncoder = new UintOptRleEncoder();
    }

    toUint8Array () {
      const encoder = createEncoder();
      writeVarUint(encoder, 0); // this is a feature flag that we might use in the future
      writeVarUint8Array(encoder, this.keyClockEncoder.toUint8Array());
      writeVarUint8Array(encoder, this.clientEncoder.toUint8Array());
      writeVarUint8Array(encoder, this.leftClockEncoder.toUint8Array());
      writeVarUint8Array(encoder, this.rightClockEncoder.toUint8Array());
      writeVarUint8Array(encoder, toUint8Array(this.infoEncoder));
      writeVarUint8Array(encoder, this.stringEncoder.toUint8Array());
      writeVarUint8Array(encoder, toUint8Array(this.parentInfoEncoder));
      writeVarUint8Array(encoder, this.typeRefEncoder.toUint8Array());
      writeVarUint8Array(encoder, this.lenEncoder.toUint8Array());
      // @note The rest encoder is appended! (note the missing var)
      writeUint8Array(encoder, toUint8Array(this.restEncoder));
      return toUint8Array(encoder)
    }

    /**
     * @param {ID} id
     */
    writeLeftID (id) {
      this.clientEncoder.write(id.client);
      this.leftClockEncoder.write(id.clock);
    }

    /**
     * @param {ID} id
     */
    writeRightID (id) {
      this.clientEncoder.write(id.client);
      this.rightClockEncoder.write(id.clock);
    }

    /**
     * @param {number} client
     */
    writeClient (client) {
      this.clientEncoder.write(client);
    }

    /**
     * @param {number} info An unsigned 8-bit integer
     */
    writeInfo (info) {
      this.infoEncoder.write(info);
    }

    /**
     * @param {string} s
     */
    writeString (s) {
      this.stringEncoder.write(s);
    }

    /**
     * @param {boolean} isYKey
     */
    writeParentInfo (isYKey) {
      this.parentInfoEncoder.write(isYKey ? 1 : 0);
    }

    /**
     * @param {number} info An unsigned 8-bit integer
     */
    writeTypeRef (info) {
      this.typeRefEncoder.write(info);
    }

    /**
     * Write len of a struct - well suited for Opt RLE encoder.
     *
     * @param {number} len
     */
    writeLen (len) {
      this.lenEncoder.write(len);
    }

    /**
     * @param {any} any
     */
    writeAny (any) {
      writeAny(this.restEncoder, any);
    }

    /**
     * @param {Uint8Array} buf
     */
    writeBuf (buf) {
      writeVarUint8Array(this.restEncoder, buf);
    }

    /**
     * This is mainly here for legacy purposes.
     *
     * Initial we incoded objects using JSON. Now we use the much faster lib0/any-encoder. This method mainly exists for legacy purposes for the v1 encoder.
     *
     * @param {any} embed
     */
    writeJSON (embed) {
      writeAny(this.restEncoder, embed);
    }

    /**
     * Property keys are often reused. For example, in y-prosemirror the key `bold` might
     * occur very often. For a 3d application, the key `position` might occur very often.
     *
     * We cache these keys in a Map and refer to them via a unique number.
     *
     * @param {string} key
     */
    writeKey (key) {
      const clock = this.keyMap.get(key);
      if (clock === undefined) {
        /**
         * @todo uncomment to introduce this feature finally
         *
         * Background. The ContentFormat object was always encoded using writeKey, but the decoder used to use readString.
         * Furthermore, I forgot to set the keyclock. So everything was working fine.
         *
         * However, this feature here is basically useless as it is not being used (it actually only consumes extra memory).
         *
         * I don't know yet how to reintroduce this feature..
         *
         * Older clients won't be able to read updates when we reintroduce this feature. So this should probably be done using a flag.
         *
         */
        // this.keyMap.set(key, this.keyClock)
        this.keyClockEncoder.write(this.keyClock++);
        this.stringEncoder.write(key);
      } else {
        this.keyClockEncoder.write(clock);
      }
    }
  }

  /**
   * @module encoding
   */
  /*
   * We use the first five bits in the info flag for determining the type of the struct.
   *
   * 0: GC
   * 1: Item with Deleted content
   * 2: Item with JSON content
   * 3: Item with Binary content
   * 4: Item with String content
   * 5: Item with Embed content (for richtext content)
   * 6: Item with Format content (a formatting marker for richtext content)
   * 7: Item with Type
   */


  /**
   * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder
   * @param {Array<GC|Item>} structs All structs by `client`
   * @param {number} client
   * @param {number} clock write structs starting with `ID(client,clock)`
   *
   * @function
   */
  const writeStructs = (encoder, structs, client, clock) => {
    // write first id
    clock = max(clock, structs[0].id.clock); // make sure the first id exists
    const startNewStructs = findIndexSS(structs, clock);
    // write # encoded structs
    writeVarUint(encoder.restEncoder, structs.length - startNewStructs);
    encoder.writeClient(client);
    writeVarUint(encoder.restEncoder, clock);
    const firstStruct = structs[startNewStructs];
    // write first struct with an offset
    firstStruct.write(encoder, clock - firstStruct.id.clock);
    for (let i = startNewStructs + 1; i < structs.length; i++) {
      structs[i].write(encoder, 0);
    }
  };

  /**
   * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder
   * @param {StructStore} store
   * @param {Map<number,number>} _sm
   *
   * @private
   * @function
   */
  const writeClientsStructs = (encoder, store, _sm) => {
    // we filter all valid _sm entries into sm
    const sm = new Map();
    _sm.forEach((clock, client) => {
      // only write if new structs are available
      if (getState(store, client) > clock) {
        sm.set(client, clock);
      }
    });
    getStateVector(store).forEach((_clock, client) => {
      if (!_sm.has(client)) {
        sm.set(client, 0);
      }
    });
    // write # states that were updated
    writeVarUint(encoder.restEncoder, sm.size);
    // Write items with higher client ids first
    // This heavily improves the conflict algorithm.
    from$2(sm.entries()).sort((a, b) => b[0] - a[0]).forEach(([client, clock]) => {
      writeStructs(encoder, /** @type {Array<GC|Item>} */ (store.clients.get(client)), client, clock);
    });
  };

  /**
   * @param {UpdateDecoderV1 | UpdateDecoderV2} decoder The decoder object to read data from.
   * @param {Doc} doc
   * @return {Map<number, { i: number, refs: Array<Item | GC> }>}
   *
   * @private
   * @function
   */
  const readClientsStructRefs = (decoder, doc) => {
    /**
     * @type {Map<number, { i: number, refs: Array<Item | GC> }>}
     */
    const clientRefs = create$6();
    const numOfStateUpdates = readVarUint(decoder.restDecoder);
    for (let i = 0; i < numOfStateUpdates; i++) {
      const numberOfStructs = readVarUint(decoder.restDecoder);
      /**
       * @type {Array<GC|Item>}
       */
      const refs = new Array(numberOfStructs);
      const client = decoder.readClient();
      let clock = readVarUint(decoder.restDecoder);
      // const start = performance.now()
      clientRefs.set(client, { i: 0, refs });
      for (let i = 0; i < numberOfStructs; i++) {
        const info = decoder.readInfo();
        switch (BITS5 & info) {
          case 0: { // GC
            const len = decoder.readLen();
            refs[i] = new GC(createID(client, clock), len);
            clock += len;
            break
          }
          case 10: { // Skip Struct (nothing to apply)
            // @todo we could reduce the amount of checks by adding Skip struct to clientRefs so we know that something is missing.
            const len = readVarUint(decoder.restDecoder);
            refs[i] = new Skip(createID(client, clock), len);
            clock += len;
            break
          }
          default: { // Item with content
            /**
             * The optimized implementation doesn't use any variables because inlining variables is faster.
             * Below a non-optimized version is shown that implements the basic algorithm with
             * a few comments
             */
            const cantCopyParentInfo = (info & (BIT7 | BIT8)) === 0;
            // If parent = null and neither left nor right are defined, then we know that `parent` is child of `y`
            // and we read the next string as parentYKey.
            // It indicates how we store/retrieve parent from `y.share`
            // @type {string|null}
            const struct = new Item(
              createID(client, clock),
              null, // left
              (info & BIT8) === BIT8 ? decoder.readLeftID() : null, // origin
              null, // right
              (info & BIT7) === BIT7 ? decoder.readRightID() : null, // right origin
              cantCopyParentInfo ? (decoder.readParentInfo() ? doc.get(decoder.readString()) : decoder.readLeftID()) : null, // parent
              cantCopyParentInfo && (info & BIT6) === BIT6 ? decoder.readString() : null, // parentSub
              readItemContent(decoder, info) // item content
            );
            /* A non-optimized implementation of the above algorithm:

            // The item that was originally to the left of this item.
            const origin = (info & binary.BIT8) === binary.BIT8 ? decoder.readLeftID() : null
            // The item that was originally to the right of this item.
            const rightOrigin = (info & binary.BIT7) === binary.BIT7 ? decoder.readRightID() : null
            const cantCopyParentInfo = (info & (binary.BIT7 | binary.BIT8)) === 0
            const hasParentYKey = cantCopyParentInfo ? decoder.readParentInfo() : false
            // If parent = null and neither left nor right are defined, then we know that `parent` is child of `y`
            // and we read the next string as parentYKey.
            // It indicates how we store/retrieve parent from `y.share`
            // @type {string|null}
            const parentYKey = cantCopyParentInfo && hasParentYKey ? decoder.readString() : null

            const struct = new Item(
              createID(client, clock),
              null, // left
              origin, // origin
              null, // right
              rightOrigin, // right origin
              cantCopyParentInfo && !hasParentYKey ? decoder.readLeftID() : (parentYKey !== null ? doc.get(parentYKey) : null), // parent
              cantCopyParentInfo && (info & binary.BIT6) === binary.BIT6 ? decoder.readString() : null, // parentSub
              readItemContent(decoder, info) // item content
            )
            */
            refs[i] = struct;
            clock += struct.length;
          }
        }
      }
      // console.log('time to read: ', performance.now() - start) // @todo remove
    }
    return clientRefs
  };

  /**
   * Resume computing structs generated by struct readers.
   *
   * While there is something to do, we integrate structs in this order
   * 1. top element on stack, if stack is not empty
   * 2. next element from current struct reader (if empty, use next struct reader)
   *
   * If struct causally depends on another struct (ref.missing), we put next reader of
   * `ref.id.client` on top of stack.
   *
   * At some point we find a struct that has no causal dependencies,
   * then we start emptying the stack.
   *
   * It is not possible to have circles: i.e. struct1 (from client1) depends on struct2 (from client2)
   * depends on struct3 (from client1). Therefore the max stack size is equal to `structReaders.length`.
   *
   * This method is implemented in a way so that we can resume computation if this update
   * causally depends on another update.
   *
   * @param {Transaction} transaction
   * @param {StructStore} store
   * @param {Map<number, { i: number, refs: (GC | Item)[] }>} clientsStructRefs
   * @return { null | { update: Uint8Array, missing: Map<number,number> } }
   *
   * @private
   * @function
   */
  const integrateStructs = (transaction, store, clientsStructRefs) => {
    /**
     * @type {Array<Item | GC>}
     */
    const stack = [];
    // sort them so that we take the higher id first, in case of conflicts the lower id will probably not conflict with the id from the higher user.
    let clientsStructRefsIds = from$2(clientsStructRefs.keys()).sort((a, b) => a - b);
    if (clientsStructRefsIds.length === 0) {
      return null
    }
    const getNextStructTarget = () => {
      if (clientsStructRefsIds.length === 0) {
        return null
      }
      let nextStructsTarget = /** @type {{i:number,refs:Array<GC|Item>}} */ (clientsStructRefs.get(clientsStructRefsIds[clientsStructRefsIds.length - 1]));
      while (nextStructsTarget.refs.length === nextStructsTarget.i) {
        clientsStructRefsIds.pop();
        if (clientsStructRefsIds.length > 0) {
          nextStructsTarget = /** @type {{i:number,refs:Array<GC|Item>}} */ (clientsStructRefs.get(clientsStructRefsIds[clientsStructRefsIds.length - 1]));
        } else {
          return null
        }
      }
      return nextStructsTarget
    };
    let curStructsTarget = getNextStructTarget();
    if (curStructsTarget === null) {
      return null
    }

    /**
     * @type {StructStore}
     */
    const restStructs = new StructStore();
    const missingSV = new Map();
    /**
     * @param {number} client
     * @param {number} clock
     */
    const updateMissingSv = (client, clock) => {
      const mclock = missingSV.get(client);
      if (mclock == null || mclock > clock) {
        missingSV.set(client, clock);
      }
    };
    /**
     * @type {GC|Item}
     */
    let stackHead = /** @type {any} */ (curStructsTarget).refs[/** @type {any} */ (curStructsTarget).i++];
    // caching the state because it is used very often
    const state = new Map();

    const addStackToRestSS = () => {
      for (const item of stack) {
        const client = item.id.client;
        const inapplicableItems = clientsStructRefs.get(client);
        if (inapplicableItems) {
          // decrement because we weren't able to apply previous operation
          inapplicableItems.i--;
          restStructs.clients.set(client, inapplicableItems.refs.slice(inapplicableItems.i));
          clientsStructRefs.delete(client);
          inapplicableItems.i = 0;
          inapplicableItems.refs = [];
        } else {
          // item was the last item on clientsStructRefs and the field was already cleared. Add item to restStructs and continue
          restStructs.clients.set(client, [item]);
        }
        // remove client from clientsStructRefsIds to prevent users from applying the same update again
        clientsStructRefsIds = clientsStructRefsIds.filter(c => c !== client);
      }
      stack.length = 0;
    };

    // iterate over all struct readers until we are done
    while (true) {
      if (stackHead.constructor !== Skip) {
        const localClock = setIfUndefined(state, stackHead.id.client, () => getState(store, stackHead.id.client));
        const offset = localClock - stackHead.id.clock;
        if (offset < 0) {
          // update from the same client is missing
          stack.push(stackHead);
          updateMissingSv(stackHead.id.client, stackHead.id.clock - 1);
          // hid a dead wall, add all items from stack to restSS
          addStackToRestSS();
        } else {
          const missing = stackHead.getMissing(transaction, store);
          if (missing !== null) {
            stack.push(stackHead);
            // get the struct reader that has the missing struct
            /**
             * @type {{ refs: Array<GC|Item>, i: number }}
             */
            const structRefs = clientsStructRefs.get(/** @type {number} */ (missing)) || { refs: [], i: 0 };
            if (structRefs.refs.length === structRefs.i) {
              // This update message causally depends on another update message that doesn't exist yet
              updateMissingSv(/** @type {number} */ (missing), getState(store, missing));
              addStackToRestSS();
            } else {
              stackHead = structRefs.refs[structRefs.i++];
              continue
            }
          } else if (offset === 0 || offset < stackHead.length) {
            // all fine, apply the stackhead
            stackHead.integrate(transaction, offset);
            state.set(stackHead.id.client, stackHead.id.clock + stackHead.length);
          }
        }
      }
      // iterate to next stackHead
      if (stack.length > 0) {
        stackHead = /** @type {GC|Item} */ (stack.pop());
      } else if (curStructsTarget !== null && curStructsTarget.i < curStructsTarget.refs.length) {
        stackHead = /** @type {GC|Item} */ (curStructsTarget.refs[curStructsTarget.i++]);
      } else {
        curStructsTarget = getNextStructTarget();
        if (curStructsTarget === null) {
          // we are done!
          break
        } else {
          stackHead = /** @type {GC|Item} */ (curStructsTarget.refs[curStructsTarget.i++]);
        }
      }
    }
    if (restStructs.clients.size > 0) {
      const encoder = new UpdateEncoderV2();
      writeClientsStructs(encoder, restStructs, new Map());
      // write empty deleteset
      // writeDeleteSet(encoder, new DeleteSet())
      writeVarUint(encoder.restEncoder, 0); // => no need for an extra function call, just write 0 deletes
      return { missing: missingSV, update: encoder.toUint8Array() }
    }
    return null
  };

  /**
   * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder
   * @param {Transaction} transaction
   *
   * @private
   * @function
   */
  const writeStructsFromTransaction = (encoder, transaction) => writeClientsStructs(encoder, transaction.doc.store, transaction.beforeState);

  /**
   * Read and apply a document update.
   *
   * This function has the same effect as `applyUpdate` but accepts a decoder.
   *
   * @param {decoding.Decoder} decoder
   * @param {Doc} ydoc
   * @param {any} [transactionOrigin] This will be stored on `transaction.origin` and `.on('update', (update, origin))`
   * @param {UpdateDecoderV1 | UpdateDecoderV2} [structDecoder]
   *
   * @function
   */
  const readUpdateV2 = (decoder, ydoc, transactionOrigin, structDecoder = new UpdateDecoderV2(decoder)) =>
    transact(ydoc, transaction => {
      // force that transaction.local is set to non-local
      transaction.local = false;
      let retry = false;
      const doc = transaction.doc;
      const store = doc.store;
      // let start = performance.now()
      const ss = readClientsStructRefs(structDecoder, doc);
      // console.log('time to read structs: ', performance.now() - start) // @todo remove
      // start = performance.now()
      // console.log('time to merge: ', performance.now() - start) // @todo remove
      // start = performance.now()
      const restStructs = integrateStructs(transaction, store, ss);
      const pending = store.pendingStructs;
      if (pending) {
        // check if we can apply something
        for (const [client, clock] of pending.missing) {
          if (clock < getState(store, client)) {
            retry = true;
            break
          }
        }
        if (restStructs) {
          // merge restStructs into store.pending
          for (const [client, clock] of restStructs.missing) {
            const mclock = pending.missing.get(client);
            if (mclock == null || mclock > clock) {
              pending.missing.set(client, clock);
            }
          }
          pending.update = mergeUpdatesV2([pending.update, restStructs.update]);
        }
      } else {
        store.pendingStructs = restStructs;
      }
      // console.log('time to integrate: ', performance.now() - start) // @todo remove
      // start = performance.now()
      const dsRest = readAndApplyDeleteSet(structDecoder, transaction, store);
      if (store.pendingDs) {
        // @todo we could make a lower-bound state-vector check as we do above
        const pendingDSUpdate = new UpdateDecoderV2(createDecoder(store.pendingDs));
        readVarUint(pendingDSUpdate.restDecoder); // read 0 structs, because we only encode deletes in pendingdsupdate
        const dsRest2 = readAndApplyDeleteSet(pendingDSUpdate, transaction, store);
        if (dsRest && dsRest2) {
          // case 1: ds1 != null && ds2 != null
          store.pendingDs = mergeUpdatesV2([dsRest, dsRest2]);
        } else {
          // case 2: ds1 != null
          // case 3: ds2 != null
          // case 4: ds1 == null && ds2 == null
          store.pendingDs = dsRest || dsRest2;
        }
      } else {
        // Either dsRest == null && pendingDs == null OR dsRest != null
        store.pendingDs = dsRest;
      }
      // console.log('time to cleanup: ', performance.now() - start) // @todo remove
      // start = performance.now()

      // console.log('time to resume delete readers: ', performance.now() - start) // @todo remove
      // start = performance.now()
      if (retry) {
        const update = /** @type {{update: Uint8Array}} */ (store.pendingStructs).update;
        store.pendingStructs = null;
        applyUpdateV2(transaction.doc, update);
      }
    }, transactionOrigin, false);

  /**
   * Apply a document update created by, for example, `y.on('update', update => ..)` or `update = encodeStateAsUpdate()`.
   *
   * This function has the same effect as `readUpdate` but accepts an Uint8Array instead of a Decoder.
   *
   * @param {Doc} ydoc
   * @param {Uint8Array} update
   * @param {any} [transactionOrigin] This will be stored on `transaction.origin` and `.on('update', (update, origin))`
   * @param {typeof UpdateDecoderV1 | typeof UpdateDecoderV2} [YDecoder]
   *
   * @function
   */
  const applyUpdateV2 = (ydoc, update, transactionOrigin, YDecoder = UpdateDecoderV2) => {
    const decoder = createDecoder(update);
    readUpdateV2(decoder, ydoc, transactionOrigin, new YDecoder(decoder));
  };

  /**
   * Apply a document update created by, for example, `y.on('update', update => ..)` or `update = encodeStateAsUpdate()`.
   *
   * This function has the same effect as `readUpdate` but accepts an Uint8Array instead of a Decoder.
   *
   * @param {Doc} ydoc
   * @param {Uint8Array} update
   * @param {any} [transactionOrigin] This will be stored on `transaction.origin` and `.on('update', (update, origin))`
   *
   * @function
   */
  const applyUpdate = (ydoc, update, transactionOrigin) => applyUpdateV2(ydoc, update, transactionOrigin, UpdateDecoderV1);

  /**
   * Write all the document as a single update message. If you specify the state of the remote client (`targetStateVector`) it will
   * only write the operations that are missing.
   *
   * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder
   * @param {Doc} doc
   * @param {Map<number,number>} [targetStateVector] The state of the target that receives the update. Leave empty to write all known structs
   *
   * @function
   */
  const writeStateAsUpdate = (encoder, doc, targetStateVector = new Map()) => {
    writeClientsStructs(encoder, doc.store, targetStateVector);
    writeDeleteSet(encoder, createDeleteSetFromStructStore(doc.store));
  };

  /**
   * Write all the document as a single update message that can be applied on the remote document. If you specify the state of the remote client (`targetState`) it will
   * only write the operations that are missing.
   *
   * Use `writeStateAsUpdate` instead if you are working with lib0/encoding.js#Encoder
   *
   * @param {Doc} doc
   * @param {Uint8Array} [encodedTargetStateVector] The state of the target that receives the update. Leave empty to write all known structs
   * @param {UpdateEncoderV1 | UpdateEncoderV2} [encoder]
   * @return {Uint8Array}
   *
   * @function
   */
  const encodeStateAsUpdateV2 = (doc, encodedTargetStateVector = new Uint8Array([0]), encoder = new UpdateEncoderV2()) => {
    const targetStateVector = decodeStateVector$1(encodedTargetStateVector);
    writeStateAsUpdate(encoder, doc, targetStateVector);
    const updates = [encoder.toUint8Array()];
    // also add the pending updates (if there are any)
    if (doc.store.pendingDs) {
      updates.push(doc.store.pendingDs);
    }
    if (doc.store.pendingStructs) {
      updates.push(diffUpdateV2(doc.store.pendingStructs.update, encodedTargetStateVector));
    }
    if (updates.length > 1) {
      if (encoder.constructor === UpdateEncoderV1) {
        return mergeUpdates$1(updates.map((update, i) => i === 0 ? update : convertUpdateFormatV2ToV1(update)))
      } else if (encoder.constructor === UpdateEncoderV2) {
        return mergeUpdatesV2(updates)
      }
    }
    return updates[0]
  };

  /**
   * Write all the document as a single update message that can be applied on the remote document. If you specify the state of the remote client (`targetState`) it will
   * only write the operations that are missing.
   *
   * Use `writeStateAsUpdate` instead if you are working with lib0/encoding.js#Encoder
   *
   * @param {Doc} doc
   * @param {Uint8Array} [encodedTargetStateVector] The state of the target that receives the update. Leave empty to write all known structs
   * @return {Uint8Array}
   *
   * @function
   */
  const encodeStateAsUpdate = (doc, encodedTargetStateVector) => encodeStateAsUpdateV2(doc, encodedTargetStateVector, new UpdateEncoderV1());

  /**
   * Read state vector from Decoder and return as Map
   *
   * @param {DSDecoderV1 | DSDecoderV2} decoder
   * @return {Map<number,number>} Maps `client` to the number next expected `clock` from that client.
   *
   * @function
   */
  const readStateVector$2 = decoder => {
    const ss = new Map();
    const ssLength = readVarUint(decoder.restDecoder);
    for (let i = 0; i < ssLength; i++) {
      const client = readVarUint(decoder.restDecoder);
      const clock = readVarUint(decoder.restDecoder);
      ss.set(client, clock);
    }
    return ss
  };

  /**
   * Read decodedState and return State as Map.
   *
   * @param {Uint8Array} decodedState
   * @return {Map<number,number>} Maps `client` to the number next expected `clock` from that client.
   *
   * @function
   */
  // export const decodeStateVectorV2 = decodedState => readStateVector(new DSDecoderV2(decoding.createDecoder(decodedState)))

  /**
   * Read decodedState and return State as Map.
   *
   * @param {Uint8Array} decodedState
   * @return {Map<number,number>} Maps `client` to the number next expected `clock` from that client.
   *
   * @function
   */
  const decodeStateVector$1 = decodedState => readStateVector$2(new DSDecoderV1(createDecoder(decodedState)));

  /**
   * @param {DSEncoderV1 | DSEncoderV2} encoder
   * @param {Map<number,number>} sv
   * @function
   */
  const writeStateVector$1 = (encoder, sv) => {
    writeVarUint(encoder.restEncoder, sv.size);
    from$2(sv.entries()).sort((a, b) => b[0] - a[0]).forEach(([client, clock]) => {
      writeVarUint(encoder.restEncoder, client); // @todo use a special client decoder that is based on mapping
      writeVarUint(encoder.restEncoder, clock);
    });
    return encoder
  };

  /**
   * @param {DSEncoderV1 | DSEncoderV2} encoder
   * @param {Doc} doc
   *
   * @function
   */
  const writeDocumentStateVector = (encoder, doc) => writeStateVector$1(encoder, getStateVector(doc.store));

  /**
   * Encode State as Uint8Array.
   *
   * @param {Doc|Map<number,number>} doc
   * @param {DSEncoderV1 | DSEncoderV2} [encoder]
   * @return {Uint8Array}
   *
   * @function
   */
  const encodeStateVectorV2 = (doc, encoder = new DSEncoderV2()) => {
    if (doc instanceof Map) {
      writeStateVector$1(encoder, doc);
    } else {
      writeDocumentStateVector(encoder, doc);
    }
    return encoder.toUint8Array()
  };

  /**
   * Encode State as Uint8Array.
   *
   * @param {Doc|Map<number,number>} doc
   * @return {Uint8Array}
   *
   * @function
   */
  const encodeStateVector = doc => encodeStateVectorV2(doc, new DSEncoderV1());

  /**
   * General event handler implementation.
   *
   * @template ARG0, ARG1
   *
   * @private
   */
  class EventHandler {
    constructor () {
      /**
       * @type {Array<function(ARG0, ARG1):void>}
       */
      this.l = [];
    }
  }

  /**
   * @template ARG0,ARG1
   * @returns {EventHandler<ARG0,ARG1>}
   *
   * @private
   * @function
   */
  const createEventHandler = () => new EventHandler();

  /**
   * Adds an event listener that is called when
   * {@link EventHandler#callEventListeners} is called.
   *
   * @template ARG0,ARG1
   * @param {EventHandler<ARG0,ARG1>} eventHandler
   * @param {function(ARG0,ARG1):void} f The event handler.
   *
   * @private
   * @function
   */
  const addEventHandlerListener = (eventHandler, f) =>
    eventHandler.l.push(f);

  /**
   * Removes an event listener.
   *
   * @template ARG0,ARG1
   * @param {EventHandler<ARG0,ARG1>} eventHandler
   * @param {function(ARG0,ARG1):void} f The event handler that was added with
   *                     {@link EventHandler#addEventListener}
   *
   * @private
   * @function
   */
  const removeEventHandlerListener = (eventHandler, f) => {
    const l = eventHandler.l;
    const len = l.length;
    eventHandler.l = l.filter(g => f !== g);
    if (len === eventHandler.l.length) {
      console.error('[yjs] Tried to remove event handler that doesn\'t exist.');
    }
  };

  /**
   * Call all event listeners that were added via
   * {@link EventHandler#addEventListener}.
   *
   * @template ARG0,ARG1
   * @param {EventHandler<ARG0,ARG1>} eventHandler
   * @param {ARG0} arg0
   * @param {ARG1} arg1
   *
   * @private
   * @function
   */
  const callEventHandlerListeners = (eventHandler, arg0, arg1) =>
    callAll(eventHandler.l, [arg0, arg1]);

  class ID {
    /**
     * @param {number} client client id
     * @param {number} clock unique per client id, continuous number
     */
    constructor (client, clock) {
      /**
       * Client id
       * @type {number}
       */
      this.client = client;
      /**
       * unique per client id, continuous number
       * @type {number}
       */
      this.clock = clock;
    }
  }

  /**
   * @param {ID | null} a
   * @param {ID | null} b
   * @return {boolean}
   *
   * @function
   */
  const compareIDs = (a, b) => a === b || (a !== null && b !== null && a.client === b.client && a.clock === b.clock);

  /**
   * @param {number} client
   * @param {number} clock
   *
   * @private
   * @function
   */
  const createID = (client, clock) => new ID(client, clock);

  /**
   * The top types are mapped from y.share.get(keyname) => type.
   * `type` does not store any information about the `keyname`.
   * This function finds the correct `keyname` for `type` and throws otherwise.
   *
   * @param {AbstractType<any>} type
   * @return {string}
   *
   * @private
   * @function
   */
  const findRootTypeKey = type => {
    // @ts-ignore _y must be defined, otherwise unexpected case
    for (const [key, value] of type.doc.share.entries()) {
      if (value === type) {
        return key
      }
    }
    throw unexpectedCase()
  };

  /**
   * Check if `parent` is a parent of `child`.
   *
   * @param {AbstractType<any>} parent
   * @param {Item|null} child
   * @return {Boolean} Whether `parent` is a parent of `child`.
   *
   * @private
   * @function
   */
  const isParentOf = (parent, child) => {
    while (child !== null) {
      if (child.parent === parent) {
        return true
      }
      child = /** @type {AbstractType<any>} */ (child.parent)._item;
    }
    return false
  };

  class Snapshot {
    /**
     * @param {DeleteSet} ds
     * @param {Map<number,number>} sv state map
     */
    constructor (ds, sv) {
      /**
       * @type {DeleteSet}
       */
      this.ds = ds;
      /**
       * State Map
       * @type {Map<number,number>}
       */
      this.sv = sv;
    }
  }

  /**
   * @param {DeleteSet} ds
   * @param {Map<number,number>} sm
   * @return {Snapshot}
   */
  const createSnapshot = (ds, sm) => new Snapshot(ds, sm);

  createSnapshot(createDeleteSet(), new Map());

  /**
   * @param {Item} item
   * @param {Snapshot|undefined} snapshot
   *
   * @protected
   * @function
   */
  const isVisible = (item, snapshot) => snapshot === undefined
    ? !item.deleted
    : snapshot.sv.has(item.id.client) && (snapshot.sv.get(item.id.client) || 0) > item.id.clock && !isDeleted(snapshot.ds, item.id);

  /**
   * @param {Transaction} transaction
   * @param {Snapshot} snapshot
   */
  const splitSnapshotAffectedStructs = (transaction, snapshot) => {
    const meta = setIfUndefined(transaction.meta, splitSnapshotAffectedStructs, create$5);
    const store = transaction.doc.store;
    // check if we already split for this snapshot
    if (!meta.has(snapshot)) {
      snapshot.sv.forEach((clock, client) => {
        if (clock < getState(store, client)) {
          getItemCleanStart(transaction, createID(client, clock));
        }
      });
      iterateDeletedStructs(transaction, snapshot.ds, _item => {});
      meta.add(snapshot);
    }
  };

  class StructStore {
    constructor () {
      /**
       * @type {Map<number,Array<GC|Item>>}
       */
      this.clients = new Map();
      /**
       * @type {null | { missing: Map<number, number>, update: Uint8Array }}
       */
      this.pendingStructs = null;
      /**
       * @type {null | Uint8Array}
       */
      this.pendingDs = null;
    }
  }

  /**
   * Return the states as a Map<client,clock>.
   * Note that clock refers to the next expected clock id.
   *
   * @param {StructStore} store
   * @return {Map<number,number>}
   *
   * @public
   * @function
   */
  const getStateVector = store => {
    const sm = new Map();
    store.clients.forEach((structs, client) => {
      const struct = structs[structs.length - 1];
      sm.set(client, struct.id.clock + struct.length);
    });
    return sm
  };

  /**
   * @param {StructStore} store
   * @param {number} client
   * @return {number}
   *
   * @public
   * @function
   */
  const getState = (store, client) => {
    const structs = store.clients.get(client);
    if (structs === undefined) {
      return 0
    }
    const lastStruct = structs[structs.length - 1];
    return lastStruct.id.clock + lastStruct.length
  };

  /**
   * @param {StructStore} store
   * @param {GC|Item} struct
   *
   * @private
   * @function
   */
  const addStruct = (store, struct) => {
    let structs = store.clients.get(struct.id.client);
    if (structs === undefined) {
      structs = [];
      store.clients.set(struct.id.client, structs);
    } else {
      const lastStruct = structs[structs.length - 1];
      if (lastStruct.id.clock + lastStruct.length !== struct.id.clock) {
        throw unexpectedCase()
      }
    }
    structs.push(struct);
  };

  /**
   * Perform a binary search on a sorted array
   * @param {Array<Item|GC>} structs
   * @param {number} clock
   * @return {number}
   *
   * @private
   * @function
   */
  const findIndexSS = (structs, clock) => {
    let left = 0;
    let right = structs.length - 1;
    let mid = structs[right];
    let midclock = mid.id.clock;
    if (midclock === clock) {
      return right
    }
    // @todo does it even make sense to pivot the search?
    // If a good split misses, it might actually increase the time to find the correct item.
    // Currently, the only advantage is that search with pivoting might find the item on the first try.
    let midindex = floor((clock / (midclock + mid.length - 1)) * right); // pivoting the search
    while (left <= right) {
      mid = structs[midindex];
      midclock = mid.id.clock;
      if (midclock <= clock) {
        if (clock < midclock + mid.length) {
          return midindex
        }
        left = midindex + 1;
      } else {
        right = midindex - 1;
      }
      midindex = floor((left + right) / 2);
    }
    // Always check state before looking for a struct in StructStore
    // Therefore the case of not finding a struct is unexpected
    throw unexpectedCase()
  };

  /**
   * Expects that id is actually in store. This function throws or is an infinite loop otherwise.
   *
   * @param {StructStore} store
   * @param {ID} id
   * @return {GC|Item}
   *
   * @private
   * @function
   */
  const find$1 = (store, id) => {
    /**
     * @type {Array<GC|Item>}
     */
    // @ts-ignore
    const structs = store.clients.get(id.client);
    return structs[findIndexSS(structs, id.clock)]
  };

  /**
   * Expects that id is actually in store. This function throws or is an infinite loop otherwise.
   * @private
   * @function
   */
  const getItem = /** @type {function(StructStore,ID):Item} */ (find$1);

  /**
   * @param {Transaction} transaction
   * @param {Array<Item|GC>} structs
   * @param {number} clock
   */
  const findIndexCleanStart = (transaction, structs, clock) => {
    const index = findIndexSS(structs, clock);
    const struct = structs[index];
    if (struct.id.clock < clock && struct instanceof Item) {
      structs.splice(index + 1, 0, splitItem(transaction, struct, clock - struct.id.clock));
      return index + 1
    }
    return index
  };

  /**
   * Expects that id is actually in store. This function throws or is an infinite loop otherwise.
   *
   * @param {Transaction} transaction
   * @param {ID} id
   * @return {Item}
   *
   * @private
   * @function
   */
  const getItemCleanStart = (transaction, id) => {
    const structs = /** @type {Array<Item>} */ (transaction.doc.store.clients.get(id.client));
    return structs[findIndexCleanStart(transaction, structs, id.clock)]
  };

  /**
   * Expects that id is actually in store. This function throws or is an infinite loop otherwise.
   *
   * @param {Transaction} transaction
   * @param {StructStore} store
   * @param {ID} id
   * @return {Item}
   *
   * @private
   * @function
   */
  const getItemCleanEnd = (transaction, store, id) => {
    /**
     * @type {Array<Item>}
     */
    // @ts-ignore
    const structs = store.clients.get(id.client);
    const index = findIndexSS(structs, id.clock);
    const struct = structs[index];
    if (id.clock !== struct.id.clock + struct.length - 1 && struct.constructor !== GC) {
      structs.splice(index + 1, 0, splitItem(transaction, struct, id.clock - struct.id.clock + 1));
    }
    return struct
  };

  /**
   * Replace `item` with `newitem` in store
   * @param {StructStore} store
   * @param {GC|Item} struct
   * @param {GC|Item} newStruct
   *
   * @private
   * @function
   */
  const replaceStruct = (store, struct, newStruct) => {
    const structs = /** @type {Array<GC|Item>} */ (store.clients.get(struct.id.client));
    structs[findIndexSS(structs, struct.id.clock)] = newStruct;
  };

  /**
   * Iterate over a range of structs
   *
   * @param {Transaction} transaction
   * @param {Array<Item|GC>} structs
   * @param {number} clockStart Inclusive start
   * @param {number} len
   * @param {function(GC|Item):void} f
   *
   * @function
   */
  const iterateStructs = (transaction, structs, clockStart, len, f) => {
    if (len === 0) {
      return
    }
    const clockEnd = clockStart + len;
    let index = findIndexCleanStart(transaction, structs, clockStart);
    let struct;
    do {
      struct = structs[index++];
      if (clockEnd < struct.id.clock + struct.length) {
        findIndexCleanStart(transaction, structs, clockEnd);
      }
      f(struct);
    } while (index < structs.length && structs[index].id.clock < clockEnd)
  };

  /**
   * A transaction is created for every change on the Yjs model. It is possible
   * to bundle changes on the Yjs model in a single transaction to
   * minimize the number on messages sent and the number of observer calls.
   * If possible the user of this library should bundle as many changes as
   * possible. Here is an example to illustrate the advantages of bundling:
   *
   * @example
   * const ydoc = new Y.Doc()
   * const map = ydoc.getMap('map')
   * // Log content when change is triggered
   * map.observe(() => {
   *   console.log('change triggered')
   * })
   * // Each change on the map type triggers a log message:
   * map.set('a', 0) // => "change triggered"
   * map.set('b', 0) // => "change triggered"
   * // When put in a transaction, it will trigger the log after the transaction:
   * ydoc.transact(() => {
   *   map.set('a', 1)
   *   map.set('b', 1)
   * }) // => "change triggered"
   *
   * @public
   */
  class Transaction {
    /**
     * @param {Doc} doc
     * @param {any} origin
     * @param {boolean} local
     */
    constructor (doc, origin, local) {
      /**
       * The Yjs instance.
       * @type {Doc}
       */
      this.doc = doc;
      /**
       * Describes the set of deleted items by ids
       * @type {DeleteSet}
       */
      this.deleteSet = new DeleteSet();
      /**
       * Holds the state before the transaction started.
       * @type {Map<Number,Number>}
       */
      this.beforeState = getStateVector(doc.store);
      /**
       * Holds the state after the transaction.
       * @type {Map<Number,Number>}
       */
      this.afterState = new Map();
      /**
       * All types that were directly modified (property added or child
       * inserted/deleted). New types are not included in this Set.
       * Maps from type to parentSubs (`item.parentSub = null` for YArray)
       * @type {Map<AbstractType<YEvent<any>>,Set<String|null>>}
       */
      this.changed = new Map();
      /**
       * Stores the events for the types that observe also child elements.
       * It is mainly used by `observeDeep`.
       * @type {Map<AbstractType<YEvent<any>>,Array<YEvent<any>>>}
       */
      this.changedParentTypes = new Map();
      /**
       * @type {Array<AbstractStruct>}
       */
      this._mergeStructs = [];
      /**
       * @type {any}
       */
      this.origin = origin;
      /**
       * Stores meta information on the transaction
       * @type {Map<any,any>}
       */
      this.meta = new Map();
      /**
       * Whether this change originates from this doc.
       * @type {boolean}
       */
      this.local = local;
      /**
       * @type {Set<Doc>}
       */
      this.subdocsAdded = new Set();
      /**
       * @type {Set<Doc>}
       */
      this.subdocsRemoved = new Set();
      /**
       * @type {Set<Doc>}
       */
      this.subdocsLoaded = new Set();
      /**
       * @type {boolean}
       */
      this._needFormattingCleanup = false;
    }
  }

  /**
   * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder
   * @param {Transaction} transaction
   * @return {boolean} Whether data was written.
   */
  const writeUpdateMessageFromTransaction = (encoder, transaction) => {
    if (transaction.deleteSet.clients.size === 0 && !any(transaction.afterState, (clock, client) => transaction.beforeState.get(client) !== clock)) {
      return false
    }
    sortAndMergeDeleteSet(transaction.deleteSet);
    writeStructsFromTransaction(encoder, transaction);
    writeDeleteSet(encoder, transaction.deleteSet);
    return true
  };

  /**
   * If `type.parent` was added in current transaction, `type` technically
   * did not change, it was just added and we should not fire events for `type`.
   *
   * @param {Transaction} transaction
   * @param {AbstractType<YEvent<any>>} type
   * @param {string|null} parentSub
   */
  const addChangedTypeToTransaction = (transaction, type, parentSub) => {
    const item = type._item;
    if (item === null || (item.id.clock < (transaction.beforeState.get(item.id.client) || 0) && !item.deleted)) {
      setIfUndefined(transaction.changed, type, create$5).add(parentSub);
    }
  };

  /**
   * @param {Array<AbstractStruct>} structs
   * @param {number} pos
   * @return {number} # of merged structs
   */
  const tryToMergeWithLefts = (structs, pos) => {
    let right = structs[pos];
    let left = structs[pos - 1];
    let i = pos;
    for (; i > 0; right = left, left = structs[--i - 1]) {
      if (left.deleted === right.deleted && left.constructor === right.constructor) {
        if (left.mergeWith(right)) {
          if (right instanceof Item && right.parentSub !== null && /** @type {AbstractType<any>} */ (right.parent)._map.get(right.parentSub) === right) {
            /** @type {AbstractType<any>} */ (right.parent)._map.set(right.parentSub, /** @type {Item} */ (left));
          }
          continue
        }
      }
      break
    }
    const merged = pos - i;
    if (merged) {
      // remove all merged structs from the array
      structs.splice(pos + 1 - merged, merged);
    }
    return merged
  };

  /**
   * @param {DeleteSet} ds
   * @param {StructStore} store
   * @param {function(Item):boolean} gcFilter
   */
  const tryGcDeleteSet = (ds, store, gcFilter) => {
    for (const [client, deleteItems] of ds.clients.entries()) {
      const structs = /** @type {Array<GC|Item>} */ (store.clients.get(client));
      for (let di = deleteItems.length - 1; di >= 0; di--) {
        const deleteItem = deleteItems[di];
        const endDeleteItemClock = deleteItem.clock + deleteItem.len;
        for (
          let si = findIndexSS(structs, deleteItem.clock), struct = structs[si];
          si < structs.length && struct.id.clock < endDeleteItemClock;
          struct = structs[++si]
        ) {
          const struct = structs[si];
          if (deleteItem.clock + deleteItem.len <= struct.id.clock) {
            break
          }
          if (struct instanceof Item && struct.deleted && !struct.keep && gcFilter(struct)) {
            struct.gc(store, false);
          }
        }
      }
    }
  };

  /**
   * @param {DeleteSet} ds
   * @param {StructStore} store
   */
  const tryMergeDeleteSet = (ds, store) => {
    // try to merge deleted / gc'd items
    // merge from right to left for better efficiency and so we don't miss any merge targets
    ds.clients.forEach((deleteItems, client) => {
      const structs = /** @type {Array<GC|Item>} */ (store.clients.get(client));
      for (let di = deleteItems.length - 1; di >= 0; di--) {
        const deleteItem = deleteItems[di];
        // start with merging the item next to the last deleted item
        const mostRightIndexToCheck = min(structs.length - 1, 1 + findIndexSS(structs, deleteItem.clock + deleteItem.len - 1));
        for (
          let si = mostRightIndexToCheck, struct = structs[si];
          si > 0 && struct.id.clock >= deleteItem.clock;
          struct = structs[si]
        ) {
          si -= 1 + tryToMergeWithLefts(structs, si);
        }
      }
    });
  };

  /**
   * @param {Array<Transaction>} transactionCleanups
   * @param {number} i
   */
  const cleanupTransactions = (transactionCleanups, i) => {
    if (i < transactionCleanups.length) {
      const transaction = transactionCleanups[i];
      const doc = transaction.doc;
      const store = doc.store;
      const ds = transaction.deleteSet;
      const mergeStructs = transaction._mergeStructs;
      try {
        sortAndMergeDeleteSet(ds);
        transaction.afterState = getStateVector(transaction.doc.store);
        doc.emit('beforeObserverCalls', [transaction, doc]);
        /**
         * An array of event callbacks.
         *
         * Each callback is called even if the other ones throw errors.
         *
         * @type {Array<function():void>}
         */
        const fs = [];
        // observe events on changed types
        transaction.changed.forEach((subs, itemtype) =>
          fs.push(() => {
            if (itemtype._item === null || !itemtype._item.deleted) {
              itemtype._callObserver(transaction, subs);
            }
          })
        );
        fs.push(() => {
          // deep observe events
          transaction.changedParentTypes.forEach((events, type) => {
            // We need to think about the possibility that the user transforms the
            // Y.Doc in the event.
            if (type._dEH.l.length > 0 && (type._item === null || !type._item.deleted)) {
              events = events
                .filter(event =>
                  event.target._item === null || !event.target._item.deleted
                );
              events
                .forEach(event => {
                  event.currentTarget = type;
                  // path is relative to the current target
                  event._path = null;
                });
              // sort events by path length so that top-level events are fired first.
              events
                .sort((event1, event2) => event1.path.length - event2.path.length);
              // We don't need to check for events.length
              // because we know it has at least one element
              callEventHandlerListeners(type._dEH, events, transaction);
            }
          });
        });
        fs.push(() => doc.emit('afterTransaction', [transaction, doc]));
        callAll(fs, []);
        if (transaction._needFormattingCleanup) {
          cleanupYTextAfterTransaction(transaction);
        }
      } finally {
        // Replace deleted items with ItemDeleted / GC.
        // This is where content is actually remove from the Yjs Doc.
        if (doc.gc) {
          tryGcDeleteSet(ds, store, doc.gcFilter);
        }
        tryMergeDeleteSet(ds, store);

        // on all affected store.clients props, try to merge
        transaction.afterState.forEach((clock, client) => {
          const beforeClock = transaction.beforeState.get(client) || 0;
          if (beforeClock !== clock) {
            const structs = /** @type {Array<GC|Item>} */ (store.clients.get(client));
            // we iterate from right to left so we can safely remove entries
            const firstChangePos = max(findIndexSS(structs, beforeClock), 1);
            for (let i = structs.length - 1; i >= firstChangePos;) {
              i -= 1 + tryToMergeWithLefts(structs, i);
            }
          }
        });
        // try to merge mergeStructs
        // @todo: it makes more sense to transform mergeStructs to a DS, sort it, and merge from right to left
        //        but at the moment DS does not handle duplicates
        for (let i = mergeStructs.length - 1; i >= 0; i--) {
          const { client, clock } = mergeStructs[i].id;
          const structs = /** @type {Array<GC|Item>} */ (store.clients.get(client));
          const replacedStructPos = findIndexSS(structs, clock);
          if (replacedStructPos + 1 < structs.length) {
            if (tryToMergeWithLefts(structs, replacedStructPos + 1) > 1) {
              continue // no need to perform next check, both are already merged
            }
          }
          if (replacedStructPos > 0) {
            tryToMergeWithLefts(structs, replacedStructPos);
          }
        }
        if (!transaction.local && transaction.afterState.get(doc.clientID) !== transaction.beforeState.get(doc.clientID)) {
          print(ORANGE, BOLD, '[yjs] ', UNBOLD, RED, 'Changed the client-id because another client seems to be using it.');
          doc.clientID = generateNewClientId();
        }
        // @todo Merge all the transactions into one and provide send the data as a single update message
        doc.emit('afterTransactionCleanup', [transaction, doc]);
        if (doc._observers.has('update')) {
          const encoder = new UpdateEncoderV1();
          const hasContent = writeUpdateMessageFromTransaction(encoder, transaction);
          if (hasContent) {
            doc.emit('update', [encoder.toUint8Array(), transaction.origin, doc, transaction]);
          }
        }
        if (doc._observers.has('updateV2')) {
          const encoder = new UpdateEncoderV2();
          const hasContent = writeUpdateMessageFromTransaction(encoder, transaction);
          if (hasContent) {
            doc.emit('updateV2', [encoder.toUint8Array(), transaction.origin, doc, transaction]);
          }
        }
        const { subdocsAdded, subdocsLoaded, subdocsRemoved } = transaction;
        if (subdocsAdded.size > 0 || subdocsRemoved.size > 0 || subdocsLoaded.size > 0) {
          subdocsAdded.forEach(subdoc => {
            subdoc.clientID = doc.clientID;
            if (subdoc.collectionid == null) {
              subdoc.collectionid = doc.collectionid;
            }
            doc.subdocs.add(subdoc);
          });
          subdocsRemoved.forEach(subdoc => doc.subdocs.delete(subdoc));
          doc.emit('subdocs', [{ loaded: subdocsLoaded, added: subdocsAdded, removed: subdocsRemoved }, doc, transaction]);
          subdocsRemoved.forEach(subdoc => subdoc.destroy());
        }

        if (transactionCleanups.length <= i + 1) {
          doc._transactionCleanups = [];
          doc.emit('afterAllTransactions', [doc, transactionCleanups]);
        } else {
          cleanupTransactions(transactionCleanups, i + 1);
        }
      }
    }
  };

  /**
   * Implements the functionality of `y.transact(()=>{..})`
   *
   * @template T
   * @param {Doc} doc
   * @param {function(Transaction):T} f
   * @param {any} [origin=true]
   * @return {T}
   *
   * @function
   */
  const transact = (doc, f, origin = null, local = true) => {
    const transactionCleanups = doc._transactionCleanups;
    let initialCall = false;
    /**
     * @type {any}
     */
    let result = null;
    if (doc._transaction === null) {
      initialCall = true;
      doc._transaction = new Transaction(doc, origin, local);
      transactionCleanups.push(doc._transaction);
      if (transactionCleanups.length === 1) {
        doc.emit('beforeAllTransactions', [doc]);
      }
      doc.emit('beforeTransaction', [doc._transaction, doc]);
    }
    try {
      result = f(doc._transaction);
    } finally {
      if (initialCall) {
        const finishCleanup = doc._transaction === transactionCleanups[0];
        doc._transaction = null;
        if (finishCleanup) {
          // The first transaction ended, now process observer calls.
          // Observer call may create new transactions for which we need to call the observers and do cleanup.
          // We don't want to nest these calls, so we execute these calls one after
          // another.
          // Also we need to ensure that all cleanups are called, even if the
          // observes throw errors.
          // This file is full of hacky try {} finally {} blocks to ensure that an
          // event can throw errors and also that the cleanup is called.
          cleanupTransactions(transactionCleanups, 0);
        }
      }
    }
    return result
  };

  class StackItem {
    /**
     * @param {DeleteSet} deletions
     * @param {DeleteSet} insertions
     */
    constructor (deletions, insertions) {
      this.insertions = insertions;
      this.deletions = deletions;
      /**
       * Use this to save and restore metadata like selection range
       */
      this.meta = new Map();
    }
  }
  /**
   * @param {Transaction} tr
   * @param {UndoManager} um
   * @param {StackItem} stackItem
   */
  const clearUndoManagerStackItem = (tr, um, stackItem) => {
    iterateDeletedStructs(tr, stackItem.deletions, item => {
      if (item instanceof Item && um.scope.some(type => type === tr.doc || isParentOf(/** @type {AbstractType<any>} */ (type), item))) {
        keepItem(item, false);
      }
    });
  };

  /**
   * @param {UndoManager} undoManager
   * @param {Array<StackItem>} stack
   * @param {'undo'|'redo'} eventType
   * @return {StackItem?}
   */
  const popStackItem = (undoManager, stack, eventType) => {
    /**
     * Keep a reference to the transaction so we can fire the event with the changedParentTypes
     * @type {any}
     */
    let _tr = null;
    const doc = undoManager.doc;
    const scope = undoManager.scope;
    transact(doc, transaction => {
      while (stack.length > 0 && undoManager.currStackItem === null) {
        const store = doc.store;
        const stackItem = /** @type {StackItem} */ (stack.pop());
        /**
         * @type {Set<Item>}
         */
        const itemsToRedo = new Set();
        /**
         * @type {Array<Item>}
         */
        const itemsToDelete = [];
        let performedChange = false;
        iterateDeletedStructs(transaction, stackItem.insertions, struct => {
          if (struct instanceof Item) {
            if (struct.redone !== null) {
              let { item, diff } = followRedone(store, struct.id);
              if (diff > 0) {
                item = getItemCleanStart(transaction, createID(item.id.client, item.id.clock + diff));
              }
              struct = item;
            }
            if (!struct.deleted && scope.some(type => type === transaction.doc || isParentOf(/** @type {AbstractType<any>} */ (type), /** @type {Item} */ (struct)))) {
              itemsToDelete.push(struct);
            }
          }
        });
        iterateDeletedStructs(transaction, stackItem.deletions, struct => {
          if (
            struct instanceof Item &&
            scope.some(type => type === transaction.doc || isParentOf(/** @type {AbstractType<any>} */ (type), struct)) &&
            // Never redo structs in stackItem.insertions because they were created and deleted in the same capture interval.
            !isDeleted(stackItem.insertions, struct.id)
          ) {
            itemsToRedo.add(struct);
          }
        });
        itemsToRedo.forEach(struct => {
          performedChange = redoItem(transaction, struct, itemsToRedo, stackItem.insertions, undoManager.ignoreRemoteMapChanges, undoManager) !== null || performedChange;
        });
        // We want to delete in reverse order so that children are deleted before
        // parents, so we have more information available when items are filtered.
        for (let i = itemsToDelete.length - 1; i >= 0; i--) {
          const item = itemsToDelete[i];
          if (undoManager.deleteFilter(item)) {
            item.delete(transaction);
            performedChange = true;
          }
        }
        undoManager.currStackItem = performedChange ? stackItem : null;
      }
      transaction.changed.forEach((subProps, type) => {
        // destroy search marker if necessary
        if (subProps.has(null) && type._searchMarker) {
          type._searchMarker.length = 0;
        }
      });
      _tr = transaction;
    }, undoManager);
    const res = undoManager.currStackItem;
    if (res != null) {
      const changedParentTypes = _tr.changedParentTypes;
      undoManager.emit('stack-item-popped', [{ stackItem: res, type: eventType, changedParentTypes, origin: undoManager }, undoManager]);
      undoManager.currStackItem = null;
    }
    return res
  };

  /**
   * @typedef {Object} UndoManagerOptions
   * @property {number} [UndoManagerOptions.captureTimeout=500]
   * @property {function(Transaction):boolean} [UndoManagerOptions.captureTransaction] Do not capture changes of a Transaction if result false.
   * @property {function(Item):boolean} [UndoManagerOptions.deleteFilter=()=>true] Sometimes
   * it is necessary to filter what an Undo/Redo operation can delete. If this
   * filter returns false, the type/item won't be deleted even it is in the
   * undo/redo scope.
   * @property {Set<any>} [UndoManagerOptions.trackedOrigins=new Set([null])]
   * @property {boolean} [ignoreRemoteMapChanges] Experimental. By default, the UndoManager will never overwrite remote changes. Enable this property to enable overwriting remote changes on key-value changes (Y.Map, properties on Y.Xml, etc..).
   * @property {Doc} [doc] The document that this UndoManager operates on. Only needed if typeScope is empty.
   */

  /**
   * @typedef {Object} StackItemEvent
   * @property {StackItem} StackItemEvent.stackItem
   * @property {any} StackItemEvent.origin
   * @property {'undo'|'redo'} StackItemEvent.type
   * @property {Map<AbstractType<YEvent<any>>,Array<YEvent<any>>>} StackItemEvent.changedParentTypes
   */

  /**
   * Fires 'stack-item-added' event when a stack item was added to either the undo- or
   * the redo-stack. You may store additional stack information via the
   * metadata property on `event.stackItem.meta` (it is a `Map` of metadata properties).
   * Fires 'stack-item-popped' event when a stack item was popped from either the
   * undo- or the redo-stack. You may restore the saved stack information from `event.stackItem.meta`.
   *
   * @extends {ObservableV2<{'stack-item-added':function(StackItemEvent, UndoManager):void, 'stack-item-popped': function(StackItemEvent, UndoManager):void, 'stack-cleared': function({ undoStackCleared: boolean, redoStackCleared: boolean }):void, 'stack-item-updated': function(StackItemEvent, UndoManager):void }>}
   */
  class UndoManager extends ObservableV2 {
    /**
     * @param {Doc|AbstractType<any>|Array<AbstractType<any>>} typeScope Limits the scope of the UndoManager. If this is set to a ydoc instance, all changes on that ydoc will be undone. If set to a specific type, only changes on that type or its children will be undone. Also accepts an array of types.
     * @param {UndoManagerOptions} options
     */
    constructor (typeScope, {
      captureTimeout = 500,
      captureTransaction = _tr => true,
      deleteFilter = () => true,
      trackedOrigins = new Set([null]),
      ignoreRemoteMapChanges = false,
      doc = /** @type {Doc} */ (isArray(typeScope) ? typeScope[0].doc : typeScope instanceof Doc ? typeScope : typeScope.doc)
    } = {}) {
      super();
      /**
       * @type {Array<AbstractType<any> | Doc>}
       */
      this.scope = [];
      this.doc = doc;
      this.addToScope(typeScope);
      this.deleteFilter = deleteFilter;
      trackedOrigins.add(this);
      this.trackedOrigins = trackedOrigins;
      this.captureTransaction = captureTransaction;
      /**
       * @type {Array<StackItem>}
       */
      this.undoStack = [];
      /**
       * @type {Array<StackItem>}
       */
      this.redoStack = [];
      /**
       * Whether the client is currently undoing (calling UndoManager.undo)
       *
       * @type {boolean}
       */
      this.undoing = false;
      this.redoing = false;
      /**
       * The currently popped stack item if UndoManager.undoing or UndoManager.redoing
       *
       * @type {StackItem|null}
       */
      this.currStackItem = null;
      this.lastChange = 0;
      this.ignoreRemoteMapChanges = ignoreRemoteMapChanges;
      this.captureTimeout = captureTimeout;
      /**
       * @param {Transaction} transaction
       */
      this.afterTransactionHandler = transaction => {
        // Only track certain transactions
        if (
          !this.captureTransaction(transaction) ||
          !this.scope.some(type => transaction.changedParentTypes.has(/** @type {AbstractType<any>} */ (type)) || type === this.doc) ||
          (!this.trackedOrigins.has(transaction.origin) && (!transaction.origin || !this.trackedOrigins.has(transaction.origin.constructor)))
        ) {
          return
        }
        const undoing = this.undoing;
        const redoing = this.redoing;
        const stack = undoing ? this.redoStack : this.undoStack;
        if (undoing) {
          this.stopCapturing(); // next undo should not be appended to last stack item
        } else if (!redoing) {
          // neither undoing nor redoing: delete redoStack
          this.clear(false, true);
        }
        const insertions = new DeleteSet();
        transaction.afterState.forEach((endClock, client) => {
          const startClock = transaction.beforeState.get(client) || 0;
          const len = endClock - startClock;
          if (len > 0) {
            addToDeleteSet(insertions, client, startClock, len);
          }
        });
        const now = getUnixTime();
        let didAdd = false;
        if (this.lastChange > 0 && now - this.lastChange < this.captureTimeout && stack.length > 0 && !undoing && !redoing) {
          // append change to last stack op
          const lastOp = stack[stack.length - 1];
          lastOp.deletions = mergeDeleteSets([lastOp.deletions, transaction.deleteSet]);
          lastOp.insertions = mergeDeleteSets([lastOp.insertions, insertions]);
        } else {
          // create a new stack op
          stack.push(new StackItem(transaction.deleteSet, insertions));
          didAdd = true;
        }
        if (!undoing && !redoing) {
          this.lastChange = now;
        }
        // make sure that deleted structs are not gc'd
        iterateDeletedStructs(transaction, transaction.deleteSet, /** @param {Item|GC} item */ item => {
          if (item instanceof Item && this.scope.some(type => type === transaction.doc || isParentOf(/** @type {AbstractType<any>} */ (type), item))) {
            keepItem(item, true);
          }
        });
        /**
         * @type {[StackItemEvent, UndoManager]}
         */
        const changeEvent = [{ stackItem: stack[stack.length - 1], origin: transaction.origin, type: undoing ? 'redo' : 'undo', changedParentTypes: transaction.changedParentTypes }, this];
        if (didAdd) {
          this.emit('stack-item-added', changeEvent);
        } else {
          this.emit('stack-item-updated', changeEvent);
        }
      };
      this.doc.on('afterTransaction', this.afterTransactionHandler);
      this.doc.on('destroy', () => {
        this.destroy();
      });
    }

    /**
     * Extend the scope.
     *
     * @param {Array<AbstractType<any> | Doc> | AbstractType<any> | Doc} ytypes
     */
    addToScope (ytypes) {
      const tmpSet = new Set(this.scope);
      ytypes = isArray(ytypes) ? ytypes : [ytypes];
      ytypes.forEach(ytype => {
        if (!tmpSet.has(ytype)) {
          tmpSet.add(ytype);
          if (ytype instanceof AbstractType ? ytype.doc !== this.doc : ytype !== this.doc) warn('[yjs#509] Not same Y.Doc'); // use MultiDocUndoManager instead. also see https://github.com/yjs/yjs/issues/509
          this.scope.push(ytype);
        }
      });
    }

    /**
     * @param {any} origin
     */
    addTrackedOrigin (origin) {
      this.trackedOrigins.add(origin);
    }

    /**
     * @param {any} origin
     */
    removeTrackedOrigin (origin) {
      this.trackedOrigins.delete(origin);
    }

    clear (clearUndoStack = true, clearRedoStack = true) {
      if ((clearUndoStack && this.canUndo()) || (clearRedoStack && this.canRedo())) {
        this.doc.transact(tr => {
          if (clearUndoStack) {
            this.undoStack.forEach(item => clearUndoManagerStackItem(tr, this, item));
            this.undoStack = [];
          }
          if (clearRedoStack) {
            this.redoStack.forEach(item => clearUndoManagerStackItem(tr, this, item));
            this.redoStack = [];
          }
          this.emit('stack-cleared', [{ undoStackCleared: clearUndoStack, redoStackCleared: clearRedoStack }]);
        });
      }
    }

    /**
     * UndoManager merges Undo-StackItem if they are created within time-gap
     * smaller than `options.captureTimeout`. Call `um.stopCapturing()` so that the next
     * StackItem won't be merged.
     *
     *
     * @example
     *     // without stopCapturing
     *     ytext.insert(0, 'a')
     *     ytext.insert(1, 'b')
     *     um.undo()
     *     ytext.toString() // => '' (note that 'ab' was removed)
     *     // with stopCapturing
     *     ytext.insert(0, 'a')
     *     um.stopCapturing()
     *     ytext.insert(0, 'b')
     *     um.undo()
     *     ytext.toString() // => 'a' (note that only 'b' was removed)
     *
     */
    stopCapturing () {
      this.lastChange = 0;
    }

    /**
     * Undo last changes on type.
     *
     * @return {StackItem?} Returns StackItem if a change was applied
     */
    undo () {
      this.undoing = true;
      let res;
      try {
        res = popStackItem(this, this.undoStack, 'undo');
      } finally {
        this.undoing = false;
      }
      return res
    }

    /**
     * Redo last undo operation.
     *
     * @return {StackItem?} Returns StackItem if a change was applied
     */
    redo () {
      this.redoing = true;
      let res;
      try {
        res = popStackItem(this, this.redoStack, 'redo');
      } finally {
        this.redoing = false;
      }
      return res
    }

    /**
     * Are undo steps available?
     *
     * @return {boolean} `true` if undo is possible
     */
    canUndo () {
      return this.undoStack.length > 0
    }

    /**
     * Are redo steps available?
     *
     * @return {boolean} `true` if redo is possible
     */
    canRedo () {
      return this.redoStack.length > 0
    }

    destroy () {
      this.trackedOrigins.delete(this);
      this.doc.off('afterTransaction', this.afterTransactionHandler);
      super.destroy();
    }
  }

  /**
   * @param {UpdateDecoderV1 | UpdateDecoderV2} decoder
   */
  function * lazyStructReaderGenerator (decoder) {
    const numOfStateUpdates = readVarUint(decoder.restDecoder);
    for (let i = 0; i < numOfStateUpdates; i++) {
      const numberOfStructs = readVarUint(decoder.restDecoder);
      const client = decoder.readClient();
      let clock = readVarUint(decoder.restDecoder);
      for (let i = 0; i < numberOfStructs; i++) {
        const info = decoder.readInfo();
        // @todo use switch instead of ifs
        if (info === 10) {
          const len = readVarUint(decoder.restDecoder);
          yield new Skip(createID(client, clock), len);
          clock += len;
        } else if ((BITS5 & info) !== 0) {
          const cantCopyParentInfo = (info & (BIT7 | BIT8)) === 0;
          // If parent = null and neither left nor right are defined, then we know that `parent` is child of `y`
          // and we read the next string as parentYKey.
          // It indicates how we store/retrieve parent from `y.share`
          // @type {string|null}
          const struct = new Item(
            createID(client, clock),
            null, // left
            (info & BIT8) === BIT8 ? decoder.readLeftID() : null, // origin
            null, // right
            (info & BIT7) === BIT7 ? decoder.readRightID() : null, // right origin
            // @ts-ignore Force writing a string here.
            cantCopyParentInfo ? (decoder.readParentInfo() ? decoder.readString() : decoder.readLeftID()) : null, // parent
            cantCopyParentInfo && (info & BIT6) === BIT6 ? decoder.readString() : null, // parentSub
            readItemContent(decoder, info) // item content
          );
          yield struct;
          clock += struct.length;
        } else {
          const len = decoder.readLen();
          yield new GC(createID(client, clock), len);
          clock += len;
        }
      }
    }
  }

  class LazyStructReader {
    /**
     * @param {UpdateDecoderV1 | UpdateDecoderV2} decoder
     * @param {boolean} filterSkips
     */
    constructor (decoder, filterSkips) {
      this.gen = lazyStructReaderGenerator(decoder);
      /**
       * @type {null | Item | Skip | GC}
       */
      this.curr = null;
      this.done = false;
      this.filterSkips = filterSkips;
      this.next();
    }

    /**
     * @return {Item | GC | Skip |null}
     */
    next () {
      // ignore "Skip" structs
      do {
        this.curr = this.gen.next().value || null;
      } while (this.filterSkips && this.curr !== null && this.curr.constructor === Skip)
      return this.curr
    }
  }

  class LazyStructWriter {
    /**
     * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder
     */
    constructor (encoder) {
      this.currClient = 0;
      this.startClock = 0;
      this.written = 0;
      this.encoder = encoder;
      /**
       * We want to write operations lazily, but also we need to know beforehand how many operations we want to write for each client.
       *
       * This kind of meta-information (#clients, #structs-per-client-written) is written to the restEncoder.
       *
       * We fragment the restEncoder and store a slice of it per-client until we know how many clients there are.
       * When we flush (toUint8Array) we write the restEncoder using the fragments and the meta-information.
       *
       * @type {Array<{ written: number, restEncoder: Uint8Array }>}
       */
      this.clientStructs = [];
    }
  }

  /**
   * @param {Array<Uint8Array>} updates
   * @return {Uint8Array}
   */
  const mergeUpdates$1 = updates => mergeUpdatesV2(updates, UpdateDecoderV1, UpdateEncoderV1);

  /**
   * This method is intended to slice any kind of struct and retrieve the right part.
   * It does not handle side-effects, so it should only be used by the lazy-encoder.
   *
   * @param {Item | GC | Skip} left
   * @param {number} diff
   * @return {Item | GC}
   */
  const sliceStruct = (left, diff) => {
    if (left.constructor === GC) {
      const { client, clock } = left.id;
      return new GC(createID(client, clock + diff), left.length - diff)
    } else if (left.constructor === Skip) {
      const { client, clock } = left.id;
      return new Skip(createID(client, clock + diff), left.length - diff)
    } else {
      const leftItem = /** @type {Item} */ (left);
      const { client, clock } = leftItem.id;
      return new Item(
        createID(client, clock + diff),
        null,
        createID(client, clock + diff - 1),
        null,
        leftItem.rightOrigin,
        leftItem.parent,
        leftItem.parentSub,
        leftItem.content.splice(diff)
      )
    }
  };

  /**
   *
   * This function works similarly to `readUpdateV2`.
   *
   * @param {Array<Uint8Array>} updates
   * @param {typeof UpdateDecoderV1 | typeof UpdateDecoderV2} [YDecoder]
   * @param {typeof UpdateEncoderV1 | typeof UpdateEncoderV2} [YEncoder]
   * @return {Uint8Array}
   */
  const mergeUpdatesV2 = (updates, YDecoder = UpdateDecoderV2, YEncoder = UpdateEncoderV2) => {
    if (updates.length === 1) {
      return updates[0]
    }
    const updateDecoders = updates.map(update => new YDecoder(createDecoder(update)));
    let lazyStructDecoders = updateDecoders.map(decoder => new LazyStructReader(decoder, true));

    /**
     * @todo we don't need offset because we always slice before
     * @type {null | { struct: Item | GC | Skip, offset: number }}
     */
    let currWrite = null;

    const updateEncoder = new YEncoder();
    // write structs lazily
    const lazyStructEncoder = new LazyStructWriter(updateEncoder);

    // Note: We need to ensure that all lazyStructDecoders are fully consumed
    // Note: Should merge document updates whenever possible - even from different updates
    // Note: Should handle that some operations cannot be applied yet ()

    while (true) {
      // Write higher clients first ⇒ sort by clientID & clock and remove decoders without content
      lazyStructDecoders = lazyStructDecoders.filter(dec => dec.curr !== null);
      lazyStructDecoders.sort(
        /** @type {function(any,any):number} */ (dec1, dec2) => {
          if (dec1.curr.id.client === dec2.curr.id.client) {
            const clockDiff = dec1.curr.id.clock - dec2.curr.id.clock;
            if (clockDiff === 0) {
              // @todo remove references to skip since the structDecoders must filter Skips.
              return dec1.curr.constructor === dec2.curr.constructor
                ? 0
                : dec1.curr.constructor === Skip ? 1 : -1 // we are filtering skips anyway.
            } else {
              return clockDiff
            }
          } else {
            return dec2.curr.id.client - dec1.curr.id.client
          }
        }
      );
      if (lazyStructDecoders.length === 0) {
        break
      }
      const currDecoder = lazyStructDecoders[0];
      // write from currDecoder until the next operation is from another client or if filler-struct
      // then we need to reorder the decoders and find the next operation to write
      const firstClient = /** @type {Item | GC} */ (currDecoder.curr).id.client;

      if (currWrite !== null) {
        let curr = /** @type {Item | GC | null} */ (currDecoder.curr);
        let iterated = false;

        // iterate until we find something that we haven't written already
        // remember: first the high client-ids are written
        while (curr !== null && curr.id.clock + curr.length <= currWrite.struct.id.clock + currWrite.struct.length && curr.id.client >= currWrite.struct.id.client) {
          curr = currDecoder.next();
          iterated = true;
        }
        if (
          curr === null || // current decoder is empty
          curr.id.client !== firstClient || // check whether there is another decoder that has has updates from `firstClient`
          (iterated && curr.id.clock > currWrite.struct.id.clock + currWrite.struct.length) // the above while loop was used and we are potentially missing updates
        ) {
          continue
        }

        if (firstClient !== currWrite.struct.id.client) {
          writeStructToLazyStructWriter(lazyStructEncoder, currWrite.struct, currWrite.offset);
          currWrite = { struct: curr, offset: 0 };
          currDecoder.next();
        } else {
          if (currWrite.struct.id.clock + currWrite.struct.length < curr.id.clock) {
            // @todo write currStruct & set currStruct = Skip(clock = currStruct.id.clock + currStruct.length, length = curr.id.clock - self.clock)
            if (currWrite.struct.constructor === Skip) {
              // extend existing skip
              currWrite.struct.length = curr.id.clock + curr.length - currWrite.struct.id.clock;
            } else {
              writeStructToLazyStructWriter(lazyStructEncoder, currWrite.struct, currWrite.offset);
              const diff = curr.id.clock - currWrite.struct.id.clock - currWrite.struct.length;
              /**
               * @type {Skip}
               */
              const struct = new Skip(createID(firstClient, currWrite.struct.id.clock + currWrite.struct.length), diff);
              currWrite = { struct, offset: 0 };
            }
          } else { // if (currWrite.struct.id.clock + currWrite.struct.length >= curr.id.clock) {
            const diff = currWrite.struct.id.clock + currWrite.struct.length - curr.id.clock;
            if (diff > 0) {
              if (currWrite.struct.constructor === Skip) {
                // prefer to slice Skip because the other struct might contain more information
                currWrite.struct.length -= diff;
              } else {
                curr = sliceStruct(curr, diff);
              }
            }
            if (!currWrite.struct.mergeWith(/** @type {any} */ (curr))) {
              writeStructToLazyStructWriter(lazyStructEncoder, currWrite.struct, currWrite.offset);
              currWrite = { struct: curr, offset: 0 };
              currDecoder.next();
            }
          }
        }
      } else {
        currWrite = { struct: /** @type {Item | GC} */ (currDecoder.curr), offset: 0 };
        currDecoder.next();
      }
      for (
        let next = currDecoder.curr;
        next !== null && next.id.client === firstClient && next.id.clock === currWrite.struct.id.clock + currWrite.struct.length && next.constructor !== Skip;
        next = currDecoder.next()
      ) {
        writeStructToLazyStructWriter(lazyStructEncoder, currWrite.struct, currWrite.offset);
        currWrite = { struct: next, offset: 0 };
      }
    }
    if (currWrite !== null) {
      writeStructToLazyStructWriter(lazyStructEncoder, currWrite.struct, currWrite.offset);
      currWrite = null;
    }
    finishLazyStructWriting(lazyStructEncoder);

    const dss = updateDecoders.map(decoder => readDeleteSet(decoder));
    const ds = mergeDeleteSets(dss);
    writeDeleteSet(updateEncoder, ds);
    return updateEncoder.toUint8Array()
  };

  /**
   * @param {Uint8Array} update
   * @param {Uint8Array} sv
   * @param {typeof UpdateDecoderV1 | typeof UpdateDecoderV2} [YDecoder]
   * @param {typeof UpdateEncoderV1 | typeof UpdateEncoderV2} [YEncoder]
   */
  const diffUpdateV2 = (update, sv, YDecoder = UpdateDecoderV2, YEncoder = UpdateEncoderV2) => {
    const state = decodeStateVector$1(sv);
    const encoder = new YEncoder();
    const lazyStructWriter = new LazyStructWriter(encoder);
    const decoder = new YDecoder(createDecoder(update));
    const reader = new LazyStructReader(decoder, false);
    while (reader.curr) {
      const curr = reader.curr;
      const currClient = curr.id.client;
      const svClock = state.get(currClient) || 0;
      if (reader.curr.constructor === Skip) {
        // the first written struct shouldn't be a skip
        reader.next();
        continue
      }
      if (curr.id.clock + curr.length > svClock) {
        writeStructToLazyStructWriter(lazyStructWriter, curr, max(svClock - curr.id.clock, 0));
        reader.next();
        while (reader.curr && reader.curr.id.client === currClient) {
          writeStructToLazyStructWriter(lazyStructWriter, reader.curr, 0);
          reader.next();
        }
      } else {
        // read until something new comes up
        while (reader.curr && reader.curr.id.client === currClient && reader.curr.id.clock + reader.curr.length <= svClock) {
          reader.next();
        }
      }
    }
    finishLazyStructWriting(lazyStructWriter);
    // write ds
    const ds = readDeleteSet(decoder);
    writeDeleteSet(encoder, ds);
    return encoder.toUint8Array()
  };

  /**
   * @param {LazyStructWriter} lazyWriter
   */
  const flushLazyStructWriter = lazyWriter => {
    if (lazyWriter.written > 0) {
      lazyWriter.clientStructs.push({ written: lazyWriter.written, restEncoder: toUint8Array(lazyWriter.encoder.restEncoder) });
      lazyWriter.encoder.restEncoder = createEncoder();
      lazyWriter.written = 0;
    }
  };

  /**
   * @param {LazyStructWriter} lazyWriter
   * @param {Item | GC} struct
   * @param {number} offset
   */
  const writeStructToLazyStructWriter = (lazyWriter, struct, offset) => {
    // flush curr if we start another client
    if (lazyWriter.written > 0 && lazyWriter.currClient !== struct.id.client) {
      flushLazyStructWriter(lazyWriter);
    }
    if (lazyWriter.written === 0) {
      lazyWriter.currClient = struct.id.client;
      // write next client
      lazyWriter.encoder.writeClient(struct.id.client);
      // write startClock
      writeVarUint(lazyWriter.encoder.restEncoder, struct.id.clock + offset);
    }
    struct.write(lazyWriter.encoder, offset);
    lazyWriter.written++;
  };
  /**
   * Call this function when we collected all parts and want to
   * put all the parts together. After calling this method,
   * you can continue using the UpdateEncoder.
   *
   * @param {LazyStructWriter} lazyWriter
   */
  const finishLazyStructWriting = (lazyWriter) => {
    flushLazyStructWriter(lazyWriter);

    // this is a fresh encoder because we called flushCurr
    const restEncoder = lazyWriter.encoder.restEncoder;

    /**
     * Now we put all the fragments together.
     * This works similarly to `writeClientsStructs`
     */

    // write # states that were updated - i.e. the clients
    writeVarUint(restEncoder, lazyWriter.clientStructs.length);

    for (let i = 0; i < lazyWriter.clientStructs.length; i++) {
      const partStructs = lazyWriter.clientStructs[i];
      /**
       * Works similarly to `writeStructs`
       */
      // write # encoded structs
      writeVarUint(restEncoder, partStructs.written);
      // write the rest of the fragment
      writeUint8Array(restEncoder, partStructs.restEncoder);
    }
  };

  /**
   * @param {Uint8Array} update
   * @param {function(Item|GC|Skip):Item|GC|Skip} blockTransformer
   * @param {typeof UpdateDecoderV2 | typeof UpdateDecoderV1} YDecoder
   * @param {typeof UpdateEncoderV2 | typeof UpdateEncoderV1 } YEncoder
   */
  const convertUpdateFormat = (update, blockTransformer, YDecoder, YEncoder) => {
    const updateDecoder = new YDecoder(createDecoder(update));
    const lazyDecoder = new LazyStructReader(updateDecoder, false);
    const updateEncoder = new YEncoder();
    const lazyWriter = new LazyStructWriter(updateEncoder);
    for (let curr = lazyDecoder.curr; curr !== null; curr = lazyDecoder.next()) {
      writeStructToLazyStructWriter(lazyWriter, blockTransformer(curr), 0);
    }
    finishLazyStructWriting(lazyWriter);
    const ds = readDeleteSet(updateDecoder);
    writeDeleteSet(updateEncoder, ds);
    return updateEncoder.toUint8Array()
  };

  /**
   * @param {Uint8Array} update
   */
  const convertUpdateFormatV2ToV1 = update => convertUpdateFormat(update, id, UpdateDecoderV2, UpdateEncoderV1);

  const errorComputeChanges = 'You must not compute changes after the event-handler fired.';

  /**
   * @template {AbstractType<any>} T
   * YEvent describes the changes on a YType.
   */
  class YEvent {
    /**
     * @param {T} target The changed type.
     * @param {Transaction} transaction
     */
    constructor (target, transaction) {
      /**
       * The type on which this event was created on.
       * @type {T}
       */
      this.target = target;
      /**
       * The current target on which the observe callback is called.
       * @type {AbstractType<any>}
       */
      this.currentTarget = target;
      /**
       * The transaction that triggered this event.
       * @type {Transaction}
       */
      this.transaction = transaction;
      /**
       * @type {Object|null}
       */
      this._changes = null;
      /**
       * @type {null | Map<string, { action: 'add' | 'update' | 'delete', oldValue: any, newValue: any }>}
       */
      this._keys = null;
      /**
       * @type {null | Array<{ insert?: string | Array<any> | object | AbstractType<any>, retain?: number, delete?: number, attributes?: Object<string, any> }>}
       */
      this._delta = null;
      /**
       * @type {Array<string|number>|null}
       */
      this._path = null;
    }

    /**
     * Computes the path from `y` to the changed type.
     *
     * @todo v14 should standardize on path: Array<{parent, index}> because that is easier to work with.
     *
     * The following property holds:
     * @example
     *   let type = y
     *   event.path.forEach(dir => {
     *     type = type.get(dir)
     *   })
     *   type === event.target // => true
     */
    get path () {
      return this._path || (this._path = getPathTo(this.currentTarget, this.target))
    }

    /**
     * Check if a struct is deleted by this event.
     *
     * In contrast to change.deleted, this method also returns true if the struct was added and then deleted.
     *
     * @param {AbstractStruct} struct
     * @return {boolean}
     */
    deletes (struct) {
      return isDeleted(this.transaction.deleteSet, struct.id)
    }

    /**
     * @type {Map<string, { action: 'add' | 'update' | 'delete', oldValue: any, newValue: any }>}
     */
    get keys () {
      if (this._keys === null) {
        if (this.transaction.doc._transactionCleanups.length === 0) {
          throw create$4(errorComputeChanges)
        }
        const keys = new Map();
        const target = this.target;
        const changed = /** @type Set<string|null> */ (this.transaction.changed.get(target));
        changed.forEach(key => {
          if (key !== null) {
            const item = /** @type {Item} */ (target._map.get(key));
            /**
             * @type {'delete' | 'add' | 'update'}
             */
            let action;
            let oldValue;
            if (this.adds(item)) {
              let prev = item.left;
              while (prev !== null && this.adds(prev)) {
                prev = prev.left;
              }
              if (this.deletes(item)) {
                if (prev !== null && this.deletes(prev)) {
                  action = 'delete';
                  oldValue = last(prev.content.getContent());
                } else {
                  return
                }
              } else {
                if (prev !== null && this.deletes(prev)) {
                  action = 'update';
                  oldValue = last(prev.content.getContent());
                } else {
                  action = 'add';
                  oldValue = undefined;
                }
              }
            } else {
              if (this.deletes(item)) {
                action = 'delete';
                oldValue = last(/** @type {Item} */ item.content.getContent());
              } else {
                return // nop
              }
            }
            keys.set(key, { action, oldValue });
          }
        });
        this._keys = keys;
      }
      return this._keys
    }

    /**
     * This is a computed property. Note that this can only be safely computed during the
     * event call. Computing this property after other changes happened might result in
     * unexpected behavior (incorrect computation of deltas). A safe way to collect changes
     * is to store the `changes` or the `delta` object. Avoid storing the `transaction` object.
     *
     * @type {Array<{insert?: string | Array<any> | object | AbstractType<any>, retain?: number, delete?: number, attributes?: Object<string, any>}>}
     */
    get delta () {
      return this.changes.delta
    }

    /**
     * Check if a struct is added by this event.
     *
     * In contrast to change.deleted, this method also returns true if the struct was added and then deleted.
     *
     * @param {AbstractStruct} struct
     * @return {boolean}
     */
    adds (struct) {
      return struct.id.clock >= (this.transaction.beforeState.get(struct.id.client) || 0)
    }

    /**
     * This is a computed property. Note that this can only be safely computed during the
     * event call. Computing this property after other changes happened might result in
     * unexpected behavior (incorrect computation of deltas). A safe way to collect changes
     * is to store the `changes` or the `delta` object. Avoid storing the `transaction` object.
     *
     * @type {{added:Set<Item>,deleted:Set<Item>,keys:Map<string,{action:'add'|'update'|'delete',oldValue:any}>,delta:Array<{insert?:Array<any>|string, delete?:number, retain?:number}>}}
     */
    get changes () {
      let changes = this._changes;
      if (changes === null) {
        if (this.transaction.doc._transactionCleanups.length === 0) {
          throw create$4(errorComputeChanges)
        }
        const target = this.target;
        const added = create$5();
        const deleted = create$5();
        /**
         * @type {Array<{insert:Array<any>}|{delete:number}|{retain:number}>}
         */
        const delta = [];
        changes = {
          added,
          deleted,
          delta,
          keys: this.keys
        };
        const changed = /** @type Set<string|null> */ (this.transaction.changed.get(target));
        if (changed.has(null)) {
          /**
           * @type {any}
           */
          let lastOp = null;
          const packOp = () => {
            if (lastOp) {
              delta.push(lastOp);
            }
          };
          for (let item = target._start; item !== null; item = item.right) {
            if (item.deleted) {
              if (this.deletes(item) && !this.adds(item)) {
                if (lastOp === null || lastOp.delete === undefined) {
                  packOp();
                  lastOp = { delete: 0 };
                }
                lastOp.delete += item.length;
                deleted.add(item);
              } // else nop
            } else {
              if (this.adds(item)) {
                if (lastOp === null || lastOp.insert === undefined) {
                  packOp();
                  lastOp = { insert: [] };
                }
                lastOp.insert = lastOp.insert.concat(item.content.getContent());
                added.add(item);
              } else {
                if (lastOp === null || lastOp.retain === undefined) {
                  packOp();
                  lastOp = { retain: 0 };
                }
                lastOp.retain += item.length;
              }
            }
          }
          if (lastOp !== null && lastOp.retain === undefined) {
            packOp();
          }
        }
        this._changes = changes;
      }
      return /** @type {any} */ (changes)
    }
  }

  /**
   * Compute the path from this type to the specified target.
   *
   * @example
   *   // `child` should be accessible via `type.get(path[0]).get(path[1])..`
   *   const path = type.getPathTo(child)
   *   // assuming `type instanceof YArray`
   *   console.log(path) // might look like => [2, 'key1']
   *   child === type.get(path[0]).get(path[1])
   *
   * @param {AbstractType<any>} parent
   * @param {AbstractType<any>} child target
   * @return {Array<string|number>} Path to the target
   *
   * @private
   * @function
   */
  const getPathTo = (parent, child) => {
    const path = [];
    while (child._item !== null && child !== parent) {
      if (child._item.parentSub !== null) {
        // parent is map-ish
        path.unshift(child._item.parentSub);
      } else {
        // parent is array-ish
        let i = 0;
        let c = /** @type {AbstractType<any>} */ (child._item.parent)._start;
        while (c !== child._item && c !== null) {
          if (!c.deleted && c.countable) {
            i += c.length;
          }
          c = c.right;
        }
        path.unshift(i);
      }
      child = /** @type {AbstractType<any>} */ (child._item.parent);
    }
    return path
  };

  /**
   * https://docs.yjs.dev/getting-started/working-with-shared-types#caveats
   */
  const warnPrematureAccess = () => { warn('Invalid access: Add Yjs type to a document before reading data.'); };

  const maxSearchMarker = 80;

  /**
   * A unique timestamp that identifies each marker.
   *
   * Time is relative,.. this is more like an ever-increasing clock.
   *
   * @type {number}
   */
  let globalSearchMarkerTimestamp = 0;

  class ArraySearchMarker {
    /**
     * @param {Item} p
     * @param {number} index
     */
    constructor (p, index) {
      p.marker = true;
      this.p = p;
      this.index = index;
      this.timestamp = globalSearchMarkerTimestamp++;
    }
  }

  /**
   * @param {ArraySearchMarker} marker
   */
  const refreshMarkerTimestamp = marker => { marker.timestamp = globalSearchMarkerTimestamp++; };

  /**
   * This is rather complex so this function is the only thing that should overwrite a marker
   *
   * @param {ArraySearchMarker} marker
   * @param {Item} p
   * @param {number} index
   */
  const overwriteMarker = (marker, p, index) => {
    marker.p.marker = false;
    marker.p = p;
    p.marker = true;
    marker.index = index;
    marker.timestamp = globalSearchMarkerTimestamp++;
  };

  /**
   * @param {Array<ArraySearchMarker>} searchMarker
   * @param {Item} p
   * @param {number} index
   */
  const markPosition = (searchMarker, p, index) => {
    if (searchMarker.length >= maxSearchMarker) {
      // override oldest marker (we don't want to create more objects)
      const marker = searchMarker.reduce((a, b) => a.timestamp < b.timestamp ? a : b);
      overwriteMarker(marker, p, index);
      return marker
    } else {
      // create new marker
      const pm = new ArraySearchMarker(p, index);
      searchMarker.push(pm);
      return pm
    }
  };

  /**
   * Search marker help us to find positions in the associative array faster.
   *
   * They speed up the process of finding a position without much bookkeeping.
   *
   * A maximum of `maxSearchMarker` objects are created.
   *
   * This function always returns a refreshed marker (updated timestamp)
   *
   * @param {AbstractType<any>} yarray
   * @param {number} index
   */
  const findMarker = (yarray, index) => {
    if (yarray._start === null || index === 0 || yarray._searchMarker === null) {
      return null
    }
    const marker = yarray._searchMarker.length === 0 ? null : yarray._searchMarker.reduce((a, b) => abs(index - a.index) < abs(index - b.index) ? a : b);
    let p = yarray._start;
    let pindex = 0;
    if (marker !== null) {
      p = marker.p;
      pindex = marker.index;
      refreshMarkerTimestamp(marker); // we used it, we might need to use it again
    }
    // iterate to right if possible
    while (p.right !== null && pindex < index) {
      if (!p.deleted && p.countable) {
        if (index < pindex + p.length) {
          break
        }
        pindex += p.length;
      }
      p = p.right;
    }
    // iterate to left if necessary (might be that pindex > index)
    while (p.left !== null && pindex > index) {
      p = p.left;
      if (!p.deleted && p.countable) {
        pindex -= p.length;
      }
    }
    // we want to make sure that p can't be merged with left, because that would screw up everything
    // in that cas just return what we have (it is most likely the best marker anyway)
    // iterate to left until p can't be merged with left
    while (p.left !== null && p.left.id.client === p.id.client && p.left.id.clock + p.left.length === p.id.clock) {
      p = p.left;
      if (!p.deleted && p.countable) {
        pindex -= p.length;
      }
    }

    // @todo remove!
    // assure position
    // {
    //   let start = yarray._start
    //   let pos = 0
    //   while (start !== p) {
    //     if (!start.deleted && start.countable) {
    //       pos += start.length
    //     }
    //     start = /** @type {Item} */ (start.right)
    //   }
    //   if (pos !== pindex) {
    //     debugger
    //     throw new Error('Gotcha position fail!')
    //   }
    // }
    // if (marker) {
    //   if (window.lengths == null) {
    //     window.lengths = []
    //     window.getLengths = () => window.lengths.sort((a, b) => a - b)
    //   }
    //   window.lengths.push(marker.index - pindex)
    //   console.log('distance', marker.index - pindex, 'len', p && p.parent.length)
    // }
    if (marker !== null && abs(marker.index - pindex) < /** @type {YText|YArray<any>} */ (p.parent).length / maxSearchMarker) {
      // adjust existing marker
      overwriteMarker(marker, p, pindex);
      return marker
    } else {
      // create new marker
      return markPosition(yarray._searchMarker, p, pindex)
    }
  };

  /**
   * Update markers when a change happened.
   *
   * This should be called before doing a deletion!
   *
   * @param {Array<ArraySearchMarker>} searchMarker
   * @param {number} index
   * @param {number} len If insertion, len is positive. If deletion, len is negative.
   */
  const updateMarkerChanges = (searchMarker, index, len) => {
    for (let i = searchMarker.length - 1; i >= 0; i--) {
      const m = searchMarker[i];
      if (len > 0) {
        /**
         * @type {Item|null}
         */
        let p = m.p;
        p.marker = false;
        // Ideally we just want to do a simple position comparison, but this will only work if
        // search markers don't point to deleted items for formats.
        // Iterate marker to prev undeleted countable position so we know what to do when updating a position
        while (p && (p.deleted || !p.countable)) {
          p = p.left;
          if (p && !p.deleted && p.countable) {
            // adjust position. the loop should break now
            m.index -= p.length;
          }
        }
        if (p === null || p.marker === true) {
          // remove search marker if updated position is null or if position is already marked
          searchMarker.splice(i, 1);
          continue
        }
        m.p = p;
        p.marker = true;
      }
      if (index < m.index || (len > 0 && index === m.index)) { // a simple index <= m.index check would actually suffice
        m.index = max(index, m.index + len);
      }
    }
  };

  /**
   * Call event listeners with an event. This will also add an event to all
   * parents (for `.observeDeep` handlers).
   *
   * @template EventType
   * @param {AbstractType<EventType>} type
   * @param {Transaction} transaction
   * @param {EventType} event
   */
  const callTypeObservers = (type, transaction, event) => {
    const changedType = type;
    const changedParentTypes = transaction.changedParentTypes;
    while (true) {
      // @ts-ignore
      setIfUndefined(changedParentTypes, type, () => []).push(event);
      if (type._item === null) {
        break
      }
      type = /** @type {AbstractType<any>} */ (type._item.parent);
    }
    callEventHandlerListeners(changedType._eH, event, transaction);
  };

  /**
   * @template EventType
   * Abstract Yjs Type class
   */
  class AbstractType {
    constructor () {
      /**
       * @type {Item|null}
       */
      this._item = null;
      /**
       * @type {Map<string,Item>}
       */
      this._map = new Map();
      /**
       * @type {Item|null}
       */
      this._start = null;
      /**
       * @type {Doc|null}
       */
      this.doc = null;
      this._length = 0;
      /**
       * Event handlers
       * @type {EventHandler<EventType,Transaction>}
       */
      this._eH = createEventHandler();
      /**
       * Deep event handlers
       * @type {EventHandler<Array<YEvent<any>>,Transaction>}
       */
      this._dEH = createEventHandler();
      /**
       * @type {null | Array<ArraySearchMarker>}
       */
      this._searchMarker = null;
    }

    /**
     * @return {AbstractType<any>|null}
     */
    get parent () {
      return this._item ? /** @type {AbstractType<any>} */ (this._item.parent) : null
    }

    /**
     * Integrate this type into the Yjs instance.
     *
     * * Save this struct in the os
     * * This type is sent to other client
     * * Observer functions are fired
     *
     * @param {Doc} y The Yjs instance
     * @param {Item|null} item
     */
    _integrate (y, item) {
      this.doc = y;
      this._item = item;
    }

    /**
     * @return {AbstractType<EventType>}
     */
    _copy () {
      throw methodUnimplemented()
    }

    /**
     * Makes a copy of this data type that can be included somewhere else.
     *
     * Note that the content is only readable _after_ it has been included somewhere in the Ydoc.
     *
     * @return {AbstractType<EventType>}
     */
    clone () {
      throw methodUnimplemented()
    }

    /**
     * @param {UpdateEncoderV1 | UpdateEncoderV2} _encoder
     */
    _write (_encoder) { }

    /**
     * The first non-deleted item
     */
    get _first () {
      let n = this._start;
      while (n !== null && n.deleted) {
        n = n.right;
      }
      return n
    }

    /**
     * Creates YEvent and calls all type observers.
     * Must be implemented by each type.
     *
     * @param {Transaction} transaction
     * @param {Set<null|string>} _parentSubs Keys changed on this type. `null` if list was modified.
     */
    _callObserver (transaction, _parentSubs) {
      if (!transaction.local && this._searchMarker) {
        this._searchMarker.length = 0;
      }
    }

    /**
     * Observe all events that are created on this type.
     *
     * @param {function(EventType, Transaction):void} f Observer function
     */
    observe (f) {
      addEventHandlerListener(this._eH, f);
    }

    /**
     * Observe all events that are created by this type and its children.
     *
     * @param {function(Array<YEvent<any>>,Transaction):void} f Observer function
     */
    observeDeep (f) {
      addEventHandlerListener(this._dEH, f);
    }

    /**
     * Unregister an observer function.
     *
     * @param {function(EventType,Transaction):void} f Observer function
     */
    unobserve (f) {
      removeEventHandlerListener(this._eH, f);
    }

    /**
     * Unregister an observer function.
     *
     * @param {function(Array<YEvent<any>>,Transaction):void} f Observer function
     */
    unobserveDeep (f) {
      removeEventHandlerListener(this._dEH, f);
    }

    /**
     * @abstract
     * @return {any}
     */
    toJSON () {}
  }

  /**
   * @param {AbstractType<any>} type
   * @param {number} start
   * @param {number} end
   * @return {Array<any>}
   *
   * @private
   * @function
   */
  const typeListSlice = (type, start, end) => {
    type.doc ?? warnPrematureAccess();
    if (start < 0) {
      start = type._length + start;
    }
    if (end < 0) {
      end = type._length + end;
    }
    let len = end - start;
    const cs = [];
    let n = type._start;
    while (n !== null && len > 0) {
      if (n.countable && !n.deleted) {
        const c = n.content.getContent();
        if (c.length <= start) {
          start -= c.length;
        } else {
          for (let i = start; i < c.length && len > 0; i++) {
            cs.push(c[i]);
            len--;
          }
          start = 0;
        }
      }
      n = n.right;
    }
    return cs
  };

  /**
   * @param {AbstractType<any>} type
   * @return {Array<any>}
   *
   * @private
   * @function
   */
  const typeListToArray = type => {
    type.doc ?? warnPrematureAccess();
    const cs = [];
    let n = type._start;
    while (n !== null) {
      if (n.countable && !n.deleted) {
        const c = n.content.getContent();
        for (let i = 0; i < c.length; i++) {
          cs.push(c[i]);
        }
      }
      n = n.right;
    }
    return cs
  };

  /**
   * Executes a provided function on once on every element of this YArray.
   *
   * @param {AbstractType<any>} type
   * @param {function(any,number,any):void} f A function to execute on every element of this YArray.
   *
   * @private
   * @function
   */
  const typeListForEach = (type, f) => {
    let index = 0;
    let n = type._start;
    type.doc ?? warnPrematureAccess();
    while (n !== null) {
      if (n.countable && !n.deleted) {
        const c = n.content.getContent();
        for (let i = 0; i < c.length; i++) {
          f(c[i], index++, type);
        }
      }
      n = n.right;
    }
  };

  /**
   * @template C,R
   * @param {AbstractType<any>} type
   * @param {function(C,number,AbstractType<any>):R} f
   * @return {Array<R>}
   *
   * @private
   * @function
   */
  const typeListMap = (type, f) => {
    /**
     * @type {Array<any>}
     */
    const result = [];
    typeListForEach(type, (c, i) => {
      result.push(f(c, i, type));
    });
    return result
  };

  /**
   * @param {AbstractType<any>} type
   * @return {IterableIterator<any>}
   *
   * @private
   * @function
   */
  const typeListCreateIterator = type => {
    let n = type._start;
    /**
     * @type {Array<any>|null}
     */
    let currentContent = null;
    let currentContentIndex = 0;
    return {
      [Symbol.iterator] () {
        return this
      },
      next: () => {
        // find some content
        if (currentContent === null) {
          while (n !== null && n.deleted) {
            n = n.right;
          }
          // check if we reached the end, no need to check currentContent, because it does not exist
          if (n === null) {
            return {
              done: true,
              value: undefined
            }
          }
          // we found n, so we can set currentContent
          currentContent = n.content.getContent();
          currentContentIndex = 0;
          n = n.right; // we used the content of n, now iterate to next
        }
        const value = currentContent[currentContentIndex++];
        // check if we need to empty currentContent
        if (currentContent.length <= currentContentIndex) {
          currentContent = null;
        }
        return {
          done: false,
          value
        }
      }
    }
  };

  /**
   * @param {AbstractType<any>} type
   * @param {number} index
   * @return {any}
   *
   * @private
   * @function
   */
  const typeListGet = (type, index) => {
    type.doc ?? warnPrematureAccess();
    const marker = findMarker(type, index);
    let n = type._start;
    if (marker !== null) {
      n = marker.p;
      index -= marker.index;
    }
    for (; n !== null; n = n.right) {
      if (!n.deleted && n.countable) {
        if (index < n.length) {
          return n.content.getContent()[index]
        }
        index -= n.length;
      }
    }
  };

  /**
   * @param {Transaction} transaction
   * @param {AbstractType<any>} parent
   * @param {Item?} referenceItem
   * @param {Array<Object<string,any>|Array<any>|boolean|number|null|string|Uint8Array>} content
   *
   * @private
   * @function
   */
  const typeListInsertGenericsAfter = (transaction, parent, referenceItem, content) => {
    let left = referenceItem;
    const doc = transaction.doc;
    const ownClientId = doc.clientID;
    const store = doc.store;
    const right = referenceItem === null ? parent._start : referenceItem.right;
    /**
     * @type {Array<Object|Array<any>|number|null>}
     */
    let jsonContent = [];
    const packJsonContent = () => {
      if (jsonContent.length > 0) {
        left = new Item(createID(ownClientId, getState(store, ownClientId)), left, left && left.lastId, right, right && right.id, parent, null, new ContentAny(jsonContent));
        left.integrate(transaction, 0);
        jsonContent = [];
      }
    };
    content.forEach(c => {
      if (c === null) {
        jsonContent.push(c);
      } else {
        switch (c.constructor) {
          case Number:
          case Object:
          case Boolean:
          case Array:
          case String:
            jsonContent.push(c);
            break
          default:
            packJsonContent();
            switch (c.constructor) {
              case Uint8Array:
              case ArrayBuffer:
                left = new Item(createID(ownClientId, getState(store, ownClientId)), left, left && left.lastId, right, right && right.id, parent, null, new ContentBinary(new Uint8Array(/** @type {Uint8Array} */ (c))));
                left.integrate(transaction, 0);
                break
              case Doc:
                left = new Item(createID(ownClientId, getState(store, ownClientId)), left, left && left.lastId, right, right && right.id, parent, null, new ContentDoc(/** @type {Doc} */ (c)));
                left.integrate(transaction, 0);
                break
              default:
                if (c instanceof AbstractType) {
                  left = new Item(createID(ownClientId, getState(store, ownClientId)), left, left && left.lastId, right, right && right.id, parent, null, new ContentType(c));
                  left.integrate(transaction, 0);
                } else {
                  throw new Error('Unexpected content type in insert operation')
                }
            }
        }
      }
    });
    packJsonContent();
  };

  const lengthExceeded = () => create$4('Length exceeded!');

  /**
   * @param {Transaction} transaction
   * @param {AbstractType<any>} parent
   * @param {number} index
   * @param {Array<Object<string,any>|Array<any>|number|null|string|Uint8Array>} content
   *
   * @private
   * @function
   */
  const typeListInsertGenerics = (transaction, parent, index, content) => {
    if (index > parent._length) {
      throw lengthExceeded()
    }
    if (index === 0) {
      if (parent._searchMarker) {
        updateMarkerChanges(parent._searchMarker, index, content.length);
      }
      return typeListInsertGenericsAfter(transaction, parent, null, content)
    }
    const startIndex = index;
    const marker = findMarker(parent, index);
    let n = parent._start;
    if (marker !== null) {
      n = marker.p;
      index -= marker.index;
      // we need to iterate one to the left so that the algorithm works
      if (index === 0) {
        // @todo refactor this as it actually doesn't consider formats
        n = n.prev; // important! get the left undeleted item so that we can actually decrease index
        index += (n && n.countable && !n.deleted) ? n.length : 0;
      }
    }
    for (; n !== null; n = n.right) {
      if (!n.deleted && n.countable) {
        if (index <= n.length) {
          if (index < n.length) {
            // insert in-between
            getItemCleanStart(transaction, createID(n.id.client, n.id.clock + index));
          }
          break
        }
        index -= n.length;
      }
    }
    if (parent._searchMarker) {
      updateMarkerChanges(parent._searchMarker, startIndex, content.length);
    }
    return typeListInsertGenericsAfter(transaction, parent, n, content)
  };

  /**
   * Pushing content is special as we generally want to push after the last item. So we don't have to update
   * the search marker.
   *
   * @param {Transaction} transaction
   * @param {AbstractType<any>} parent
   * @param {Array<Object<string,any>|Array<any>|number|null|string|Uint8Array>} content
   *
   * @private
   * @function
   */
  const typeListPushGenerics = (transaction, parent, content) => {
    // Use the marker with the highest index and iterate to the right.
    const marker = (parent._searchMarker || []).reduce((maxMarker, currMarker) => currMarker.index > maxMarker.index ? currMarker : maxMarker, { index: 0, p: parent._start });
    let n = marker.p;
    if (n) {
      while (n.right) {
        n = n.right;
      }
    }
    return typeListInsertGenericsAfter(transaction, parent, n, content)
  };

  /**
   * @param {Transaction} transaction
   * @param {AbstractType<any>} parent
   * @param {number} index
   * @param {number} length
   *
   * @private
   * @function
   */
  const typeListDelete = (transaction, parent, index, length) => {
    if (length === 0) { return }
    const startIndex = index;
    const startLength = length;
    const marker = findMarker(parent, index);
    let n = parent._start;
    if (marker !== null) {
      n = marker.p;
      index -= marker.index;
    }
    // compute the first item to be deleted
    for (; n !== null && index > 0; n = n.right) {
      if (!n.deleted && n.countable) {
        if (index < n.length) {
          getItemCleanStart(transaction, createID(n.id.client, n.id.clock + index));
        }
        index -= n.length;
      }
    }
    // delete all items until done
    while (length > 0 && n !== null) {
      if (!n.deleted) {
        if (length < n.length) {
          getItemCleanStart(transaction, createID(n.id.client, n.id.clock + length));
        }
        n.delete(transaction);
        length -= n.length;
      }
      n = n.right;
    }
    if (length > 0) {
      throw lengthExceeded()
    }
    if (parent._searchMarker) {
      updateMarkerChanges(parent._searchMarker, startIndex, -startLength + length /* in case we remove the above exception */);
    }
  };

  /**
   * @param {Transaction} transaction
   * @param {AbstractType<any>} parent
   * @param {string} key
   *
   * @private
   * @function
   */
  const typeMapDelete = (transaction, parent, key) => {
    const c = parent._map.get(key);
    if (c !== undefined) {
      c.delete(transaction);
    }
  };

  /**
   * @param {Transaction} transaction
   * @param {AbstractType<any>} parent
   * @param {string} key
   * @param {Object|number|null|Array<any>|string|Uint8Array|AbstractType<any>} value
   *
   * @private
   * @function
   */
  const typeMapSet = (transaction, parent, key, value) => {
    const left = parent._map.get(key) || null;
    const doc = transaction.doc;
    const ownClientId = doc.clientID;
    let content;
    if (value == null) {
      content = new ContentAny([value]);
    } else {
      switch (value.constructor) {
        case Number:
        case Object:
        case Boolean:
        case Array:
        case String:
          content = new ContentAny([value]);
          break
        case Uint8Array:
          content = new ContentBinary(/** @type {Uint8Array} */ (value));
          break
        case Doc:
          content = new ContentDoc(/** @type {Doc} */ (value));
          break
        default:
          if (value instanceof AbstractType) {
            content = new ContentType(value);
          } else {
            throw new Error('Unexpected content type')
          }
      }
    }
    new Item(createID(ownClientId, getState(doc.store, ownClientId)), left, left && left.lastId, null, null, parent, key, content).integrate(transaction, 0);
  };

  /**
   * @param {AbstractType<any>} parent
   * @param {string} key
   * @return {Object<string,any>|number|null|Array<any>|string|Uint8Array|AbstractType<any>|undefined}
   *
   * @private
   * @function
   */
  const typeMapGet = (parent, key) => {
    parent.doc ?? warnPrematureAccess();
    const val = parent._map.get(key);
    return val !== undefined && !val.deleted ? val.content.getContent()[val.length - 1] : undefined
  };

  /**
   * @param {AbstractType<any>} parent
   * @return {Object<string,Object<string,any>|number|null|Array<any>|string|Uint8Array|AbstractType<any>|undefined>}
   *
   * @private
   * @function
   */
  const typeMapGetAll = (parent) => {
    /**
     * @type {Object<string,any>}
     */
    const res = {};
    parent.doc ?? warnPrematureAccess();
    parent._map.forEach((value, key) => {
      if (!value.deleted) {
        res[key] = value.content.getContent()[value.length - 1];
      }
    });
    return res
  };

  /**
   * @param {AbstractType<any>} parent
   * @param {string} key
   * @return {boolean}
   *
   * @private
   * @function
   */
  const typeMapHas = (parent, key) => {
    parent.doc ?? warnPrematureAccess();
    const val = parent._map.get(key);
    return val !== undefined && !val.deleted
  };

  /**
   * @param {AbstractType<any>} parent
   * @param {Snapshot} snapshot
   * @return {Object<string,Object<string,any>|number|null|Array<any>|string|Uint8Array|AbstractType<any>|undefined>}
   *
   * @private
   * @function
   */
  const typeMapGetAllSnapshot = (parent, snapshot) => {
    /**
     * @type {Object<string,any>}
     */
    const res = {};
    parent._map.forEach((value, key) => {
      /**
       * @type {Item|null}
       */
      let v = value;
      while (v !== null && (!snapshot.sv.has(v.id.client) || v.id.clock >= (snapshot.sv.get(v.id.client) || 0))) {
        v = v.left;
      }
      if (v !== null && isVisible(v, snapshot)) {
        res[key] = v.content.getContent()[v.length - 1];
      }
    });
    return res
  };

  /**
   * @param {AbstractType<any> & { _map: Map<string, Item> }} type
   * @return {IterableIterator<Array<any>>}
   *
   * @private
   * @function
   */
  const createMapIterator = type => {
    type.doc ?? warnPrematureAccess();
    return iteratorFilter(type._map.entries(), /** @param {any} entry */ entry => !entry[1].deleted)
  };

  /**
   * @module YArray
   */


  /**
   * Event that describes the changes on a YArray
   * @template T
   * @extends YEvent<YArray<T>>
   */
  class YArrayEvent extends YEvent {}

  /**
   * A shared Array implementation.
   * @template T
   * @extends AbstractType<YArrayEvent<T>>
   * @implements {Iterable<T>}
   */
  class YArray extends AbstractType {
    constructor () {
      super();
      /**
       * @type {Array<any>?}
       * @private
       */
      this._prelimContent = [];
      /**
       * @type {Array<ArraySearchMarker>}
       */
      this._searchMarker = [];
    }

    /**
     * Construct a new YArray containing the specified items.
     * @template {Object<string,any>|Array<any>|number|null|string|Uint8Array} T
     * @param {Array<T>} items
     * @return {YArray<T>}
     */
    static from (items) {
      /**
       * @type {YArray<T>}
       */
      const a = new YArray();
      a.push(items);
      return a
    }

    /**
     * Integrate this type into the Yjs instance.
     *
     * * Save this struct in the os
     * * This type is sent to other client
     * * Observer functions are fired
     *
     * @param {Doc} y The Yjs instance
     * @param {Item} item
     */
    _integrate (y, item) {
      super._integrate(y, item);
      this.insert(0, /** @type {Array<any>} */ (this._prelimContent));
      this._prelimContent = null;
    }

    /**
     * @return {YArray<T>}
     */
    _copy () {
      return new YArray()
    }

    /**
     * Makes a copy of this data type that can be included somewhere else.
     *
     * Note that the content is only readable _after_ it has been included somewhere in the Ydoc.
     *
     * @return {YArray<T>}
     */
    clone () {
      /**
       * @type {YArray<T>}
       */
      const arr = new YArray();
      arr.insert(0, this.toArray().map(el =>
        el instanceof AbstractType ? /** @type {typeof el} */ (el.clone()) : el
      ));
      return arr
    }

    get length () {
      this.doc ?? warnPrematureAccess();
      return this._length
    }

    /**
     * Creates YArrayEvent and calls observers.
     *
     * @param {Transaction} transaction
     * @param {Set<null|string>} parentSubs Keys changed on this type. `null` if list was modified.
     */
    _callObserver (transaction, parentSubs) {
      super._callObserver(transaction, parentSubs);
      callTypeObservers(this, transaction, new YArrayEvent(this, transaction));
    }

    /**
     * Inserts new content at an index.
     *
     * Important: This function expects an array of content. Not just a content
     * object. The reason for this "weirdness" is that inserting several elements
     * is very efficient when it is done as a single operation.
     *
     * @example
     *  // Insert character 'a' at position 0
     *  yarray.insert(0, ['a'])
     *  // Insert numbers 1, 2 at position 1
     *  yarray.insert(1, [1, 2])
     *
     * @param {number} index The index to insert content at.
     * @param {Array<T>} content The array of content
     */
    insert (index, content) {
      if (this.doc !== null) {
        transact(this.doc, transaction => {
          typeListInsertGenerics(transaction, this, index, /** @type {any} */ (content));
        });
      } else {
        /** @type {Array<any>} */ (this._prelimContent).splice(index, 0, ...content);
      }
    }

    /**
     * Appends content to this YArray.
     *
     * @param {Array<T>} content Array of content to append.
     *
     * @todo Use the following implementation in all types.
     */
    push (content) {
      if (this.doc !== null) {
        transact(this.doc, transaction => {
          typeListPushGenerics(transaction, this, /** @type {any} */ (content));
        });
      } else {
        /** @type {Array<any>} */ (this._prelimContent).push(...content);
      }
    }

    /**
     * Prepends content to this YArray.
     *
     * @param {Array<T>} content Array of content to prepend.
     */
    unshift (content) {
      this.insert(0, content);
    }

    /**
     * Deletes elements starting from an index.
     *
     * @param {number} index Index at which to start deleting elements
     * @param {number} length The number of elements to remove. Defaults to 1.
     */
    delete (index, length = 1) {
      if (this.doc !== null) {
        transact(this.doc, transaction => {
          typeListDelete(transaction, this, index, length);
        });
      } else {
        /** @type {Array<any>} */ (this._prelimContent).splice(index, length);
      }
    }

    /**
     * Returns the i-th element from a YArray.
     *
     * @param {number} index The index of the element to return from the YArray
     * @return {T}
     */
    get (index) {
      return typeListGet(this, index)
    }

    /**
     * Transforms this YArray to a JavaScript Array.
     *
     * @return {Array<T>}
     */
    toArray () {
      return typeListToArray(this)
    }

    /**
     * Returns a portion of this YArray into a JavaScript Array selected
     * from start to end (end not included).
     *
     * @param {number} [start]
     * @param {number} [end]
     * @return {Array<T>}
     */
    slice (start = 0, end = this.length) {
      return typeListSlice(this, start, end)
    }

    /**
     * Transforms this Shared Type to a JSON object.
     *
     * @return {Array<any>}
     */
    toJSON () {
      return this.map(c => c instanceof AbstractType ? c.toJSON() : c)
    }

    /**
     * Returns an Array with the result of calling a provided function on every
     * element of this YArray.
     *
     * @template M
     * @param {function(T,number,YArray<T>):M} f Function that produces an element of the new Array
     * @return {Array<M>} A new array with each element being the result of the
     *                 callback function
     */
    map (f) {
      return typeListMap(this, /** @type {any} */ (f))
    }

    /**
     * Executes a provided function once on every element of this YArray.
     *
     * @param {function(T,number,YArray<T>):void} f A function to execute on every element of this YArray.
     */
    forEach (f) {
      typeListForEach(this, f);
    }

    /**
     * @return {IterableIterator<T>}
     */
    [Symbol.iterator] () {
      return typeListCreateIterator(this)
    }

    /**
     * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder
     */
    _write (encoder) {
      encoder.writeTypeRef(YArrayRefID);
    }
  }

  /**
   * @param {UpdateDecoderV1 | UpdateDecoderV2} _decoder
   *
   * @private
   * @function
   */
  const readYArray = _decoder => new YArray();

  /**
   * @module YMap
   */


  /**
   * @template T
   * @extends YEvent<YMap<T>>
   * Event that describes the changes on a YMap.
   */
  class YMapEvent extends YEvent {
    /**
     * @param {YMap<T>} ymap The YArray that changed.
     * @param {Transaction} transaction
     * @param {Set<any>} subs The keys that changed.
     */
    constructor (ymap, transaction, subs) {
      super(ymap, transaction);
      this.keysChanged = subs;
    }
  }

  /**
   * @template MapType
   * A shared Map implementation.
   *
   * @extends AbstractType<YMapEvent<MapType>>
   * @implements {Iterable<[string, MapType]>}
   */
  class YMap extends AbstractType {
    /**
     *
     * @param {Iterable<readonly [string, any]>=} entries - an optional iterable to initialize the YMap
     */
    constructor (entries) {
      super();
      /**
       * @type {Map<string,any>?}
       * @private
       */
      this._prelimContent = null;

      if (entries === undefined) {
        this._prelimContent = new Map();
      } else {
        this._prelimContent = new Map(entries);
      }
    }

    /**
     * Integrate this type into the Yjs instance.
     *
     * * Save this struct in the os
     * * This type is sent to other client
     * * Observer functions are fired
     *
     * @param {Doc} y The Yjs instance
     * @param {Item} item
     */
    _integrate (y, item) {
      super._integrate(y, item)
      ;/** @type {Map<string, any>} */ (this._prelimContent).forEach((value, key) => {
        this.set(key, value);
      });
      this._prelimContent = null;
    }

    /**
     * @return {YMap<MapType>}
     */
    _copy () {
      return new YMap()
    }

    /**
     * Makes a copy of this data type that can be included somewhere else.
     *
     * Note that the content is only readable _after_ it has been included somewhere in the Ydoc.
     *
     * @return {YMap<MapType>}
     */
    clone () {
      /**
       * @type {YMap<MapType>}
       */
      const map = new YMap();
      this.forEach((value, key) => {
        map.set(key, value instanceof AbstractType ? /** @type {typeof value} */ (value.clone()) : value);
      });
      return map
    }

    /**
     * Creates YMapEvent and calls observers.
     *
     * @param {Transaction} transaction
     * @param {Set<null|string>} parentSubs Keys changed on this type. `null` if list was modified.
     */
    _callObserver (transaction, parentSubs) {
      callTypeObservers(this, transaction, new YMapEvent(this, transaction, parentSubs));
    }

    /**
     * Transforms this Shared Type to a JSON object.
     *
     * @return {Object<string,any>}
     */
    toJSON () {
      this.doc ?? warnPrematureAccess();
      /**
       * @type {Object<string,MapType>}
       */
      const map = {};
      this._map.forEach((item, key) => {
        if (!item.deleted) {
          const v = item.content.getContent()[item.length - 1];
          map[key] = v instanceof AbstractType ? v.toJSON() : v;
        }
      });
      return map
    }

    /**
     * Returns the size of the YMap (count of key/value pairs)
     *
     * @return {number}
     */
    get size () {
      return [...createMapIterator(this)].length
    }

    /**
     * Returns the keys for each element in the YMap Type.
     *
     * @return {IterableIterator<string>}
     */
    keys () {
      return iteratorMap(createMapIterator(this), /** @param {any} v */ v => v[0])
    }

    /**
     * Returns the values for each element in the YMap Type.
     *
     * @return {IterableIterator<MapType>}
     */
    values () {
      return iteratorMap(createMapIterator(this), /** @param {any} v */ v => v[1].content.getContent()[v[1].length - 1])
    }

    /**
     * Returns an Iterator of [key, value] pairs
     *
     * @return {IterableIterator<[string, MapType]>}
     */
    entries () {
      return iteratorMap(createMapIterator(this), /** @param {any} v */ v => /** @type {any} */ ([v[0], v[1].content.getContent()[v[1].length - 1]]))
    }

    /**
     * Executes a provided function on once on every key-value pair.
     *
     * @param {function(MapType,string,YMap<MapType>):void} f A function to execute on every element of this YArray.
     */
    forEach (f) {
      this.doc ?? warnPrematureAccess();
      this._map.forEach((item, key) => {
        if (!item.deleted) {
          f(item.content.getContent()[item.length - 1], key, this);
        }
      });
    }

    /**
     * Returns an Iterator of [key, value] pairs
     *
     * @return {IterableIterator<[string, MapType]>}
     */
    [Symbol.iterator] () {
      return this.entries()
    }

    /**
     * Remove a specified element from this YMap.
     *
     * @param {string} key The key of the element to remove.
     */
    delete (key) {
      if (this.doc !== null) {
        transact(this.doc, transaction => {
          typeMapDelete(transaction, this, key);
        });
      } else {
        /** @type {Map<string, any>} */ (this._prelimContent).delete(key);
      }
    }

    /**
     * Adds or updates an element with a specified key and value.
     * @template {MapType} VAL
     *
     * @param {string} key The key of the element to add to this YMap
     * @param {VAL} value The value of the element to add
     * @return {VAL}
     */
    set (key, value) {
      if (this.doc !== null) {
        transact(this.doc, transaction => {
          typeMapSet(transaction, this, key, /** @type {any} */ (value));
        });
      } else {
        /** @type {Map<string, any>} */ (this._prelimContent).set(key, value);
      }
      return value
    }

    /**
     * Returns a specified element from this YMap.
     *
     * @param {string} key
     * @return {MapType|undefined}
     */
    get (key) {
      return /** @type {any} */ (typeMapGet(this, key))
    }

    /**
     * Returns a boolean indicating whether the specified key exists or not.
     *
     * @param {string} key The key to test.
     * @return {boolean}
     */
    has (key) {
      return typeMapHas(this, key)
    }

    /**
     * Removes all elements from this YMap.
     */
    clear () {
      if (this.doc !== null) {
        transact(this.doc, transaction => {
          this.forEach(function (_value, key, map) {
            typeMapDelete(transaction, map, key);
          });
        });
      } else {
        /** @type {Map<string, any>} */ (this._prelimContent).clear();
      }
    }

    /**
     * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder
     */
    _write (encoder) {
      encoder.writeTypeRef(YMapRefID);
    }
  }

  /**
   * @param {UpdateDecoderV1 | UpdateDecoderV2} _decoder
   *
   * @private
   * @function
   */
  const readYMap = _decoder => new YMap();

  /**
   * @module YText
   */


  /**
   * @param {any} a
   * @param {any} b
   * @return {boolean}
   */
  const equalAttrs = (a, b) => a === b || (typeof a === 'object' && typeof b === 'object' && a && b && equalFlat(a, b));

  class ItemTextListPosition {
    /**
     * @param {Item|null} left
     * @param {Item|null} right
     * @param {number} index
     * @param {Map<string,any>} currentAttributes
     */
    constructor (left, right, index, currentAttributes) {
      this.left = left;
      this.right = right;
      this.index = index;
      this.currentAttributes = currentAttributes;
    }

    /**
     * Only call this if you know that this.right is defined
     */
    forward () {
      if (this.right === null) {
        unexpectedCase();
      }
      switch (this.right.content.constructor) {
        case ContentFormat:
          if (!this.right.deleted) {
            updateCurrentAttributes(this.currentAttributes, /** @type {ContentFormat} */ (this.right.content));
          }
          break
        default:
          if (!this.right.deleted) {
            this.index += this.right.length;
          }
          break
      }
      this.left = this.right;
      this.right = this.right.right;
    }
  }

  /**
   * @param {Transaction} transaction
   * @param {ItemTextListPosition} pos
   * @param {number} count steps to move forward
   * @return {ItemTextListPosition}
   *
   * @private
   * @function
   */
  const findNextPosition = (transaction, pos, count) => {
    while (pos.right !== null && count > 0) {
      switch (pos.right.content.constructor) {
        case ContentFormat:
          if (!pos.right.deleted) {
            updateCurrentAttributes(pos.currentAttributes, /** @type {ContentFormat} */ (pos.right.content));
          }
          break
        default:
          if (!pos.right.deleted) {
            if (count < pos.right.length) {
              // split right
              getItemCleanStart(transaction, createID(pos.right.id.client, pos.right.id.clock + count));
            }
            pos.index += pos.right.length;
            count -= pos.right.length;
          }
          break
      }
      pos.left = pos.right;
      pos.right = pos.right.right;
      // pos.forward() - we don't forward because that would halve the performance because we already do the checks above
    }
    return pos
  };

  /**
   * @param {Transaction} transaction
   * @param {AbstractType<any>} parent
   * @param {number} index
   * @param {boolean} useSearchMarker
   * @return {ItemTextListPosition}
   *
   * @private
   * @function
   */
  const findPosition = (transaction, parent, index, useSearchMarker) => {
    const currentAttributes = new Map();
    const marker = useSearchMarker ? findMarker(parent, index) : null;
    if (marker) {
      const pos = new ItemTextListPosition(marker.p.left, marker.p, marker.index, currentAttributes);
      return findNextPosition(transaction, pos, index - marker.index)
    } else {
      const pos = new ItemTextListPosition(null, parent._start, 0, currentAttributes);
      return findNextPosition(transaction, pos, index)
    }
  };

  /**
   * Negate applied formats
   *
   * @param {Transaction} transaction
   * @param {AbstractType<any>} parent
   * @param {ItemTextListPosition} currPos
   * @param {Map<string,any>} negatedAttributes
   *
   * @private
   * @function
   */
  const insertNegatedAttributes = (transaction, parent, currPos, negatedAttributes) => {
    // check if we really need to remove attributes
    while (
      currPos.right !== null && (
        currPos.right.deleted === true || (
          currPos.right.content.constructor === ContentFormat &&
          equalAttrs(negatedAttributes.get(/** @type {ContentFormat} */ (currPos.right.content).key), /** @type {ContentFormat} */ (currPos.right.content).value)
        )
      )
    ) {
      if (!currPos.right.deleted) {
        negatedAttributes.delete(/** @type {ContentFormat} */ (currPos.right.content).key);
      }
      currPos.forward();
    }
    const doc = transaction.doc;
    const ownClientId = doc.clientID;
    negatedAttributes.forEach((val, key) => {
      const left = currPos.left;
      const right = currPos.right;
      const nextFormat = new Item(createID(ownClientId, getState(doc.store, ownClientId)), left, left && left.lastId, right, right && right.id, parent, null, new ContentFormat(key, val));
      nextFormat.integrate(transaction, 0);
      currPos.right = nextFormat;
      currPos.forward();
    });
  };

  /**
   * @param {Map<string,any>} currentAttributes
   * @param {ContentFormat} format
   *
   * @private
   * @function
   */
  const updateCurrentAttributes = (currentAttributes, format) => {
    const { key, value } = format;
    if (value === null) {
      currentAttributes.delete(key);
    } else {
      currentAttributes.set(key, value);
    }
  };

  /**
   * @param {ItemTextListPosition} currPos
   * @param {Object<string,any>} attributes
   *
   * @private
   * @function
   */
  const minimizeAttributeChanges = (currPos, attributes) => {
    // go right while attributes[right.key] === right.value (or right is deleted)
    while (true) {
      if (currPos.right === null) {
        break
      } else if (currPos.right.deleted || (currPos.right.content.constructor === ContentFormat && equalAttrs(attributes[(/** @type {ContentFormat} */ (currPos.right.content)).key] ?? null, /** @type {ContentFormat} */ (currPos.right.content).value))) ; else {
        break
      }
      currPos.forward();
    }
  };

  /**
   * @param {Transaction} transaction
   * @param {AbstractType<any>} parent
   * @param {ItemTextListPosition} currPos
   * @param {Object<string,any>} attributes
   * @return {Map<string,any>}
   *
   * @private
   * @function
   **/
  const insertAttributes = (transaction, parent, currPos, attributes) => {
    const doc = transaction.doc;
    const ownClientId = doc.clientID;
    const negatedAttributes = new Map();
    // insert format-start items
    for (const key in attributes) {
      const val = attributes[key];
      const currentVal = currPos.currentAttributes.get(key) ?? null;
      if (!equalAttrs(currentVal, val)) {
        // save negated attribute (set null if currentVal undefined)
        negatedAttributes.set(key, currentVal);
        const { left, right } = currPos;
        currPos.right = new Item(createID(ownClientId, getState(doc.store, ownClientId)), left, left && left.lastId, right, right && right.id, parent, null, new ContentFormat(key, val));
        currPos.right.integrate(transaction, 0);
        currPos.forward();
      }
    }
    return negatedAttributes
  };

  /**
   * @param {Transaction} transaction
   * @param {AbstractType<any>} parent
   * @param {ItemTextListPosition} currPos
   * @param {string|object|AbstractType<any>} text
   * @param {Object<string,any>} attributes
   *
   * @private
   * @function
   **/
  const insertText = (transaction, parent, currPos, text, attributes) => {
    currPos.currentAttributes.forEach((_val, key) => {
      if (attributes[key] === undefined) {
        attributes[key] = null;
      }
    });
    const doc = transaction.doc;
    const ownClientId = doc.clientID;
    minimizeAttributeChanges(currPos, attributes);
    const negatedAttributes = insertAttributes(transaction, parent, currPos, attributes);
    // insert content
    const content = text.constructor === String ? new ContentString(/** @type {string} */ (text)) : (text instanceof AbstractType ? new ContentType(text) : new ContentEmbed(text));
    let { left, right, index } = currPos;
    if (parent._searchMarker) {
      updateMarkerChanges(parent._searchMarker, currPos.index, content.getLength());
    }
    right = new Item(createID(ownClientId, getState(doc.store, ownClientId)), left, left && left.lastId, right, right && right.id, parent, null, content);
    right.integrate(transaction, 0);
    currPos.right = right;
    currPos.index = index;
    currPos.forward();
    insertNegatedAttributes(transaction, parent, currPos, negatedAttributes);
  };

  /**
   * @param {Transaction} transaction
   * @param {AbstractType<any>} parent
   * @param {ItemTextListPosition} currPos
   * @param {number} length
   * @param {Object<string,any>} attributes
   *
   * @private
   * @function
   */
  const formatText = (transaction, parent, currPos, length, attributes) => {
    const doc = transaction.doc;
    const ownClientId = doc.clientID;
    minimizeAttributeChanges(currPos, attributes);
    const negatedAttributes = insertAttributes(transaction, parent, currPos, attributes);
    // iterate until first non-format or null is found
    // delete all formats with attributes[format.key] != null
    // also check the attributes after the first non-format as we do not want to insert redundant negated attributes there
    // eslint-disable-next-line no-labels
    iterationLoop: while (
      currPos.right !== null &&
      (length > 0 ||
        (
          negatedAttributes.size > 0 &&
          (currPos.right.deleted || currPos.right.content.constructor === ContentFormat)
        )
      )
    ) {
      if (!currPos.right.deleted) {
        switch (currPos.right.content.constructor) {
          case ContentFormat: {
            const { key, value } = /** @type {ContentFormat} */ (currPos.right.content);
            const attr = attributes[key];
            if (attr !== undefined) {
              if (equalAttrs(attr, value)) {
                negatedAttributes.delete(key);
              } else {
                if (length === 0) {
                  // no need to further extend negatedAttributes
                  // eslint-disable-next-line no-labels
                  break iterationLoop
                }
                negatedAttributes.set(key, value);
              }
              currPos.right.delete(transaction);
            } else {
              currPos.currentAttributes.set(key, value);
            }
            break
          }
          default:
            if (length < currPos.right.length) {
              getItemCleanStart(transaction, createID(currPos.right.id.client, currPos.right.id.clock + length));
            }
            length -= currPos.right.length;
            break
        }
      }
      currPos.forward();
    }
    // Quill just assumes that the editor starts with a newline and that it always
    // ends with a newline. We only insert that newline when a new newline is
    // inserted - i.e when length is bigger than type.length
    if (length > 0) {
      let newlines = '';
      for (; length > 0; length--) {
        newlines += '\n';
      }
      currPos.right = new Item(createID(ownClientId, getState(doc.store, ownClientId)), currPos.left, currPos.left && currPos.left.lastId, currPos.right, currPos.right && currPos.right.id, parent, null, new ContentString(newlines));
      currPos.right.integrate(transaction, 0);
      currPos.forward();
    }
    insertNegatedAttributes(transaction, parent, currPos, negatedAttributes);
  };

  /**
   * Call this function after string content has been deleted in order to
   * clean up formatting Items.
   *
   * @param {Transaction} transaction
   * @param {Item} start
   * @param {Item|null} curr exclusive end, automatically iterates to the next Content Item
   * @param {Map<string,any>} startAttributes
   * @param {Map<string,any>} currAttributes
   * @return {number} The amount of formatting Items deleted.
   *
   * @function
   */
  const cleanupFormattingGap = (transaction, start, curr, startAttributes, currAttributes) => {
    /**
     * @type {Item|null}
     */
    let end = start;
    /**
     * @type {Map<string,ContentFormat>}
     */
    const endFormats = create$6();
    while (end && (!end.countable || end.deleted)) {
      if (!end.deleted && end.content.constructor === ContentFormat) {
        const cf = /** @type {ContentFormat} */ (end.content);
        endFormats.set(cf.key, cf);
      }
      end = end.right;
    }
    let cleanups = 0;
    let reachedCurr = false;
    while (start !== end) {
      if (curr === start) {
        reachedCurr = true;
      }
      if (!start.deleted) {
        const content = start.content;
        switch (content.constructor) {
          case ContentFormat: {
            const { key, value } = /** @type {ContentFormat} */ (content);
            const startAttrValue = startAttributes.get(key) ?? null;
            if (endFormats.get(key) !== content || startAttrValue === value) {
              // Either this format is overwritten or it is not necessary because the attribute already existed.
              start.delete(transaction);
              cleanups++;
              if (!reachedCurr && (currAttributes.get(key) ?? null) === value && startAttrValue !== value) {
                if (startAttrValue === null) {
                  currAttributes.delete(key);
                } else {
                  currAttributes.set(key, startAttrValue);
                }
              }
            }
            if (!reachedCurr && !start.deleted) {
              updateCurrentAttributes(currAttributes, /** @type {ContentFormat} */ (content));
            }
            break
          }
        }
      }
      start = /** @type {Item} */ (start.right);
    }
    return cleanups
  };

  /**
   * @param {Transaction} transaction
   * @param {Item | null} item
   */
  const cleanupContextlessFormattingGap = (transaction, item) => {
    // iterate until item.right is null or content
    while (item && item.right && (item.right.deleted || !item.right.countable)) {
      item = item.right;
    }
    const attrs = new Set();
    // iterate back until a content item is found
    while (item && (item.deleted || !item.countable)) {
      if (!item.deleted && item.content.constructor === ContentFormat) {
        const key = /** @type {ContentFormat} */ (item.content).key;
        if (attrs.has(key)) {
          item.delete(transaction);
        } else {
          attrs.add(key);
        }
      }
      item = item.left;
    }
  };

  /**
   * This function is experimental and subject to change / be removed.
   *
   * Ideally, we don't need this function at all. Formatting attributes should be cleaned up
   * automatically after each change. This function iterates twice over the complete YText type
   * and removes unnecessary formatting attributes. This is also helpful for testing.
   *
   * This function won't be exported anymore as soon as there is confidence that the YText type works as intended.
   *
   * @param {YText} type
   * @return {number} How many formatting attributes have been cleaned up.
   */
  const cleanupYTextFormatting = type => {
    let res = 0;
    transact(/** @type {Doc} */ (type.doc), transaction => {
      let start = /** @type {Item} */ (type._start);
      let end = type._start;
      let startAttributes = create$6();
      const currentAttributes = copy(startAttributes);
      while (end) {
        if (end.deleted === false) {
          switch (end.content.constructor) {
            case ContentFormat:
              updateCurrentAttributes(currentAttributes, /** @type {ContentFormat} */ (end.content));
              break
            default:
              res += cleanupFormattingGap(transaction, start, end, startAttributes, currentAttributes);
              startAttributes = copy(currentAttributes);
              start = end;
              break
          }
        }
        end = end.right;
      }
    });
    return res
  };

  /**
   * This will be called by the transaction once the event handlers are called to potentially cleanup
   * formatting attributes.
   *
   * @param {Transaction} transaction
   */
  const cleanupYTextAfterTransaction = transaction => {
    /**
     * @type {Set<YText>}
     */
    const needFullCleanup = new Set();
    // check if another formatting item was inserted
    const doc = transaction.doc;
    for (const [client, afterClock] of transaction.afterState.entries()) {
      const clock = transaction.beforeState.get(client) || 0;
      if (afterClock === clock) {
        continue
      }
      iterateStructs(transaction, /** @type {Array<Item|GC>} */ (doc.store.clients.get(client)), clock, afterClock, item => {
        if (
          !item.deleted && /** @type {Item} */ (item).content.constructor === ContentFormat && item.constructor !== GC
        ) {
          needFullCleanup.add(/** @type {any} */ (item).parent);
        }
      });
    }
    // cleanup in a new transaction
    transact(doc, (t) => {
      iterateDeletedStructs(transaction, transaction.deleteSet, item => {
        if (item instanceof GC || !(/** @type {YText} */ (item.parent)._hasFormatting) || needFullCleanup.has(/** @type {YText} */ (item.parent))) {
          return
        }
        const parent = /** @type {YText} */ (item.parent);
        if (item.content.constructor === ContentFormat) {
          needFullCleanup.add(parent);
        } else {
          // If no formatting attribute was inserted or deleted, we can make due with contextless
          // formatting cleanups.
          // Contextless: it is not necessary to compute currentAttributes for the affected position.
          cleanupContextlessFormattingGap(t, item);
        }
      });
      // If a formatting item was inserted, we simply clean the whole type.
      // We need to compute currentAttributes for the current position anyway.
      for (const yText of needFullCleanup) {
        cleanupYTextFormatting(yText);
      }
    });
  };

  /**
   * @param {Transaction} transaction
   * @param {ItemTextListPosition} currPos
   * @param {number} length
   * @return {ItemTextListPosition}
   *
   * @private
   * @function
   */
  const deleteText = (transaction, currPos, length) => {
    const startLength = length;
    const startAttrs = copy(currPos.currentAttributes);
    const start = currPos.right;
    while (length > 0 && currPos.right !== null) {
      if (currPos.right.deleted === false) {
        switch (currPos.right.content.constructor) {
          case ContentType:
          case ContentEmbed:
          case ContentString:
            if (length < currPos.right.length) {
              getItemCleanStart(transaction, createID(currPos.right.id.client, currPos.right.id.clock + length));
            }
            length -= currPos.right.length;
            currPos.right.delete(transaction);
            break
        }
      }
      currPos.forward();
    }
    if (start) {
      cleanupFormattingGap(transaction, start, currPos.right, startAttrs, currPos.currentAttributes);
    }
    const parent = /** @type {AbstractType<any>} */ (/** @type {Item} */ (currPos.left || currPos.right).parent);
    if (parent._searchMarker) {
      updateMarkerChanges(parent._searchMarker, currPos.index, -startLength + length);
    }
    return currPos
  };

  /**
   * The Quill Delta format represents changes on a text document with
   * formatting information. For more information visit {@link https://quilljs.com/docs/delta/|Quill Delta}
   *
   * @example
   *   {
   *     ops: [
   *       { insert: 'Gandalf', attributes: { bold: true } },
   *       { insert: ' the ' },
   *       { insert: 'Grey', attributes: { color: '#cccccc' } }
   *     ]
   *   }
   *
   */

  /**
    * Attributes that can be assigned to a selection of text.
    *
    * @example
    *   {
    *     bold: true,
    *     font-size: '40px'
    *   }
    *
    * @typedef {Object} TextAttributes
    */

  /**
   * @extends YEvent<YText>
   * Event that describes the changes on a YText type.
   */
  class YTextEvent extends YEvent {
    /**
     * @param {YText} ytext
     * @param {Transaction} transaction
     * @param {Set<any>} subs The keys that changed
     */
    constructor (ytext, transaction, subs) {
      super(ytext, transaction);
      /**
       * Whether the children changed.
       * @type {Boolean}
       * @private
       */
      this.childListChanged = false;
      /**
       * Set of all changed attributes.
       * @type {Set<string>}
       */
      this.keysChanged = new Set();
      subs.forEach((sub) => {
        if (sub === null) {
          this.childListChanged = true;
        } else {
          this.keysChanged.add(sub);
        }
      });
    }

    /**
     * @type {{added:Set<Item>,deleted:Set<Item>,keys:Map<string,{action:'add'|'update'|'delete',oldValue:any}>,delta:Array<{insert?:Array<any>|string, delete?:number, retain?:number}>}}
     */
    get changes () {
      if (this._changes === null) {
        /**
         * @type {{added:Set<Item>,deleted:Set<Item>,keys:Map<string,{action:'add'|'update'|'delete',oldValue:any}>,delta:Array<{insert?:Array<any>|string|AbstractType<any>|object, delete?:number, retain?:number}>}}
         */
        const changes = {
          keys: this.keys,
          delta: this.delta,
          added: new Set(),
          deleted: new Set()
        };
        this._changes = changes;
      }
      return /** @type {any} */ (this._changes)
    }

    /**
     * Compute the changes in the delta format.
     * A {@link https://quilljs.com/docs/delta/|Quill Delta}) that represents the changes on the document.
     *
     * @type {Array<{insert?:string|object|AbstractType<any>, delete?:number, retain?:number, attributes?: Object<string,any>}>}
     *
     * @public
     */
    get delta () {
      if (this._delta === null) {
        const y = /** @type {Doc} */ (this.target.doc);
        /**
         * @type {Array<{insert?:string|object|AbstractType<any>, delete?:number, retain?:number, attributes?: Object<string,any>}>}
         */
        const delta = [];
        transact(y, transaction => {
          const currentAttributes = new Map(); // saves all current attributes for insert
          const oldAttributes = new Map();
          let item = this.target._start;
          /**
           * @type {string?}
           */
          let action = null;
          /**
           * @type {Object<string,any>}
           */
          const attributes = {}; // counts added or removed new attributes for retain
          /**
           * @type {string|object}
           */
          let insert = '';
          let retain = 0;
          let deleteLen = 0;
          const addOp = () => {
            if (action !== null) {
              /**
               * @type {any}
               */
              let op = null;
              switch (action) {
                case 'delete':
                  if (deleteLen > 0) {
                    op = { delete: deleteLen };
                  }
                  deleteLen = 0;
                  break
                case 'insert':
                  if (typeof insert === 'object' || insert.length > 0) {
                    op = { insert };
                    if (currentAttributes.size > 0) {
                      op.attributes = {};
                      currentAttributes.forEach((value, key) => {
                        if (value !== null) {
                          op.attributes[key] = value;
                        }
                      });
                    }
                  }
                  insert = '';
                  break
                case 'retain':
                  if (retain > 0) {
                    op = { retain };
                    if (!isEmpty(attributes)) {
                      op.attributes = assign({}, attributes);
                    }
                  }
                  retain = 0;
                  break
              }
              if (op) delta.push(op);
              action = null;
            }
          };
          while (item !== null) {
            switch (item.content.constructor) {
              case ContentType:
              case ContentEmbed:
                if (this.adds(item)) {
                  if (!this.deletes(item)) {
                    addOp();
                    action = 'insert';
                    insert = item.content.getContent()[0];
                    addOp();
                  }
                } else if (this.deletes(item)) {
                  if (action !== 'delete') {
                    addOp();
                    action = 'delete';
                  }
                  deleteLen += 1;
                } else if (!item.deleted) {
                  if (action !== 'retain') {
                    addOp();
                    action = 'retain';
                  }
                  retain += 1;
                }
                break
              case ContentString:
                if (this.adds(item)) {
                  if (!this.deletes(item)) {
                    if (action !== 'insert') {
                      addOp();
                      action = 'insert';
                    }
                    insert += /** @type {ContentString} */ (item.content).str;
                  }
                } else if (this.deletes(item)) {
                  if (action !== 'delete') {
                    addOp();
                    action = 'delete';
                  }
                  deleteLen += item.length;
                } else if (!item.deleted) {
                  if (action !== 'retain') {
                    addOp();
                    action = 'retain';
                  }
                  retain += item.length;
                }
                break
              case ContentFormat: {
                const { key, value } = /** @type {ContentFormat} */ (item.content);
                if (this.adds(item)) {
                  if (!this.deletes(item)) {
                    const curVal = currentAttributes.get(key) ?? null;
                    if (!equalAttrs(curVal, value)) {
                      if (action === 'retain') {
                        addOp();
                      }
                      if (equalAttrs(value, (oldAttributes.get(key) ?? null))) {
                        delete attributes[key];
                      } else {
                        attributes[key] = value;
                      }
                    } else if (value !== null) {
                      item.delete(transaction);
                    }
                  }
                } else if (this.deletes(item)) {
                  oldAttributes.set(key, value);
                  const curVal = currentAttributes.get(key) ?? null;
                  if (!equalAttrs(curVal, value)) {
                    if (action === 'retain') {
                      addOp();
                    }
                    attributes[key] = curVal;
                  }
                } else if (!item.deleted) {
                  oldAttributes.set(key, value);
                  const attr = attributes[key];
                  if (attr !== undefined) {
                    if (!equalAttrs(attr, value)) {
                      if (action === 'retain') {
                        addOp();
                      }
                      if (value === null) {
                        delete attributes[key];
                      } else {
                        attributes[key] = value;
                      }
                    } else if (attr !== null) { // this will be cleaned up automatically by the contextless cleanup function
                      item.delete(transaction);
                    }
                  }
                }
                if (!item.deleted) {
                  if (action === 'insert') {
                    addOp();
                  }
                  updateCurrentAttributes(currentAttributes, /** @type {ContentFormat} */ (item.content));
                }
                break
              }
            }
            item = item.right;
          }
          addOp();
          while (delta.length > 0) {
            const lastOp = delta[delta.length - 1];
            if (lastOp.retain !== undefined && lastOp.attributes === undefined) {
              // retain delta's if they don't assign attributes
              delta.pop();
            } else {
              break
            }
          }
        });
        this._delta = delta;
      }
      return /** @type {any} */ (this._delta)
    }
  }

  /**
   * Type that represents text with formatting information.
   *
   * This type replaces y-richtext as this implementation is able to handle
   * block formats (format information on a paragraph), embeds (complex elements
   * like pictures and videos), and text formats (**bold**, *italic*).
   *
   * @extends AbstractType<YTextEvent>
   */
  class YText extends AbstractType {
    /**
     * @param {String} [string] The initial value of the YText.
     */
    constructor (string) {
      super();
      /**
       * Array of pending operations on this type
       * @type {Array<function():void>?}
       */
      this._pending = string !== undefined ? [() => this.insert(0, string)] : [];
      /**
       * @type {Array<ArraySearchMarker>|null}
       */
      this._searchMarker = [];
      /**
       * Whether this YText contains formatting attributes.
       * This flag is updated when a formatting item is integrated (see ContentFormat.integrate)
       */
      this._hasFormatting = false;
    }

    /**
     * Number of characters of this text type.
     *
     * @type {number}
     */
    get length () {
      this.doc ?? warnPrematureAccess();
      return this._length
    }

    /**
     * @param {Doc} y
     * @param {Item} item
     */
    _integrate (y, item) {
      super._integrate(y, item);
      try {
        /** @type {Array<function>} */ (this._pending).forEach(f => f());
      } catch (e) {
        console.error(e);
      }
      this._pending = null;
    }

    _copy () {
      return new YText()
    }

    /**
     * Makes a copy of this data type that can be included somewhere else.
     *
     * Note that the content is only readable _after_ it has been included somewhere in the Ydoc.
     *
     * @return {YText}
     */
    clone () {
      const text = new YText();
      text.applyDelta(this.toDelta());
      return text
    }

    /**
     * Creates YTextEvent and calls observers.
     *
     * @param {Transaction} transaction
     * @param {Set<null|string>} parentSubs Keys changed on this type. `null` if list was modified.
     */
    _callObserver (transaction, parentSubs) {
      super._callObserver(transaction, parentSubs);
      const event = new YTextEvent(this, transaction, parentSubs);
      callTypeObservers(this, transaction, event);
      // If a remote change happened, we try to cleanup potential formatting duplicates.
      if (!transaction.local && this._hasFormatting) {
        transaction._needFormattingCleanup = true;
      }
    }

    /**
     * Returns the unformatted string representation of this YText type.
     *
     * @public
     */
    toString () {
      this.doc ?? warnPrematureAccess();
      let str = '';
      /**
       * @type {Item|null}
       */
      let n = this._start;
      while (n !== null) {
        if (!n.deleted && n.countable && n.content.constructor === ContentString) {
          str += /** @type {ContentString} */ (n.content).str;
        }
        n = n.right;
      }
      return str
    }

    /**
     * Returns the unformatted string representation of this YText type.
     *
     * @return {string}
     * @public
     */
    toJSON () {
      return this.toString()
    }

    /**
     * Apply a {@link Delta} on this shared YText type.
     *
     * @param {Array<any>} delta The changes to apply on this element.
     * @param {object}  opts
     * @param {boolean} [opts.sanitize] Sanitize input delta. Removes ending newlines if set to true.
     *
     *
     * @public
     */
    applyDelta (delta, { sanitize = true } = {}) {
      if (this.doc !== null) {
        transact(this.doc, transaction => {
          const currPos = new ItemTextListPosition(null, this._start, 0, new Map());
          for (let i = 0; i < delta.length; i++) {
            const op = delta[i];
            if (op.insert !== undefined) {
              // Quill assumes that the content starts with an empty paragraph.
              // Yjs/Y.Text assumes that it starts empty. We always hide that
              // there is a newline at the end of the content.
              // If we omit this step, clients will see a different number of
              // paragraphs, but nothing bad will happen.
              const ins = (!sanitize && typeof op.insert === 'string' && i === delta.length - 1 && currPos.right === null && op.insert.slice(-1) === '\n') ? op.insert.slice(0, -1) : op.insert;
              if (typeof ins !== 'string' || ins.length > 0) {
                insertText(transaction, this, currPos, ins, op.attributes || {});
              }
            } else if (op.retain !== undefined) {
              formatText(transaction, this, currPos, op.retain, op.attributes || {});
            } else if (op.delete !== undefined) {
              deleteText(transaction, currPos, op.delete);
            }
          }
        });
      } else {
        /** @type {Array<function>} */ (this._pending).push(() => this.applyDelta(delta));
      }
    }

    /**
     * Returns the Delta representation of this YText type.
     *
     * @param {Snapshot} [snapshot]
     * @param {Snapshot} [prevSnapshot]
     * @param {function('removed' | 'added', ID):any} [computeYChange]
     * @return {any} The Delta representation of this type.
     *
     * @public
     */
    toDelta (snapshot, prevSnapshot, computeYChange) {
      this.doc ?? warnPrematureAccess();
      /**
       * @type{Array<any>}
       */
      const ops = [];
      const currentAttributes = new Map();
      const doc = /** @type {Doc} */ (this.doc);
      let str = '';
      let n = this._start;
      function packStr () {
        if (str.length > 0) {
          // pack str with attributes to ops
          /**
           * @type {Object<string,any>}
           */
          const attributes = {};
          let addAttributes = false;
          currentAttributes.forEach((value, key) => {
            addAttributes = true;
            attributes[key] = value;
          });
          /**
           * @type {Object<string,any>}
           */
          const op = { insert: str };
          if (addAttributes) {
            op.attributes = attributes;
          }
          ops.push(op);
          str = '';
        }
      }
      const computeDelta = () => {
        while (n !== null) {
          if (isVisible(n, snapshot) || (prevSnapshot !== undefined && isVisible(n, prevSnapshot))) {
            switch (n.content.constructor) {
              case ContentString: {
                const cur = currentAttributes.get('ychange');
                if (snapshot !== undefined && !isVisible(n, snapshot)) {
                  if (cur === undefined || cur.user !== n.id.client || cur.type !== 'removed') {
                    packStr();
                    currentAttributes.set('ychange', computeYChange ? computeYChange('removed', n.id) : { type: 'removed' });
                  }
                } else if (prevSnapshot !== undefined && !isVisible(n, prevSnapshot)) {
                  if (cur === undefined || cur.user !== n.id.client || cur.type !== 'added') {
                    packStr();
                    currentAttributes.set('ychange', computeYChange ? computeYChange('added', n.id) : { type: 'added' });
                  }
                } else if (cur !== undefined) {
                  packStr();
                  currentAttributes.delete('ychange');
                }
                str += /** @type {ContentString} */ (n.content).str;
                break
              }
              case ContentType:
              case ContentEmbed: {
                packStr();
                /**
                 * @type {Object<string,any>}
                 */
                const op = {
                  insert: n.content.getContent()[0]
                };
                if (currentAttributes.size > 0) {
                  const attrs = /** @type {Object<string,any>} */ ({});
                  op.attributes = attrs;
                  currentAttributes.forEach((value, key) => {
                    attrs[key] = value;
                  });
                }
                ops.push(op);
                break
              }
              case ContentFormat:
                if (isVisible(n, snapshot)) {
                  packStr();
                  updateCurrentAttributes(currentAttributes, /** @type {ContentFormat} */ (n.content));
                }
                break
            }
          }
          n = n.right;
        }
        packStr();
      };
      if (snapshot || prevSnapshot) {
        // snapshots are merged again after the transaction, so we need to keep the
        // transaction alive until we are done
        transact(doc, transaction => {
          if (snapshot) {
            splitSnapshotAffectedStructs(transaction, snapshot);
          }
          if (prevSnapshot) {
            splitSnapshotAffectedStructs(transaction, prevSnapshot);
          }
          computeDelta();
        }, 'cleanup');
      } else {
        computeDelta();
      }
      return ops
    }

    /**
     * Insert text at a given index.
     *
     * @param {number} index The index at which to start inserting.
     * @param {String} text The text to insert at the specified position.
     * @param {TextAttributes} [attributes] Optionally define some formatting
     *                                    information to apply on the inserted
     *                                    Text.
     * @public
     */
    insert (index, text, attributes) {
      if (text.length <= 0) {
        return
      }
      const y = this.doc;
      if (y !== null) {
        transact(y, transaction => {
          const pos = findPosition(transaction, this, index, !attributes);
          if (!attributes) {
            attributes = {};
            // @ts-ignore
            pos.currentAttributes.forEach((v, k) => { attributes[k] = v; });
          }
          insertText(transaction, this, pos, text, attributes);
        });
      } else {
        /** @type {Array<function>} */ (this._pending).push(() => this.insert(index, text, attributes));
      }
    }

    /**
     * Inserts an embed at a index.
     *
     * @param {number} index The index to insert the embed at.
     * @param {Object | AbstractType<any>} embed The Object that represents the embed.
     * @param {TextAttributes} [attributes] Attribute information to apply on the
     *                                    embed
     *
     * @public
     */
    insertEmbed (index, embed, attributes) {
      const y = this.doc;
      if (y !== null) {
        transact(y, transaction => {
          const pos = findPosition(transaction, this, index, !attributes);
          insertText(transaction, this, pos, embed, attributes || {});
        });
      } else {
        /** @type {Array<function>} */ (this._pending).push(() => this.insertEmbed(index, embed, attributes || {}));
      }
    }

    /**
     * Deletes text starting from an index.
     *
     * @param {number} index Index at which to start deleting.
     * @param {number} length The number of characters to remove. Defaults to 1.
     *
     * @public
     */
    delete (index, length) {
      if (length === 0) {
        return
      }
      const y = this.doc;
      if (y !== null) {
        transact(y, transaction => {
          deleteText(transaction, findPosition(transaction, this, index, true), length);
        });
      } else {
        /** @type {Array<function>} */ (this._pending).push(() => this.delete(index, length));
      }
    }

    /**
     * Assigns properties to a range of text.
     *
     * @param {number} index The position where to start formatting.
     * @param {number} length The amount of characters to assign properties to.
     * @param {TextAttributes} attributes Attribute information to apply on the
     *                                    text.
     *
     * @public
     */
    format (index, length, attributes) {
      if (length === 0) {
        return
      }
      const y = this.doc;
      if (y !== null) {
        transact(y, transaction => {
          const pos = findPosition(transaction, this, index, false);
          if (pos.right === null) {
            return
          }
          formatText(transaction, this, pos, length, attributes);
        });
      } else {
        /** @type {Array<function>} */ (this._pending).push(() => this.format(index, length, attributes));
      }
    }

    /**
     * Removes an attribute.
     *
     * @note Xml-Text nodes don't have attributes. You can use this feature to assign properties to complete text-blocks.
     *
     * @param {String} attributeName The attribute name that is to be removed.
     *
     * @public
     */
    removeAttribute (attributeName) {
      if (this.doc !== null) {
        transact(this.doc, transaction => {
          typeMapDelete(transaction, this, attributeName);
        });
      } else {
        /** @type {Array<function>} */ (this._pending).push(() => this.removeAttribute(attributeName));
      }
    }

    /**
     * Sets or updates an attribute.
     *
     * @note Xml-Text nodes don't have attributes. You can use this feature to assign properties to complete text-blocks.
     *
     * @param {String} attributeName The attribute name that is to be set.
     * @param {any} attributeValue The attribute value that is to be set.
     *
     * @public
     */
    setAttribute (attributeName, attributeValue) {
      if (this.doc !== null) {
        transact(this.doc, transaction => {
          typeMapSet(transaction, this, attributeName, attributeValue);
        });
      } else {
        /** @type {Array<function>} */ (this._pending).push(() => this.setAttribute(attributeName, attributeValue));
      }
    }

    /**
     * Returns an attribute value that belongs to the attribute name.
     *
     * @note Xml-Text nodes don't have attributes. You can use this feature to assign properties to complete text-blocks.
     *
     * @param {String} attributeName The attribute name that identifies the
     *                               queried value.
     * @return {any} The queried attribute value.
     *
     * @public
     */
    getAttribute (attributeName) {
      return /** @type {any} */ (typeMapGet(this, attributeName))
    }

    /**
     * Returns all attribute name/value pairs in a JSON Object.
     *
     * @note Xml-Text nodes don't have attributes. You can use this feature to assign properties to complete text-blocks.
     *
     * @return {Object<string, any>} A JSON Object that describes the attributes.
     *
     * @public
     */
    getAttributes () {
      return typeMapGetAll(this)
    }

    /**
     * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder
     */
    _write (encoder) {
      encoder.writeTypeRef(YTextRefID);
    }
  }

  /**
   * @param {UpdateDecoderV1 | UpdateDecoderV2} _decoder
   * @return {YText}
   *
   * @private
   * @function
   */
  const readYText = _decoder => new YText();

  /**
   * @module YXml
   */


  /**
   * Define the elements to which a set of CSS queries apply.
   * {@link https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Selectors|CSS_Selectors}
   *
   * @example
   *   query = '.classSelector'
   *   query = 'nodeSelector'
   *   query = '#idSelector'
   *
   * @typedef {string} CSS_Selector
   */

  /**
   * Dom filter function.
   *
   * @callback domFilter
   * @param {string} nodeName The nodeName of the element
   * @param {Map} attributes The map of attributes.
   * @return {boolean} Whether to include the Dom node in the YXmlElement.
   */

  /**
   * Represents a subset of the nodes of a YXmlElement / YXmlFragment and a
   * position within them.
   *
   * Can be created with {@link YXmlFragment#createTreeWalker}
   *
   * @public
   * @implements {Iterable<YXmlElement|YXmlText|YXmlElement|YXmlHook>}
   */
  class YXmlTreeWalker {
    /**
     * @param {YXmlFragment | YXmlElement} root
     * @param {function(AbstractType<any>):boolean} [f]
     */
    constructor (root, f = () => true) {
      this._filter = f;
      this._root = root;
      /**
       * @type {Item}
       */
      this._currentNode = /** @type {Item} */ (root._start);
      this._firstCall = true;
      root.doc ?? warnPrematureAccess();
    }

    [Symbol.iterator] () {
      return this
    }

    /**
     * Get the next node.
     *
     * @return {IteratorResult<YXmlElement|YXmlText|YXmlHook>} The next node.
     *
     * @public
     */
    next () {
      /**
       * @type {Item|null}
       */
      let n = this._currentNode;
      let type = n && n.content && /** @type {any} */ (n.content).type;
      if (n !== null && (!this._firstCall || n.deleted || !this._filter(type))) { // if first call, we check if we can use the first item
        do {
          type = /** @type {any} */ (n.content).type;
          if (!n.deleted && (type.constructor === YXmlElement || type.constructor === YXmlFragment) && type._start !== null) {
            // walk down in the tree
            n = type._start;
          } else {
            // walk right or up in the tree
            while (n !== null) {
              /**
               * @type {Item | null}
               */
              const nxt = n.next;
              if (nxt !== null) {
                n = nxt;
                break
              } else if (n.parent === this._root) {
                n = null;
              } else {
                n = /** @type {AbstractType<any>} */ (n.parent)._item;
              }
            }
          }
        } while (n !== null && (n.deleted || !this._filter(/** @type {ContentType} */ (n.content).type)))
      }
      this._firstCall = false;
      if (n === null) {
        // @ts-ignore
        return { value: undefined, done: true }
      }
      this._currentNode = n;
      return { value: /** @type {any} */ (n.content).type, done: false }
    }
  }

  /**
   * Represents a list of {@link YXmlElement}.and {@link YXmlText} types.
   * A YxmlFragment is similar to a {@link YXmlElement}, but it does not have a
   * nodeName and it does not have attributes. Though it can be bound to a DOM
   * element - in this case the attributes and the nodeName are not shared.
   *
   * @public
   * @extends AbstractType<YXmlEvent>
   */
  class YXmlFragment extends AbstractType {
    constructor () {
      super();
      /**
       * @type {Array<any>|null}
       */
      this._prelimContent = [];
    }

    /**
     * @type {YXmlElement|YXmlText|null}
     */
    get firstChild () {
      const first = this._first;
      return first ? first.content.getContent()[0] : null
    }

    /**
     * Integrate this type into the Yjs instance.
     *
     * * Save this struct in the os
     * * This type is sent to other client
     * * Observer functions are fired
     *
     * @param {Doc} y The Yjs instance
     * @param {Item} item
     */
    _integrate (y, item) {
      super._integrate(y, item);
      this.insert(0, /** @type {Array<any>} */ (this._prelimContent));
      this._prelimContent = null;
    }

    _copy () {
      return new YXmlFragment()
    }

    /**
     * Makes a copy of this data type that can be included somewhere else.
     *
     * Note that the content is only readable _after_ it has been included somewhere in the Ydoc.
     *
     * @return {YXmlFragment}
     */
    clone () {
      const el = new YXmlFragment();
      // @ts-ignore
      el.insert(0, this.toArray().map(item => item instanceof AbstractType ? item.clone() : item));
      return el
    }

    get length () {
      this.doc ?? warnPrematureAccess();
      return this._prelimContent === null ? this._length : this._prelimContent.length
    }

    /**
     * Create a subtree of childNodes.
     *
     * @example
     * const walker = elem.createTreeWalker(dom => dom.nodeName === 'div')
     * for (let node in walker) {
     *   // `node` is a div node
     *   nop(node)
     * }
     *
     * @param {function(AbstractType<any>):boolean} filter Function that is called on each child element and
     *                          returns a Boolean indicating whether the child
     *                          is to be included in the subtree.
     * @return {YXmlTreeWalker} A subtree and a position within it.
     *
     * @public
     */
    createTreeWalker (filter) {
      return new YXmlTreeWalker(this, filter)
    }

    /**
     * Returns the first YXmlElement that matches the query.
     * Similar to DOM's {@link querySelector}.
     *
     * Query support:
     *   - tagname
     * TODO:
     *   - id
     *   - attribute
     *
     * @param {CSS_Selector} query The query on the children.
     * @return {YXmlElement|YXmlText|YXmlHook|null} The first element that matches the query or null.
     *
     * @public
     */
    querySelector (query) {
      query = query.toUpperCase();
      // @ts-ignore
      const iterator = new YXmlTreeWalker(this, element => element.nodeName && element.nodeName.toUpperCase() === query);
      const next = iterator.next();
      if (next.done) {
        return null
      } else {
        return next.value
      }
    }

    /**
     * Returns all YXmlElements that match the query.
     * Similar to Dom's {@link querySelectorAll}.
     *
     * @todo Does not yet support all queries. Currently only query by tagName.
     *
     * @param {CSS_Selector} query The query on the children
     * @return {Array<YXmlElement|YXmlText|YXmlHook|null>} The elements that match this query.
     *
     * @public
     */
    querySelectorAll (query) {
      query = query.toUpperCase();
      // @ts-ignore
      return from$2(new YXmlTreeWalker(this, element => element.nodeName && element.nodeName.toUpperCase() === query))
    }

    /**
     * Creates YXmlEvent and calls observers.
     *
     * @param {Transaction} transaction
     * @param {Set<null|string>} parentSubs Keys changed on this type. `null` if list was modified.
     */
    _callObserver (transaction, parentSubs) {
      callTypeObservers(this, transaction, new YXmlEvent(this, parentSubs, transaction));
    }

    /**
     * Get the string representation of all the children of this YXmlFragment.
     *
     * @return {string} The string representation of all children.
     */
    toString () {
      return typeListMap(this, xml => xml.toString()).join('')
    }

    /**
     * @return {string}
     */
    toJSON () {
      return this.toString()
    }

    /**
     * Creates a Dom Element that mirrors this YXmlElement.
     *
     * @param {Document} [_document=document] The document object (you must define
     *                                        this when calling this method in
     *                                        nodejs)
     * @param {Object<string, any>} [hooks={}] Optional property to customize how hooks
     *                                             are presented in the DOM
     * @param {any} [binding] You should not set this property. This is
     *                               used if DomBinding wants to create a
     *                               association to the created DOM type.
     * @return {Node} The {@link https://developer.mozilla.org/en-US/docs/Web/API/Element|Dom Element}
     *
     * @public
     */
    toDOM (_document = document, hooks = {}, binding) {
      const fragment = _document.createDocumentFragment();
      if (binding !== undefined) {
        binding._createAssociation(fragment, this);
      }
      typeListForEach(this, xmlType => {
        fragment.insertBefore(xmlType.toDOM(_document, hooks, binding), null);
      });
      return fragment
    }

    /**
     * Inserts new content at an index.
     *
     * @example
     *  // Insert character 'a' at position 0
     *  xml.insert(0, [new Y.XmlText('text')])
     *
     * @param {number} index The index to insert content at
     * @param {Array<YXmlElement|YXmlText>} content The array of content
     */
    insert (index, content) {
      if (this.doc !== null) {
        transact(this.doc, transaction => {
          typeListInsertGenerics(transaction, this, index, content);
        });
      } else {
        // @ts-ignore _prelimContent is defined because this is not yet integrated
        this._prelimContent.splice(index, 0, ...content);
      }
    }

    /**
     * Inserts new content at an index.
     *
     * @example
     *  // Insert character 'a' at position 0
     *  xml.insert(0, [new Y.XmlText('text')])
     *
     * @param {null|Item|YXmlElement|YXmlText} ref The index to insert content at
     * @param {Array<YXmlElement|YXmlText>} content The array of content
     */
    insertAfter (ref, content) {
      if (this.doc !== null) {
        transact(this.doc, transaction => {
          const refItem = (ref && ref instanceof AbstractType) ? ref._item : ref;
          typeListInsertGenericsAfter(transaction, this, refItem, content);
        });
      } else {
        const pc = /** @type {Array<any>} */ (this._prelimContent);
        const index = ref === null ? 0 : pc.findIndex(el => el === ref) + 1;
        if (index === 0 && ref !== null) {
          throw create$4('Reference item not found')
        }
        pc.splice(index, 0, ...content);
      }
    }

    /**
     * Deletes elements starting from an index.
     *
     * @param {number} index Index at which to start deleting elements
     * @param {number} [length=1] The number of elements to remove. Defaults to 1.
     */
    delete (index, length = 1) {
      if (this.doc !== null) {
        transact(this.doc, transaction => {
          typeListDelete(transaction, this, index, length);
        });
      } else {
        // @ts-ignore _prelimContent is defined because this is not yet integrated
        this._prelimContent.splice(index, length);
      }
    }

    /**
     * Transforms this YArray to a JavaScript Array.
     *
     * @return {Array<YXmlElement|YXmlText|YXmlHook>}
     */
    toArray () {
      return typeListToArray(this)
    }

    /**
     * Appends content to this YArray.
     *
     * @param {Array<YXmlElement|YXmlText>} content Array of content to append.
     */
    push (content) {
      this.insert(this.length, content);
    }

    /**
     * Prepends content to this YArray.
     *
     * @param {Array<YXmlElement|YXmlText>} content Array of content to prepend.
     */
    unshift (content) {
      this.insert(0, content);
    }

    /**
     * Returns the i-th element from a YArray.
     *
     * @param {number} index The index of the element to return from the YArray
     * @return {YXmlElement|YXmlText}
     */
    get (index) {
      return typeListGet(this, index)
    }

    /**
     * Returns a portion of this YXmlFragment into a JavaScript Array selected
     * from start to end (end not included).
     *
     * @param {number} [start]
     * @param {number} [end]
     * @return {Array<YXmlElement|YXmlText>}
     */
    slice (start = 0, end = this.length) {
      return typeListSlice(this, start, end)
    }

    /**
     * Executes a provided function on once on every child element.
     *
     * @param {function(YXmlElement|YXmlText,number, typeof self):void} f A function to execute on every element of this YArray.
     */
    forEach (f) {
      typeListForEach(this, f);
    }

    /**
     * Transform the properties of this type to binary and write it to an
     * BinaryEncoder.
     *
     * This is called when this Item is sent to a remote peer.
     *
     * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder The encoder to write data to.
     */
    _write (encoder) {
      encoder.writeTypeRef(YXmlFragmentRefID);
    }
  }

  /**
   * @param {UpdateDecoderV1 | UpdateDecoderV2} _decoder
   * @return {YXmlFragment}
   *
   * @private
   * @function
   */
  const readYXmlFragment = _decoder => new YXmlFragment();

  /**
   * @typedef {Object|number|null|Array<any>|string|Uint8Array|AbstractType<any>} ValueTypes
   */

  /**
   * An YXmlElement imitates the behavior of a
   * https://developer.mozilla.org/en-US/docs/Web/API/Element|Dom Element
   *
   * * An YXmlElement has attributes (key value pairs)
   * * An YXmlElement has childElements that must inherit from YXmlElement
   *
   * @template {{ [key: string]: ValueTypes }} [KV={ [key: string]: string }]
   */
  class YXmlElement extends YXmlFragment {
    constructor (nodeName = 'UNDEFINED') {
      super();
      this.nodeName = nodeName;
      /**
       * @type {Map<string, any>|null}
       */
      this._prelimAttrs = new Map();
    }

    /**
     * @type {YXmlElement|YXmlText|null}
     */
    get nextSibling () {
      const n = this._item ? this._item.next : null;
      return n ? /** @type {YXmlElement|YXmlText} */ (/** @type {ContentType} */ (n.content).type) : null
    }

    /**
     * @type {YXmlElement|YXmlText|null}
     */
    get prevSibling () {
      const n = this._item ? this._item.prev : null;
      return n ? /** @type {YXmlElement|YXmlText} */ (/** @type {ContentType} */ (n.content).type) : null
    }

    /**
     * Integrate this type into the Yjs instance.
     *
     * * Save this struct in the os
     * * This type is sent to other client
     * * Observer functions are fired
     *
     * @param {Doc} y The Yjs instance
     * @param {Item} item
     */
    _integrate (y, item) {
      super._integrate(y, item)
      ;(/** @type {Map<string, any>} */ (this._prelimAttrs)).forEach((value, key) => {
        this.setAttribute(key, value);
      });
      this._prelimAttrs = null;
    }

    /**
     * Creates an Item with the same effect as this Item (without position effect)
     *
     * @return {YXmlElement}
     */
    _copy () {
      return new YXmlElement(this.nodeName)
    }

    /**
     * Makes a copy of this data type that can be included somewhere else.
     *
     * Note that the content is only readable _after_ it has been included somewhere in the Ydoc.
     *
     * @return {YXmlElement<KV>}
     */
    clone () {
      /**
       * @type {YXmlElement<KV>}
       */
      const el = new YXmlElement(this.nodeName);
      const attrs = this.getAttributes();
      forEach$2(attrs, (value, key) => {
        if (typeof value === 'string') {
          el.setAttribute(key, value);
        }
      });
      // @ts-ignore
      el.insert(0, this.toArray().map(item => item instanceof AbstractType ? item.clone() : item));
      return el
    }

    /**
     * Returns the XML serialization of this YXmlElement.
     * The attributes are ordered by attribute-name, so you can easily use this
     * method to compare YXmlElements
     *
     * @return {string} The string representation of this type.
     *
     * @public
     */
    toString () {
      const attrs = this.getAttributes();
      const stringBuilder = [];
      const keys = [];
      for (const key in attrs) {
        keys.push(key);
      }
      keys.sort();
      const keysLen = keys.length;
      for (let i = 0; i < keysLen; i++) {
        const key = keys[i];
        stringBuilder.push(key + '="' + attrs[key] + '"');
      }
      const nodeName = this.nodeName.toLocaleLowerCase();
      const attrsString = stringBuilder.length > 0 ? ' ' + stringBuilder.join(' ') : '';
      return `<${nodeName}${attrsString}>${super.toString()}</${nodeName}>`
    }

    /**
     * Removes an attribute from this YXmlElement.
     *
     * @param {string} attributeName The attribute name that is to be removed.
     *
     * @public
     */
    removeAttribute (attributeName) {
      if (this.doc !== null) {
        transact(this.doc, transaction => {
          typeMapDelete(transaction, this, attributeName);
        });
      } else {
        /** @type {Map<string,any>} */ (this._prelimAttrs).delete(attributeName);
      }
    }

    /**
     * Sets or updates an attribute.
     *
     * @template {keyof KV & string} KEY
     *
     * @param {KEY} attributeName The attribute name that is to be set.
     * @param {KV[KEY]} attributeValue The attribute value that is to be set.
     *
     * @public
     */
    setAttribute (attributeName, attributeValue) {
      if (this.doc !== null) {
        transact(this.doc, transaction => {
          typeMapSet(transaction, this, attributeName, attributeValue);
        });
      } else {
        /** @type {Map<string, any>} */ (this._prelimAttrs).set(attributeName, attributeValue);
      }
    }

    /**
     * Returns an attribute value that belongs to the attribute name.
     *
     * @template {keyof KV & string} KEY
     *
     * @param {KEY} attributeName The attribute name that identifies the
     *                               queried value.
     * @return {KV[KEY]|undefined} The queried attribute value.
     *
     * @public
     */
    getAttribute (attributeName) {
      return /** @type {any} */ (typeMapGet(this, attributeName))
    }

    /**
     * Returns whether an attribute exists
     *
     * @param {string} attributeName The attribute name to check for existence.
     * @return {boolean} whether the attribute exists.
     *
     * @public
     */
    hasAttribute (attributeName) {
      return /** @type {any} */ (typeMapHas(this, attributeName))
    }

    /**
     * Returns all attribute name/value pairs in a JSON Object.
     *
     * @param {Snapshot} [snapshot]
     * @return {{ [Key in Extract<keyof KV,string>]?: KV[Key]}} A JSON Object that describes the attributes.
     *
     * @public
     */
    getAttributes (snapshot) {
      return /** @type {any} */ (snapshot ? typeMapGetAllSnapshot(this, snapshot) : typeMapGetAll(this))
    }

    /**
     * Creates a Dom Element that mirrors this YXmlElement.
     *
     * @param {Document} [_document=document] The document object (you must define
     *                                        this when calling this method in
     *                                        nodejs)
     * @param {Object<string, any>} [hooks={}] Optional property to customize how hooks
     *                                             are presented in the DOM
     * @param {any} [binding] You should not set this property. This is
     *                               used if DomBinding wants to create a
     *                               association to the created DOM type.
     * @return {Node} The {@link https://developer.mozilla.org/en-US/docs/Web/API/Element|Dom Element}
     *
     * @public
     */
    toDOM (_document = document, hooks = {}, binding) {
      const dom = _document.createElement(this.nodeName);
      const attrs = this.getAttributes();
      for (const key in attrs) {
        const value = attrs[key];
        if (typeof value === 'string') {
          dom.setAttribute(key, value);
        }
      }
      typeListForEach(this, yxml => {
        dom.appendChild(yxml.toDOM(_document, hooks, binding));
      });
      if (binding !== undefined) {
        binding._createAssociation(dom, this);
      }
      return dom
    }

    /**
     * Transform the properties of this type to binary and write it to an
     * BinaryEncoder.
     *
     * This is called when this Item is sent to a remote peer.
     *
     * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder The encoder to write data to.
     */
    _write (encoder) {
      encoder.writeTypeRef(YXmlElementRefID);
      encoder.writeKey(this.nodeName);
    }
  }

  /**
   * @param {UpdateDecoderV1 | UpdateDecoderV2} decoder
   * @return {YXmlElement}
   *
   * @function
   */
  const readYXmlElement = decoder => new YXmlElement(decoder.readKey());

  /**
   * @extends YEvent<YXmlElement|YXmlText|YXmlFragment>
   * An Event that describes changes on a YXml Element or Yxml Fragment
   */
  class YXmlEvent extends YEvent {
    /**
     * @param {YXmlElement|YXmlText|YXmlFragment} target The target on which the event is created.
     * @param {Set<string|null>} subs The set of changed attributes. `null` is included if the
     *                   child list changed.
     * @param {Transaction} transaction The transaction instance with which the
     *                                  change was created.
     */
    constructor (target, subs, transaction) {
      super(target, transaction);
      /**
       * Whether the children changed.
       * @type {Boolean}
       * @private
       */
      this.childListChanged = false;
      /**
       * Set of all changed attributes.
       * @type {Set<string>}
       */
      this.attributesChanged = new Set();
      subs.forEach((sub) => {
        if (sub === null) {
          this.childListChanged = true;
        } else {
          this.attributesChanged.add(sub);
        }
      });
    }
  }

  /**
   * You can manage binding to a custom type with YXmlHook.
   *
   * @extends {YMap<any>}
   */
  class YXmlHook extends YMap {
    /**
     * @param {string} hookName nodeName of the Dom Node.
     */
    constructor (hookName) {
      super();
      /**
       * @type {string}
       */
      this.hookName = hookName;
    }

    /**
     * Creates an Item with the same effect as this Item (without position effect)
     */
    _copy () {
      return new YXmlHook(this.hookName)
    }

    /**
     * Makes a copy of this data type that can be included somewhere else.
     *
     * Note that the content is only readable _after_ it has been included somewhere in the Ydoc.
     *
     * @return {YXmlHook}
     */
    clone () {
      const el = new YXmlHook(this.hookName);
      this.forEach((value, key) => {
        el.set(key, value);
      });
      return el
    }

    /**
     * Creates a Dom Element that mirrors this YXmlElement.
     *
     * @param {Document} [_document=document] The document object (you must define
     *                                        this when calling this method in
     *                                        nodejs)
     * @param {Object.<string, any>} [hooks] Optional property to customize how hooks
     *                                             are presented in the DOM
     * @param {any} [binding] You should not set this property. This is
     *                               used if DomBinding wants to create a
     *                               association to the created DOM type
     * @return {Element} The {@link https://developer.mozilla.org/en-US/docs/Web/API/Element|Dom Element}
     *
     * @public
     */
    toDOM (_document = document, hooks = {}, binding) {
      const hook = hooks[this.hookName];
      let dom;
      if (hook !== undefined) {
        dom = hook.createDom(this);
      } else {
        dom = document.createElement(this.hookName);
      }
      dom.setAttribute('data-yjs-hook', this.hookName);
      if (binding !== undefined) {
        binding._createAssociation(dom, this);
      }
      return dom
    }

    /**
     * Transform the properties of this type to binary and write it to an
     * BinaryEncoder.
     *
     * This is called when this Item is sent to a remote peer.
     *
     * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder The encoder to write data to.
     */
    _write (encoder) {
      encoder.writeTypeRef(YXmlHookRefID);
      encoder.writeKey(this.hookName);
    }
  }

  /**
   * @param {UpdateDecoderV1 | UpdateDecoderV2} decoder
   * @return {YXmlHook}
   *
   * @private
   * @function
   */
  const readYXmlHook = decoder =>
    new YXmlHook(decoder.readKey());

  /**
   * Represents text in a Dom Element. In the future this type will also handle
   * simple formatting information like bold and italic.
   */
  class YXmlText extends YText {
    /**
     * @type {YXmlElement|YXmlText|null}
     */
    get nextSibling () {
      const n = this._item ? this._item.next : null;
      return n ? /** @type {YXmlElement|YXmlText} */ (/** @type {ContentType} */ (n.content).type) : null
    }

    /**
     * @type {YXmlElement|YXmlText|null}
     */
    get prevSibling () {
      const n = this._item ? this._item.prev : null;
      return n ? /** @type {YXmlElement|YXmlText} */ (/** @type {ContentType} */ (n.content).type) : null
    }

    _copy () {
      return new YXmlText()
    }

    /**
     * Makes a copy of this data type that can be included somewhere else.
     *
     * Note that the content is only readable _after_ it has been included somewhere in the Ydoc.
     *
     * @return {YXmlText}
     */
    clone () {
      const text = new YXmlText();
      text.applyDelta(this.toDelta());
      return text
    }

    /**
     * Creates a Dom Element that mirrors this YXmlText.
     *
     * @param {Document} [_document=document] The document object (you must define
     *                                        this when calling this method in
     *                                        nodejs)
     * @param {Object<string, any>} [hooks] Optional property to customize how hooks
     *                                             are presented in the DOM
     * @param {any} [binding] You should not set this property. This is
     *                               used if DomBinding wants to create a
     *                               association to the created DOM type.
     * @return {Text} The {@link https://developer.mozilla.org/en-US/docs/Web/API/Element|Dom Element}
     *
     * @public
     */
    toDOM (_document = document, hooks, binding) {
      const dom = _document.createTextNode(this.toString());
      if (binding !== undefined) {
        binding._createAssociation(dom, this);
      }
      return dom
    }

    toString () {
      // @ts-ignore
      return this.toDelta().map(delta => {
        const nestedNodes = [];
        for (const nodeName in delta.attributes) {
          const attrs = [];
          for (const key in delta.attributes[nodeName]) {
            attrs.push({ key, value: delta.attributes[nodeName][key] });
          }
          // sort attributes to get a unique order
          attrs.sort((a, b) => a.key < b.key ? -1 : 1);
          nestedNodes.push({ nodeName, attrs });
        }
        // sort node order to get a unique order
        nestedNodes.sort((a, b) => a.nodeName < b.nodeName ? -1 : 1);
        // now convert to dom string
        let str = '';
        for (let i = 0; i < nestedNodes.length; i++) {
          const node = nestedNodes[i];
          str += `<${node.nodeName}`;
          for (let j = 0; j < node.attrs.length; j++) {
            const attr = node.attrs[j];
            str += ` ${attr.key}="${attr.value}"`;
          }
          str += '>';
        }
        str += delta.insert;
        for (let i = nestedNodes.length - 1; i >= 0; i--) {
          str += `</${nestedNodes[i].nodeName}>`;
        }
        return str
      }).join('')
    }

    /**
     * @return {string}
     */
    toJSON () {
      return this.toString()
    }

    /**
     * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder
     */
    _write (encoder) {
      encoder.writeTypeRef(YXmlTextRefID);
    }
  }

  /**
   * @param {UpdateDecoderV1 | UpdateDecoderV2} decoder
   * @return {YXmlText}
   *
   * @private
   * @function
   */
  const readYXmlText = decoder => new YXmlText();

  class AbstractStruct {
    /**
     * @param {ID} id
     * @param {number} length
     */
    constructor (id, length) {
      this.id = id;
      this.length = length;
    }

    /**
     * @type {boolean}
     */
    get deleted () {
      throw methodUnimplemented()
    }

    /**
     * Merge this struct with the item to the right.
     * This method is already assuming that `this.id.clock + this.length === this.id.clock`.
     * Also this method does *not* remove right from StructStore!
     * @param {AbstractStruct} right
     * @return {boolean} whether this merged with right
     */
    mergeWith (right) {
      return false
    }

    /**
     * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder The encoder to write data to.
     * @param {number} offset
     * @param {number} encodingRef
     */
    write (encoder, offset, encodingRef) {
      throw methodUnimplemented()
    }

    /**
     * @param {Transaction} transaction
     * @param {number} offset
     */
    integrate (transaction, offset) {
      throw methodUnimplemented()
    }
  }

  const structGCRefNumber = 0;

  /**
   * @private
   */
  class GC extends AbstractStruct {
    get deleted () {
      return true
    }

    delete () {}

    /**
     * @param {GC} right
     * @return {boolean}
     */
    mergeWith (right) {
      if (this.constructor !== right.constructor) {
        return false
      }
      this.length += right.length;
      return true
    }

    /**
     * @param {Transaction} transaction
     * @param {number} offset
     */
    integrate (transaction, offset) {
      if (offset > 0) {
        this.id.clock += offset;
        this.length -= offset;
      }
      addStruct(transaction.doc.store, this);
    }

    /**
     * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder
     * @param {number} offset
     */
    write (encoder, offset) {
      encoder.writeInfo(structGCRefNumber);
      encoder.writeLen(this.length - offset);
    }

    /**
     * @param {Transaction} transaction
     * @param {StructStore} store
     * @return {null | number}
     */
    getMissing (transaction, store) {
      return null
    }
  }

  class ContentBinary {
    /**
     * @param {Uint8Array} content
     */
    constructor (content) {
      this.content = content;
    }

    /**
     * @return {number}
     */
    getLength () {
      return 1
    }

    /**
     * @return {Array<any>}
     */
    getContent () {
      return [this.content]
    }

    /**
     * @return {boolean}
     */
    isCountable () {
      return true
    }

    /**
     * @return {ContentBinary}
     */
    copy () {
      return new ContentBinary(this.content)
    }

    /**
     * @param {number} offset
     * @return {ContentBinary}
     */
    splice (offset) {
      throw methodUnimplemented()
    }

    /**
     * @param {ContentBinary} right
     * @return {boolean}
     */
    mergeWith (right) {
      return false
    }

    /**
     * @param {Transaction} transaction
     * @param {Item} item
     */
    integrate (transaction, item) {}
    /**
     * @param {Transaction} transaction
     */
    delete (transaction) {}
    /**
     * @param {StructStore} store
     */
    gc (store) {}
    /**
     * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder
     * @param {number} offset
     */
    write (encoder, offset) {
      encoder.writeBuf(this.content);
    }

    /**
     * @return {number}
     */
    getRef () {
      return 3
    }
  }

  /**
   * @param {UpdateDecoderV1 | UpdateDecoderV2 } decoder
   * @return {ContentBinary}
   */
  const readContentBinary = decoder => new ContentBinary(decoder.readBuf());

  class ContentDeleted {
    /**
     * @param {number} len
     */
    constructor (len) {
      this.len = len;
    }

    /**
     * @return {number}
     */
    getLength () {
      return this.len
    }

    /**
     * @return {Array<any>}
     */
    getContent () {
      return []
    }

    /**
     * @return {boolean}
     */
    isCountable () {
      return false
    }

    /**
     * @return {ContentDeleted}
     */
    copy () {
      return new ContentDeleted(this.len)
    }

    /**
     * @param {number} offset
     * @return {ContentDeleted}
     */
    splice (offset) {
      const right = new ContentDeleted(this.len - offset);
      this.len = offset;
      return right
    }

    /**
     * @param {ContentDeleted} right
     * @return {boolean}
     */
    mergeWith (right) {
      this.len += right.len;
      return true
    }

    /**
     * @param {Transaction} transaction
     * @param {Item} item
     */
    integrate (transaction, item) {
      addToDeleteSet(transaction.deleteSet, item.id.client, item.id.clock, this.len);
      item.markDeleted();
    }

    /**
     * @param {Transaction} transaction
     */
    delete (transaction) {}
    /**
     * @param {StructStore} store
     */
    gc (store) {}
    /**
     * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder
     * @param {number} offset
     */
    write (encoder, offset) {
      encoder.writeLen(this.len - offset);
    }

    /**
     * @return {number}
     */
    getRef () {
      return 1
    }
  }

  /**
   * @private
   *
   * @param {UpdateDecoderV1 | UpdateDecoderV2 } decoder
   * @return {ContentDeleted}
   */
  const readContentDeleted = decoder => new ContentDeleted(decoder.readLen());

  /**
   * @param {string} guid
   * @param {Object<string, any>} opts
   */
  const createDocFromOpts = (guid, opts) => new Doc({ guid, ...opts, shouldLoad: opts.shouldLoad || opts.autoLoad || false });

  /**
   * @private
   */
  class ContentDoc {
    /**
     * @param {Doc} doc
     */
    constructor (doc) {
      if (doc._item) {
        console.error('This document was already integrated as a sub-document. You should create a second instance instead with the same guid.');
      }
      /**
       * @type {Doc}
       */
      this.doc = doc;
      /**
       * @type {any}
       */
      const opts = {};
      this.opts = opts;
      if (!doc.gc) {
        opts.gc = false;
      }
      if (doc.autoLoad) {
        opts.autoLoad = true;
      }
      if (doc.meta !== null) {
        opts.meta = doc.meta;
      }
    }

    /**
     * @return {number}
     */
    getLength () {
      return 1
    }

    /**
     * @return {Array<any>}
     */
    getContent () {
      return [this.doc]
    }

    /**
     * @return {boolean}
     */
    isCountable () {
      return true
    }

    /**
     * @return {ContentDoc}
     */
    copy () {
      return new ContentDoc(createDocFromOpts(this.doc.guid, this.opts))
    }

    /**
     * @param {number} offset
     * @return {ContentDoc}
     */
    splice (offset) {
      throw methodUnimplemented()
    }

    /**
     * @param {ContentDoc} right
     * @return {boolean}
     */
    mergeWith (right) {
      return false
    }

    /**
     * @param {Transaction} transaction
     * @param {Item} item
     */
    integrate (transaction, item) {
      // this needs to be reflected in doc.destroy as well
      this.doc._item = item;
      transaction.subdocsAdded.add(this.doc);
      if (this.doc.shouldLoad) {
        transaction.subdocsLoaded.add(this.doc);
      }
    }

    /**
     * @param {Transaction} transaction
     */
    delete (transaction) {
      if (transaction.subdocsAdded.has(this.doc)) {
        transaction.subdocsAdded.delete(this.doc);
      } else {
        transaction.subdocsRemoved.add(this.doc);
      }
    }

    /**
     * @param {StructStore} store
     */
    gc (store) { }

    /**
     * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder
     * @param {number} offset
     */
    write (encoder, offset) {
      encoder.writeString(this.doc.guid);
      encoder.writeAny(this.opts);
    }

    /**
     * @return {number}
     */
    getRef () {
      return 9
    }
  }

  /**
   * @private
   *
   * @param {UpdateDecoderV1 | UpdateDecoderV2} decoder
   * @return {ContentDoc}
   */
  const readContentDoc = decoder => new ContentDoc(createDocFromOpts(decoder.readString(), decoder.readAny()));

  /**
   * @private
   */
  class ContentEmbed {
    /**
     * @param {Object} embed
     */
    constructor (embed) {
      this.embed = embed;
    }

    /**
     * @return {number}
     */
    getLength () {
      return 1
    }

    /**
     * @return {Array<any>}
     */
    getContent () {
      return [this.embed]
    }

    /**
     * @return {boolean}
     */
    isCountable () {
      return true
    }

    /**
     * @return {ContentEmbed}
     */
    copy () {
      return new ContentEmbed(this.embed)
    }

    /**
     * @param {number} offset
     * @return {ContentEmbed}
     */
    splice (offset) {
      throw methodUnimplemented()
    }

    /**
     * @param {ContentEmbed} right
     * @return {boolean}
     */
    mergeWith (right) {
      return false
    }

    /**
     * @param {Transaction} transaction
     * @param {Item} item
     */
    integrate (transaction, item) {}
    /**
     * @param {Transaction} transaction
     */
    delete (transaction) {}
    /**
     * @param {StructStore} store
     */
    gc (store) {}
    /**
     * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder
     * @param {number} offset
     */
    write (encoder, offset) {
      encoder.writeJSON(this.embed);
    }

    /**
     * @return {number}
     */
    getRef () {
      return 5
    }
  }

  /**
   * @private
   *
   * @param {UpdateDecoderV1 | UpdateDecoderV2} decoder
   * @return {ContentEmbed}
   */
  const readContentEmbed = decoder => new ContentEmbed(decoder.readJSON());

  /**
   * @private
   */
  class ContentFormat {
    /**
     * @param {string} key
     * @param {Object} value
     */
    constructor (key, value) {
      this.key = key;
      this.value = value;
    }

    /**
     * @return {number}
     */
    getLength () {
      return 1
    }

    /**
     * @return {Array<any>}
     */
    getContent () {
      return []
    }

    /**
     * @return {boolean}
     */
    isCountable () {
      return false
    }

    /**
     * @return {ContentFormat}
     */
    copy () {
      return new ContentFormat(this.key, this.value)
    }

    /**
     * @param {number} _offset
     * @return {ContentFormat}
     */
    splice (_offset) {
      throw methodUnimplemented()
    }

    /**
     * @param {ContentFormat} _right
     * @return {boolean}
     */
    mergeWith (_right) {
      return false
    }

    /**
     * @param {Transaction} _transaction
     * @param {Item} item
     */
    integrate (_transaction, item) {
      // @todo searchmarker are currently unsupported for rich text documents
      const p = /** @type {YText} */ (item.parent);
      p._searchMarker = null;
      p._hasFormatting = true;
    }

    /**
     * @param {Transaction} transaction
     */
    delete (transaction) {}
    /**
     * @param {StructStore} store
     */
    gc (store) {}
    /**
     * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder
     * @param {number} offset
     */
    write (encoder, offset) {
      encoder.writeKey(this.key);
      encoder.writeJSON(this.value);
    }

    /**
     * @return {number}
     */
    getRef () {
      return 6
    }
  }

  /**
   * @param {UpdateDecoderV1 | UpdateDecoderV2} decoder
   * @return {ContentFormat}
   */
  const readContentFormat = decoder => new ContentFormat(decoder.readKey(), decoder.readJSON());

  /**
   * @private
   */
  class ContentJSON {
    /**
     * @param {Array<any>} arr
     */
    constructor (arr) {
      /**
       * @type {Array<any>}
       */
      this.arr = arr;
    }

    /**
     * @return {number}
     */
    getLength () {
      return this.arr.length
    }

    /**
     * @return {Array<any>}
     */
    getContent () {
      return this.arr
    }

    /**
     * @return {boolean}
     */
    isCountable () {
      return true
    }

    /**
     * @return {ContentJSON}
     */
    copy () {
      return new ContentJSON(this.arr)
    }

    /**
     * @param {number} offset
     * @return {ContentJSON}
     */
    splice (offset) {
      const right = new ContentJSON(this.arr.slice(offset));
      this.arr = this.arr.slice(0, offset);
      return right
    }

    /**
     * @param {ContentJSON} right
     * @return {boolean}
     */
    mergeWith (right) {
      this.arr = this.arr.concat(right.arr);
      return true
    }

    /**
     * @param {Transaction} transaction
     * @param {Item} item
     */
    integrate (transaction, item) {}
    /**
     * @param {Transaction} transaction
     */
    delete (transaction) {}
    /**
     * @param {StructStore} store
     */
    gc (store) {}
    /**
     * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder
     * @param {number} offset
     */
    write (encoder, offset) {
      const len = this.arr.length;
      encoder.writeLen(len - offset);
      for (let i = offset; i < len; i++) {
        const c = this.arr[i];
        encoder.writeString(c === undefined ? 'undefined' : JSON.stringify(c));
      }
    }

    /**
     * @return {number}
     */
    getRef () {
      return 2
    }
  }

  /**
   * @private
   *
   * @param {UpdateDecoderV1 | UpdateDecoderV2} decoder
   * @return {ContentJSON}
   */
  const readContentJSON = decoder => {
    const len = decoder.readLen();
    const cs = [];
    for (let i = 0; i < len; i++) {
      const c = decoder.readString();
      if (c === 'undefined') {
        cs.push(undefined);
      } else {
        cs.push(JSON.parse(c));
      }
    }
    return new ContentJSON(cs)
  };

  const isDevMode = getVariable('node_env') === 'development';

  class ContentAny {
    /**
     * @param {Array<any>} arr
     */
    constructor (arr) {
      /**
       * @type {Array<any>}
       */
      this.arr = arr;
      isDevMode && deepFreeze(arr);
    }

    /**
     * @return {number}
     */
    getLength () {
      return this.arr.length
    }

    /**
     * @return {Array<any>}
     */
    getContent () {
      return this.arr
    }

    /**
     * @return {boolean}
     */
    isCountable () {
      return true
    }

    /**
     * @return {ContentAny}
     */
    copy () {
      return new ContentAny(this.arr)
    }

    /**
     * @param {number} offset
     * @return {ContentAny}
     */
    splice (offset) {
      const right = new ContentAny(this.arr.slice(offset));
      this.arr = this.arr.slice(0, offset);
      return right
    }

    /**
     * @param {ContentAny} right
     * @return {boolean}
     */
    mergeWith (right) {
      this.arr = this.arr.concat(right.arr);
      return true
    }

    /**
     * @param {Transaction} transaction
     * @param {Item} item
     */
    integrate (transaction, item) {}
    /**
     * @param {Transaction} transaction
     */
    delete (transaction) {}
    /**
     * @param {StructStore} store
     */
    gc (store) {}
    /**
     * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder
     * @param {number} offset
     */
    write (encoder, offset) {
      const len = this.arr.length;
      encoder.writeLen(len - offset);
      for (let i = offset; i < len; i++) {
        const c = this.arr[i];
        encoder.writeAny(c);
      }
    }

    /**
     * @return {number}
     */
    getRef () {
      return 8
    }
  }

  /**
   * @param {UpdateDecoderV1 | UpdateDecoderV2} decoder
   * @return {ContentAny}
   */
  const readContentAny = decoder => {
    const len = decoder.readLen();
    const cs = [];
    for (let i = 0; i < len; i++) {
      cs.push(decoder.readAny());
    }
    return new ContentAny(cs)
  };

  /**
   * @private
   */
  class ContentString {
    /**
     * @param {string} str
     */
    constructor (str) {
      /**
       * @type {string}
       */
      this.str = str;
    }

    /**
     * @return {number}
     */
    getLength () {
      return this.str.length
    }

    /**
     * @return {Array<any>}
     */
    getContent () {
      return this.str.split('')
    }

    /**
     * @return {boolean}
     */
    isCountable () {
      return true
    }

    /**
     * @return {ContentString}
     */
    copy () {
      return new ContentString(this.str)
    }

    /**
     * @param {number} offset
     * @return {ContentString}
     */
    splice (offset) {
      const right = new ContentString(this.str.slice(offset));
      this.str = this.str.slice(0, offset);

      // Prevent encoding invalid documents because of splitting of surrogate pairs: https://github.com/yjs/yjs/issues/248
      const firstCharCode = this.str.charCodeAt(offset - 1);
      if (firstCharCode >= 0xD800 && firstCharCode <= 0xDBFF) {
        // Last character of the left split is the start of a surrogate utf16/ucs2 pair.
        // We don't support splitting of surrogate pairs because this may lead to invalid documents.
        // Replace the invalid character with a unicode replacement character (� / U+FFFD)
        this.str = this.str.slice(0, offset - 1) + '�';
        // replace right as well
        right.str = '�' + right.str.slice(1);
      }
      return right
    }

    /**
     * @param {ContentString} right
     * @return {boolean}
     */
    mergeWith (right) {
      this.str += right.str;
      return true
    }

    /**
     * @param {Transaction} transaction
     * @param {Item} item
     */
    integrate (transaction, item) {}
    /**
     * @param {Transaction} transaction
     */
    delete (transaction) {}
    /**
     * @param {StructStore} store
     */
    gc (store) {}
    /**
     * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder
     * @param {number} offset
     */
    write (encoder, offset) {
      encoder.writeString(offset === 0 ? this.str : this.str.slice(offset));
    }

    /**
     * @return {number}
     */
    getRef () {
      return 4
    }
  }

  /**
   * @private
   *
   * @param {UpdateDecoderV1 | UpdateDecoderV2} decoder
   * @return {ContentString}
   */
  const readContentString = decoder => new ContentString(decoder.readString());

  /**
   * @type {Array<function(UpdateDecoderV1 | UpdateDecoderV2):AbstractType<any>>}
   * @private
   */
  const typeRefs = [
    readYArray,
    readYMap,
    readYText,
    readYXmlElement,
    readYXmlFragment,
    readYXmlHook,
    readYXmlText
  ];

  const YArrayRefID = 0;
  const YMapRefID = 1;
  const YTextRefID = 2;
  const YXmlElementRefID = 3;
  const YXmlFragmentRefID = 4;
  const YXmlHookRefID = 5;
  const YXmlTextRefID = 6;

  /**
   * @private
   */
  class ContentType {
    /**
     * @param {AbstractType<any>} type
     */
    constructor (type) {
      /**
       * @type {AbstractType<any>}
       */
      this.type = type;
    }

    /**
     * @return {number}
     */
    getLength () {
      return 1
    }

    /**
     * @return {Array<any>}
     */
    getContent () {
      return [this.type]
    }

    /**
     * @return {boolean}
     */
    isCountable () {
      return true
    }

    /**
     * @return {ContentType}
     */
    copy () {
      return new ContentType(this.type._copy())
    }

    /**
     * @param {number} offset
     * @return {ContentType}
     */
    splice (offset) {
      throw methodUnimplemented()
    }

    /**
     * @param {ContentType} right
     * @return {boolean}
     */
    mergeWith (right) {
      return false
    }

    /**
     * @param {Transaction} transaction
     * @param {Item} item
     */
    integrate (transaction, item) {
      this.type._integrate(transaction.doc, item);
    }

    /**
     * @param {Transaction} transaction
     */
    delete (transaction) {
      let item = this.type._start;
      while (item !== null) {
        if (!item.deleted) {
          item.delete(transaction);
        } else if (item.id.clock < (transaction.beforeState.get(item.id.client) || 0)) {
          // This will be gc'd later and we want to merge it if possible
          // We try to merge all deleted items after each transaction,
          // but we have no knowledge about that this needs to be merged
          // since it is not in transaction.ds. Hence we add it to transaction._mergeStructs
          transaction._mergeStructs.push(item);
        }
        item = item.right;
      }
      this.type._map.forEach(item => {
        if (!item.deleted) {
          item.delete(transaction);
        } else if (item.id.clock < (transaction.beforeState.get(item.id.client) || 0)) {
          // same as above
          transaction._mergeStructs.push(item);
        }
      });
      transaction.changed.delete(this.type);
    }

    /**
     * @param {StructStore} store
     */
    gc (store) {
      let item = this.type._start;
      while (item !== null) {
        item.gc(store, true);
        item = item.right;
      }
      this.type._start = null;
      this.type._map.forEach(/** @param {Item | null} item */ (item) => {
        while (item !== null) {
          item.gc(store, true);
          item = item.left;
        }
      });
      this.type._map = new Map();
    }

    /**
     * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder
     * @param {number} offset
     */
    write (encoder, offset) {
      this.type._write(encoder);
    }

    /**
     * @return {number}
     */
    getRef () {
      return 7
    }
  }

  /**
   * @private
   *
   * @param {UpdateDecoderV1 | UpdateDecoderV2} decoder
   * @return {ContentType}
   */
  const readContentType = decoder => new ContentType(typeRefs[decoder.readTypeRef()](decoder));

  /**
   * @todo This should return several items
   *
   * @param {StructStore} store
   * @param {ID} id
   * @return {{item:Item, diff:number}}
   */
  const followRedone = (store, id) => {
    /**
     * @type {ID|null}
     */
    let nextID = id;
    let diff = 0;
    let item;
    do {
      if (diff > 0) {
        nextID = createID(nextID.client, nextID.clock + diff);
      }
      item = getItem(store, nextID);
      diff = nextID.clock - item.id.clock;
      nextID = item.redone;
    } while (nextID !== null && item instanceof Item)
    return {
      item, diff
    }
  };

  /**
   * Make sure that neither item nor any of its parents is ever deleted.
   *
   * This property does not persist when storing it into a database or when
   * sending it to other peers
   *
   * @param {Item|null} item
   * @param {boolean} keep
   */
  const keepItem = (item, keep) => {
    while (item !== null && item.keep !== keep) {
      item.keep = keep;
      item = /** @type {AbstractType<any>} */ (item.parent)._item;
    }
  };

  /**
   * Split leftItem into two items
   * @param {Transaction} transaction
   * @param {Item} leftItem
   * @param {number} diff
   * @return {Item}
   *
   * @function
   * @private
   */
  const splitItem = (transaction, leftItem, diff) => {
    // create rightItem
    const { client, clock } = leftItem.id;
    const rightItem = new Item(
      createID(client, clock + diff),
      leftItem,
      createID(client, clock + diff - 1),
      leftItem.right,
      leftItem.rightOrigin,
      leftItem.parent,
      leftItem.parentSub,
      leftItem.content.splice(diff)
    );
    if (leftItem.deleted) {
      rightItem.markDeleted();
    }
    if (leftItem.keep) {
      rightItem.keep = true;
    }
    if (leftItem.redone !== null) {
      rightItem.redone = createID(leftItem.redone.client, leftItem.redone.clock + diff);
    }
    // update left (do not set leftItem.rightOrigin as it will lead to problems when syncing)
    leftItem.right = rightItem;
    // update right
    if (rightItem.right !== null) {
      rightItem.right.left = rightItem;
    }
    // right is more specific.
    transaction._mergeStructs.push(rightItem);
    // update parent._map
    if (rightItem.parentSub !== null && rightItem.right === null) {
      /** @type {AbstractType<any>} */ (rightItem.parent)._map.set(rightItem.parentSub, rightItem);
    }
    leftItem.length = diff;
    return rightItem
  };

  /**
   * @param {Array<StackItem>} stack
   * @param {ID} id
   */
  const isDeletedByUndoStack = (stack, id) => some$1(stack, /** @param {StackItem} s */ s => isDeleted(s.deletions, id));

  /**
   * Redoes the effect of this operation.
   *
   * @param {Transaction} transaction The Yjs instance.
   * @param {Item} item
   * @param {Set<Item>} redoitems
   * @param {DeleteSet} itemsToDelete
   * @param {boolean} ignoreRemoteMapChanges
   * @param {import('../utils/UndoManager.js').UndoManager} um
   *
   * @return {Item|null}
   *
   * @private
   */
  const redoItem = (transaction, item, redoitems, itemsToDelete, ignoreRemoteMapChanges, um) => {
    const doc = transaction.doc;
    const store = doc.store;
    const ownClientID = doc.clientID;
    const redone = item.redone;
    if (redone !== null) {
      return getItemCleanStart(transaction, redone)
    }
    let parentItem = /** @type {AbstractType<any>} */ (item.parent)._item;
    /**
     * @type {Item|null}
     */
    let left = null;
    /**
     * @type {Item|null}
     */
    let right;
    // make sure that parent is redone
    if (parentItem !== null && parentItem.deleted === true) {
      // try to undo parent if it will be undone anyway
      if (parentItem.redone === null && (!redoitems.has(parentItem) || redoItem(transaction, parentItem, redoitems, itemsToDelete, ignoreRemoteMapChanges, um) === null)) {
        return null
      }
      while (parentItem.redone !== null) {
        parentItem = getItemCleanStart(transaction, parentItem.redone);
      }
    }
    const parentType = parentItem === null ? /** @type {AbstractType<any>} */ (item.parent) : /** @type {ContentType} */ (parentItem.content).type;

    if (item.parentSub === null) {
      // Is an array item. Insert at the old position
      left = item.left;
      right = item;
      // find next cloned_redo items
      while (left !== null) {
        /**
         * @type {Item|null}
         */
        let leftTrace = left;
        // trace redone until parent matches
        while (leftTrace !== null && /** @type {AbstractType<any>} */ (leftTrace.parent)._item !== parentItem) {
          leftTrace = leftTrace.redone === null ? null : getItemCleanStart(transaction, leftTrace.redone);
        }
        if (leftTrace !== null && /** @type {AbstractType<any>} */ (leftTrace.parent)._item === parentItem) {
          left = leftTrace;
          break
        }
        left = left.left;
      }
      while (right !== null) {
        /**
         * @type {Item|null}
         */
        let rightTrace = right;
        // trace redone until parent matches
        while (rightTrace !== null && /** @type {AbstractType<any>} */ (rightTrace.parent)._item !== parentItem) {
          rightTrace = rightTrace.redone === null ? null : getItemCleanStart(transaction, rightTrace.redone);
        }
        if (rightTrace !== null && /** @type {AbstractType<any>} */ (rightTrace.parent)._item === parentItem) {
          right = rightTrace;
          break
        }
        right = right.right;
      }
    } else {
      right = null;
      if (item.right && !ignoreRemoteMapChanges) {
        left = item;
        // Iterate right while right is in itemsToDelete
        // If it is intended to delete right while item is redone, we can expect that item should replace right.
        while (left !== null && left.right !== null && (left.right.redone || isDeleted(itemsToDelete, left.right.id) || isDeletedByUndoStack(um.undoStack, left.right.id) || isDeletedByUndoStack(um.redoStack, left.right.id))) {
          left = left.right;
          // follow redone
          while (left.redone) left = getItemCleanStart(transaction, left.redone);
        }
        if (left && left.right !== null) {
          // It is not possible to redo this item because it conflicts with a
          // change from another client
          return null
        }
      } else {
        left = parentType._map.get(item.parentSub) || null;
      }
    }
    const nextClock = getState(store, ownClientID);
    const nextId = createID(ownClientID, nextClock);
    const redoneItem = new Item(
      nextId,
      left, left && left.lastId,
      right, right && right.id,
      parentType,
      item.parentSub,
      item.content.copy()
    );
    item.redone = nextId;
    keepItem(redoneItem, true);
    redoneItem.integrate(transaction, 0);
    return redoneItem
  };

  /**
   * Abstract class that represents any content.
   */
  class Item extends AbstractStruct {
    /**
     * @param {ID} id
     * @param {Item | null} left
     * @param {ID | null} origin
     * @param {Item | null} right
     * @param {ID | null} rightOrigin
     * @param {AbstractType<any>|ID|null} parent Is a type if integrated, is null if it is possible to copy parent from left or right, is ID before integration to search for it.
     * @param {string | null} parentSub
     * @param {AbstractContent} content
     */
    constructor (id, left, origin, right, rightOrigin, parent, parentSub, content) {
      super(id, content.getLength());
      /**
       * The item that was originally to the left of this item.
       * @type {ID | null}
       */
      this.origin = origin;
      /**
       * The item that is currently to the left of this item.
       * @type {Item | null}
       */
      this.left = left;
      /**
       * The item that is currently to the right of this item.
       * @type {Item | null}
       */
      this.right = right;
      /**
       * The item that was originally to the right of this item.
       * @type {ID | null}
       */
      this.rightOrigin = rightOrigin;
      /**
       * @type {AbstractType<any>|ID|null}
       */
      this.parent = parent;
      /**
       * If the parent refers to this item with some kind of key (e.g. YMap, the
       * key is specified here. The key is then used to refer to the list in which
       * to insert this item. If `parentSub = null` type._start is the list in
       * which to insert to. Otherwise it is `parent._map`.
       * @type {String | null}
       */
      this.parentSub = parentSub;
      /**
       * If this type's effect is redone this type refers to the type that undid
       * this operation.
       * @type {ID | null}
       */
      this.redone = null;
      /**
       * @type {AbstractContent}
       */
      this.content = content;
      /**
       * bit1: keep
       * bit2: countable
       * bit3: deleted
       * bit4: mark - mark node as fast-search-marker
       * @type {number} byte
       */
      this.info = this.content.isCountable() ? BIT2 : 0;
    }

    /**
     * This is used to mark the item as an indexed fast-search marker
     *
     * @type {boolean}
     */
    set marker (isMarked) {
      if (((this.info & BIT4) > 0) !== isMarked) {
        this.info ^= BIT4;
      }
    }

    get marker () {
      return (this.info & BIT4) > 0
    }

    /**
     * If true, do not garbage collect this Item.
     */
    get keep () {
      return (this.info & BIT1) > 0
    }

    set keep (doKeep) {
      if (this.keep !== doKeep) {
        this.info ^= BIT1;
      }
    }

    get countable () {
      return (this.info & BIT2) > 0
    }

    /**
     * Whether this item was deleted or not.
     * @type {Boolean}
     */
    get deleted () {
      return (this.info & BIT3) > 0
    }

    set deleted (doDelete) {
      if (this.deleted !== doDelete) {
        this.info ^= BIT3;
      }
    }

    markDeleted () {
      this.info |= BIT3;
    }

    /**
     * Return the creator clientID of the missing op or define missing items and return null.
     *
     * @param {Transaction} transaction
     * @param {StructStore} store
     * @return {null | number}
     */
    getMissing (transaction, store) {
      if (this.origin && this.origin.client !== this.id.client && this.origin.clock >= getState(store, this.origin.client)) {
        return this.origin.client
      }
      if (this.rightOrigin && this.rightOrigin.client !== this.id.client && this.rightOrigin.clock >= getState(store, this.rightOrigin.client)) {
        return this.rightOrigin.client
      }
      if (this.parent && this.parent.constructor === ID && this.id.client !== this.parent.client && this.parent.clock >= getState(store, this.parent.client)) {
        return this.parent.client
      }

      // We have all missing ids, now find the items

      if (this.origin) {
        this.left = getItemCleanEnd(transaction, store, this.origin);
        this.origin = this.left.lastId;
      }
      if (this.rightOrigin) {
        this.right = getItemCleanStart(transaction, this.rightOrigin);
        this.rightOrigin = this.right.id;
      }
      if ((this.left && this.left.constructor === GC) || (this.right && this.right.constructor === GC)) {
        this.parent = null;
      } else if (!this.parent) {
        // only set parent if this shouldn't be garbage collected
        if (this.left && this.left.constructor === Item) {
          this.parent = this.left.parent;
          this.parentSub = this.left.parentSub;
        } else if (this.right && this.right.constructor === Item) {
          this.parent = this.right.parent;
          this.parentSub = this.right.parentSub;
        }
      } else if (this.parent.constructor === ID) {
        const parentItem = getItem(store, this.parent);
        if (parentItem.constructor === GC) {
          this.parent = null;
        } else {
          this.parent = /** @type {ContentType} */ (parentItem.content).type;
        }
      }
      return null
    }

    /**
     * @param {Transaction} transaction
     * @param {number} offset
     */
    integrate (transaction, offset) {
      if (offset > 0) {
        this.id.clock += offset;
        this.left = getItemCleanEnd(transaction, transaction.doc.store, createID(this.id.client, this.id.clock - 1));
        this.origin = this.left.lastId;
        this.content = this.content.splice(offset);
        this.length -= offset;
      }

      if (this.parent) {
        if ((!this.left && (!this.right || this.right.left !== null)) || (this.left && this.left.right !== this.right)) {
          /**
           * @type {Item|null}
           */
          let left = this.left;

          /**
           * @type {Item|null}
           */
          let o;
          // set o to the first conflicting item
          if (left !== null) {
            o = left.right;
          } else if (this.parentSub !== null) {
            o = /** @type {AbstractType<any>} */ (this.parent)._map.get(this.parentSub) || null;
            while (o !== null && o.left !== null) {
              o = o.left;
            }
          } else {
            o = /** @type {AbstractType<any>} */ (this.parent)._start;
          }
          // TODO: use something like DeleteSet here (a tree implementation would be best)
          // @todo use global set definitions
          /**
           * @type {Set<Item>}
           */
          const conflictingItems = new Set();
          /**
           * @type {Set<Item>}
           */
          const itemsBeforeOrigin = new Set();
          // Let c in conflictingItems, b in itemsBeforeOrigin
          // ***{origin}bbbb{this}{c,b}{c,b}{o}***
          // Note that conflictingItems is a subset of itemsBeforeOrigin
          while (o !== null && o !== this.right) {
            itemsBeforeOrigin.add(o);
            conflictingItems.add(o);
            if (compareIDs(this.origin, o.origin)) {
              // case 1
              if (o.id.client < this.id.client) {
                left = o;
                conflictingItems.clear();
              } else if (compareIDs(this.rightOrigin, o.rightOrigin)) {
                // this and o are conflicting and point to the same integration points. The id decides which item comes first.
                // Since this is to the left of o, we can break here
                break
              } // else, o might be integrated before an item that this conflicts with. If so, we will find it in the next iterations
            } else if (o.origin !== null && itemsBeforeOrigin.has(getItem(transaction.doc.store, o.origin))) { // use getItem instead of getItemCleanEnd because we don't want / need to split items.
              // case 2
              if (!conflictingItems.has(getItem(transaction.doc.store, o.origin))) {
                left = o;
                conflictingItems.clear();
              }
            } else {
              break
            }
            o = o.right;
          }
          this.left = left;
        }
        // reconnect left/right + update parent map/start if necessary
        if (this.left !== null) {
          const right = this.left.right;
          this.right = right;
          this.left.right = this;
        } else {
          let r;
          if (this.parentSub !== null) {
            r = /** @type {AbstractType<any>} */ (this.parent)._map.get(this.parentSub) || null;
            while (r !== null && r.left !== null) {
              r = r.left;
            }
          } else {
            r = /** @type {AbstractType<any>} */ (this.parent)._start
            ;/** @type {AbstractType<any>} */ (this.parent)._start = this;
          }
          this.right = r;
        }
        if (this.right !== null) {
          this.right.left = this;
        } else if (this.parentSub !== null) {
          // set as current parent value if right === null and this is parentSub
          /** @type {AbstractType<any>} */ (this.parent)._map.set(this.parentSub, this);
          if (this.left !== null) {
            // this is the current attribute value of parent. delete right
            this.left.delete(transaction);
          }
        }
        // adjust length of parent
        if (this.parentSub === null && this.countable && !this.deleted) {
          /** @type {AbstractType<any>} */ (this.parent)._length += this.length;
        }
        addStruct(transaction.doc.store, this);
        this.content.integrate(transaction, this);
        // add parent to transaction.changed
        addChangedTypeToTransaction(transaction, /** @type {AbstractType<any>} */ (this.parent), this.parentSub);
        if ((/** @type {AbstractType<any>} */ (this.parent)._item !== null && /** @type {AbstractType<any>} */ (this.parent)._item.deleted) || (this.parentSub !== null && this.right !== null)) {
          // delete if parent is deleted or if this is not the current attribute value of parent
          this.delete(transaction);
        }
      } else {
        // parent is not defined. Integrate GC struct instead
        new GC(this.id, this.length).integrate(transaction, 0);
      }
    }

    /**
     * Returns the next non-deleted item
     */
    get next () {
      let n = this.right;
      while (n !== null && n.deleted) {
        n = n.right;
      }
      return n
    }

    /**
     * Returns the previous non-deleted item
     */
    get prev () {
      let n = this.left;
      while (n !== null && n.deleted) {
        n = n.left;
      }
      return n
    }

    /**
     * Computes the last content address of this Item.
     */
    get lastId () {
      // allocating ids is pretty costly because of the amount of ids created, so we try to reuse whenever possible
      return this.length === 1 ? this.id : createID(this.id.client, this.id.clock + this.length - 1)
    }

    /**
     * Try to merge two items
     *
     * @param {Item} right
     * @return {boolean}
     */
    mergeWith (right) {
      if (
        this.constructor === right.constructor &&
        compareIDs(right.origin, this.lastId) &&
        this.right === right &&
        compareIDs(this.rightOrigin, right.rightOrigin) &&
        this.id.client === right.id.client &&
        this.id.clock + this.length === right.id.clock &&
        this.deleted === right.deleted &&
        this.redone === null &&
        right.redone === null &&
        this.content.constructor === right.content.constructor &&
        this.content.mergeWith(right.content)
      ) {
        const searchMarker = /** @type {AbstractType<any>} */ (this.parent)._searchMarker;
        if (searchMarker) {
          searchMarker.forEach(marker => {
            if (marker.p === right) {
              // right is going to be "forgotten" so we need to update the marker
              marker.p = this;
              // adjust marker index
              if (!this.deleted && this.countable) {
                marker.index -= this.length;
              }
            }
          });
        }
        if (right.keep) {
          this.keep = true;
        }
        this.right = right.right;
        if (this.right !== null) {
          this.right.left = this;
        }
        this.length += right.length;
        return true
      }
      return false
    }

    /**
     * Mark this Item as deleted.
     *
     * @param {Transaction} transaction
     */
    delete (transaction) {
      if (!this.deleted) {
        const parent = /** @type {AbstractType<any>} */ (this.parent);
        // adjust the length of parent
        if (this.countable && this.parentSub === null) {
          parent._length -= this.length;
        }
        this.markDeleted();
        addToDeleteSet(transaction.deleteSet, this.id.client, this.id.clock, this.length);
        addChangedTypeToTransaction(transaction, parent, this.parentSub);
        this.content.delete(transaction);
      }
    }

    /**
     * @param {StructStore} store
     * @param {boolean} parentGCd
     */
    gc (store, parentGCd) {
      if (!this.deleted) {
        throw unexpectedCase()
      }
      this.content.gc(store);
      if (parentGCd) {
        replaceStruct(store, this, new GC(this.id, this.length));
      } else {
        this.content = new ContentDeleted(this.length);
      }
    }

    /**
     * Transform the properties of this type to binary and write it to an
     * BinaryEncoder.
     *
     * This is called when this Item is sent to a remote peer.
     *
     * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder The encoder to write data to.
     * @param {number} offset
     */
    write (encoder, offset) {
      const origin = offset > 0 ? createID(this.id.client, this.id.clock + offset - 1) : this.origin;
      const rightOrigin = this.rightOrigin;
      const parentSub = this.parentSub;
      const info = (this.content.getRef() & BITS5) |
        (origin === null ? 0 : BIT8) | // origin is defined
        (rightOrigin === null ? 0 : BIT7) | // right origin is defined
        (parentSub === null ? 0 : BIT6); // parentSub is non-null
      encoder.writeInfo(info);
      if (origin !== null) {
        encoder.writeLeftID(origin);
      }
      if (rightOrigin !== null) {
        encoder.writeRightID(rightOrigin);
      }
      if (origin === null && rightOrigin === null) {
        const parent = /** @type {AbstractType<any>} */ (this.parent);
        if (parent._item !== undefined) {
          const parentItem = parent._item;
          if (parentItem === null) {
            // parent type on y._map
            // find the correct key
            const ykey = findRootTypeKey(parent);
            encoder.writeParentInfo(true); // write parentYKey
            encoder.writeString(ykey);
          } else {
            encoder.writeParentInfo(false); // write parent id
            encoder.writeLeftID(parentItem.id);
          }
        } else if (parent.constructor === String) { // this edge case was added by differential updates
          encoder.writeParentInfo(true); // write parentYKey
          encoder.writeString(parent);
        } else if (parent.constructor === ID) {
          encoder.writeParentInfo(false); // write parent id
          encoder.writeLeftID(parent);
        } else {
          unexpectedCase();
        }
        if (parentSub !== null) {
          encoder.writeString(parentSub);
        }
      }
      this.content.write(encoder, offset);
    }
  }

  /**
   * @param {UpdateDecoderV1 | UpdateDecoderV2} decoder
   * @param {number} info
   */
  const readItemContent = (decoder, info) => contentRefs[info & BITS5](decoder);

  /**
   * A lookup map for reading Item content.
   *
   * @type {Array<function(UpdateDecoderV1 | UpdateDecoderV2):AbstractContent>}
   */
  const contentRefs = [
    () => { unexpectedCase(); }, // GC is not ItemContent
    readContentDeleted, // 1
    readContentJSON, // 2
    readContentBinary, // 3
    readContentString, // 4
    readContentEmbed, // 5
    readContentFormat, // 6
    readContentType, // 7
    readContentAny, // 8
    readContentDoc, // 9
    () => { unexpectedCase(); } // 10 - Skip is not ItemContent
  ];

  const structSkipRefNumber = 10;

  /**
   * @private
   */
  class Skip extends AbstractStruct {
    get deleted () {
      return true
    }

    delete () {}

    /**
     * @param {Skip} right
     * @return {boolean}
     */
    mergeWith (right) {
      if (this.constructor !== right.constructor) {
        return false
      }
      this.length += right.length;
      return true
    }

    /**
     * @param {Transaction} transaction
     * @param {number} offset
     */
    integrate (transaction, offset) {
      // skip structs cannot be integrated
      unexpectedCase();
    }

    /**
     * @param {UpdateEncoderV1 | UpdateEncoderV2} encoder
     * @param {number} offset
     */
    write (encoder, offset) {
      encoder.writeInfo(structSkipRefNumber);
      // write as VarUint because Skips can't make use of predictable length-encoding
      writeVarUint(encoder.restEncoder, this.length - offset);
    }

    /**
     * @param {Transaction} transaction
     * @param {StructStore} store
     * @return {null | number}
     */
    getMissing (transaction, store) {
      return null
    }
  }

  /** eslint-env browser */


  const glo = /** @type {any} */ (typeof globalThis !== 'undefined'
    ? globalThis
    : typeof window !== 'undefined'
      ? window
      // @ts-ignore
      : typeof global !== 'undefined' ? global : {});

  const importIdentifier = '__ $YJS$ __';

  if (glo[importIdentifier] === true) {
    /**
     * Dear reader of this message. Please take this seriously.
     *
     * If you see this message, make sure that you only import one version of Yjs. In many cases,
     * your package manager installs two versions of Yjs that are used by different packages within your project.
     * Another reason for this message is that some parts of your project use the commonjs version of Yjs
     * and others use the EcmaScript version of Yjs.
     *
     * This often leads to issues that are hard to debug. We often need to perform constructor checks,
     * e.g. `struct instanceof GC`. If you imported different versions of Yjs, it is impossible for us to
     * do the constructor checks anymore - which might break the CRDT algorithm.
     *
     * https://github.com/yjs/yjs/issues/438
     */
    console.error('Yjs was already imported. This breaks constructor checks and will lead to issues! - https://github.com/yjs/yjs/issues/438');
  }
  glo[importIdentifier] = true;

  var supports$1 = function supports (...manifests) {
    const manifest = manifests.reduce((acc, m) => Object.assign(acc, m), {});

    return Object.assign(manifest, {
      snapshots: manifest.snapshots || false,
      permanence: manifest.permanence || false,
      seek: manifest.seek || false,
      clear: manifest.clear || false,
      getMany: manifest.getMany || false,
      keyIterator: manifest.keyIterator || false,
      valueIterator: manifest.valueIterator || false,
      iteratorNextv: manifest.iteratorNextv || false,
      iteratorAll: manifest.iteratorAll || false,
      status: manifest.status || false,
      createIfMissing: manifest.createIfMissing || false,
      errorIfExists: manifest.errorIfExists || false,
      deferredOpen: manifest.deferredOpen || false,
      promises: manifest.promises || false,
      streams: manifest.streams || false,
      encodings: Object.assign({}, manifest.encodings),
      events: Object.assign({}, manifest.events),
      additionalMethods: Object.assign({}, manifest.additionalMethods)
    })
  };

  var levelSupports = {
  	supports: supports$1
  };

  var moduleError = class ModuleError extends Error {
    /**
     * @param {string} message Error message
     * @param {{ code?: string, cause?: Error, expected?: boolean, transient?: boolean }} [options]
     */
    constructor (message, options) {
      super(message || '');

      if (typeof options === 'object' && options !== null) {
        if (options.code) this.code = String(options.code);
        if (options.expected) this.expected = true;
        if (options.transient) this.transient = true;
        if (options.cause) this.cause = options.cause;
      }

      if (Error.captureStackTrace) {
        Error.captureStackTrace(this, this.constructor);
      }
    }
  };

  /** @type {{ textEncoder: TextEncoder, textDecoder: TextDecoder }|null} */
  let lazy = null;

  /**
   * Get semi-global instances of TextEncoder and TextDecoder.
   * @returns {{ textEncoder: TextEncoder, textDecoder: TextDecoder }}
   */
  var textEndec = function () {
    if (lazy === null) {
      lazy = {
        textEncoder: new TextEncoder(),
        textDecoder: new TextDecoder()
      };
    }

    return lazy
  };

  const formats$2 = new Set(['buffer', 'view', 'utf8']);

  /**
   * @template TIn, TFormat, TOut
   * @abstract
   */
  class Encoding$2 {
    /**
     * @param {IEncoding<TIn,TFormat,TOut>} options
     */
    constructor (options) {
      /** @type {(data: TIn) => TFormat} */
      this.encode = options.encode || this.encode;

      /** @type {(data: TFormat) => TOut} */
      this.decode = options.decode || this.decode;

      /** @type {string} */
      this.name = options.name || this.name;

      /** @type {string} */
      this.format = options.format || this.format;

      if (typeof this.encode !== 'function') {
        throw new TypeError("The 'encode' property must be a function")
      }

      if (typeof this.decode !== 'function') {
        throw new TypeError("The 'decode' property must be a function")
      }

      this.encode = this.encode.bind(this);
      this.decode = this.decode.bind(this);

      if (typeof this.name !== 'string' || this.name === '') {
        throw new TypeError("The 'name' property must be a string")
      }

      if (typeof this.format !== 'string' || !formats$2.has(this.format)) {
        throw new TypeError("The 'format' property must be one of 'buffer', 'view', 'utf8'")
      }

      if (options.createViewTranscoder) {
        this.createViewTranscoder = options.createViewTranscoder;
      }

      if (options.createBufferTranscoder) {
        this.createBufferTranscoder = options.createBufferTranscoder;
      }

      if (options.createUTF8Transcoder) {
        this.createUTF8Transcoder = options.createUTF8Transcoder;
      }
    }

    get commonName () {
      return /** @type {string} */ (this.name.split('+')[0])
    }

    /** @return {BufferFormat<TIn,TOut>} */
    createBufferTranscoder () {
      throw new moduleError(`Encoding '${this.name}' cannot be transcoded to 'buffer'`, {
        code: 'LEVEL_ENCODING_NOT_SUPPORTED'
      })
    }

    /** @return {ViewFormat<TIn,TOut>} */
    createViewTranscoder () {
      throw new moduleError(`Encoding '${this.name}' cannot be transcoded to 'view'`, {
        code: 'LEVEL_ENCODING_NOT_SUPPORTED'
      })
    }

    /** @return {UTF8Format<TIn,TOut>} */
    createUTF8Transcoder () {
      throw new moduleError(`Encoding '${this.name}' cannot be transcoded to 'utf8'`, {
        code: 'LEVEL_ENCODING_NOT_SUPPORTED'
      })
    }
  }

  var Encoding_1 = Encoding$2;

  /**
   * @typedef {import('./encoding').IEncoding<TIn,TFormat,TOut>} IEncoding
   * @template TIn, TFormat, TOut
   */

  /**
   * @typedef {import('./formats').BufferFormat<TIn,TOut>} BufferFormat
   * @template TIn, TOut
   */

  /**
   * @typedef {import('./formats').ViewFormat<TIn,TOut>} ViewFormat
   * @template TIn, TOut
   */

  /**
   * @typedef {import('./formats').UTF8Format<TIn,TOut>} UTF8Format
   * @template TIn, TOut
   */

  var encoding = {
  	Encoding: Encoding_1
  };

  const { Buffer: Buffer$7 } = buffer$1 || {};
  const { Encoding: Encoding$1 } = encoding;


  /**
   * @template TIn, TOut
   * @extends {Encoding<TIn,Buffer,TOut>}
   */
  class BufferFormat$2 extends Encoding$1 {
    /**
     * @param {Omit<IEncoding<TIn, Buffer, TOut>, 'format'>} options
     */
    constructor (options) {
      super({ ...options, format: 'buffer' });
    }

    /** @override */
    createViewTranscoder () {
      return new ViewFormat$2({
        encode: this.encode, // Buffer is a view (UInt8Array)
        decode: (data) => this.decode(
          Buffer$7.from(data.buffer, data.byteOffset, data.byteLength)
        ),
        name: `${this.name}+view`
      })
    }

    /** @override */
    createBufferTranscoder () {
      return this
    }
  }

  /**
   * @extends {Encoding<TIn,Uint8Array,TOut>}
   * @template TIn, TOut
   */
  class ViewFormat$2 extends Encoding$1 {
    /**
     * @param {Omit<IEncoding<TIn, Uint8Array, TOut>, 'format'>} options
     */
    constructor (options) {
      super({ ...options, format: 'view' });
    }

    /** @override */
    createBufferTranscoder () {
      return new BufferFormat$2({
        encode: (data) => {
          const view = this.encode(data);
          return Buffer$7.from(view.buffer, view.byteOffset, view.byteLength)
        },
        decode: this.decode, // Buffer is a view (UInt8Array)
        name: `${this.name}+buffer`
      })
    }

    /** @override */
    createViewTranscoder () {
      return this
    }
  }

  /**
   * @extends {Encoding<TIn,string,TOut>}
   * @template TIn, TOut
   */
  class UTF8Format$2 extends Encoding$1 {
    /**
     * @param {Omit<IEncoding<TIn, string, TOut>, 'format'>} options
     */
    constructor (options) {
      super({ ...options, format: 'utf8' });
    }

    /** @override */
    createBufferTranscoder () {
      return new BufferFormat$2({
        encode: (data) => Buffer$7.from(this.encode(data), 'utf8'),
        decode: (data) => this.decode(data.toString('utf8')),
        name: `${this.name}+buffer`
      })
    }

    /** @override */
    createViewTranscoder () {
      const { textEncoder, textDecoder } = textEndec();

      return new ViewFormat$2({
        encode: (data) => textEncoder.encode(this.encode(data)),
        decode: (data) => this.decode(textDecoder.decode(data)),
        name: `${this.name}+view`
      })
    }

    /** @override */
    createUTF8Transcoder () {
      return this
    }
  }

  var BufferFormat_1 = BufferFormat$2;
  var ViewFormat_1 = ViewFormat$2;
  var UTF8Format_1 = UTF8Format$2;

  /**
   * @typedef {import('./encoding').IEncoding<TIn,TFormat,TOut>} IEncoding
   * @template TIn, TFormat, TOut
   */

  var formats$1 = {
  	BufferFormat: BufferFormat_1,
  	ViewFormat: ViewFormat_1,
  	UTF8Format: UTF8Format_1
  };

  const { Buffer: Buffer$6 } = buffer$1 || { Buffer: { isBuffer: () => false } };
  const { textEncoder: textEncoder$2, textDecoder } = textEndec();
  const { BufferFormat: BufferFormat$1, ViewFormat: ViewFormat$1, UTF8Format: UTF8Format$1 } = formats$1;

  /** @type {<T>(v: T) => v} */
  const identity = (v) => v;

  /**
   * @type {typeof import('./encodings').utf8}
   */
  var utf8 = new UTF8Format$1({
    encode: function (data) {
      // On node 16.9.1 buffer.toString() is 5x faster than TextDecoder
      return Buffer$6.isBuffer(data)
        ? data.toString('utf8')
        : ArrayBuffer.isView(data)
          ? textDecoder.decode(data)
          : String(data)
    },
    decode: identity,
    name: 'utf8',
    createViewTranscoder () {
      return new ViewFormat$1({
        encode: function (data) {
          return ArrayBuffer.isView(data) ? data : textEncoder$2.encode(data)
        },
        decode: function (data) {
          return textDecoder.decode(data)
        },
        name: `${this.name}+view`
      })
    },
    createBufferTranscoder () {
      return new BufferFormat$1({
        encode: function (data) {
          return Buffer$6.isBuffer(data)
            ? data
            : ArrayBuffer.isView(data)
              ? Buffer$6.from(data.buffer, data.byteOffset, data.byteLength)
              : Buffer$6.from(String(data), 'utf8')
        },
        decode: function (data) {
          return data.toString('utf8')
        },
        name: `${this.name}+buffer`
      })
    }
  });

  /**
   * @type {typeof import('./encodings').json}
   */
  var json = new UTF8Format$1({
    encode: JSON.stringify,
    decode: JSON.parse,
    name: 'json'
  });

  /**
   * @type {typeof import('./encodings').buffer}
   */
  var buffer = new BufferFormat$1({
    encode: function (data) {
      return Buffer$6.isBuffer(data)
        ? data
        : ArrayBuffer.isView(data)
          ? Buffer$6.from(data.buffer, data.byteOffset, data.byteLength)
          : Buffer$6.from(String(data), 'utf8')
    },
    decode: identity,
    name: 'buffer',
    createViewTranscoder () {
      return new ViewFormat$1({
        encode: function (data) {
          return ArrayBuffer.isView(data) ? data : Buffer$6.from(String(data), 'utf8')
        },
        decode: function (data) {
          return Buffer$6.from(data.buffer, data.byteOffset, data.byteLength)
        },
        name: `${this.name}+view`
      })
    }
  });

  /**
   * @type {typeof import('./encodings').view}
   */
  var view = new ViewFormat$1({
    encode: function (data) {
      return ArrayBuffer.isView(data) ? data : textEncoder$2.encode(data)
    },
    decode: identity,
    name: 'view',
    createBufferTranscoder () {
      return new BufferFormat$1({
        encode: function (data) {
          return Buffer$6.isBuffer(data)
            ? data
            : ArrayBuffer.isView(data)
              ? Buffer$6.from(data.buffer, data.byteOffset, data.byteLength)
              : Buffer$6.from(String(data), 'utf8')
        },
        decode: identity,
        name: `${this.name}+buffer`
      })
    }
  });

  /**
   * @type {typeof import('./encodings').hex}
   */
  var hex = new BufferFormat$1({
    encode: function (data) {
      return Buffer$6.isBuffer(data) ? data : Buffer$6.from(String(data), 'hex')
    },
    decode: function (buffer) {
      return buffer.toString('hex')
    },
    name: 'hex'
  });

  /**
   * @type {typeof import('./encodings').base64}
   */
  var base64 = new BufferFormat$1({
    encode: function (data) {
      return Buffer$6.isBuffer(data) ? data : Buffer$6.from(String(data), 'base64')
    },
    decode: function (buffer) {
      return buffer.toString('base64')
    },
    name: 'base64'
  });

  var encodings = {
  	utf8: utf8,
  	json: json,
  	buffer: buffer,
  	view: view,
  	hex: hex,
  	base64: base64
  };

  const { Encoding } = encoding;
  const { BufferFormat, ViewFormat, UTF8Format } = formats$1;

  const kFormats = Symbol('formats');
  const kEncodings = Symbol('encodings');
  const validFormats = new Set(['buffer', 'view', 'utf8']);

  /** @template T */
  class Transcoder$1 {
    /**
     * @param {Array<'buffer'|'view'|'utf8'>} formats
     */
    constructor (formats) {
      if (!Array.isArray(formats)) {
        throw new TypeError("The first argument 'formats' must be an array")
      } else if (!formats.every(f => validFormats.has(f))) {
        // Note: we only only support aliases in key- and valueEncoding options (where we already did)
        throw new TypeError("Format must be one of 'buffer', 'view', 'utf8'")
      }

      /** @type {Map<string|MixedEncoding<any, any, any>, Encoding<any, any, any>>} */
      this[kEncodings] = new Map();
      this[kFormats] = new Set(formats);

      // Register encodings (done early in order to populate encodings())
      for (const k in encodings) {
        try {
          this.encoding(k);
        } catch (err) {
          /* istanbul ignore if: assertion */
          if (err.code !== 'LEVEL_ENCODING_NOT_SUPPORTED') throw err
        }
      }
    }

    /**
     * @returns {Array<Encoding<any,T,any>>}
     */
    encodings () {
      return Array.from(new Set(this[kEncodings].values()))
    }

    /**
     * @param {string|MixedEncoding<any, any, any>} encoding
     * @returns {Encoding<any, T, any>}
     */
    encoding (encoding) {
      let resolved = this[kEncodings].get(encoding);

      if (resolved === undefined) {
        if (typeof encoding === 'string' && encoding !== '') {
          resolved = lookup[encoding];

          if (!resolved) {
            throw new moduleError(`Encoding '${encoding}' is not found`, {
              code: 'LEVEL_ENCODING_NOT_FOUND'
            })
          }
        } else if (typeof encoding !== 'object' || encoding === null) {
          throw new TypeError("First argument 'encoding' must be a string or object")
        } else {
          resolved = from$1(encoding);
        }

        const { name, format } = resolved;

        if (!this[kFormats].has(format)) {
          if (this[kFormats].has('view')) {
            resolved = resolved.createViewTranscoder();
          } else if (this[kFormats].has('buffer')) {
            resolved = resolved.createBufferTranscoder();
          } else if (this[kFormats].has('utf8')) {
            resolved = resolved.createUTF8Transcoder();
          } else {
            throw new moduleError(`Encoding '${name}' cannot be transcoded`, {
              code: 'LEVEL_ENCODING_NOT_SUPPORTED'
            })
          }
        }

        for (const k of [encoding, name, resolved.name, resolved.commonName]) {
          this[kEncodings].set(k, resolved);
        }
      }

      return resolved
    }
  }

  var Transcoder_1 = Transcoder$1;

  /**
   * @param {MixedEncoding<any, any, any>} options
   * @returns {Encoding<any, any, any>}
   */
  function from$1 (options) {
    if (options instanceof Encoding) {
      return options
    }

    // Loosely typed for ecosystem compatibility
    const maybeType = 'type' in options && typeof options.type === 'string' ? options.type : undefined;
    const name = options.name || maybeType || `anonymous-${anonymousCount++}`;

    switch (detectFormat(options)) {
      case 'view': return new ViewFormat({ ...options, name })
      case 'utf8': return new UTF8Format({ ...options, name })
      case 'buffer': return new BufferFormat({ ...options, name })
      default: {
        throw new TypeError("Format must be one of 'buffer', 'view', 'utf8'")
      }
    }
  }

  /**
   * If format is not provided, fallback to detecting `level-codec`
   * or `multiformats` encodings, else assume a format of buffer.
   * @param {MixedEncoding<any, any, any>} options
   * @returns {string}
   */
  function detectFormat (options) {
    if ('format' in options && options.format !== undefined) {
      return options.format
    } else if ('buffer' in options && typeof options.buffer === 'boolean') {
      return options.buffer ? 'buffer' : 'utf8' // level-codec
    } else if ('code' in options && Number.isInteger(options.code)) {
      return 'view' // multiformats
    } else {
      return 'buffer'
    }
  }

  /**
   * @typedef {import('./lib/encoding').MixedEncoding<TIn,TFormat,TOut>} MixedEncoding
   * @template TIn, TFormat, TOut
   */

  /**
   * @type {Object.<string, Encoding<any, any, any>>}
   */
  const aliases = {
    binary: encodings.buffer,
    'utf-8': encodings.utf8
  };

  /**
   * @type {Object.<string, Encoding<any, any, any>>}
   */
  const lookup = {
    ...encodings,
    ...aliases
  };

  let anonymousCount = 0;

  var levelTranscoder = {
  	Transcoder: Transcoder_1
  };

  // Copyright Joyent, Inc. and other Node contributors.

  var R = typeof Reflect === 'object' ? Reflect : null;
  var ReflectApply = R && typeof R.apply === 'function'
    ? R.apply
    : function ReflectApply(target, receiver, args) {
      return Function.prototype.apply.call(target, receiver, args);
    };

  var ReflectOwnKeys;
  if (R && typeof R.ownKeys === 'function') {
    ReflectOwnKeys = R.ownKeys;
  } else if (Object.getOwnPropertySymbols) {
    ReflectOwnKeys = function ReflectOwnKeys(target) {
      return Object.getOwnPropertyNames(target)
        .concat(Object.getOwnPropertySymbols(target));
    };
  } else {
    ReflectOwnKeys = function ReflectOwnKeys(target) {
      return Object.getOwnPropertyNames(target);
    };
  }

  function ProcessEmitWarning(warning) {
    if (console && console.warn) console.warn(warning);
  }

  var NumberIsNaN$3 = Number.isNaN || function NumberIsNaN(value) {
    return value !== value;
  };

  function EventEmitter$1() {
    EventEmitter$1.init.call(this);
  }
  var events = EventEmitter$1;
  var once_1 = once$2;

  // Backwards-compat with node 0.10.x
  EventEmitter$1.EventEmitter = EventEmitter$1;

  EventEmitter$1.prototype._events = undefined;
  EventEmitter$1.prototype._eventsCount = 0;
  EventEmitter$1.prototype._maxListeners = undefined;

  // By default EventEmitters will print a warning if more than 10 listeners are
  // added to it. This is a useful default which helps finding memory leaks.
  var defaultMaxListeners = 10;

  function checkListener(listener) {
    if (typeof listener !== 'function') {
      throw new TypeError('The "listener" argument must be of type Function. Received type ' + typeof listener);
    }
  }

  Object.defineProperty(EventEmitter$1, 'defaultMaxListeners', {
    enumerable: true,
    get: function() {
      return defaultMaxListeners;
    },
    set: function(arg) {
      if (typeof arg !== 'number' || arg < 0 || NumberIsNaN$3(arg)) {
        throw new RangeError('The value of "defaultMaxListeners" is out of range. It must be a non-negative number. Received ' + arg + '.');
      }
      defaultMaxListeners = arg;
    }
  });

  EventEmitter$1.init = function() {

    if (this._events === undefined ||
        this._events === Object.getPrototypeOf(this)._events) {
      this._events = Object.create(null);
      this._eventsCount = 0;
    }

    this._maxListeners = this._maxListeners || undefined;
  };

  // Obviously not all Emitters should be limited to 10. This function allows
  // that to be increased. Set to zero for unlimited.
  EventEmitter$1.prototype.setMaxListeners = function setMaxListeners(n) {
    if (typeof n !== 'number' || n < 0 || NumberIsNaN$3(n)) {
      throw new RangeError('The value of "n" is out of range. It must be a non-negative number. Received ' + n + '.');
    }
    this._maxListeners = n;
    return this;
  };

  function _getMaxListeners(that) {
    if (that._maxListeners === undefined)
      return EventEmitter$1.defaultMaxListeners;
    return that._maxListeners;
  }

  EventEmitter$1.prototype.getMaxListeners = function getMaxListeners() {
    return _getMaxListeners(this);
  };

  EventEmitter$1.prototype.emit = function emit(type) {
    var args = [];
    for (var i = 1; i < arguments.length; i++) args.push(arguments[i]);
    var doError = (type === 'error');

    var events = this._events;
    if (events !== undefined)
      doError = (doError && events.error === undefined);
    else if (!doError)
      return false;

    // If there is no 'error' event listener then throw.
    if (doError) {
      var er;
      if (args.length > 0)
        er = args[0];
      if (er instanceof Error) {
        // Note: The comments on the `throw` lines are intentional, they show
        // up in Node's output if this results in an unhandled exception.
        throw er; // Unhandled 'error' event
      }
      // At least give some kind of context to the user
      var err = new Error('Unhandled error.' + (er ? ' (' + er.message + ')' : ''));
      err.context = er;
      throw err; // Unhandled 'error' event
    }

    var handler = events[type];

    if (handler === undefined)
      return false;

    if (typeof handler === 'function') {
      ReflectApply(handler, this, args);
    } else {
      var len = handler.length;
      var listeners = arrayClone(handler, len);
      for (var i = 0; i < len; ++i)
        ReflectApply(listeners[i], this, args);
    }

    return true;
  };

  function _addListener(target, type, listener, prepend) {
    var m;
    var events;
    var existing;

    checkListener(listener);

    events = target._events;
    if (events === undefined) {
      events = target._events = Object.create(null);
      target._eventsCount = 0;
    } else {
      // To avoid recursion in the case that type === "newListener"! Before
      // adding it to the listeners, first emit "newListener".
      if (events.newListener !== undefined) {
        target.emit('newListener', type,
                    listener.listener ? listener.listener : listener);

        // Re-assign `events` because a newListener handler could have caused the
        // this._events to be assigned to a new object
        events = target._events;
      }
      existing = events[type];
    }

    if (existing === undefined) {
      // Optimize the case of one listener. Don't need the extra array object.
      existing = events[type] = listener;
      ++target._eventsCount;
    } else {
      if (typeof existing === 'function') {
        // Adding the second element, need to change to array.
        existing = events[type] =
          prepend ? [listener, existing] : [existing, listener];
        // If we've already got an array, just append.
      } else if (prepend) {
        existing.unshift(listener);
      } else {
        existing.push(listener);
      }

      // Check for listener leak
      m = _getMaxListeners(target);
      if (m > 0 && existing.length > m && !existing.warned) {
        existing.warned = true;
        // No error code for this since it is a Warning
        // eslint-disable-next-line no-restricted-syntax
        var w = new Error('Possible EventEmitter memory leak detected. ' +
                            existing.length + ' ' + String(type) + ' listeners ' +
                            'added. Use emitter.setMaxListeners() to ' +
                            'increase limit');
        w.name = 'MaxListenersExceededWarning';
        w.emitter = target;
        w.type = type;
        w.count = existing.length;
        ProcessEmitWarning(w);
      }
    }

    return target;
  }

  EventEmitter$1.prototype.addListener = function addListener(type, listener) {
    return _addListener(this, type, listener, false);
  };

  EventEmitter$1.prototype.on = EventEmitter$1.prototype.addListener;

  EventEmitter$1.prototype.prependListener =
      function prependListener(type, listener) {
        return _addListener(this, type, listener, true);
      };

  function onceWrapper() {
    if (!this.fired) {
      this.target.removeListener(this.type, this.wrapFn);
      this.fired = true;
      if (arguments.length === 0)
        return this.listener.call(this.target);
      return this.listener.apply(this.target, arguments);
    }
  }

  function _onceWrap(target, type, listener) {
    var state = { fired: false, wrapFn: undefined, target: target, type: type, listener: listener };
    var wrapped = onceWrapper.bind(state);
    wrapped.listener = listener;
    state.wrapFn = wrapped;
    return wrapped;
  }

  EventEmitter$1.prototype.once = function once(type, listener) {
    checkListener(listener);
    this.on(type, _onceWrap(this, type, listener));
    return this;
  };

  EventEmitter$1.prototype.prependOnceListener =
      function prependOnceListener(type, listener) {
        checkListener(listener);
        this.prependListener(type, _onceWrap(this, type, listener));
        return this;
      };

  // Emits a 'removeListener' event if and only if the listener was removed.
  EventEmitter$1.prototype.removeListener =
      function removeListener(type, listener) {
        var list, events, position, i, originalListener;

        checkListener(listener);

        events = this._events;
        if (events === undefined)
          return this;

        list = events[type];
        if (list === undefined)
          return this;

        if (list === listener || list.listener === listener) {
          if (--this._eventsCount === 0)
            this._events = Object.create(null);
          else {
            delete events[type];
            if (events.removeListener)
              this.emit('removeListener', type, list.listener || listener);
          }
        } else if (typeof list !== 'function') {
          position = -1;

          for (i = list.length - 1; i >= 0; i--) {
            if (list[i] === listener || list[i].listener === listener) {
              originalListener = list[i].listener;
              position = i;
              break;
            }
          }

          if (position < 0)
            return this;

          if (position === 0)
            list.shift();
          else {
            spliceOne(list, position);
          }

          if (list.length === 1)
            events[type] = list[0];

          if (events.removeListener !== undefined)
            this.emit('removeListener', type, originalListener || listener);
        }

        return this;
      };

  EventEmitter$1.prototype.off = EventEmitter$1.prototype.removeListener;

  EventEmitter$1.prototype.removeAllListeners =
      function removeAllListeners(type) {
        var listeners, events, i;

        events = this._events;
        if (events === undefined)
          return this;

        // not listening for removeListener, no need to emit
        if (events.removeListener === undefined) {
          if (arguments.length === 0) {
            this._events = Object.create(null);
            this._eventsCount = 0;
          } else if (events[type] !== undefined) {
            if (--this._eventsCount === 0)
              this._events = Object.create(null);
            else
              delete events[type];
          }
          return this;
        }

        // emit removeListener for all listeners on all events
        if (arguments.length === 0) {
          var keys = Object.keys(events);
          var key;
          for (i = 0; i < keys.length; ++i) {
            key = keys[i];
            if (key === 'removeListener') continue;
            this.removeAllListeners(key);
          }
          this.removeAllListeners('removeListener');
          this._events = Object.create(null);
          this._eventsCount = 0;
          return this;
        }

        listeners = events[type];

        if (typeof listeners === 'function') {
          this.removeListener(type, listeners);
        } else if (listeners !== undefined) {
          // LIFO order
          for (i = listeners.length - 1; i >= 0; i--) {
            this.removeListener(type, listeners[i]);
          }
        }

        return this;
      };

  function _listeners(target, type, unwrap) {
    var events = target._events;

    if (events === undefined)
      return [];

    var evlistener = events[type];
    if (evlistener === undefined)
      return [];

    if (typeof evlistener === 'function')
      return unwrap ? [evlistener.listener || evlistener] : [evlistener];

    return unwrap ?
      unwrapListeners(evlistener) : arrayClone(evlistener, evlistener.length);
  }

  EventEmitter$1.prototype.listeners = function listeners(type) {
    return _listeners(this, type, true);
  };

  EventEmitter$1.prototype.rawListeners = function rawListeners(type) {
    return _listeners(this, type, false);
  };

  EventEmitter$1.listenerCount = function(emitter, type) {
    if (typeof emitter.listenerCount === 'function') {
      return emitter.listenerCount(type);
    } else {
      return listenerCount.call(emitter, type);
    }
  };

  EventEmitter$1.prototype.listenerCount = listenerCount;
  function listenerCount(type) {
    var events = this._events;

    if (events !== undefined) {
      var evlistener = events[type];

      if (typeof evlistener === 'function') {
        return 1;
      } else if (evlistener !== undefined) {
        return evlistener.length;
      }
    }

    return 0;
  }

  EventEmitter$1.prototype.eventNames = function eventNames() {
    return this._eventsCount > 0 ? ReflectOwnKeys(this._events) : [];
  };

  function arrayClone(arr, n) {
    var copy = new Array(n);
    for (var i = 0; i < n; ++i)
      copy[i] = arr[i];
    return copy;
  }

  function spliceOne(list, index) {
    for (; index + 1 < list.length; index++)
      list[index] = list[index + 1];
    list.pop();
  }

  function unwrapListeners(arr) {
    var ret = new Array(arr.length);
    for (var i = 0; i < ret.length; ++i) {
      ret[i] = arr[i].listener || arr[i];
    }
    return ret;
  }

  function once$2(emitter, name) {
    return new Promise(function (resolve, reject) {
      function errorListener(err) {
        emitter.removeListener(name, resolver);
        reject(err);
      }

      function resolver() {
        if (typeof emitter.removeListener === 'function') {
          emitter.removeListener('error', errorListener);
        }
        resolve([].slice.call(arguments));
      }
      eventTargetAgnosticAddListener(emitter, name, resolver, { once: true });
      if (name !== 'error') {
        addErrorHandlerIfEventEmitter(emitter, errorListener, { once: true });
      }
    });
  }

  function addErrorHandlerIfEventEmitter(emitter, handler, flags) {
    if (typeof emitter.on === 'function') {
      eventTargetAgnosticAddListener(emitter, 'error', handler, flags);
    }
  }

  function eventTargetAgnosticAddListener(emitter, name, listener, flags) {
    if (typeof emitter.on === 'function') {
      if (flags.once) {
        emitter.once(name, listener);
      } else {
        emitter.on(name, listener);
      }
    } else if (typeof emitter.addEventListener === 'function') {
      // EventTarget does not have `error` event semantics like Node
      // EventEmitters, we do not listen for `error` events here.
      emitter.addEventListener(name, function wrapListener(arg) {
        // IE does not have builtin `{ once: true }` support so we
        // have to do it manually.
        if (flags.once) {
          emitter.removeEventListener(name, wrapListener);
        }
        listener(arg);
      });
    } else {
      throw new TypeError('The "emitter" argument must be of type EventEmitter. Received type ' + typeof emitter);
    }
  }
  events.once = once_1;

  var nextTickBrowser$1 = typeof queueMicrotask === 'function' ? queueMicrotask : (fn) => Promise.resolve().then(fn);

  var fromCallback$4 = function (callback, symbol) {
    if (callback === undefined) {
      var promise = new Promise(function (resolve, reject) {
        callback = function (err, res) {
          if (err) reject(err);
          else resolve(res);
        };
      });

      callback[symbol !== undefined ? symbol : 'promise'] = promise;
    } else if (typeof callback !== 'function') {
      throw new TypeError('Callback must be a function')
    }

    return callback
  };

  var fromPromise = function (promise, callback) {
    if (callback === undefined) return promise

    promise
      .then(function (res) { nextTickBrowser$1(() => callback(null, res)); })
      .catch(function (err) { nextTickBrowser$1(() => callback(err)); });
  };

  var catering = {
  	fromCallback: fromCallback$4,
  	fromPromise: fromPromise
  };

  var getCallback$3 = function (options, callback) {
    return typeof options === 'function' ? options : callback
  };

  var getOptions$3 = function (options, def) {
    if (typeof options === 'object' && options !== null) {
      return options
    }

    if (def !== undefined) {
      return def
    }

    return {}
  };

  var common = {
  	getCallback: getCallback$3,
  	getOptions: getOptions$3
  };

  const { fromCallback: fromCallback$3 } = catering;

  const { getOptions: getOptions$2, getCallback: getCallback$2 } = common;

  const kPromise$3 = Symbol('promise');
  const kCallback$3 = Symbol('callback');
  const kWorking = Symbol('working');
  const kHandleOne$2 = Symbol('handleOne');
  const kHandleMany$2 = Symbol('handleMany');
  const kAutoClose = Symbol('autoClose');
  const kFinishWork = Symbol('finishWork');
  const kReturnMany = Symbol('returnMany');
  const kClosing = Symbol('closing');
  const kHandleClose = Symbol('handleClose');
  const kClosed$1 = Symbol('closed');
  const kCloseCallbacks$1 = Symbol('closeCallbacks');
  const kKeyEncoding$1 = Symbol('keyEncoding');
  const kValueEncoding$1 = Symbol('valueEncoding');
  const kAbortOnClose = Symbol('abortOnClose');
  const kLegacy = Symbol('legacy');
  const kKeys = Symbol('keys');
  const kValues = Symbol('values');
  const kLimit = Symbol('limit');
  const kCount = Symbol('count');

  const emptyOptions$1 = Object.freeze({});
  const noop$1 = () => {};
  let warnedEnd = false;

  // This class is an internal utility for common functionality between AbstractIterator,
  // AbstractKeyIterator and AbstractValueIterator. It's not exported.
  class CommonIterator {
    constructor (db, options, legacy) {
      if (typeof db !== 'object' || db === null) {
        const hint = db === null ? 'null' : typeof db;
        throw new TypeError(`The first argument must be an abstract-level database, received ${hint}`)
      }

      if (typeof options !== 'object' || options === null) {
        throw new TypeError('The second argument must be an options object')
      }

      this[kClosed$1] = false;
      this[kCloseCallbacks$1] = [];
      this[kWorking] = false;
      this[kClosing] = false;
      this[kAutoClose] = false;
      this[kCallback$3] = null;
      this[kHandleOne$2] = this[kHandleOne$2].bind(this);
      this[kHandleMany$2] = this[kHandleMany$2].bind(this);
      this[kHandleClose] = this[kHandleClose].bind(this);
      this[kKeyEncoding$1] = options[kKeyEncoding$1];
      this[kValueEncoding$1] = options[kValueEncoding$1];
      this[kLegacy] = legacy;
      this[kLimit] = Number.isInteger(options.limit) && options.limit >= 0 ? options.limit : Infinity;
      this[kCount] = 0;

      // Undocumented option to abort pending work on close(). Used by the
      // many-level module as a temporary solution to a blocked close().
      // TODO (next major): consider making this the default behavior. Native
      // implementations should have their own logic to safely close iterators.
      this[kAbortOnClose] = !!options.abortOnClose;

      this.db = db;
      this.db.attachResource(this);
      this.nextTick = db.nextTick;
    }

    get count () {
      return this[kCount]
    }

    get limit () {
      return this[kLimit]
    }

    next (callback) {
      let promise;

      if (callback === undefined) {
        promise = new Promise((resolve, reject) => {
          callback = (err, key, value) => {
            if (err) reject(err);
            else if (!this[kLegacy]) resolve(key);
            else if (key === undefined && value === undefined) resolve();
            else resolve([key, value]);
          };
        });
      } else if (typeof callback !== 'function') {
        throw new TypeError('Callback must be a function')
      }

      if (this[kClosing]) {
        this.nextTick(callback, new moduleError('Iterator is not open: cannot call next() after close()', {
          code: 'LEVEL_ITERATOR_NOT_OPEN'
        }));
      } else if (this[kWorking]) {
        this.nextTick(callback, new moduleError('Iterator is busy: cannot call next() until previous call has completed', {
          code: 'LEVEL_ITERATOR_BUSY'
        }));
      } else {
        this[kWorking] = true;
        this[kCallback$3] = callback;

        if (this[kCount] >= this[kLimit]) this.nextTick(this[kHandleOne$2], null);
        else this._next(this[kHandleOne$2]);
      }

      return promise
    }

    _next (callback) {
      this.nextTick(callback);
    }

    nextv (size, options, callback) {
      callback = getCallback$2(options, callback);
      callback = fromCallback$3(callback, kPromise$3);
      options = getOptions$2(options, emptyOptions$1);

      if (!Number.isInteger(size)) {
        this.nextTick(callback, new TypeError("The first argument 'size' must be an integer"));
        return callback[kPromise$3]
      }

      if (this[kClosing]) {
        this.nextTick(callback, new moduleError('Iterator is not open: cannot call nextv() after close()', {
          code: 'LEVEL_ITERATOR_NOT_OPEN'
        }));
      } else if (this[kWorking]) {
        this.nextTick(callback, new moduleError('Iterator is busy: cannot call nextv() until previous call has completed', {
          code: 'LEVEL_ITERATOR_BUSY'
        }));
      } else {
        if (size < 1) size = 1;
        if (this[kLimit] < Infinity) size = Math.min(size, this[kLimit] - this[kCount]);

        this[kWorking] = true;
        this[kCallback$3] = callback;

        if (size <= 0) this.nextTick(this[kHandleMany$2], null, []);
        else this._nextv(size, options, this[kHandleMany$2]);
      }

      return callback[kPromise$3]
    }

    _nextv (size, options, callback) {
      const acc = [];
      const onnext = (err, key, value) => {
        if (err) {
          return callback(err)
        } else if (this[kLegacy] ? key === undefined && value === undefined : key === undefined) {
          return callback(null, acc)
        }

        acc.push(this[kLegacy] ? [key, value] : key);

        if (acc.length === size) {
          callback(null, acc);
        } else {
          this._next(onnext);
        }
      };

      this._next(onnext);
    }

    all (options, callback) {
      callback = getCallback$2(options, callback);
      callback = fromCallback$3(callback, kPromise$3);
      options = getOptions$2(options, emptyOptions$1);

      if (this[kClosing]) {
        this.nextTick(callback, new moduleError('Iterator is not open: cannot call all() after close()', {
          code: 'LEVEL_ITERATOR_NOT_OPEN'
        }));
      } else if (this[kWorking]) {
        this.nextTick(callback, new moduleError('Iterator is busy: cannot call all() until previous call has completed', {
          code: 'LEVEL_ITERATOR_BUSY'
        }));
      } else {
        this[kWorking] = true;
        this[kCallback$3] = callback;
        this[kAutoClose] = true;

        if (this[kCount] >= this[kLimit]) this.nextTick(this[kHandleMany$2], null, []);
        else this._all(options, this[kHandleMany$2]);
      }

      return callback[kPromise$3]
    }

    _all (options, callback) {
      // Must count here because we're directly calling _nextv()
      let count = this[kCount];
      const acc = [];

      const nextv = () => {
        // Not configurable, because implementations should optimize _all().
        const size = this[kLimit] < Infinity ? Math.min(1e3, this[kLimit] - count) : 1e3;

        if (size <= 0) {
          this.nextTick(callback, null, acc);
        } else {
          this._nextv(size, emptyOptions$1, onnextv);
        }
      };

      const onnextv = (err, items) => {
        if (err) {
          callback(err);
        } else if (items.length === 0) {
          callback(null, acc);
        } else {
          acc.push.apply(acc, items);
          count += items.length;
          nextv();
        }
      };

      nextv();
    }

    [kFinishWork] () {
      const cb = this[kCallback$3];

      // Callback will be null if work was aborted on close
      if (this[kAbortOnClose] && cb === null) return noop$1

      this[kWorking] = false;
      this[kCallback$3] = null;

      if (this[kClosing]) this._close(this[kHandleClose]);

      return cb
    }

    [kReturnMany] (cb, err, items) {
      if (this[kAutoClose]) {
        this.close(cb.bind(null, err, items));
      } else {
        cb(err, items);
      }
    }

    seek (target, options) {
      options = getOptions$2(options, emptyOptions$1);

      if (this[kClosing]) ; else if (this[kWorking]) {
        throw new moduleError('Iterator is busy: cannot call seek() until next() has completed', {
          code: 'LEVEL_ITERATOR_BUSY'
        })
      } else {
        const keyEncoding = this.db.keyEncoding(options.keyEncoding || this[kKeyEncoding$1]);
        const keyFormat = keyEncoding.format;

        if (options.keyEncoding !== keyFormat) {
          options = { ...options, keyEncoding: keyFormat };
        }

        const mapped = this.db.prefixKey(keyEncoding.encode(target), keyFormat);
        this._seek(mapped, options);
      }
    }

    _seek (target, options) {
      throw new moduleError('Iterator does not support seek()', {
        code: 'LEVEL_NOT_SUPPORTED'
      })
    }

    close (callback) {
      callback = fromCallback$3(callback, kPromise$3);

      if (this[kClosed$1]) {
        this.nextTick(callback);
      } else if (this[kClosing]) {
        this[kCloseCallbacks$1].push(callback);
      } else {
        this[kClosing] = true;
        this[kCloseCallbacks$1].push(callback);

        if (!this[kWorking]) {
          this._close(this[kHandleClose]);
        } else if (this[kAbortOnClose]) {
          // Don't wait for work to finish. Subsequently ignore the result.
          const cb = this[kFinishWork]();

          cb(new moduleError('Aborted on iterator close()', {
            code: 'LEVEL_ITERATOR_NOT_OPEN'
          }));
        }
      }

      return callback[kPromise$3]
    }

    _close (callback) {
      this.nextTick(callback);
    }

    [kHandleClose] () {
      this[kClosed$1] = true;
      this.db.detachResource(this);

      const callbacks = this[kCloseCallbacks$1];
      this[kCloseCallbacks$1] = [];

      for (const cb of callbacks) {
        cb();
      }
    }

    async * [Symbol.asyncIterator] () {
      try {
        let item;

        while ((item = (await this.next())) !== undefined) {
          yield item;
        }
      } finally {
        if (!this[kClosed$1]) await this.close();
      }
    }
  }

  // For backwards compatibility this class is not (yet) called AbstractEntryIterator.
  class AbstractIterator$5 extends CommonIterator {
    constructor (db, options) {
      super(db, options, true);
      this[kKeys] = options.keys !== false;
      this[kValues] = options.values !== false;
    }

    [kHandleOne$2] (err, key, value) {
      const cb = this[kFinishWork]();
      if (err) return cb(err)

      try {
        key = this[kKeys] && key !== undefined ? this[kKeyEncoding$1].decode(key) : undefined;
        value = this[kValues] && value !== undefined ? this[kValueEncoding$1].decode(value) : undefined;
      } catch (err) {
        return cb(new IteratorDecodeError('entry', err))
      }

      if (!(key === undefined && value === undefined)) {
        this[kCount]++;
      }

      cb(null, key, value);
    }

    [kHandleMany$2] (err, entries) {
      const cb = this[kFinishWork]();
      if (err) return this[kReturnMany](cb, err)

      try {
        for (const entry of entries) {
          const key = entry[0];
          const value = entry[1];

          entry[0] = this[kKeys] && key !== undefined ? this[kKeyEncoding$1].decode(key) : undefined;
          entry[1] = this[kValues] && value !== undefined ? this[kValueEncoding$1].decode(value) : undefined;
        }
      } catch (err) {
        return this[kReturnMany](cb, new IteratorDecodeError('entries', err))
      }

      this[kCount] += entries.length;
      this[kReturnMany](cb, null, entries);
    }

    end (callback) {
      if (!warnedEnd && typeof console !== 'undefined') {
        warnedEnd = true;
        console.warn(new moduleError(
          'The iterator.end() method was renamed to close() and end() is an alias that will be removed in a future version',
          { code: 'LEVEL_LEGACY' }
        ));
      }

      return this.close(callback)
    }
  }

  class AbstractKeyIterator$4 extends CommonIterator {
    constructor (db, options) {
      super(db, options, false);
    }

    [kHandleOne$2] (err, key) {
      const cb = this[kFinishWork]();
      if (err) return cb(err)

      try {
        key = key !== undefined ? this[kKeyEncoding$1].decode(key) : undefined;
      } catch (err) {
        return cb(new IteratorDecodeError('key', err))
      }

      if (key !== undefined) this[kCount]++;
      cb(null, key);
    }

    [kHandleMany$2] (err, keys) {
      const cb = this[kFinishWork]();
      if (err) return this[kReturnMany](cb, err)

      try {
        for (let i = 0; i < keys.length; i++) {
          const key = keys[i];
          keys[i] = key !== undefined ? this[kKeyEncoding$1].decode(key) : undefined;
        }
      } catch (err) {
        return this[kReturnMany](cb, new IteratorDecodeError('keys', err))
      }

      this[kCount] += keys.length;
      this[kReturnMany](cb, null, keys);
    }
  }

  class AbstractValueIterator$4 extends CommonIterator {
    constructor (db, options) {
      super(db, options, false);
    }

    [kHandleOne$2] (err, value) {
      const cb = this[kFinishWork]();
      if (err) return cb(err)

      try {
        value = value !== undefined ? this[kValueEncoding$1].decode(value) : undefined;
      } catch (err) {
        return cb(new IteratorDecodeError('value', err))
      }

      if (value !== undefined) this[kCount]++;
      cb(null, value);
    }

    [kHandleMany$2] (err, values) {
      const cb = this[kFinishWork]();
      if (err) return this[kReturnMany](cb, err)

      try {
        for (let i = 0; i < values.length; i++) {
          const value = values[i];
          values[i] = value !== undefined ? this[kValueEncoding$1].decode(value) : undefined;
        }
      } catch (err) {
        return this[kReturnMany](cb, new IteratorDecodeError('values', err))
      }

      this[kCount] += values.length;
      this[kReturnMany](cb, null, values);
    }
  }

  // Internal utility, not typed or exported
  class IteratorDecodeError extends moduleError {
    constructor (subject, cause) {
      super(`Iterator could not decode ${subject}`, {
        code: 'LEVEL_DECODE_ERROR',
        cause
      });
    }
  }

  // To help migrating to abstract-level
  for (const k of ['_ended property', '_nexting property', '_end method']) {
    Object.defineProperty(AbstractIterator$5.prototype, k.split(' ')[0], {
      get () { throw new moduleError(`The ${k} has been removed`, { code: 'LEVEL_LEGACY' }) },
      set () { throw new moduleError(`The ${k} has been removed`, { code: 'LEVEL_LEGACY' }) }
    });
  }

  // Exposed so that AbstractLevel can set these options
  AbstractIterator$5.keyEncoding = kKeyEncoding$1;
  AbstractIterator$5.valueEncoding = kValueEncoding$1;

  var AbstractIterator_1 = AbstractIterator$5;
  var AbstractKeyIterator_1 = AbstractKeyIterator$4;
  var AbstractValueIterator_1 = AbstractValueIterator$4;

  var abstractIterator = {
  	AbstractIterator: AbstractIterator_1,
  	AbstractKeyIterator: AbstractKeyIterator_1,
  	AbstractValueIterator: AbstractValueIterator_1
  };

  const { AbstractKeyIterator: AbstractKeyIterator$3, AbstractValueIterator: AbstractValueIterator$3 } = abstractIterator;

  const kIterator$2 = Symbol('iterator');
  const kCallback$2 = Symbol('callback');
  const kHandleOne$1 = Symbol('handleOne');
  const kHandleMany$1 = Symbol('handleMany');

  class DefaultKeyIterator$1 extends AbstractKeyIterator$3 {
    constructor (db, options) {
      super(db, options);

      this[kIterator$2] = db.iterator({ ...options, keys: true, values: false });
      this[kHandleOne$1] = this[kHandleOne$1].bind(this);
      this[kHandleMany$1] = this[kHandleMany$1].bind(this);
    }
  }

  class DefaultValueIterator$1 extends AbstractValueIterator$3 {
    constructor (db, options) {
      super(db, options);

      this[kIterator$2] = db.iterator({ ...options, keys: false, values: true });
      this[kHandleOne$1] = this[kHandleOne$1].bind(this);
      this[kHandleMany$1] = this[kHandleMany$1].bind(this);
    }
  }

  for (const Iterator of [DefaultKeyIterator$1, DefaultValueIterator$1]) {
    const keys = Iterator === DefaultKeyIterator$1;
    const mapEntry = keys ? (entry) => entry[0] : (entry) => entry[1];

    Iterator.prototype._next = function (callback) {
      this[kCallback$2] = callback;
      this[kIterator$2].next(this[kHandleOne$1]);
    };

    Iterator.prototype[kHandleOne$1] = function (err, key, value) {
      const callback = this[kCallback$2];
      if (err) callback(err);
      else callback(null, keys ? key : value);
    };

    Iterator.prototype._nextv = function (size, options, callback) {
      this[kCallback$2] = callback;
      this[kIterator$2].nextv(size, options, this[kHandleMany$1]);
    };

    Iterator.prototype._all = function (options, callback) {
      this[kCallback$2] = callback;
      this[kIterator$2].all(options, this[kHandleMany$1]);
    };

    Iterator.prototype[kHandleMany$1] = function (err, entries) {
      const callback = this[kCallback$2];
      if (err) callback(err);
      else callback(null, entries.map(mapEntry));
    };

    Iterator.prototype._seek = function (target, options) {
      this[kIterator$2].seek(target, options);
    };

    Iterator.prototype._close = function (callback) {
      this[kIterator$2].close(callback);
    };
  }

  // Internal utilities, should be typed as AbstractKeyIterator and AbstractValueIterator
  var DefaultKeyIterator_1 = DefaultKeyIterator$1;
  var DefaultValueIterator_1 = DefaultValueIterator$1;

  var defaultKvIterator = {
  	DefaultKeyIterator: DefaultKeyIterator_1,
  	DefaultValueIterator: DefaultValueIterator_1
  };

  const { AbstractIterator: AbstractIterator$4, AbstractKeyIterator: AbstractKeyIterator$2, AbstractValueIterator: AbstractValueIterator$2 } = abstractIterator;


  const kNut = Symbol('nut');
  const kUndefer$1 = Symbol('undefer');
  const kFactory = Symbol('factory');

  class DeferredIterator$1 extends AbstractIterator$4 {
    constructor (db, options) {
      super(db, options);

      this[kNut] = null;
      this[kFactory] = () => db.iterator(options);

      this.db.defer(() => this[kUndefer$1]());
    }
  }

  class DeferredKeyIterator$1 extends AbstractKeyIterator$2 {
    constructor (db, options) {
      super(db, options);

      this[kNut] = null;
      this[kFactory] = () => db.keys(options);

      this.db.defer(() => this[kUndefer$1]());
    }
  }

  class DeferredValueIterator$1 extends AbstractValueIterator$2 {
    constructor (db, options) {
      super(db, options);

      this[kNut] = null;
      this[kFactory] = () => db.values(options);

      this.db.defer(() => this[kUndefer$1]());
    }
  }

  for (const Iterator of [DeferredIterator$1, DeferredKeyIterator$1, DeferredValueIterator$1]) {
    Iterator.prototype[kUndefer$1] = function () {
      if (this.db.status === 'open') {
        this[kNut] = this[kFactory]();
      }
    };

    Iterator.prototype._next = function (callback) {
      if (this[kNut] !== null) {
        this[kNut].next(callback);
      } else if (this.db.status === 'opening') {
        this.db.defer(() => this._next(callback));
      } else {
        this.nextTick(callback, new moduleError('Iterator is not open: cannot call next() after close()', {
          code: 'LEVEL_ITERATOR_NOT_OPEN'
        }));
      }
    };

    Iterator.prototype._nextv = function (size, options, callback) {
      if (this[kNut] !== null) {
        this[kNut].nextv(size, options, callback);
      } else if (this.db.status === 'opening') {
        this.db.defer(() => this._nextv(size, options, callback));
      } else {
        this.nextTick(callback, new moduleError('Iterator is not open: cannot call nextv() after close()', {
          code: 'LEVEL_ITERATOR_NOT_OPEN'
        }));
      }
    };

    Iterator.prototype._all = function (options, callback) {
      if (this[kNut] !== null) {
        this[kNut].all(callback);
      } else if (this.db.status === 'opening') {
        this.db.defer(() => this._all(options, callback));
      } else {
        this.nextTick(callback, new moduleError('Iterator is not open: cannot call all() after close()', {
          code: 'LEVEL_ITERATOR_NOT_OPEN'
        }));
      }
    };

    Iterator.prototype._seek = function (target, options) {
      if (this[kNut] !== null) {
        // TODO: explain why we need _seek() rather than seek() here
        this[kNut]._seek(target, options);
      } else if (this.db.status === 'opening') {
        this.db.defer(() => this._seek(target, options));
      }
    };

    Iterator.prototype._close = function (callback) {
      if (this[kNut] !== null) {
        this[kNut].close(callback);
      } else if (this.db.status === 'opening') {
        this.db.defer(() => this._close(callback));
      } else {
        this.nextTick(callback);
      }
    };
  }

  var DeferredIterator_1 = DeferredIterator$1;
  var DeferredKeyIterator_1 = DeferredKeyIterator$1;
  var DeferredValueIterator_1 = DeferredValueIterator$1;

  var deferredIterator = {
  	DeferredIterator: DeferredIterator_1,
  	DeferredKeyIterator: DeferredKeyIterator_1,
  	DeferredValueIterator: DeferredValueIterator_1
  };

  const { fromCallback: fromCallback$2 } = catering;

  const { getCallback: getCallback$1, getOptions: getOptions$1 } = common;

  const kPromise$2 = Symbol('promise');
  const kStatus$1 = Symbol('status');
  const kOperations$1 = Symbol('operations');
  const kFinishClose = Symbol('finishClose');
  const kCloseCallbacks = Symbol('closeCallbacks');

  class AbstractChainedBatch$2 {
    constructor (db) {
      if (typeof db !== 'object' || db === null) {
        const hint = db === null ? 'null' : typeof db;
        throw new TypeError(`The first argument must be an abstract-level database, received ${hint}`)
      }

      this[kOperations$1] = [];
      this[kCloseCallbacks] = [];
      this[kStatus$1] = 'open';
      this[kFinishClose] = this[kFinishClose].bind(this);

      this.db = db;
      this.db.attachResource(this);
      this.nextTick = db.nextTick;
    }

    get length () {
      return this[kOperations$1].length
    }

    put (key, value, options) {
      if (this[kStatus$1] !== 'open') {
        throw new moduleError('Batch is not open: cannot call put() after write() or close()', {
          code: 'LEVEL_BATCH_NOT_OPEN'
        })
      }

      const err = this.db._checkKey(key) || this.db._checkValue(value);
      if (err) throw err

      const db = options && options.sublevel != null ? options.sublevel : this.db;
      const original = options;
      const keyEncoding = db.keyEncoding(options && options.keyEncoding);
      const valueEncoding = db.valueEncoding(options && options.valueEncoding);
      const keyFormat = keyEncoding.format;

      // Forward encoding options
      options = { ...options, keyEncoding: keyFormat, valueEncoding: valueEncoding.format };

      // Prevent double prefixing
      if (db !== this.db) {
        options.sublevel = null;
      }

      const mappedKey = db.prefixKey(keyEncoding.encode(key), keyFormat);
      const mappedValue = valueEncoding.encode(value);

      this._put(mappedKey, mappedValue, options);
      this[kOperations$1].push({ ...original, type: 'put', key, value });

      return this
    }

    _put (key, value, options) {}

    del (key, options) {
      if (this[kStatus$1] !== 'open') {
        throw new moduleError('Batch is not open: cannot call del() after write() or close()', {
          code: 'LEVEL_BATCH_NOT_OPEN'
        })
      }

      const err = this.db._checkKey(key);
      if (err) throw err

      const db = options && options.sublevel != null ? options.sublevel : this.db;
      const original = options;
      const keyEncoding = db.keyEncoding(options && options.keyEncoding);
      const keyFormat = keyEncoding.format;

      // Forward encoding options
      options = { ...options, keyEncoding: keyFormat };

      // Prevent double prefixing
      if (db !== this.db) {
        options.sublevel = null;
      }

      this._del(db.prefixKey(keyEncoding.encode(key), keyFormat), options);
      this[kOperations$1].push({ ...original, type: 'del', key });

      return this
    }

    _del (key, options) {}

    clear () {
      if (this[kStatus$1] !== 'open') {
        throw new moduleError('Batch is not open: cannot call clear() after write() or close()', {
          code: 'LEVEL_BATCH_NOT_OPEN'
        })
      }

      this._clear();
      this[kOperations$1] = [];

      return this
    }

    _clear () {}

    write (options, callback) {
      callback = getCallback$1(options, callback);
      callback = fromCallback$2(callback, kPromise$2);
      options = getOptions$1(options);

      if (this[kStatus$1] !== 'open') {
        this.nextTick(callback, new moduleError('Batch is not open: cannot call write() after write() or close()', {
          code: 'LEVEL_BATCH_NOT_OPEN'
        }));
      } else if (this.length === 0) {
        this.close(callback);
      } else {
        this[kStatus$1] = 'writing';
        this._write(options, (err) => {
          this[kStatus$1] = 'closing';
          this[kCloseCallbacks].push(() => callback(err));

          // Emit after setting 'closing' status, because event may trigger a
          // db close which in turn triggers (idempotently) closing this batch.
          if (!err) this.db.emit('batch', this[kOperations$1]);

          this._close(this[kFinishClose]);
        });
      }

      return callback[kPromise$2]
    }

    _write (options, callback) {}

    close (callback) {
      callback = fromCallback$2(callback, kPromise$2);

      if (this[kStatus$1] === 'closing') {
        this[kCloseCallbacks].push(callback);
      } else if (this[kStatus$1] === 'closed') {
        this.nextTick(callback);
      } else {
        this[kCloseCallbacks].push(callback);

        if (this[kStatus$1] !== 'writing') {
          this[kStatus$1] = 'closing';
          this._close(this[kFinishClose]);
        }
      }

      return callback[kPromise$2]
    }

    _close (callback) {
      this.nextTick(callback);
    }

    [kFinishClose] () {
      this[kStatus$1] = 'closed';
      this.db.detachResource(this);

      const callbacks = this[kCloseCallbacks];
      this[kCloseCallbacks] = [];

      for (const cb of callbacks) {
        cb();
      }
    }
  }

  var AbstractChainedBatch_1 = AbstractChainedBatch$2;

  var abstractChainedBatch = {
  	AbstractChainedBatch: AbstractChainedBatch_1
  };

  const { AbstractChainedBatch: AbstractChainedBatch$1 } = abstractChainedBatch;

  const kEncoded = Symbol('encoded');

  // Functional default for chained batch, with support of deferred open
  class DefaultChainedBatch$1 extends AbstractChainedBatch$1 {
    constructor (db) {
      super(db);
      this[kEncoded] = [];
    }

    _put (key, value, options) {
      this[kEncoded].push({ ...options, type: 'put', key, value });
    }

    _del (key, options) {
      this[kEncoded].push({ ...options, type: 'del', key });
    }

    _clear () {
      this[kEncoded] = [];
    }

    // Assumes this[kEncoded] cannot change after write()
    _write (options, callback) {
      if (this.db.status === 'opening') {
        this.db.defer(() => this._write(options, callback));
      } else if (this.db.status === 'open') {
        if (this[kEncoded].length === 0) this.nextTick(callback);
        else this.db._batch(this[kEncoded], options, callback);
      } else {
        this.nextTick(callback, new moduleError('Batch is not open: cannot call write() after write() or close()', {
          code: 'LEVEL_BATCH_NOT_OPEN'
        }));
      }
    }
  }

  var DefaultChainedBatch_1 = DefaultChainedBatch$1;

  var defaultChainedBatch = {
  	DefaultChainedBatch: DefaultChainedBatch_1
  };

  const hasOwnProperty = Object.prototype.hasOwnProperty;
  const rangeOptions = new Set(['lt', 'lte', 'gt', 'gte']);

  var rangeOptions_1 = function (options, keyEncoding) {
    const result = {};

    for (const k in options) {
      if (!hasOwnProperty.call(options, k)) continue
      if (k === 'keyEncoding' || k === 'valueEncoding') continue

      if (k === 'start' || k === 'end') {
        throw new moduleError(`The legacy range option '${k}' has been removed`, {
          code: 'LEVEL_LEGACY'
        })
      } else if (k === 'encoding') {
        // To help migrating to abstract-level
        throw new moduleError("The levelup-style 'encoding' alias has been removed, use 'valueEncoding' instead", {
          code: 'LEVEL_LEGACY'
        })
      }

      if (rangeOptions.has(k)) {
        // Note that we don't reject nullish and empty options here. While
        // those types are invalid as keys, they are valid as range options.
        result[k] = keyEncoding.encode(options[k]);
      } else {
        result[k] = options[k];
      }
    }

    result.reverse = !!result.reverse;
    result.limit = Number.isInteger(result.limit) && result.limit >= 0 ? result.limit : -1;

    return result
  };

  /*! queue-microtask. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> */
  let promise;

  var queueMicrotask_1 = typeof queueMicrotask === 'function'
    ? queueMicrotask.bind(typeof window !== 'undefined' ? window : commonjsGlobal)
    // reuse resolved promise, and allocate it lazily
    : cb => (promise || (promise = Promise.resolve()))
      .then(cb)
      .catch(err => setTimeout(() => { throw err }, 0));

  var nextTickBrowser = function (fn, ...args) {
    if (args.length === 0) {
      queueMicrotask_1(fn);
    } else {
      queueMicrotask_1(() => fn(...args));
    }
  };

  const { AbstractIterator: AbstractIterator$3, AbstractKeyIterator: AbstractKeyIterator$1, AbstractValueIterator: AbstractValueIterator$1 } = abstractIterator;

  const kUnfix$1 = Symbol('unfix');
  const kIterator$1 = Symbol('iterator');
  const kHandleOne = Symbol('handleOne');
  const kHandleMany = Symbol('handleMany');
  const kCallback$1 = Symbol('callback');

  // TODO: unfix natively if db supports it
  class AbstractSublevelIterator$1 extends AbstractIterator$3 {
    constructor (db, options, iterator, unfix) {
      super(db, options);

      this[kIterator$1] = iterator;
      this[kUnfix$1] = unfix;
      this[kHandleOne] = this[kHandleOne].bind(this);
      this[kHandleMany] = this[kHandleMany].bind(this);
      this[kCallback$1] = null;
    }

    [kHandleOne] (err, key, value) {
      const callback = this[kCallback$1];
      if (err) return callback(err)
      if (key !== undefined) key = this[kUnfix$1](key);
      callback(err, key, value);
    }

    [kHandleMany] (err, entries) {
      const callback = this[kCallback$1];
      if (err) return callback(err)

      for (const entry of entries) {
        const key = entry[0];
        if (key !== undefined) entry[0] = this[kUnfix$1](key);
      }

      callback(err, entries);
    }
  }

  class AbstractSublevelKeyIterator$1 extends AbstractKeyIterator$1 {
    constructor (db, options, iterator, unfix) {
      super(db, options);

      this[kIterator$1] = iterator;
      this[kUnfix$1] = unfix;
      this[kHandleOne] = this[kHandleOne].bind(this);
      this[kHandleMany] = this[kHandleMany].bind(this);
      this[kCallback$1] = null;
    }

    [kHandleOne] (err, key) {
      const callback = this[kCallback$1];
      if (err) return callback(err)
      if (key !== undefined) key = this[kUnfix$1](key);
      callback(err, key);
    }

    [kHandleMany] (err, keys) {
      const callback = this[kCallback$1];
      if (err) return callback(err)

      for (let i = 0; i < keys.length; i++) {
        const key = keys[i];
        if (key !== undefined) keys[i] = this[kUnfix$1](key);
      }

      callback(err, keys);
    }
  }

  class AbstractSublevelValueIterator$1 extends AbstractValueIterator$1 {
    constructor (db, options, iterator) {
      super(db, options);
      this[kIterator$1] = iterator;
    }
  }

  for (const Iterator of [AbstractSublevelIterator$1, AbstractSublevelKeyIterator$1]) {
    Iterator.prototype._next = function (callback) {
      this[kCallback$1] = callback;
      this[kIterator$1].next(this[kHandleOne]);
    };

    Iterator.prototype._nextv = function (size, options, callback) {
      this[kCallback$1] = callback;
      this[kIterator$1].nextv(size, options, this[kHandleMany]);
    };

    Iterator.prototype._all = function (options, callback) {
      this[kCallback$1] = callback;
      this[kIterator$1].all(options, this[kHandleMany]);
    };
  }

  for (const Iterator of [AbstractSublevelValueIterator$1]) {
    Iterator.prototype._next = function (callback) {
      this[kIterator$1].next(callback);
    };

    Iterator.prototype._nextv = function (size, options, callback) {
      this[kIterator$1].nextv(size, options, callback);
    };

    Iterator.prototype._all = function (options, callback) {
      this[kIterator$1].all(options, callback);
    };
  }

  for (const Iterator of [AbstractSublevelIterator$1, AbstractSublevelKeyIterator$1, AbstractSublevelValueIterator$1]) {
    Iterator.prototype._seek = function (target, options) {
      this[kIterator$1].seek(target, options);
    };

    Iterator.prototype._close = function (callback) {
      this[kIterator$1].close(callback);
    };
  }

  var AbstractSublevelIterator_1 = AbstractSublevelIterator$1;
  var AbstractSublevelKeyIterator_1 = AbstractSublevelKeyIterator$1;
  var AbstractSublevelValueIterator_1 = AbstractSublevelValueIterator$1;

  var abstractSublevelIterator = {
  	AbstractSublevelIterator: AbstractSublevelIterator_1,
  	AbstractSublevelKeyIterator: AbstractSublevelKeyIterator_1,
  	AbstractSublevelValueIterator: AbstractSublevelValueIterator_1
  };

  const { Buffer: Buffer$5 } = buffer$1 || {};
  const {
    AbstractSublevelIterator,
    AbstractSublevelKeyIterator,
    AbstractSublevelValueIterator
  } = abstractSublevelIterator;

  const kPrefix = Symbol('prefix');
  const kUpperBound = Symbol('upperBound');
  const kPrefixRange = Symbol('prefixRange');
  const kParent = Symbol('parent');
  const kUnfix = Symbol('unfix');

  const textEncoder$1 = new TextEncoder();
  const defaults = { separator: '!' };

  // Wrapped to avoid circular dependency
  var abstractSublevel = function ({ AbstractLevel }) {
    class AbstractSublevel extends AbstractLevel {
      static defaults (options) {
        // To help migrating from subleveldown to abstract-level
        if (typeof options === 'string') {
          throw new moduleError('The subleveldown string shorthand for { separator } has been removed', {
            code: 'LEVEL_LEGACY'
          })
        } else if (options && options.open) {
          throw new moduleError('The subleveldown open option has been removed', {
            code: 'LEVEL_LEGACY'
          })
        }

        if (options == null) {
          return defaults
        } else if (!options.separator) {
          return { ...options, separator: '!' }
        } else {
          return options
        }
      }

      // TODO: add autoClose option, which if true, does parent.attachResource(this)
      constructor (db, name, options) {
        // Don't forward AbstractSublevel options to AbstractLevel
        const { separator, manifest, ...forward } = AbstractSublevel.defaults(options);
        name = trim(name, separator);

        // Reserve one character between separator and name to give us an upper bound
        const reserved = separator.charCodeAt(0) + 1;
        const parent = db[kParent] || db;

        // Keys should sort like ['!a!', '!a!!a!', '!a"', '!aa!', '!b!'].
        // Use ASCII for consistent length between string, Buffer and Uint8Array
        if (!textEncoder$1.encode(name).every(x => x > reserved && x < 127)) {
          throw new moduleError(`Prefix must use bytes > ${reserved} < ${127}`, {
            code: 'LEVEL_INVALID_PREFIX'
          })
        }

        super(mergeManifests(parent, manifest), forward);

        const prefix = (db.prefix || '') + separator + name + separator;
        const upperBound = prefix.slice(0, -1) + String.fromCharCode(reserved);

        this[kParent] = parent;
        this[kPrefix] = new MultiFormat(prefix);
        this[kUpperBound] = new MultiFormat(upperBound);
        this[kUnfix] = new Unfixer();

        this.nextTick = parent.nextTick;
      }

      prefixKey (key, keyFormat) {
        if (keyFormat === 'utf8') {
          return this[kPrefix].utf8 + key
        } else if (key.byteLength === 0) {
          // Fast path for empty key (no copy)
          return this[kPrefix][keyFormat]
        } else if (keyFormat === 'view') {
          const view = this[kPrefix].view;
          const result = new Uint8Array(view.byteLength + key.byteLength);

          result.set(view, 0);
          result.set(key, view.byteLength);

          return result
        } else {
          const buffer = this[kPrefix].buffer;
          return Buffer$5.concat([buffer, key], buffer.byteLength + key.byteLength)
        }
      }

      // Not exposed for now.
      [kPrefixRange] (range, keyFormat) {
        if (range.gte !== undefined) {
          range.gte = this.prefixKey(range.gte, keyFormat);
        } else if (range.gt !== undefined) {
          range.gt = this.prefixKey(range.gt, keyFormat);
        } else {
          range.gte = this[kPrefix][keyFormat];
        }

        if (range.lte !== undefined) {
          range.lte = this.prefixKey(range.lte, keyFormat);
        } else if (range.lt !== undefined) {
          range.lt = this.prefixKey(range.lt, keyFormat);
        } else {
          range.lte = this[kUpperBound][keyFormat];
        }
      }

      get prefix () {
        return this[kPrefix].utf8
      }

      get db () {
        return this[kParent]
      }

      _open (options, callback) {
        // The parent db must open itself or be (re)opened by the user because
        // a sublevel should not initiate state changes on the rest of the db.
        this[kParent].open({ passive: true }, callback);
      }

      _put (key, value, options, callback) {
        this[kParent].put(key, value, options, callback);
      }

      _get (key, options, callback) {
        this[kParent].get(key, options, callback);
      }

      _getMany (keys, options, callback) {
        this[kParent].getMany(keys, options, callback);
      }

      _del (key, options, callback) {
        this[kParent].del(key, options, callback);
      }

      _batch (operations, options, callback) {
        this[kParent].batch(operations, options, callback);
      }

      _clear (options, callback) {
        // TODO (refactor): move to AbstractLevel
        this[kPrefixRange](options, options.keyEncoding);
        this[kParent].clear(options, callback);
      }

      _iterator (options) {
        // TODO (refactor): move to AbstractLevel
        this[kPrefixRange](options, options.keyEncoding);
        const iterator = this[kParent].iterator(options);
        const unfix = this[kUnfix].get(this[kPrefix].utf8.length, options.keyEncoding);
        return new AbstractSublevelIterator(this, options, iterator, unfix)
      }

      _keys (options) {
        this[kPrefixRange](options, options.keyEncoding);
        const iterator = this[kParent].keys(options);
        const unfix = this[kUnfix].get(this[kPrefix].utf8.length, options.keyEncoding);
        return new AbstractSublevelKeyIterator(this, options, iterator, unfix)
      }

      _values (options) {
        this[kPrefixRange](options, options.keyEncoding);
        const iterator = this[kParent].values(options);
        return new AbstractSublevelValueIterator(this, options, iterator)
      }
    }

    return { AbstractSublevel }
  };

  const mergeManifests = function (parent, manifest) {
    return {
      // Inherit manifest of parent db
      ...parent.supports,

      // Disable unsupported features
      createIfMissing: false,
      errorIfExists: false,

      // Unset additional events because we're not forwarding them
      events: {},

      // Unset additional methods (like approximateSize) which we can't support here unless
      // the AbstractSublevel class is overridden by an implementation of `abstract-level`.
      additionalMethods: {},

      // Inherit manifest of custom AbstractSublevel subclass. Such a class is not
      // allowed to override encodings.
      ...manifest,

      encodings: {
        utf8: supportsEncoding(parent, 'utf8'),
        buffer: supportsEncoding(parent, 'buffer'),
        view: supportsEncoding(parent, 'view')
      }
    }
  };

  const supportsEncoding = function (parent, encoding) {
    // Prefer a non-transcoded encoding for optimal performance
    return parent.supports.encodings[encoding]
      ? parent.keyEncoding(encoding).name === encoding
      : false
  };

  class MultiFormat {
    constructor (key) {
      this.utf8 = key;
      this.view = textEncoder$1.encode(key);
      this.buffer = Buffer$5 ? Buffer$5.from(this.view.buffer, 0, this.view.byteLength) : {};
    }
  }

  class Unfixer {
    constructor () {
      this.cache = new Map();
    }

    get (prefixLength, keyFormat) {
      let unfix = this.cache.get(keyFormat);

      if (unfix === undefined) {
        if (keyFormat === 'view') {
          unfix = function (prefixLength, key) {
            // Avoid Uint8Array#slice() because it copies
            return key.subarray(prefixLength)
          }.bind(null, prefixLength);
        } else {
          unfix = function (prefixLength, key) {
            // Avoid Buffer#subarray() because it's slow
            return key.slice(prefixLength)
          }.bind(null, prefixLength);
        }

        this.cache.set(keyFormat, unfix);
      }

      return unfix
    }
  }

  const trim = function (str, char) {
    let start = 0;
    let end = str.length;

    while (start < end && str[start] === char) start++;
    while (end > start && str[end - 1] === char) end--;

    return str.slice(start, end)
  };

  const { supports } = levelSupports;
  const { Transcoder } = levelTranscoder;
  const { EventEmitter } = events;
  const { fromCallback: fromCallback$1 } = catering;

  const { AbstractIterator: AbstractIterator$2 } = abstractIterator;
  const { DefaultKeyIterator, DefaultValueIterator } = defaultKvIterator;
  const { DeferredIterator, DeferredKeyIterator, DeferredValueIterator } = deferredIterator;
  const { DefaultChainedBatch } = defaultChainedBatch;
  const { getCallback, getOptions } = common;


  const kPromise$1 = Symbol('promise');
  const kLanded = Symbol('landed');
  const kResources = Symbol('resources');
  const kCloseResources = Symbol('closeResources');
  const kOperations = Symbol('operations');
  const kUndefer = Symbol('undefer');
  const kDeferOpen = Symbol('deferOpen');
  const kOptions$1 = Symbol('options');
  const kStatus = Symbol('status');
  const kDefaultOptions = Symbol('defaultOptions');
  const kTranscoder = Symbol('transcoder');
  const kKeyEncoding = Symbol('keyEncoding');
  const kValueEncoding = Symbol('valueEncoding');
  const noop = () => {};

  class AbstractLevel$2 extends EventEmitter {
    constructor (manifest, options) {
      super();

      if (typeof manifest !== 'object' || manifest === null) {
        throw new TypeError("The first argument 'manifest' must be an object")
      }

      options = getOptions(options);
      const { keyEncoding, valueEncoding, passive, ...forward } = options;

      this[kResources] = new Set();
      this[kOperations] = [];
      this[kDeferOpen] = true;
      this[kOptions$1] = forward;
      this[kStatus] = 'opening';

      this.supports = supports(manifest, {
        status: true,
        promises: true,
        clear: true,
        getMany: true,
        deferredOpen: true,

        // TODO (next major): add seek
        snapshots: manifest.snapshots !== false,
        permanence: manifest.permanence !== false,

        // TODO: remove from level-supports because it's always supported
        keyIterator: true,
        valueIterator: true,
        iteratorNextv: true,
        iteratorAll: true,

        encodings: manifest.encodings || {},
        events: Object.assign({}, manifest.events, {
          opening: true,
          open: true,
          closing: true,
          closed: true,
          put: true,
          del: true,
          batch: true,
          clear: true
        })
      });

      this[kTranscoder] = new Transcoder(formats(this));
      this[kKeyEncoding] = this[kTranscoder].encoding(keyEncoding || 'utf8');
      this[kValueEncoding] = this[kTranscoder].encoding(valueEncoding || 'utf8');

      // Add custom and transcoder encodings to manifest
      for (const encoding of this[kTranscoder].encodings()) {
        if (!this.supports.encodings[encoding.commonName]) {
          this.supports.encodings[encoding.commonName] = true;
        }
      }

      this[kDefaultOptions] = {
        empty: Object.freeze({}),
        entry: Object.freeze({
          keyEncoding: this[kKeyEncoding].commonName,
          valueEncoding: this[kValueEncoding].commonName
        }),
        key: Object.freeze({
          keyEncoding: this[kKeyEncoding].commonName
        })
      };

      // Let subclass finish its constructor
      this.nextTick(() => {
        if (this[kDeferOpen]) {
          this.open({ passive: false }, noop);
        }
      });
    }

    get status () {
      return this[kStatus]
    }

    keyEncoding (encoding) {
      return this[kTranscoder].encoding(encoding != null ? encoding : this[kKeyEncoding])
    }

    valueEncoding (encoding) {
      return this[kTranscoder].encoding(encoding != null ? encoding : this[kValueEncoding])
    }

    open (options, callback) {
      callback = getCallback(options, callback);
      callback = fromCallback$1(callback, kPromise$1);

      options = { ...this[kOptions$1], ...getOptions(options) };

      options.createIfMissing = options.createIfMissing !== false;
      options.errorIfExists = !!options.errorIfExists;

      const maybeOpened = (err) => {
        if (this[kStatus] === 'closing' || this[kStatus] === 'opening') {
          // Wait until pending state changes are done
          this.once(kLanded, err ? () => maybeOpened(err) : maybeOpened);
        } else if (this[kStatus] !== 'open') {
          callback(new moduleError('Database is not open', {
            code: 'LEVEL_DATABASE_NOT_OPEN',
            cause: err
          }));
        } else {
          callback();
        }
      };

      if (options.passive) {
        if (this[kStatus] === 'opening') {
          this.once(kLanded, maybeOpened);
        } else {
          this.nextTick(maybeOpened);
        }
      } else if (this[kStatus] === 'closed' || this[kDeferOpen]) {
        this[kDeferOpen] = false;
        this[kStatus] = 'opening';
        this.emit('opening');

        this._open(options, (err) => {
          if (err) {
            this[kStatus] = 'closed';

            // Resources must be safe to close in any db state
            this[kCloseResources](() => {
              this.emit(kLanded);
              maybeOpened(err);
            });

            this[kUndefer]();
            return
          }

          this[kStatus] = 'open';
          this[kUndefer]();
          this.emit(kLanded);

          // Only emit public event if pending state changes are done
          if (this[kStatus] === 'open') this.emit('open');

          // TODO (next major): remove this alias
          if (this[kStatus] === 'open') this.emit('ready');

          maybeOpened();
        });
      } else if (this[kStatus] === 'open') {
        this.nextTick(maybeOpened);
      } else {
        this.once(kLanded, () => this.open(options, callback));
      }

      return callback[kPromise$1]
    }

    _open (options, callback) {
      this.nextTick(callback);
    }

    close (callback) {
      callback = fromCallback$1(callback, kPromise$1);

      const maybeClosed = (err) => {
        if (this[kStatus] === 'opening' || this[kStatus] === 'closing') {
          // Wait until pending state changes are done
          this.once(kLanded, err ? maybeClosed(err) : maybeClosed);
        } else if (this[kStatus] !== 'closed') {
          callback(new moduleError('Database is not closed', {
            code: 'LEVEL_DATABASE_NOT_CLOSED',
            cause: err
          }));
        } else {
          callback();
        }
      };

      if (this[kStatus] === 'open') {
        this[kStatus] = 'closing';
        this.emit('closing');

        const cancel = (err) => {
          this[kStatus] = 'open';
          this[kUndefer]();
          this.emit(kLanded);
          maybeClosed(err);
        };

        this[kCloseResources](() => {
          this._close((err) => {
            if (err) return cancel(err)

            this[kStatus] = 'closed';
            this[kUndefer]();
            this.emit(kLanded);

            // Only emit public event if pending state changes are done
            if (this[kStatus] === 'closed') this.emit('closed');

            maybeClosed();
          });
        });
      } else if (this[kStatus] === 'closed') {
        this.nextTick(maybeClosed);
      } else {
        this.once(kLanded, () => this.close(callback));
      }

      return callback[kPromise$1]
    }

    [kCloseResources] (callback) {
      if (this[kResources].size === 0) {
        return this.nextTick(callback)
      }

      let pending = this[kResources].size;
      let sync = true;

      const next = () => {
        if (--pending === 0) {
          // We don't have tests for generic resources, so dezalgo
          if (sync) this.nextTick(callback);
          else callback();
        }
      };

      // In parallel so that all resources know they are closed
      for (const resource of this[kResources]) {
        resource.close(next);
      }

      sync = false;
      this[kResources].clear();
    }

    _close (callback) {
      this.nextTick(callback);
    }

    get (key, options, callback) {
      callback = getCallback(options, callback);
      callback = fromCallback$1(callback, kPromise$1);
      options = getOptions(options, this[kDefaultOptions].entry);

      if (this[kStatus] === 'opening') {
        this.defer(() => this.get(key, options, callback));
        return callback[kPromise$1]
      }

      if (maybeError(this, callback)) {
        return callback[kPromise$1]
      }

      const err = this._checkKey(key);

      if (err) {
        this.nextTick(callback, err);
        return callback[kPromise$1]
      }

      const keyEncoding = this.keyEncoding(options.keyEncoding);
      const valueEncoding = this.valueEncoding(options.valueEncoding);
      const keyFormat = keyEncoding.format;
      const valueFormat = valueEncoding.format;

      // Forward encoding options to the underlying store
      if (options.keyEncoding !== keyFormat || options.valueEncoding !== valueFormat) {
        // Avoid spread operator because of https://bugs.chromium.org/p/chromium/issues/detail?id=1204540
        options = Object.assign({}, options, { keyEncoding: keyFormat, valueEncoding: valueFormat });
      }

      this._get(this.prefixKey(keyEncoding.encode(key), keyFormat), options, (err, value) => {
        if (err) {
          // Normalize not found error for backwards compatibility with abstract-leveldown and level(up)
          if (err.code === 'LEVEL_NOT_FOUND' || err.notFound || /NotFound/i.test(err)) {
            if (!err.code) err.code = 'LEVEL_NOT_FOUND'; // Preferred way going forward
            if (!err.notFound) err.notFound = true; // Same as level-errors
            if (!err.status) err.status = 404; // Same as level-errors
          }

          return callback(err)
        }

        try {
          value = valueEncoding.decode(value);
        } catch (err) {
          return callback(new moduleError('Could not decode value', {
            code: 'LEVEL_DECODE_ERROR',
            cause: err
          }))
        }

        callback(null, value);
      });

      return callback[kPromise$1]
    }

    _get (key, options, callback) {
      this.nextTick(callback, new Error('NotFound'));
    }

    getMany (keys, options, callback) {
      callback = getCallback(options, callback);
      callback = fromCallback$1(callback, kPromise$1);
      options = getOptions(options, this[kDefaultOptions].entry);

      if (this[kStatus] === 'opening') {
        this.defer(() => this.getMany(keys, options, callback));
        return callback[kPromise$1]
      }

      if (maybeError(this, callback)) {
        return callback[kPromise$1]
      }

      if (!Array.isArray(keys)) {
        this.nextTick(callback, new TypeError("The first argument 'keys' must be an array"));
        return callback[kPromise$1]
      }

      if (keys.length === 0) {
        this.nextTick(callback, null, []);
        return callback[kPromise$1]
      }

      const keyEncoding = this.keyEncoding(options.keyEncoding);
      const valueEncoding = this.valueEncoding(options.valueEncoding);
      const keyFormat = keyEncoding.format;
      const valueFormat = valueEncoding.format;

      // Forward encoding options
      if (options.keyEncoding !== keyFormat || options.valueEncoding !== valueFormat) {
        options = Object.assign({}, options, { keyEncoding: keyFormat, valueEncoding: valueFormat });
      }

      const mappedKeys = new Array(keys.length);

      for (let i = 0; i < keys.length; i++) {
        const key = keys[i];
        const err = this._checkKey(key);

        if (err) {
          this.nextTick(callback, err);
          return callback[kPromise$1]
        }

        mappedKeys[i] = this.prefixKey(keyEncoding.encode(key), keyFormat);
      }

      this._getMany(mappedKeys, options, (err, values) => {
        if (err) return callback(err)

        try {
          for (let i = 0; i < values.length; i++) {
            if (values[i] !== undefined) {
              values[i] = valueEncoding.decode(values[i]);
            }
          }
        } catch (err) {
          return callback(new moduleError(`Could not decode one or more of ${values.length} value(s)`, {
            code: 'LEVEL_DECODE_ERROR',
            cause: err
          }))
        }

        callback(null, values);
      });

      return callback[kPromise$1]
    }

    _getMany (keys, options, callback) {
      this.nextTick(callback, null, new Array(keys.length).fill(undefined));
    }

    put (key, value, options, callback) {
      callback = getCallback(options, callback);
      callback = fromCallback$1(callback, kPromise$1);
      options = getOptions(options, this[kDefaultOptions].entry);

      if (this[kStatus] === 'opening') {
        this.defer(() => this.put(key, value, options, callback));
        return callback[kPromise$1]
      }

      if (maybeError(this, callback)) {
        return callback[kPromise$1]
      }

      const err = this._checkKey(key) || this._checkValue(value);

      if (err) {
        this.nextTick(callback, err);
        return callback[kPromise$1]
      }

      const keyEncoding = this.keyEncoding(options.keyEncoding);
      const valueEncoding = this.valueEncoding(options.valueEncoding);
      const keyFormat = keyEncoding.format;
      const valueFormat = valueEncoding.format;

      // Forward encoding options
      if (options.keyEncoding !== keyFormat || options.valueEncoding !== valueFormat) {
        options = Object.assign({}, options, { keyEncoding: keyFormat, valueEncoding: valueFormat });
      }

      const mappedKey = this.prefixKey(keyEncoding.encode(key), keyFormat);
      const mappedValue = valueEncoding.encode(value);

      this._put(mappedKey, mappedValue, options, (err) => {
        if (err) return callback(err)
        this.emit('put', key, value);
        callback();
      });

      return callback[kPromise$1]
    }

    _put (key, value, options, callback) {
      this.nextTick(callback);
    }

    del (key, options, callback) {
      callback = getCallback(options, callback);
      callback = fromCallback$1(callback, kPromise$1);
      options = getOptions(options, this[kDefaultOptions].key);

      if (this[kStatus] === 'opening') {
        this.defer(() => this.del(key, options, callback));
        return callback[kPromise$1]
      }

      if (maybeError(this, callback)) {
        return callback[kPromise$1]
      }

      const err = this._checkKey(key);

      if (err) {
        this.nextTick(callback, err);
        return callback[kPromise$1]
      }

      const keyEncoding = this.keyEncoding(options.keyEncoding);
      const keyFormat = keyEncoding.format;

      // Forward encoding options
      if (options.keyEncoding !== keyFormat) {
        options = Object.assign({}, options, { keyEncoding: keyFormat });
      }

      this._del(this.prefixKey(keyEncoding.encode(key), keyFormat), options, (err) => {
        if (err) return callback(err)
        this.emit('del', key);
        callback();
      });

      return callback[kPromise$1]
    }

    _del (key, options, callback) {
      this.nextTick(callback);
    }

    batch (operations, options, callback) {
      if (!arguments.length) {
        if (this[kStatus] === 'opening') return new DefaultChainedBatch(this)
        if (this[kStatus] !== 'open') {
          throw new moduleError('Database is not open', {
            code: 'LEVEL_DATABASE_NOT_OPEN'
          })
        }
        return this._chainedBatch()
      }

      if (typeof operations === 'function') callback = operations;
      else callback = getCallback(options, callback);

      callback = fromCallback$1(callback, kPromise$1);
      options = getOptions(options, this[kDefaultOptions].empty);

      if (this[kStatus] === 'opening') {
        this.defer(() => this.batch(operations, options, callback));
        return callback[kPromise$1]
      }

      if (maybeError(this, callback)) {
        return callback[kPromise$1]
      }

      if (!Array.isArray(operations)) {
        this.nextTick(callback, new TypeError("The first argument 'operations' must be an array"));
        return callback[kPromise$1]
      }

      if (operations.length === 0) {
        this.nextTick(callback);
        return callback[kPromise$1]
      }

      const mapped = new Array(operations.length);
      const { keyEncoding: ke, valueEncoding: ve, ...forward } = options;

      for (let i = 0; i < operations.length; i++) {
        if (typeof operations[i] !== 'object' || operations[i] === null) {
          this.nextTick(callback, new TypeError('A batch operation must be an object'));
          return callback[kPromise$1]
        }

        const op = Object.assign({}, operations[i]);

        if (op.type !== 'put' && op.type !== 'del') {
          this.nextTick(callback, new TypeError("A batch operation must have a type property that is 'put' or 'del'"));
          return callback[kPromise$1]
        }

        const err = this._checkKey(op.key);

        if (err) {
          this.nextTick(callback, err);
          return callback[kPromise$1]
        }

        const db = op.sublevel != null ? op.sublevel : this;
        const keyEncoding = db.keyEncoding(op.keyEncoding || ke);
        const keyFormat = keyEncoding.format;

        op.key = db.prefixKey(keyEncoding.encode(op.key), keyFormat);
        op.keyEncoding = keyFormat;

        if (op.type === 'put') {
          const valueErr = this._checkValue(op.value);

          if (valueErr) {
            this.nextTick(callback, valueErr);
            return callback[kPromise$1]
          }

          const valueEncoding = db.valueEncoding(op.valueEncoding || ve);

          op.value = valueEncoding.encode(op.value);
          op.valueEncoding = valueEncoding.format;
        }

        // Prevent double prefixing
        if (db !== this) {
          op.sublevel = null;
        }

        mapped[i] = op;
      }

      this._batch(mapped, forward, (err) => {
        if (err) return callback(err)
        this.emit('batch', operations);
        callback();
      });

      return callback[kPromise$1]
    }

    _batch (operations, options, callback) {
      this.nextTick(callback);
    }

    sublevel (name, options) {
      return this._sublevel(name, AbstractSublevel$1.defaults(options))
    }

    _sublevel (name, options) {
      return new AbstractSublevel$1(this, name, options)
    }

    prefixKey (key, keyFormat) {
      return key
    }

    clear (options, callback) {
      callback = getCallback(options, callback);
      callback = fromCallback$1(callback, kPromise$1);
      options = getOptions(options, this[kDefaultOptions].empty);

      if (this[kStatus] === 'opening') {
        this.defer(() => this.clear(options, callback));
        return callback[kPromise$1]
      }

      if (maybeError(this, callback)) {
        return callback[kPromise$1]
      }

      const original = options;
      const keyEncoding = this.keyEncoding(options.keyEncoding);

      options = rangeOptions_1(options, keyEncoding);
      options.keyEncoding = keyEncoding.format;

      if (options.limit === 0) {
        this.nextTick(callback);
      } else {
        this._clear(options, (err) => {
          if (err) return callback(err)
          this.emit('clear', original);
          callback();
        });
      }

      return callback[kPromise$1]
    }

    _clear (options, callback) {
      this.nextTick(callback);
    }

    iterator (options) {
      const keyEncoding = this.keyEncoding(options && options.keyEncoding);
      const valueEncoding = this.valueEncoding(options && options.valueEncoding);

      options = rangeOptions_1(options, keyEncoding);
      options.keys = options.keys !== false;
      options.values = options.values !== false;

      // We need the original encoding options in AbstractIterator in order to decode data
      options[AbstractIterator$2.keyEncoding] = keyEncoding;
      options[AbstractIterator$2.valueEncoding] = valueEncoding;

      // Forward encoding options to private API
      options.keyEncoding = keyEncoding.format;
      options.valueEncoding = valueEncoding.format;

      if (this[kStatus] === 'opening') {
        return new DeferredIterator(this, options)
      } else if (this[kStatus] !== 'open') {
        throw new moduleError('Database is not open', {
          code: 'LEVEL_DATABASE_NOT_OPEN'
        })
      }

      return this._iterator(options)
    }

    _iterator (options) {
      return new AbstractIterator$2(this, options)
    }

    keys (options) {
      // Also include valueEncoding (though unused) because we may fallback to _iterator()
      const keyEncoding = this.keyEncoding(options && options.keyEncoding);
      const valueEncoding = this.valueEncoding(options && options.valueEncoding);

      options = rangeOptions_1(options, keyEncoding);

      // We need the original encoding options in AbstractKeyIterator in order to decode data
      options[AbstractIterator$2.keyEncoding] = keyEncoding;
      options[AbstractIterator$2.valueEncoding] = valueEncoding;

      // Forward encoding options to private API
      options.keyEncoding = keyEncoding.format;
      options.valueEncoding = valueEncoding.format;

      if (this[kStatus] === 'opening') {
        return new DeferredKeyIterator(this, options)
      } else if (this[kStatus] !== 'open') {
        throw new moduleError('Database is not open', {
          code: 'LEVEL_DATABASE_NOT_OPEN'
        })
      }

      return this._keys(options)
    }

    _keys (options) {
      return new DefaultKeyIterator(this, options)
    }

    values (options) {
      const keyEncoding = this.keyEncoding(options && options.keyEncoding);
      const valueEncoding = this.valueEncoding(options && options.valueEncoding);

      options = rangeOptions_1(options, keyEncoding);

      // We need the original encoding options in AbstractValueIterator in order to decode data
      options[AbstractIterator$2.keyEncoding] = keyEncoding;
      options[AbstractIterator$2.valueEncoding] = valueEncoding;

      // Forward encoding options to private API
      options.keyEncoding = keyEncoding.format;
      options.valueEncoding = valueEncoding.format;

      if (this[kStatus] === 'opening') {
        return new DeferredValueIterator(this, options)
      } else if (this[kStatus] !== 'open') {
        throw new moduleError('Database is not open', {
          code: 'LEVEL_DATABASE_NOT_OPEN'
        })
      }

      return this._values(options)
    }

    _values (options) {
      return new DefaultValueIterator(this, options)
    }

    defer (fn) {
      if (typeof fn !== 'function') {
        throw new TypeError('The first argument must be a function')
      }

      this[kOperations].push(fn);
    }

    [kUndefer] () {
      if (this[kOperations].length === 0) {
        return
      }

      const operations = this[kOperations];
      this[kOperations] = [];

      for (const op of operations) {
        op();
      }
    }

    // TODO: docs and types
    attachResource (resource) {
      if (typeof resource !== 'object' || resource === null ||
        typeof resource.close !== 'function') {
        throw new TypeError('The first argument must be a resource object')
      }

      this[kResources].add(resource);
    }

    // TODO: docs and types
    detachResource (resource) {
      this[kResources].delete(resource);
    }

    _chainedBatch () {
      return new DefaultChainedBatch(this)
    }

    _checkKey (key) {
      if (key === null || key === undefined) {
        return new moduleError('Key cannot be null or undefined', {
          code: 'LEVEL_INVALID_KEY'
        })
      }
    }

    _checkValue (value) {
      if (value === null || value === undefined) {
        return new moduleError('Value cannot be null or undefined', {
          code: 'LEVEL_INVALID_VALUE'
        })
      }
    }
  }

  // Expose browser-compatible nextTick for dependents
  // TODO: after we drop node 10, also use queueMicrotask in node
  AbstractLevel$2.prototype.nextTick = nextTickBrowser;

  const { AbstractSublevel: AbstractSublevel$1 } = abstractSublevel({ AbstractLevel: AbstractLevel$2 });

  var AbstractLevel_1 = AbstractLevel$2;
  var AbstractSublevel_1 = AbstractSublevel$1;

  const maybeError = function (db, callback) {
    if (db[kStatus] !== 'open') {
      db.nextTick(callback, new moduleError('Database is not open', {
        code: 'LEVEL_DATABASE_NOT_OPEN'
      }));
      return true
    }

    return false
  };

  const formats = function (db) {
    return Object.keys(db.supports.encodings)
      .filter(k => !!db.supports.encodings[k])
  };

  var abstractLevel$1 = {
  	AbstractLevel: AbstractLevel_1,
  	AbstractSublevel: AbstractSublevel_1
  };

  var AbstractLevel$1 = abstractLevel$1.AbstractLevel;
  var AbstractSublevel = abstractLevel$1.AbstractSublevel;
  var AbstractIterator$1 = abstractIterator.AbstractIterator;
  var AbstractKeyIterator = abstractIterator.AbstractKeyIterator;
  var AbstractValueIterator = abstractIterator.AbstractValueIterator;
  var AbstractChainedBatch = abstractChainedBatch.AbstractChainedBatch;

  var abstractLevel = {
  	AbstractLevel: AbstractLevel$1,
  	AbstractSublevel: AbstractSublevel,
  	AbstractIterator: AbstractIterator$1,
  	AbstractKeyIterator: AbstractKeyIterator,
  	AbstractValueIterator: AbstractValueIterator,
  	AbstractChainedBatch: AbstractChainedBatch
  };

  /*! run-parallel-limit. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> */
  var runParallelLimit_1 = runParallelLimit;



  function runParallelLimit (tasks, limit, cb) {
    if (typeof limit !== 'number') throw new Error('second argument must be a Number')
    let results, len, pending, keys, isErrored;
    let isSync = true;
    let next;

    if (Array.isArray(tasks)) {
      results = [];
      pending = len = tasks.length;
    } else {
      keys = Object.keys(tasks);
      results = {};
      pending = len = keys.length;
    }

    function done (err) {
      function end () {
        if (cb) cb(err, results);
        cb = null;
      }
      if (isSync) queueMicrotask_1(end);
      else end();
    }

    function each (i, err, result) {
      results[i] = result;
      if (err) isErrored = true;
      if (--pending === 0 || err) {
        done(err);
      } else if (!isErrored && next < len) {
        let key;
        if (keys) {
          key = keys[next];
          next += 1;
          tasks[key](function (err, result) { each(key, err, result); });
        } else {
          key = next;
          next += 1;
          tasks[key](function (err, result) { each(key, err, result); });
        }
      }
    }

    next = limit;
    if (!pending) {
      // empty
      done(null);
    } else if (keys) {
      // object
      keys.some(function (key, i) {
        tasks[key](function (err, result) { each(key, err, result); });
        if (i === limit - 1) return true // early return
        return false
      });
    } else {
      // array
      tasks.some(function (task, i) {
        task(function (err, result) { each(i, err, result); });
        if (i === limit - 1) return true // early return
        return false
      });
    }

    isSync = false;
  }

  /* global IDBKeyRange */

  var keyRange = function createKeyRange (options) {
    const lower = options.gte !== undefined ? options.gte : options.gt !== undefined ? options.gt : undefined;
    const upper = options.lte !== undefined ? options.lte : options.lt !== undefined ? options.lt : undefined;
    const lowerExclusive = options.gte === undefined;
    const upperExclusive = options.lte === undefined;

    if (lower !== undefined && upper !== undefined) {
      return IDBKeyRange.bound(lower, upper, lowerExclusive, upperExclusive)
    } else if (lower !== undefined) {
      return IDBKeyRange.lowerBound(lower, lowerExclusive)
    } else if (upper !== undefined) {
      return IDBKeyRange.upperBound(upper, upperExclusive)
    } else {
      return null
    }
  };

  const textEncoder = new TextEncoder();

  var deserialize = function (data) {
    if (data instanceof Uint8Array) {
      return data
    } else if (data instanceof ArrayBuffer) {
      return new Uint8Array(data)
    } else {
      // Non-binary data stored with an old version (level-js < 5.0.0)
      return textEncoder.encode(data)
    }
  };

  const { AbstractIterator } = abstractLevel;



  const kCache = Symbol('cache');
  const kFinished = Symbol('finished');
  const kOptions = Symbol('options');
  const kCurrentOptions = Symbol('currentOptions');
  const kPosition = Symbol('position');
  const kLocation$1 = Symbol('location');
  const kFirst = Symbol('first');
  const emptyOptions = {};

  class Iterator$1 extends AbstractIterator {
    constructor (db, location, options) {
      super(db, options);

      this[kCache] = [];
      this[kFinished] = this.limit === 0;
      this[kOptions] = options;
      this[kCurrentOptions] = { ...options };
      this[kPosition] = undefined;
      this[kLocation$1] = location;
      this[kFirst] = true;
    }

    // Note: if called by _all() then size can be Infinity. This is an internal
    // detail; by design AbstractIterator.nextv() does not support Infinity.
    _nextv (size, options, callback) {
      this[kFirst] = false;

      if (this[kFinished]) {
        return this.nextTick(callback, null, [])
      } else if (this[kCache].length > 0) {
        // TODO: mixing next and nextv is not covered by test suite
        size = Math.min(size, this[kCache].length);
        return this.nextTick(callback, null, this[kCache].splice(0, size))
      }

      // Adjust range by what we already visited
      if (this[kPosition] !== undefined) {
        if (this[kOptions].reverse) {
          this[kCurrentOptions].lt = this[kPosition];
          this[kCurrentOptions].lte = undefined;
        } else {
          this[kCurrentOptions].gt = this[kPosition];
          this[kCurrentOptions].gte = undefined;
        }
      }

      let keyRange$1;

      try {
        keyRange$1 = keyRange(this[kCurrentOptions]);
      } catch (_) {
        // The lower key is greater than the upper key.
        // IndexedDB throws an error, but we'll just return 0 results.
        this[kFinished] = true;
        return this.nextTick(callback, null, [])
      }

      const transaction = this.db.db.transaction([this[kLocation$1]], 'readonly');
      const store = transaction.objectStore(this[kLocation$1]);
      const entries = [];

      if (!this[kOptions].reverse) {
        let keys;
        let values;

        const complete = () => {
          // Wait for both requests to complete
          if (keys === undefined || values === undefined) return

          const length = Math.max(keys.length, values.length);

          if (length === 0 || size === Infinity) {
            this[kFinished] = true;
          } else {
            this[kPosition] = keys[length - 1];
          }

          // Resize
          entries.length = length;

          // Merge keys and values
          for (let i = 0; i < length; i++) {
            const key = keys[i];
            const value = values[i];

            entries[i] = [
              this[kOptions].keys && key !== undefined ? deserialize(key) : undefined,
              this[kOptions].values && value !== undefined ? deserialize(value) : undefined
            ];
          }

          maybeCommit(transaction);
        };

        // If keys were not requested and size is Infinity, we don't have to keep
        // track of position and can thus skip getting keys.
        if (this[kOptions].keys || size < Infinity) {
          store.getAllKeys(keyRange$1, size < Infinity ? size : undefined).onsuccess = (ev) => {
            keys = ev.target.result;
            complete();
          };
        } else {
          keys = [];
          this.nextTick(complete);
        }

        if (this[kOptions].values) {
          store.getAll(keyRange$1, size < Infinity ? size : undefined).onsuccess = (ev) => {
            values = ev.target.result;
            complete();
          };
        } else {
          values = [];
          this.nextTick(complete);
        }
      } else {
        // Can't use getAll() in reverse, so use a slower cursor that yields one item at a time
        // TODO: test if all target browsers support openKeyCursor
        const method = !this[kOptions].values && store.openKeyCursor ? 'openKeyCursor' : 'openCursor';

        store[method](keyRange$1, 'prev').onsuccess = (ev) => {
          const cursor = ev.target.result;

          if (cursor) {
            const { key, value } = cursor;
            this[kPosition] = key;

            entries.push([
              this[kOptions].keys && key !== undefined ? deserialize(key) : undefined,
              this[kOptions].values && value !== undefined ? deserialize(value) : undefined
            ]);

            if (entries.length < size) {
              cursor.continue();
            } else {
              maybeCommit(transaction);
            }
          } else {
            this[kFinished] = true;
          }
        };
      }

      // If an error occurs (on the request), the transaction will abort.
      transaction.onabort = () => {
        callback(transaction.error || new Error('aborted by user'));
        callback = null;
      };

      transaction.oncomplete = () => {
        callback(null, entries);
        callback = null;
      };
    }

    _next (callback) {
      if (this[kCache].length > 0) {
        const [key, value] = this[kCache].shift();
        this.nextTick(callback, null, key, value);
      } else if (this[kFinished]) {
        this.nextTick(callback);
      } else {
        let size = Math.min(100, this.limit - this.count);

        if (this[kFirst]) {
          // It's common to only want one entry initially or after a seek()
          this[kFirst] = false;
          size = 1;
        }

        this._nextv(size, emptyOptions, (err, entries) => {
          if (err) return callback(err)
          this[kCache] = entries;
          this._next(callback);
        });
      }
    }

    _all (options, callback) {
      this[kFirst] = false;

      // TODO: mixing next and all is not covered by test suite
      const cache = this[kCache].splice(0, this[kCache].length);
      const size = this.limit - this.count - cache.length;

      if (size <= 0) {
        return this.nextTick(callback, null, cache)
      }

      this._nextv(size, emptyOptions, (err, entries) => {
        if (err) return callback(err)
        if (cache.length > 0) entries = cache.concat(entries);
        callback(null, entries);
      });
    }

    _seek (target, options) {
      this[kFirst] = true;
      this[kCache] = [];
      this[kFinished] = false;
      this[kPosition] = undefined;

      // TODO: not covered by test suite
      this[kCurrentOptions] = { ...this[kOptions] };

      let keyRange$1;

      try {
        keyRange$1 = keyRange(this[kOptions]);
      } catch (_) {
        this[kFinished] = true;
        return
      }

      if (keyRange$1 !== null && !keyRange$1.includes(target)) {
        this[kFinished] = true;
      } else if (this[kOptions].reverse) {
        this[kCurrentOptions].lte = target;
      } else {
        this[kCurrentOptions].gte = target;
      }
    }
  }

  var Iterator_1 = Iterator$1;

  function maybeCommit (transaction) {
    // Commit (meaning close) now instead of waiting for auto-commit
    if (typeof transaction.commit === 'function') {
      transaction.commit();
    }
  }

  var iterator = {
  	Iterator: Iterator_1
  };

  var clear = function clear (db, location, keyRange, options, callback) {
    if (options.limit === 0) return db.nextTick(callback)

    const transaction = db.db.transaction([location], 'readwrite');
    const store = transaction.objectStore(location);
    let count = 0;

    transaction.oncomplete = function () {
      callback();
    };

    transaction.onabort = function () {
      callback(transaction.error || new Error('aborted by user'));
    };

    // A key cursor is faster (skips reading values) but not supported by IE
    // TODO: we no longer support IE. Test others
    const method = store.openKeyCursor ? 'openKeyCursor' : 'openCursor';
    const direction = options.reverse ? 'prev' : 'next';

    store[method](keyRange, direction).onsuccess = function (ev) {
      const cursor = ev.target.result;

      if (cursor) {
        // Wait for a request to complete before continuing, saving CPU.
        store.delete(cursor.key).onsuccess = function () {
          if (options.limit <= 0 || ++count < options.limit) {
            cursor.continue();
          }
        };
      }
    };
  };

  const { AbstractLevel } = abstractLevel;


  const { fromCallback } = catering;
  const { Iterator } = iterator;




  // Keep as-is for compatibility with existing level-js databases
  const DEFAULT_PREFIX = 'level-js-';

  const kIDB = Symbol('idb');
  const kNamePrefix = Symbol('namePrefix');
  const kLocation = Symbol('location');
  const kVersion = Symbol('version');
  const kStore = Symbol('store');
  const kOnComplete = Symbol('onComplete');
  const kPromise = Symbol('promise');

  class BrowserLevel extends AbstractLevel {
    constructor (location, options, _) {
      // To help migrating to abstract-level
      if (typeof options === 'function' || typeof _ === 'function') {
        throw new moduleError('The levelup-style callback argument has been removed', {
          code: 'LEVEL_LEGACY'
        })
      }

      const { prefix, version, ...forward } = options || {};

      super({
        encodings: { view: true },
        snapshots: false,
        createIfMissing: false,
        errorIfExists: false,
        seek: true
      }, forward);

      if (typeof location !== 'string') {
        throw new Error('constructor requires a location string argument')
      }

      // TODO (next major): remove default prefix
      this[kLocation] = location;
      this[kNamePrefix] = prefix == null ? DEFAULT_PREFIX : prefix;
      this[kVersion] = parseInt(version || 1, 10);
      this[kIDB] = null;
    }

    get location () {
      return this[kLocation]
    }

    get namePrefix () {
      return this[kNamePrefix]
    }

    get version () {
      return this[kVersion]
    }

    // Exposed for backwards compat and unit tests
    get db () {
      return this[kIDB]
    }

    get type () {
      return 'browser-level'
    }

    _open (options, callback) {
      const req = indexedDB.open(this[kNamePrefix] + this[kLocation], this[kVersion]);

      req.onerror = function () {
        callback(req.error || new Error('unknown error'));
      };

      req.onsuccess = () => {
        this[kIDB] = req.result;
        callback();
      };

      req.onupgradeneeded = (ev) => {
        const db = ev.target.result;

        if (!db.objectStoreNames.contains(this[kLocation])) {
          db.createObjectStore(this[kLocation]);
        }
      };
    }

    [kStore] (mode) {
      const transaction = this[kIDB].transaction([this[kLocation]], mode);
      return transaction.objectStore(this[kLocation])
    }

    [kOnComplete] (request, callback) {
      const transaction = request.transaction;

      // Take advantage of the fact that a non-canceled request error aborts
      // the transaction. I.e. no need to listen for "request.onerror".
      transaction.onabort = function () {
        callback(transaction.error || new Error('aborted by user'));
      };

      transaction.oncomplete = function () {
        callback(null, request.result);
      };
    }

    _get (key, options, callback) {
      const store = this[kStore]('readonly');
      let req;

      try {
        req = store.get(key);
      } catch (err) {
        return this.nextTick(callback, err)
      }

      this[kOnComplete](req, function (err, value) {
        if (err) return callback(err)

        if (value === undefined) {
          return callback(new moduleError('Entry not found', {
            code: 'LEVEL_NOT_FOUND'
          }))
        }

        callback(null, deserialize(value));
      });
    }

    _getMany (keys, options, callback) {
      const store = this[kStore]('readonly');
      const tasks = keys.map((key) => (next) => {
        let request;

        try {
          request = store.get(key);
        } catch (err) {
          return next(err)
        }

        request.onsuccess = () => {
          const value = request.result;
          next(null, value === undefined ? value : deserialize(value));
        };

        request.onerror = (ev) => {
          ev.stopPropagation();
          next(request.error);
        };
      });

      runParallelLimit_1(tasks, 16, callback);
    }

    _del (key, options, callback) {
      const store = this[kStore]('readwrite');
      let req;

      try {
        req = store.delete(key);
      } catch (err) {
        return this.nextTick(callback, err)
      }

      this[kOnComplete](req, callback);
    }

    _put (key, value, options, callback) {
      const store = this[kStore]('readwrite');
      let req;

      try {
        // Will throw a DataError or DataCloneError if the environment
        // does not support serializing the key or value respectively.
        req = store.put(value, key);
      } catch (err) {
        return this.nextTick(callback, err)
      }

      this[kOnComplete](req, callback);
    }

    // TODO: implement key and value iterators
    _iterator (options) {
      return new Iterator(this, this[kLocation], options)
    }

    _batch (operations, options, callback) {
      const store = this[kStore]('readwrite');
      const transaction = store.transaction;
      let index = 0;
      let error;

      transaction.onabort = function () {
        callback(error || transaction.error || new Error('aborted by user'));
      };

      transaction.oncomplete = function () {
        callback();
      };

      // Wait for a request to complete before making the next, saving CPU.
      function loop () {
        const op = operations[index++];
        const key = op.key;

        let req;

        try {
          req = op.type === 'del' ? store.delete(key) : store.put(op.value, key);
        } catch (err) {
          error = err;
          transaction.abort();
          return
        }

        if (index < operations.length) {
          req.onsuccess = loop;
        } else if (typeof transaction.commit === 'function') {
          // Commit now instead of waiting for auto-commit
          transaction.commit();
        }
      }

      loop();
    }

    _clear (options, callback) {
      let keyRange$1;
      let req;

      try {
        keyRange$1 = keyRange(options);
      } catch (e) {
        // The lower key is greater than the upper key.
        // IndexedDB throws an error, but we'll just do nothing.
        return this.nextTick(callback)
      }

      if (options.limit >= 0) {
        // IDBObjectStore#delete(range) doesn't have such an option.
        // Fall back to cursor-based implementation.
        return clear(this, this[kLocation], keyRange$1, options, callback)
      }

      try {
        const store = this[kStore]('readwrite');
        req = keyRange$1 ? store.delete(keyRange$1) : store.clear();
      } catch (err) {
        return this.nextTick(callback, err)
      }

      this[kOnComplete](req, callback);
    }

    _close (callback) {
      this[kIDB].close();
      this.nextTick(callback);
    }
  }

  BrowserLevel.destroy = function (location, prefix, callback) {
    if (typeof prefix === 'function') {
      callback = prefix;
      prefix = DEFAULT_PREFIX;
    }

    callback = fromCallback(callback, kPromise);
    const request = indexedDB.deleteDatabase(prefix + location);

    request.onsuccess = function () {
      callback();
    };

    request.onerror = function (err) {
      callback(err);
    };

    return callback[kPromise]
  };

  var BrowserLevel_1 = BrowserLevel;

  var browserLevel = {
  	BrowserLevel: BrowserLevel_1
  };

  var Level = browserLevel.BrowserLevel;

  /*
    This file is a reduced and adapted version of the main lib/internal/per_context/primordials.js file defined at

    https://github.com/nodejs/node/blob/main/lib/internal/per_context/primordials.js

    Don't try to replace with the original file and keep it up to date with the upstream file.
  */

  // This is a simplified version of AggregateError
  class AggregateError$1 extends Error {
    constructor(errors) {
      if (!Array.isArray(errors)) {
        throw new TypeError(`Expected input to be an Array, got ${typeof errors}`)
      }
      let message = '';
      for (let i = 0; i < errors.length; i++) {
        message += `    ${errors[i].stack}\n`;
      }
      super(message);
      this.name = 'AggregateError';
      this.errors = errors;
    }
  }
  var primordials = {
    AggregateError: AggregateError$1,
    ArrayIsArray(self) {
      return Array.isArray(self)
    },
    ArrayPrototypeIncludes(self, el) {
      return self.includes(el)
    },
    ArrayPrototypeIndexOf(self, el) {
      return self.indexOf(el)
    },
    ArrayPrototypeJoin(self, sep) {
      return self.join(sep)
    },
    ArrayPrototypeMap(self, fn) {
      return self.map(fn)
    },
    ArrayPrototypePop(self, el) {
      return self.pop(el)
    },
    ArrayPrototypePush(self, el) {
      return self.push(el)
    },
    ArrayPrototypeSlice(self, start, end) {
      return self.slice(start, end)
    },
    Error,
    FunctionPrototypeCall(fn, thisArgs, ...args) {
      return fn.call(thisArgs, ...args)
    },
    FunctionPrototypeSymbolHasInstance(self, instance) {
      return Function.prototype[Symbol.hasInstance].call(self, instance)
    },
    MathFloor: Math.floor,
    Number,
    NumberIsInteger: Number.isInteger,
    NumberIsNaN: Number.isNaN,
    NumberMAX_SAFE_INTEGER: Number.MAX_SAFE_INTEGER,
    NumberMIN_SAFE_INTEGER: Number.MIN_SAFE_INTEGER,
    NumberParseInt: Number.parseInt,
    ObjectDefineProperties(self, props) {
      return Object.defineProperties(self, props)
    },
    ObjectDefineProperty(self, name, prop) {
      return Object.defineProperty(self, name, prop)
    },
    ObjectGetOwnPropertyDescriptor(self, name) {
      return Object.getOwnPropertyDescriptor(self, name)
    },
    ObjectKeys(obj) {
      return Object.keys(obj)
    },
    ObjectSetPrototypeOf(target, proto) {
      return Object.setPrototypeOf(target, proto)
    },
    Promise,
    PromisePrototypeCatch(self, fn) {
      return self.catch(fn)
    },
    PromisePrototypeThen(self, thenFn, catchFn) {
      return self.then(thenFn, catchFn)
    },
    PromiseReject(err) {
      return Promise.reject(err)
    },
    PromiseResolve(val) {
      return Promise.resolve(val)
    },
    ReflectApply: Reflect.apply,
    RegExpPrototypeTest(self, value) {
      return self.test(value)
    },
    SafeSet: Set,
    String,
    StringPrototypeSlice(self, start, end) {
      return self.slice(start, end)
    },
    StringPrototypeToLowerCase(self) {
      return self.toLowerCase()
    },
    StringPrototypeToUpperCase(self) {
      return self.toUpperCase()
    },
    StringPrototypeTrim(self) {
      return self.trim()
    },
    Symbol,
    SymbolFor: Symbol.for,
    SymbolAsyncIterator: Symbol.asyncIterator,
    SymbolHasInstance: Symbol.hasInstance,
    SymbolIterator: Symbol.iterator,
    SymbolDispose: Symbol.dispose || Symbol('Symbol.dispose'),
    SymbolAsyncDispose: Symbol.asyncDispose || Symbol('Symbol.asyncDispose'),
    TypedArrayPrototypeSet(self, buf, len) {
      return self.set(buf, len)
    },
    Boolean,
    Uint8Array
  };

  /*
    This file is a reduced and adapted version of the main lib/internal/util/inspect.js file defined at

    https://github.com/nodejs/node/blob/main/lib/internal/util/inspect.js

    Don't try to replace with the original file and keep it up to date with the upstream file.
  */
  var inspect$2 = {
    format(format, ...args) {
      // Simplified version of https://nodejs.org/api/util.html#utilformatformat-args
      return format.replace(/%([sdifj])/g, function (...[_unused, type]) {
        const replacement = args.shift();
        if (type === 'f') {
          return replacement.toFixed(6)
        } else if (type === 'j') {
          return JSON.stringify(replacement)
        } else if (type === 's' && typeof replacement === 'object') {
          const ctor = replacement.constructor !== Object ? replacement.constructor.name : '';
          return `${ctor} {}`.trim()
        } else {
          return replacement.toString()
        }
      })
    },
    inspect(value) {
      // Vastly simplified version of https://nodejs.org/api/util.html#utilinspectobject-options
      switch (typeof value) {
        case 'string':
          if (value.includes("'")) {
            if (!value.includes('"')) {
              return `"${value}"`
            } else if (!value.includes('`') && !value.includes('${')) {
              return `\`${value}\``
            }
          }
          return `'${value}'`
        case 'number':
          if (isNaN(value)) {
            return 'NaN'
          } else if (Object.is(value, -0)) {
            return String(value)
          }
          return value
        case 'bigint':
          return `${String(value)}n`
        case 'boolean':
        case 'undefined':
          return String(value)
        case 'object':
          return '{}'
      }
    }
  };

  const { format, inspect: inspect$1 } = inspect$2;
  const { AggregateError: CustomAggregateError } = primordials;

  /*
    This file is a reduced and adapted version of the main lib/internal/errors.js file defined at

    https://github.com/nodejs/node/blob/main/lib/internal/errors.js

    Don't try to replace with the original file and keep it up to date (starting from E(...) definitions)
    with the upstream file.
  */

  const AggregateError = globalThis.AggregateError || CustomAggregateError;
  const kIsNodeError = Symbol('kIsNodeError');
  const kTypes = [
    'string',
    'function',
    'number',
    'object',
    // Accept 'Function' and 'Object' as alternative to the lower cased version.
    'Function',
    'Object',
    'boolean',
    'bigint',
    'symbol'
  ];
  const classRegExp = /^([A-Z][a-z0-9]*)+$/;
  const nodeInternalPrefix = '__node_internal_';
  const codes$1 = {};
  function assert$1(value, message) {
    if (!value) {
      throw new codes$1.ERR_INTERNAL_ASSERTION(message)
    }
  }

  // Only use this for integers! Decimal numbers do not work with this function.
  function addNumericalSeparator(val) {
    let res = '';
    let i = val.length;
    const start = val[0] === '-' ? 1 : 0;
    for (; i >= start + 4; i -= 3) {
      res = `_${val.slice(i - 3, i)}${res}`;
    }
    return `${val.slice(0, i)}${res}`
  }
  function getMessage(key, msg, args) {
    if (typeof msg === 'function') {
      assert$1(
        msg.length <= args.length,
        // Default options do not count.
        `Code: ${key}; The provided arguments length (${args.length}) does not match the required ones (${msg.length}).`
      );
      return msg(...args)
    }
    const expectedLength = (msg.match(/%[dfijoOs]/g) || []).length;
    assert$1(
      expectedLength === args.length,
      `Code: ${key}; The provided arguments length (${args.length}) does not match the required ones (${expectedLength}).`
    );
    if (args.length === 0) {
      return msg
    }
    return format(msg, ...args)
  }
  function E(code, message, Base) {
    if (!Base) {
      Base = Error;
    }
    class NodeError extends Base {
      constructor(...args) {
        super(getMessage(code, message, args));
      }
      toString() {
        return `${this.name} [${code}]: ${this.message}`
      }
    }
    Object.defineProperties(NodeError.prototype, {
      name: {
        value: Base.name,
        writable: true,
        enumerable: false,
        configurable: true
      },
      toString: {
        value() {
          return `${this.name} [${code}]: ${this.message}`
        },
        writable: true,
        enumerable: false,
        configurable: true
      }
    });
    NodeError.prototype.code = code;
    NodeError.prototype[kIsNodeError] = true;
    codes$1[code] = NodeError;
  }
  function hideStackFrames$1(fn) {
    // We rename the functions that will be hidden to cut off the stacktrace
    // at the outermost one
    const hidden = nodeInternalPrefix + fn.name;
    Object.defineProperty(fn, 'name', {
      value: hidden
    });
    return fn
  }
  function aggregateTwoErrors$3(innerError, outerError) {
    if (innerError && outerError && innerError !== outerError) {
      if (Array.isArray(outerError.errors)) {
        // If `outerError` is already an `AggregateError`.
        outerError.errors.push(innerError);
        return outerError
      }
      const err = new AggregateError([outerError, innerError], outerError.message);
      err.code = outerError.code;
      return err
    }
    return innerError || outerError
  }
  class AbortError$7 extends Error {
    constructor(message = 'The operation was aborted', options = undefined) {
      if (options !== undefined && typeof options !== 'object') {
        throw new codes$1.ERR_INVALID_ARG_TYPE('options', 'Object', options)
      }
      super(message, options);
      this.code = 'ABORT_ERR';
      this.name = 'AbortError';
    }
  }
  E('ERR_ASSERTION', '%s', Error);
  E(
    'ERR_INVALID_ARG_TYPE',
    (name, expected, actual) => {
      assert$1(typeof name === 'string', "'name' must be a string");
      if (!Array.isArray(expected)) {
        expected = [expected];
      }
      let msg = 'The ';
      if (name.endsWith(' argument')) {
        // For cases like 'first argument'
        msg += `${name} `;
      } else {
        msg += `"${name}" ${name.includes('.') ? 'property' : 'argument'} `;
      }
      msg += 'must be ';
      const types = [];
      const instances = [];
      const other = [];
      for (const value of expected) {
        assert$1(typeof value === 'string', 'All expected entries have to be of type string');
        if (kTypes.includes(value)) {
          types.push(value.toLowerCase());
        } else if (classRegExp.test(value)) {
          instances.push(value);
        } else {
          assert$1(value !== 'object', 'The value "object" should be written as "Object"');
          other.push(value);
        }
      }

      // Special handle `object` in case other instances are allowed to outline
      // the differences between each other.
      if (instances.length > 0) {
        const pos = types.indexOf('object');
        if (pos !== -1) {
          types.splice(types, pos, 1);
          instances.push('Object');
        }
      }
      if (types.length > 0) {
        switch (types.length) {
          case 1:
            msg += `of type ${types[0]}`;
            break
          case 2:
            msg += `one of type ${types[0]} or ${types[1]}`;
            break
          default: {
            const last = types.pop();
            msg += `one of type ${types.join(', ')}, or ${last}`;
          }
        }
        if (instances.length > 0 || other.length > 0) {
          msg += ' or ';
        }
      }
      if (instances.length > 0) {
        switch (instances.length) {
          case 1:
            msg += `an instance of ${instances[0]}`;
            break
          case 2:
            msg += `an instance of ${instances[0]} or ${instances[1]}`;
            break
          default: {
            const last = instances.pop();
            msg += `an instance of ${instances.join(', ')}, or ${last}`;
          }
        }
        if (other.length > 0) {
          msg += ' or ';
        }
      }
      switch (other.length) {
        case 0:
          break
        case 1:
          if (other[0].toLowerCase() !== other[0]) {
            msg += 'an ';
          }
          msg += `${other[0]}`;
          break
        case 2:
          msg += `one of ${other[0]} or ${other[1]}`;
          break
        default: {
          const last = other.pop();
          msg += `one of ${other.join(', ')}, or ${last}`;
        }
      }
      if (actual == null) {
        msg += `. Received ${actual}`;
      } else if (typeof actual === 'function' && actual.name) {
        msg += `. Received function ${actual.name}`;
      } else if (typeof actual === 'object') {
        var _actual$constructor;
        if (
          (_actual$constructor = actual.constructor) !== null &&
          _actual$constructor !== undefined &&
          _actual$constructor.name
        ) {
          msg += `. Received an instance of ${actual.constructor.name}`;
        } else {
          const inspected = inspect$1(actual, {
            depth: -1
          });
          msg += `. Received ${inspected}`;
        }
      } else {
        let inspected = inspect$1(actual, {
          colors: false
        });
        if (inspected.length > 25) {
          inspected = `${inspected.slice(0, 25)}...`;
        }
        msg += `. Received type ${typeof actual} (${inspected})`;
      }
      return msg
    },
    TypeError
  );
  E(
    'ERR_INVALID_ARG_VALUE',
    (name, value, reason = 'is invalid') => {
      let inspected = inspect$1(value);
      if (inspected.length > 128) {
        inspected = inspected.slice(0, 128) + '...';
      }
      const type = name.includes('.') ? 'property' : 'argument';
      return `The ${type} '${name}' ${reason}. Received ${inspected}`
    },
    TypeError
  );
  E(
    'ERR_INVALID_RETURN_VALUE',
    (input, name, value) => {
      var _value$constructor;
      const type =
        value !== null &&
        value !== undefined &&
        (_value$constructor = value.constructor) !== null &&
        _value$constructor !== undefined &&
        _value$constructor.name
          ? `instance of ${value.constructor.name}`
          : `type ${typeof value}`;
      return `Expected ${input} to be returned from the "${name}"` + ` function but got ${type}.`
    },
    TypeError
  );
  E(
    'ERR_MISSING_ARGS',
    (...args) => {
      assert$1(args.length > 0, 'At least one arg needs to be specified');
      let msg;
      const len = args.length;
      args = (Array.isArray(args) ? args : [args]).map((a) => `"${a}"`).join(' or ');
      switch (len) {
        case 1:
          msg += `The ${args[0]} argument`;
          break
        case 2:
          msg += `The ${args[0]} and ${args[1]} arguments`;
          break
        default:
          {
            const last = args.pop();
            msg += `The ${args.join(', ')}, and ${last} arguments`;
          }
          break
      }
      return `${msg} must be specified`
    },
    TypeError
  );
  E(
    'ERR_OUT_OF_RANGE',
    (str, range, input) => {
      assert$1(range, 'Missing "range" argument');
      let received;
      if (Number.isInteger(input) && Math.abs(input) > 2 ** 32) {
        received = addNumericalSeparator(String(input));
      } else if (typeof input === 'bigint') {
        received = String(input);
        const limit = BigInt(2) ** BigInt(32);
        if (input > limit || input < -limit) {
          received = addNumericalSeparator(received);
        }
        received += 'n';
      } else {
        received = inspect$1(input);
      }
      return `The value of "${str}" is out of range. It must be ${range}. Received ${received}`
    },
    RangeError
  );
  E('ERR_MULTIPLE_CALLBACK', 'Callback called multiple times', Error);
  E('ERR_METHOD_NOT_IMPLEMENTED', 'The %s method is not implemented', Error);
  E('ERR_STREAM_ALREADY_FINISHED', 'Cannot call %s after a stream was finished', Error);
  E('ERR_STREAM_CANNOT_PIPE', 'Cannot pipe, not readable', Error);
  E('ERR_STREAM_DESTROYED', 'Cannot call %s after a stream was destroyed', Error);
  E('ERR_STREAM_NULL_VALUES', 'May not write null values to stream', TypeError);
  E('ERR_STREAM_PREMATURE_CLOSE', 'Premature close', Error);
  E('ERR_STREAM_PUSH_AFTER_EOF', 'stream.push() after EOF', Error);
  E('ERR_STREAM_UNSHIFT_AFTER_END_EVENT', 'stream.unshift() after end event', Error);
  E('ERR_STREAM_WRITE_AFTER_END', 'write after end', Error);
  E('ERR_UNKNOWN_ENCODING', 'Unknown encoding: %s', TypeError);
  var errors = {
    AbortError: AbortError$7,
    aggregateTwoErrors: hideStackFrames$1(aggregateTwoErrors$3),
    hideStackFrames: hideStackFrames$1,
    codes: codes$1
  };

  /*globals self, window */

  /*eslint-disable @mysticatea/prettier */
  const { AbortController: AbortController$3, AbortSignal } =
      typeof self !== "undefined" ? self :
      typeof window !== "undefined" ? window :
      /* otherwise */ undefined;
  /*eslint-enable @mysticatea/prettier */

  var browser$1 = AbortController$3;
  var AbortSignal_1 = AbortSignal;
  var _default = AbortController$3;
  browser$1.AbortSignal = AbortSignal_1;
  browser$1.default = _default;

  var util = createCommonjsModule(function (module) {


  const { format, inspect } = inspect$2;
  const {
    codes: { ERR_INVALID_ARG_TYPE }
  } = errors;
  const { kResistStopPropagation, AggregateError, SymbolDispose } = primordials;
  const AbortSignal = globalThis.AbortSignal || browser$1.AbortSignal;
  const AbortController = globalThis.AbortController || browser$1.AbortController;
  const AsyncFunction = Object.getPrototypeOf(async function () {}).constructor;
  const Blob = globalThis.Blob || buffer$1.Blob;
  /* eslint-disable indent */
  const isBlob =
    typeof Blob !== 'undefined'
      ? function isBlob(b) {
          // eslint-disable-next-line indent
          return b instanceof Blob
        }
      : function isBlob(b) {
          return false
        };
  /* eslint-enable indent */

  const validateAbortSignal = (signal, name) => {
    if (signal !== undefined && (signal === null || typeof signal !== 'object' || !('aborted' in signal))) {
      throw new ERR_INVALID_ARG_TYPE(name, 'AbortSignal', signal)
    }
  };
  const validateFunction = (value, name) => {
    if (typeof value !== 'function') {
      throw new ERR_INVALID_ARG_TYPE(name, 'Function', value)
    }
  };
  module.exports = {
    AggregateError,
    kEmptyObject: Object.freeze({}),
    once(callback) {
      let called = false;
      return function (...args) {
        if (called) {
          return
        }
        called = true;
        callback.apply(this, args);
      }
    },
    createDeferredPromise: function () {
      let resolve;
      let reject;

      // eslint-disable-next-line promise/param-names
      const promise = new Promise((res, rej) => {
        resolve = res;
        reject = rej;
      });
      return {
        promise,
        resolve,
        reject
      }
    },
    promisify(fn) {
      return new Promise((resolve, reject) => {
        fn((err, ...args) => {
          if (err) {
            return reject(err)
          }
          return resolve(...args)
        });
      })
    },
    debuglog() {
      return function () {}
    },
    format,
    inspect,
    types: {
      isAsyncFunction(fn) {
        return fn instanceof AsyncFunction
      },
      isArrayBufferView(arr) {
        return ArrayBuffer.isView(arr)
      }
    },
    isBlob,
    deprecate(fn, message) {
      return fn
    },
    addAbortListener:
      events.addAbortListener ||
      function addAbortListener(signal, listener) {
        if (signal === undefined) {
          throw new ERR_INVALID_ARG_TYPE('signal', 'AbortSignal', signal)
        }
        validateAbortSignal(signal, 'signal');
        validateFunction(listener, 'listener');
        let removeEventListener;
        if (signal.aborted) {
          queueMicrotask(() => listener());
        } else {
          signal.addEventListener('abort', listener, {
            __proto__: null,
            once: true,
            [kResistStopPropagation]: true
          });
          removeEventListener = () => {
            signal.removeEventListener('abort', listener);
          };
        }
        return {
          __proto__: null,
          [SymbolDispose]() {
            var _removeEventListener
            ;(_removeEventListener = removeEventListener) === null || _removeEventListener === undefined
              ? undefined
              : _removeEventListener();
          }
        }
      },
    AbortSignalAny:
      AbortSignal.any ||
      function AbortSignalAny(signals) {
        // Fast path if there is only one signal.
        if (signals.length === 1) {
          return signals[0]
        }
        const ac = new AbortController();
        const abort = () => ac.abort();
        signals.forEach((signal) => {
          validateAbortSignal(signal, 'signals');
          signal.addEventListener('abort', abort, {
            once: true
          });
        });
        ac.signal.addEventListener(
          'abort',
          () => {
            signals.forEach((signal) => signal.removeEventListener('abort', abort));
          },
          {
            once: true
          }
        );
        return ac.signal
      }
  };
  module.exports.promisify.custom = Symbol.for('nodejs.util.promisify.custom');
  });

  const {
    ArrayIsArray: ArrayIsArray$2,
    ArrayPrototypeIncludes,
    ArrayPrototypeJoin,
    ArrayPrototypeMap,
    NumberIsInteger: NumberIsInteger$2,
    NumberIsNaN: NumberIsNaN$2,
    NumberMAX_SAFE_INTEGER,
    NumberMIN_SAFE_INTEGER,
    NumberParseInt: NumberParseInt$1,
    ObjectPrototypeHasOwnProperty,
    RegExpPrototypeExec,
    String: String$1,
    StringPrototypeToUpperCase,
    StringPrototypeTrim
  } = primordials;
  const {
    hideStackFrames,
    codes: { ERR_SOCKET_BAD_PORT, ERR_INVALID_ARG_TYPE: ERR_INVALID_ARG_TYPE$7, ERR_INVALID_ARG_VALUE: ERR_INVALID_ARG_VALUE$3, ERR_OUT_OF_RANGE: ERR_OUT_OF_RANGE$2, ERR_UNKNOWN_SIGNAL }
  } = errors;
  const { normalizeEncoding: normalizeEncoding$1 } = util;
  const { isAsyncFunction, isArrayBufferView } = util.types;
  const signals = {};

  /**
   * @param {*} value
   * @returns {boolean}
   */
  function isInt32(value) {
    return value === (value | 0)
  }

  /**
   * @param {*} value
   * @returns {boolean}
   */
  function isUint32(value) {
    return value === value >>> 0
  }
  const octalReg = /^[0-7]+$/;
  const modeDesc = 'must be a 32-bit unsigned integer or an octal string';

  /**
   * Parse and validate values that will be converted into mode_t (the S_*
   * constants). Only valid numbers and octal strings are allowed. They could be
   * converted to 32-bit unsigned integers or non-negative signed integers in the
   * C++ land, but any value higher than 0o777 will result in platform-specific
   * behaviors.
   * @param {*} value Values to be validated
   * @param {string} name Name of the argument
   * @param {number} [def] If specified, will be returned for invalid values
   * @returns {number}
   */
  function parseFileMode(value, name, def) {
    if (typeof value === 'undefined') {
      value = def;
    }
    if (typeof value === 'string') {
      if (RegExpPrototypeExec(octalReg, value) === null) {
        throw new ERR_INVALID_ARG_VALUE$3(name, value, modeDesc)
      }
      value = NumberParseInt$1(value, 8);
    }
    validateUint32(value, name);
    return value
  }

  /**
   * @callback validateInteger
   * @param {*} value
   * @param {string} name
   * @param {number} [min]
   * @param {number} [max]
   * @returns {asserts value is number}
   */

  /** @type {validateInteger} */
  const validateInteger$2 = hideStackFrames((value, name, min = NumberMIN_SAFE_INTEGER, max = NumberMAX_SAFE_INTEGER) => {
    if (typeof value !== 'number') throw new ERR_INVALID_ARG_TYPE$7(name, 'number', value)
    if (!NumberIsInteger$2(value)) throw new ERR_OUT_OF_RANGE$2(name, 'an integer', value)
    if (value < min || value > max) throw new ERR_OUT_OF_RANGE$2(name, `>= ${min} && <= ${max}`, value)
  });

  /**
   * @callback validateInt32
   * @param {*} value
   * @param {string} name
   * @param {number} [min]
   * @param {number} [max]
   * @returns {asserts value is number}
   */

  /** @type {validateInt32} */
  const validateInt32 = hideStackFrames((value, name, min = -2147483648, max = 2147483647) => {
    // The defaults for min and max correspond to the limits of 32-bit integers.
    if (typeof value !== 'number') {
      throw new ERR_INVALID_ARG_TYPE$7(name, 'number', value)
    }
    if (!NumberIsInteger$2(value)) {
      throw new ERR_OUT_OF_RANGE$2(name, 'an integer', value)
    }
    if (value < min || value > max) {
      throw new ERR_OUT_OF_RANGE$2(name, `>= ${min} && <= ${max}`, value)
    }
  });

  /**
   * @callback validateUint32
   * @param {*} value
   * @param {string} name
   * @param {number|boolean} [positive=false]
   * @returns {asserts value is number}
   */

  /** @type {validateUint32} */
  const validateUint32 = hideStackFrames((value, name, positive = false) => {
    if (typeof value !== 'number') {
      throw new ERR_INVALID_ARG_TYPE$7(name, 'number', value)
    }
    if (!NumberIsInteger$2(value)) {
      throw new ERR_OUT_OF_RANGE$2(name, 'an integer', value)
    }
    const min = positive ? 1 : 0;
    // 2 ** 32 === 4294967296
    const max = 4294967295;
    if (value < min || value > max) {
      throw new ERR_OUT_OF_RANGE$2(name, `>= ${min} && <= ${max}`, value)
    }
  });

  /**
   * @callback validateString
   * @param {*} value
   * @param {string} name
   * @returns {asserts value is string}
   */

  /** @type {validateString} */
  function validateString(value, name) {
    if (typeof value !== 'string') throw new ERR_INVALID_ARG_TYPE$7(name, 'string', value)
  }

  /**
   * @callback validateNumber
   * @param {*} value
   * @param {string} name
   * @param {number} [min]
   * @param {number} [max]
   * @returns {asserts value is number}
   */

  /** @type {validateNumber} */
  function validateNumber(value, name, min = undefined, max) {
    if (typeof value !== 'number') throw new ERR_INVALID_ARG_TYPE$7(name, 'number', value)
    if (
      (min != null && value < min) ||
      (max != null && value > max) ||
      ((min != null || max != null) && NumberIsNaN$2(value))
    ) {
      throw new ERR_OUT_OF_RANGE$2(
        name,
        `${min != null ? `>= ${min}` : ''}${min != null && max != null ? ' && ' : ''}${max != null ? `<= ${max}` : ''}`,
        value
      )
    }
  }

  /**
   * @callback validateOneOf
   * @template T
   * @param {T} value
   * @param {string} name
   * @param {T[]} oneOf
   */

  /** @type {validateOneOf} */
  const validateOneOf = hideStackFrames((value, name, oneOf) => {
    if (!ArrayPrototypeIncludes(oneOf, value)) {
      const allowed = ArrayPrototypeJoin(
        ArrayPrototypeMap(oneOf, (v) => (typeof v === 'string' ? `'${v}'` : String$1(v))),
        ', '
      );
      const reason = 'must be one of: ' + allowed;
      throw new ERR_INVALID_ARG_VALUE$3(name, value, reason)
    }
  });

  /**
   * @callback validateBoolean
   * @param {*} value
   * @param {string} name
   * @returns {asserts value is boolean}
   */

  /** @type {validateBoolean} */
  function validateBoolean$1(value, name) {
    if (typeof value !== 'boolean') throw new ERR_INVALID_ARG_TYPE$7(name, 'boolean', value)
  }

  /**
   * @param {any} options
   * @param {string} key
   * @param {boolean} defaultValue
   * @returns {boolean}
   */
  function getOwnPropertyValueOrDefault(options, key, defaultValue) {
    return options == null || !ObjectPrototypeHasOwnProperty(options, key) ? defaultValue : options[key]
  }

  /**
   * @callback validateObject
   * @param {*} value
   * @param {string} name
   * @param {{
   *   allowArray?: boolean,
   *   allowFunction?: boolean,
   *   nullable?: boolean
   * }} [options]
   */

  /** @type {validateObject} */
  const validateObject$3 = hideStackFrames((value, name, options = null) => {
    const allowArray = getOwnPropertyValueOrDefault(options, 'allowArray', false);
    const allowFunction = getOwnPropertyValueOrDefault(options, 'allowFunction', false);
    const nullable = getOwnPropertyValueOrDefault(options, 'nullable', false);
    if (
      (!nullable && value === null) ||
      (!allowArray && ArrayIsArray$2(value)) ||
      (typeof value !== 'object' && (!allowFunction || typeof value !== 'function'))
    ) {
      throw new ERR_INVALID_ARG_TYPE$7(name, 'Object', value)
    }
  });

  /**
   * @callback validateDictionary - We are using the Web IDL Standard definition
   *                                of "dictionary" here, which means any value
   *                                whose Type is either Undefined, Null, or
   *                                Object (which includes functions).
   * @param {*} value
   * @param {string} name
   * @see https://webidl.spec.whatwg.org/#es-dictionary
   * @see https://tc39.es/ecma262/#table-typeof-operator-results
   */

  /** @type {validateDictionary} */
  const validateDictionary = hideStackFrames((value, name) => {
    if (value != null && typeof value !== 'object' && typeof value !== 'function') {
      throw new ERR_INVALID_ARG_TYPE$7(name, 'a dictionary', value)
    }
  });

  /**
   * @callback validateArray
   * @param {*} value
   * @param {string} name
   * @param {number} [minLength]
   * @returns {asserts value is any[]}
   */

  /** @type {validateArray} */
  const validateArray = hideStackFrames((value, name, minLength = 0) => {
    if (!ArrayIsArray$2(value)) {
      throw new ERR_INVALID_ARG_TYPE$7(name, 'Array', value)
    }
    if (value.length < minLength) {
      const reason = `must be longer than ${minLength}`;
      throw new ERR_INVALID_ARG_VALUE$3(name, value, reason)
    }
  });

  /**
   * @callback validateStringArray
   * @param {*} value
   * @param {string} name
   * @returns {asserts value is string[]}
   */

  /** @type {validateStringArray} */
  function validateStringArray(value, name) {
    validateArray(value, name);
    for (let i = 0; i < value.length; i++) {
      validateString(value[i], `${name}[${i}]`);
    }
  }

  /**
   * @callback validateBooleanArray
   * @param {*} value
   * @param {string} name
   * @returns {asserts value is boolean[]}
   */

  /** @type {validateBooleanArray} */
  function validateBooleanArray(value, name) {
    validateArray(value, name);
    for (let i = 0; i < value.length; i++) {
      validateBoolean$1(value[i], `${name}[${i}]`);
    }
  }

  /**
   * @callback validateAbortSignalArray
   * @param {*} value
   * @param {string} name
   * @returns {asserts value is AbortSignal[]}
   */

  /** @type {validateAbortSignalArray} */
  function validateAbortSignalArray(value, name) {
    validateArray(value, name);
    for (let i = 0; i < value.length; i++) {
      const signal = value[i];
      const indexedName = `${name}[${i}]`;
      if (signal == null) {
        throw new ERR_INVALID_ARG_TYPE$7(indexedName, 'AbortSignal', signal)
      }
      validateAbortSignal$3(signal, indexedName);
    }
  }

  /**
   * @param {*} signal
   * @param {string} [name='signal']
   * @returns {asserts signal is keyof signals}
   */
  function validateSignalName(signal, name = 'signal') {
    validateString(signal, name);
    if (signals[signal] === undefined) {
      if (signals[StringPrototypeToUpperCase(signal)] !== undefined) {
        throw new ERR_UNKNOWN_SIGNAL(signal + ' (signals must use all capital letters)')
      }
      throw new ERR_UNKNOWN_SIGNAL(signal)
    }
  }

  /**
   * @callback validateBuffer
   * @param {*} buffer
   * @param {string} [name='buffer']
   * @returns {asserts buffer is ArrayBufferView}
   */

  /** @type {validateBuffer} */
  const validateBuffer = hideStackFrames((buffer, name = 'buffer') => {
    if (!isArrayBufferView(buffer)) {
      throw new ERR_INVALID_ARG_TYPE$7(name, ['Buffer', 'TypedArray', 'DataView'], buffer)
    }
  });

  /**
   * @param {string} data
   * @param {string} encoding
   */
  function validateEncoding(data, encoding) {
    const normalizedEncoding = normalizeEncoding$1(encoding);
    const length = data.length;
    if (normalizedEncoding === 'hex' && length % 2 !== 0) {
      throw new ERR_INVALID_ARG_VALUE$3('encoding', encoding, `is invalid for data of length ${length}`)
    }
  }

  /**
   * Check that the port number is not NaN when coerced to a number,
   * is an integer and that it falls within the legal range of port numbers.
   * @param {*} port
   * @param {string} [name='Port']
   * @param {boolean} [allowZero=true]
   * @returns {number}
   */
  function validatePort(port, name = 'Port', allowZero = true) {
    if (
      (typeof port !== 'number' && typeof port !== 'string') ||
      (typeof port === 'string' && StringPrototypeTrim(port).length === 0) ||
      +port !== +port >>> 0 ||
      port > 0xffff ||
      (port === 0 && !allowZero)
    ) {
      throw new ERR_SOCKET_BAD_PORT(name, port, allowZero)
    }
    return port | 0
  }

  /**
   * @callback validateAbortSignal
   * @param {*} signal
   * @param {string} name
   */

  /** @type {validateAbortSignal} */
  const validateAbortSignal$3 = hideStackFrames((signal, name) => {
    if (signal !== undefined && (signal === null || typeof signal !== 'object' || !('aborted' in signal))) {
      throw new ERR_INVALID_ARG_TYPE$7(name, 'AbortSignal', signal)
    }
  });

  /**
   * @callback validateFunction
   * @param {*} value
   * @param {string} name
   * @returns {asserts value is Function}
   */

  /** @type {validateFunction} */
  const validateFunction$2 = hideStackFrames((value, name) => {
    if (typeof value !== 'function') throw new ERR_INVALID_ARG_TYPE$7(name, 'Function', value)
  });

  /**
   * @callback validatePlainFunction
   * @param {*} value
   * @param {string} name
   * @returns {asserts value is Function}
   */

  /** @type {validatePlainFunction} */
  const validatePlainFunction = hideStackFrames((value, name) => {
    if (typeof value !== 'function' || isAsyncFunction(value)) throw new ERR_INVALID_ARG_TYPE$7(name, 'Function', value)
  });

  /**
   * @callback validateUndefined
   * @param {*} value
   * @param {string} name
   * @returns {asserts value is undefined}
   */

  /** @type {validateUndefined} */
  const validateUndefined = hideStackFrames((value, name) => {
    if (value !== undefined) throw new ERR_INVALID_ARG_TYPE$7(name, 'undefined', value)
  });

  /**
   * @template T
   * @param {T} value
   * @param {string} name
   * @param {T[]} union
   */
  function validateUnion(value, name, union) {
    if (!ArrayPrototypeIncludes(union, value)) {
      throw new ERR_INVALID_ARG_TYPE$7(name, `('${ArrayPrototypeJoin(union, '|')}')`, value)
    }
  }

  /*
    The rules for the Link header field are described here:
    https://www.rfc-editor.org/rfc/rfc8288.html#section-3

    This regex validates any string surrounded by angle brackets
    (not necessarily a valid URI reference) followed by zero or more
    link-params separated by semicolons.
  */
  const linkValueRegExp = /^(?:<[^>]*>)(?:\s*;\s*[^;"\s]+(?:=(")?[^;"\s]*\1)?)*$/;

  /**
   * @param {any} value
   * @param {string} name
   */
  function validateLinkHeaderFormat(value, name) {
    if (typeof value === 'undefined' || !RegExpPrototypeExec(linkValueRegExp, value)) {
      throw new ERR_INVALID_ARG_VALUE$3(
        name,
        value,
        'must be an array or string of format "</styles.css>; rel=preload; as=style"'
      )
    }
  }

  /**
   * @param {any} hints
   * @return {string}
   */
  function validateLinkHeaderValue(hints) {
    if (typeof hints === 'string') {
      validateLinkHeaderFormat(hints, 'hints');
      return hints
    } else if (ArrayIsArray$2(hints)) {
      const hintsLength = hints.length;
      let result = '';
      if (hintsLength === 0) {
        return result
      }
      for (let i = 0; i < hintsLength; i++) {
        const link = hints[i];
        validateLinkHeaderFormat(link, 'hints');
        result += link;
        if (i !== hintsLength - 1) {
          result += ', ';
        }
      }
      return result
    }
    throw new ERR_INVALID_ARG_VALUE$3(
      'hints',
      hints,
      'must be an array or string of format "</styles.css>; rel=preload; as=style"'
    )
  }
  var validators = {
    isInt32,
    isUint32,
    parseFileMode,
    validateArray,
    validateStringArray,
    validateBooleanArray,
    validateAbortSignalArray,
    validateBoolean: validateBoolean$1,
    validateBuffer,
    validateDictionary,
    validateEncoding,
    validateFunction: validateFunction$2,
    validateInt32,
    validateInteger: validateInteger$2,
    validateNumber,
    validateObject: validateObject$3,
    validateOneOf,
    validatePlainFunction,
    validatePort,
    validateSignalName,
    validateString,
    validateUint32,
    validateUndefined,
    validateUnion,
    validateAbortSignal: validateAbortSignal$3,
    validateLinkHeaderValue
  };

  const { SymbolAsyncIterator: SymbolAsyncIterator$3, SymbolIterator: SymbolIterator$2, SymbolFor } = primordials;

  // We need to use SymbolFor to make these globally available
  // for interopt with readable-stream, i.e. readable-stream
  // and node core needs to be able to read/write private state
  // from each other for proper interoperability.
  const kIsDestroyed$1 = SymbolFor('nodejs.stream.destroyed');
  const kIsErrored = SymbolFor('nodejs.stream.errored');
  const kIsReadable = SymbolFor('nodejs.stream.readable');
  const kIsWritable = SymbolFor('nodejs.stream.writable');
  const kIsDisturbed = SymbolFor('nodejs.stream.disturbed');
  const kIsClosedPromise$1 = SymbolFor('nodejs.webstream.isClosedPromise');
  const kControllerErrorFunction = SymbolFor('nodejs.webstream.controllerErrorFunction');
  function isReadableNodeStream$3(obj, strict = false) {
    var _obj$_readableState;
    return !!(
      (
        obj &&
        typeof obj.pipe === 'function' &&
        typeof obj.on === 'function' &&
        (!strict || (typeof obj.pause === 'function' && typeof obj.resume === 'function')) &&
        (!obj._writableState ||
          ((_obj$_readableState = obj._readableState) === null || _obj$_readableState === undefined
            ? undefined
            : _obj$_readableState.readable) !== false) &&
        // Duplex
        (!obj._writableState || obj._readableState)
      ) // Writable has .pipe.
    )
  }
  function isWritableNodeStream$2(obj) {
    var _obj$_writableState;
    return !!(
      (
        obj &&
        typeof obj.write === 'function' &&
        typeof obj.on === 'function' &&
        (!obj._readableState ||
          ((_obj$_writableState = obj._writableState) === null || _obj$_writableState === undefined
            ? undefined
            : _obj$_writableState.writable) !== false)
      ) // Duplex
    )
  }
  function isDuplexNodeStream$1(obj) {
    return !!(
      obj &&
      typeof obj.pipe === 'function' &&
      obj._readableState &&
      typeof obj.on === 'function' &&
      typeof obj.write === 'function'
    )
  }
  function isNodeStream$6(obj) {
    return (
      obj &&
      (obj._readableState ||
        obj._writableState ||
        (typeof obj.write === 'function' && typeof obj.on === 'function') ||
        (typeof obj.pipe === 'function' && typeof obj.on === 'function'))
    )
  }
  function isReadableStream$4(obj) {
    return !!(
      obj &&
      !isNodeStream$6(obj) &&
      typeof obj.pipeThrough === 'function' &&
      typeof obj.getReader === 'function' &&
      typeof obj.cancel === 'function'
    )
  }
  function isWritableStream$3(obj) {
    return !!(obj && !isNodeStream$6(obj) && typeof obj.getWriter === 'function' && typeof obj.abort === 'function')
  }
  function isTransformStream$2(obj) {
    return !!(obj && !isNodeStream$6(obj) && typeof obj.readable === 'object' && typeof obj.writable === 'object')
  }
  function isWebStream$3(obj) {
    return isReadableStream$4(obj) || isWritableStream$3(obj) || isTransformStream$2(obj)
  }
  function isIterable$3(obj, isAsync) {
    if (obj == null) return false
    if (isAsync === true) return typeof obj[SymbolAsyncIterator$3] === 'function'
    if (isAsync === false) return typeof obj[SymbolIterator$2] === 'function'
    return typeof obj[SymbolAsyncIterator$3] === 'function' || typeof obj[SymbolIterator$2] === 'function'
  }
  function isDestroyed$1(stream) {
    if (!isNodeStream$6(stream)) return null
    const wState = stream._writableState;
    const rState = stream._readableState;
    const state = wState || rState;
    return !!(stream.destroyed || stream[kIsDestroyed$1] || (state !== null && state !== undefined && state.destroyed))
  }

  // Have been end():d.
  function isWritableEnded(stream) {
    if (!isWritableNodeStream$2(stream)) return null
    if (stream.writableEnded === true) return true
    const wState = stream._writableState;
    if (wState !== null && wState !== undefined && wState.errored) return false
    if (typeof (wState === null || wState === undefined ? undefined : wState.ended) !== 'boolean') return null
    return wState.ended
  }

  // Have emitted 'finish'.
  function isWritableFinished$1(stream, strict) {
    if (!isWritableNodeStream$2(stream)) return null
    if (stream.writableFinished === true) return true
    const wState = stream._writableState;
    if (wState !== null && wState !== undefined && wState.errored) return false
    if (typeof (wState === null || wState === undefined ? undefined : wState.finished) !== 'boolean') return null
    return !!(wState.finished || (strict === false && wState.ended === true && wState.length === 0))
  }

  // Have been push(null):d.
  function isReadableEnded(stream) {
    if (!isReadableNodeStream$3(stream)) return null
    if (stream.readableEnded === true) return true
    const rState = stream._readableState;
    if (!rState || rState.errored) return false
    if (typeof (rState === null || rState === undefined ? undefined : rState.ended) !== 'boolean') return null
    return rState.ended
  }

  // Have emitted 'end'.
  function isReadableFinished$2(stream, strict) {
    if (!isReadableNodeStream$3(stream)) return null
    const rState = stream._readableState;
    if (rState !== null && rState !== undefined && rState.errored) return false
    if (typeof (rState === null || rState === undefined ? undefined : rState.endEmitted) !== 'boolean') return null
    return !!(rState.endEmitted || (strict === false && rState.ended === true && rState.length === 0))
  }
  function isReadable$4(stream) {
    if (stream && stream[kIsReadable] != null) return stream[kIsReadable]
    if (typeof (stream === null || stream === undefined ? undefined : stream.readable) !== 'boolean') return null
    if (isDestroyed$1(stream)) return false
    return isReadableNodeStream$3(stream) && stream.readable && !isReadableFinished$2(stream)
  }
  function isWritable$4(stream) {
    if (stream && stream[kIsWritable] != null) return stream[kIsWritable]
    if (typeof (stream === null || stream === undefined ? undefined : stream.writable) !== 'boolean') return null
    if (isDestroyed$1(stream)) return false
    return isWritableNodeStream$2(stream) && stream.writable && !isWritableEnded(stream)
  }
  function isFinished$1(stream, opts) {
    if (!isNodeStream$6(stream)) {
      return null
    }
    if (isDestroyed$1(stream)) {
      return true
    }
    if ((opts === null || opts === undefined ? undefined : opts.readable) !== false && isReadable$4(stream)) {
      return false
    }
    if ((opts === null || opts === undefined ? undefined : opts.writable) !== false && isWritable$4(stream)) {
      return false
    }
    return true
  }
  function isWritableErrored$1(stream) {
    var _stream$_writableStat, _stream$_writableStat2;
    if (!isNodeStream$6(stream)) {
      return null
    }
    if (stream.writableErrored) {
      return stream.writableErrored
    }
    return (_stream$_writableStat =
      (_stream$_writableStat2 = stream._writableState) === null || _stream$_writableStat2 === undefined
        ? undefined
        : _stream$_writableStat2.errored) !== null && _stream$_writableStat !== undefined
      ? _stream$_writableStat
      : null
  }
  function isReadableErrored$1(stream) {
    var _stream$_readableStat, _stream$_readableStat2;
    if (!isNodeStream$6(stream)) {
      return null
    }
    if (stream.readableErrored) {
      return stream.readableErrored
    }
    return (_stream$_readableStat =
      (_stream$_readableStat2 = stream._readableState) === null || _stream$_readableStat2 === undefined
        ? undefined
        : _stream$_readableStat2.errored) !== null && _stream$_readableStat !== undefined
      ? _stream$_readableStat
      : null
  }
  function isClosed$1(stream) {
    if (!isNodeStream$6(stream)) {
      return null
    }
    if (typeof stream.closed === 'boolean') {
      return stream.closed
    }
    const wState = stream._writableState;
    const rState = stream._readableState;
    if (
      typeof (wState === null || wState === undefined ? undefined : wState.closed) === 'boolean' ||
      typeof (rState === null || rState === undefined ? undefined : rState.closed) === 'boolean'
    ) {
      return (
        (wState === null || wState === undefined ? undefined : wState.closed) ||
        (rState === null || rState === undefined ? undefined : rState.closed)
      )
    }
    if (typeof stream._closed === 'boolean' && isOutgoingMessage(stream)) {
      return stream._closed
    }
    return null
  }
  function isOutgoingMessage(stream) {
    return (
      typeof stream._closed === 'boolean' &&
      typeof stream._defaultKeepAlive === 'boolean' &&
      typeof stream._removedConnection === 'boolean' &&
      typeof stream._removedContLen === 'boolean'
    )
  }
  function isServerResponse(stream) {
    return typeof stream._sent100 === 'boolean' && isOutgoingMessage(stream)
  }
  function isServerRequest$1(stream) {
    var _stream$req;
    return (
      typeof stream._consuming === 'boolean' &&
      typeof stream._dumped === 'boolean' &&
      ((_stream$req = stream.req) === null || _stream$req === undefined ? undefined : _stream$req.upgradeOrConnect) ===
        undefined
    )
  }
  function willEmitClose(stream) {
    if (!isNodeStream$6(stream)) return null
    const wState = stream._writableState;
    const rState = stream._readableState;
    const state = wState || rState;
    return (
      (!state && isServerResponse(stream)) || !!(state && state.autoDestroy && state.emitClose && state.closed === false)
    )
  }
  function isDisturbed(stream) {
    var _stream$kIsDisturbed;
    return !!(
      stream &&
      ((_stream$kIsDisturbed = stream[kIsDisturbed]) !== null && _stream$kIsDisturbed !== undefined
        ? _stream$kIsDisturbed
        : stream.readableDidRead || stream.readableAborted)
    )
  }
  function isErrored(stream) {
    var _ref,
      _ref2,
      _ref3,
      _ref4,
      _ref5,
      _stream$kIsErrored,
      _stream$_readableStat3,
      _stream$_writableStat3,
      _stream$_readableStat4,
      _stream$_writableStat4;
    return !!(
      stream &&
      ((_ref =
        (_ref2 =
          (_ref3 =
            (_ref4 =
              (_ref5 =
                (_stream$kIsErrored = stream[kIsErrored]) !== null && _stream$kIsErrored !== undefined
                  ? _stream$kIsErrored
                  : stream.readableErrored) !== null && _ref5 !== undefined
                ? _ref5
                : stream.writableErrored) !== null && _ref4 !== undefined
              ? _ref4
              : (_stream$_readableStat3 = stream._readableState) === null || _stream$_readableStat3 === undefined
              ? undefined
              : _stream$_readableStat3.errorEmitted) !== null && _ref3 !== undefined
            ? _ref3
            : (_stream$_writableStat3 = stream._writableState) === null || _stream$_writableStat3 === undefined
            ? undefined
            : _stream$_writableStat3.errorEmitted) !== null && _ref2 !== undefined
          ? _ref2
          : (_stream$_readableStat4 = stream._readableState) === null || _stream$_readableStat4 === undefined
          ? undefined
          : _stream$_readableStat4.errored) !== null && _ref !== undefined
        ? _ref
        : (_stream$_writableStat4 = stream._writableState) === null || _stream$_writableStat4 === undefined
        ? undefined
        : _stream$_writableStat4.errored)
    )
  }
  var utils = {
    isDestroyed: isDestroyed$1,
    kIsDestroyed: kIsDestroyed$1,
    isDisturbed,
    kIsDisturbed,
    isErrored,
    kIsErrored,
    isReadable: isReadable$4,
    kIsReadable,
    kIsClosedPromise: kIsClosedPromise$1,
    kControllerErrorFunction,
    kIsWritable,
    isClosed: isClosed$1,
    isDuplexNodeStream: isDuplexNodeStream$1,
    isFinished: isFinished$1,
    isIterable: isIterable$3,
    isReadableNodeStream: isReadableNodeStream$3,
    isReadableStream: isReadableStream$4,
    isReadableEnded,
    isReadableFinished: isReadableFinished$2,
    isReadableErrored: isReadableErrored$1,
    isNodeStream: isNodeStream$6,
    isWebStream: isWebStream$3,
    isWritable: isWritable$4,
    isWritableNodeStream: isWritableNodeStream$2,
    isWritableStream: isWritableStream$3,
    isWritableEnded,
    isWritableFinished: isWritableFinished$1,
    isWritableErrored: isWritableErrored$1,
    isServerRequest: isServerRequest$1,
    isServerResponse,
    willEmitClose,
    isTransformStream: isTransformStream$2
  };

  /* replacement start */



  /* replacement end */

  const { AbortError: AbortError$6, codes } = errors;
  const { ERR_INVALID_ARG_TYPE: ERR_INVALID_ARG_TYPE$6, ERR_STREAM_PREMATURE_CLOSE: ERR_STREAM_PREMATURE_CLOSE$1 } = codes;
  const { kEmptyObject, once: once$1 } = util;
  const { validateAbortSignal: validateAbortSignal$2, validateFunction: validateFunction$1, validateObject: validateObject$2, validateBoolean } = validators;
  const { Promise: Promise$5, PromisePrototypeThen: PromisePrototypeThen$2, SymbolDispose: SymbolDispose$1 } = primordials;
  const {
    isClosed,
    isReadable: isReadable$3,
    isReadableNodeStream: isReadableNodeStream$2,
    isReadableStream: isReadableStream$3,
    isReadableFinished: isReadableFinished$1,
    isReadableErrored,
    isWritable: isWritable$3,
    isWritableNodeStream: isWritableNodeStream$1,
    isWritableStream: isWritableStream$2,
    isWritableFinished,
    isWritableErrored,
    isNodeStream: isNodeStream$5,
    willEmitClose: _willEmitClose,
    kIsClosedPromise
  } = utils;
  let addAbortListener$1;
  function isRequest$1(stream) {
    return stream.setHeader && typeof stream.abort === 'function'
  }
  const nop$2 = () => {};
  function eos(stream, options, callback) {
    var _options$readable, _options$writable;
    if (arguments.length === 2) {
      callback = options;
      options = kEmptyObject;
    } else if (options == null) {
      options = kEmptyObject;
    } else {
      validateObject$2(options, 'options');
    }
    validateFunction$1(callback, 'callback');
    validateAbortSignal$2(options.signal, 'options.signal');
    callback = once$1(callback);
    if (isReadableStream$3(stream) || isWritableStream$2(stream)) {
      return eosWeb(stream, options, callback)
    }
    if (!isNodeStream$5(stream)) {
      throw new ERR_INVALID_ARG_TYPE$6('stream', ['ReadableStream', 'WritableStream', 'Stream'], stream)
    }
    const readable =
      (_options$readable = options.readable) !== null && _options$readable !== undefined
        ? _options$readable
        : isReadableNodeStream$2(stream);
    const writable =
      (_options$writable = options.writable) !== null && _options$writable !== undefined
        ? _options$writable
        : isWritableNodeStream$1(stream);
    const wState = stream._writableState;
    const rState = stream._readableState;
    const onlegacyfinish = () => {
      if (!stream.writable) {
        onfinish();
      }
    };

    // TODO (ronag): Improve soft detection to include core modules and
    // common ecosystem modules that do properly emit 'close' but fail
    // this generic check.
    let willEmitClose =
      _willEmitClose(stream) && isReadableNodeStream$2(stream) === readable && isWritableNodeStream$1(stream) === writable;
    let writableFinished = isWritableFinished(stream, false);
    const onfinish = () => {
      writableFinished = true;
      // Stream should not be destroyed here. If it is that
      // means that user space is doing something differently and
      // we cannot trust willEmitClose.
      if (stream.destroyed) {
        willEmitClose = false;
      }
      if (willEmitClose && (!stream.readable || readable)) {
        return
      }
      if (!readable || readableFinished) {
        callback.call(stream);
      }
    };
    let readableFinished = isReadableFinished$1(stream, false);
    const onend = () => {
      readableFinished = true;
      // Stream should not be destroyed here. If it is that
      // means that user space is doing something differently and
      // we cannot trust willEmitClose.
      if (stream.destroyed) {
        willEmitClose = false;
      }
      if (willEmitClose && (!stream.writable || writable)) {
        return
      }
      if (!writable || writableFinished) {
        callback.call(stream);
      }
    };
    const onerror = (err) => {
      callback.call(stream, err);
    };
    let closed = isClosed(stream);
    const onclose = () => {
      closed = true;
      const errored = isWritableErrored(stream) || isReadableErrored(stream);
      if (errored && typeof errored !== 'boolean') {
        return callback.call(stream, errored)
      }
      if (readable && !readableFinished && isReadableNodeStream$2(stream, true)) {
        if (!isReadableFinished$1(stream, false)) return callback.call(stream, new ERR_STREAM_PREMATURE_CLOSE$1())
      }
      if (writable && !writableFinished) {
        if (!isWritableFinished(stream, false)) return callback.call(stream, new ERR_STREAM_PREMATURE_CLOSE$1())
      }
      callback.call(stream);
    };
    const onclosed = () => {
      closed = true;
      const errored = isWritableErrored(stream) || isReadableErrored(stream);
      if (errored && typeof errored !== 'boolean') {
        return callback.call(stream, errored)
      }
      callback.call(stream);
    };
    const onrequest = () => {
      stream.req.on('finish', onfinish);
    };
    if (isRequest$1(stream)) {
      stream.on('complete', onfinish);
      if (!willEmitClose) {
        stream.on('abort', onclose);
      }
      if (stream.req) {
        onrequest();
      } else {
        stream.on('request', onrequest);
      }
    } else if (writable && !wState) {
      // legacy streams
      stream.on('end', onlegacyfinish);
      stream.on('close', onlegacyfinish);
    }

    // Not all streams will emit 'close' after 'aborted'.
    if (!willEmitClose && typeof stream.aborted === 'boolean') {
      stream.on('aborted', onclose);
    }
    stream.on('end', onend);
    stream.on('finish', onfinish);
    if (options.error !== false) {
      stream.on('error', onerror);
    }
    stream.on('close', onclose);
    if (closed) {
      browser$2.nextTick(onclose);
    } else if (
      (wState !== null && wState !== undefined && wState.errorEmitted) ||
      (rState !== null && rState !== undefined && rState.errorEmitted)
    ) {
      if (!willEmitClose) {
        browser$2.nextTick(onclosed);
      }
    } else if (
      !readable &&
      (!willEmitClose || isReadable$3(stream)) &&
      (writableFinished || isWritable$3(stream) === false)
    ) {
      browser$2.nextTick(onclosed);
    } else if (
      !writable &&
      (!willEmitClose || isWritable$3(stream)) &&
      (readableFinished || isReadable$3(stream) === false)
    ) {
      browser$2.nextTick(onclosed);
    } else if (rState && stream.req && stream.aborted) {
      browser$2.nextTick(onclosed);
    }
    const cleanup = () => {
      callback = nop$2;
      stream.removeListener('aborted', onclose);
      stream.removeListener('complete', onfinish);
      stream.removeListener('abort', onclose);
      stream.removeListener('request', onrequest);
      if (stream.req) stream.req.removeListener('finish', onfinish);
      stream.removeListener('end', onlegacyfinish);
      stream.removeListener('close', onlegacyfinish);
      stream.removeListener('finish', onfinish);
      stream.removeListener('end', onend);
      stream.removeListener('error', onerror);
      stream.removeListener('close', onclose);
    };
    if (options.signal && !closed) {
      const abort = () => {
        // Keep it because cleanup removes it.
        const endCallback = callback;
        cleanup();
        endCallback.call(
          stream,
          new AbortError$6(undefined, {
            cause: options.signal.reason
          })
        );
      };
      if (options.signal.aborted) {
        browser$2.nextTick(abort);
      } else {
        addAbortListener$1 = addAbortListener$1 || util.addAbortListener;
        const disposable = addAbortListener$1(options.signal, abort);
        const originalCallback = callback;
        callback = once$1((...args) => {
          disposable[SymbolDispose$1]();
          originalCallback.apply(stream, args);
        });
      }
    }
    return cleanup
  }
  function eosWeb(stream, options, callback) {
    let isAborted = false;
    let abort = nop$2;
    if (options.signal) {
      abort = () => {
        isAborted = true;
        callback.call(
          stream,
          new AbortError$6(undefined, {
            cause: options.signal.reason
          })
        );
      };
      if (options.signal.aborted) {
        browser$2.nextTick(abort);
      } else {
        addAbortListener$1 = addAbortListener$1 || util.addAbortListener;
        const disposable = addAbortListener$1(options.signal, abort);
        const originalCallback = callback;
        callback = once$1((...args) => {
          disposable[SymbolDispose$1]();
          originalCallback.apply(stream, args);
        });
      }
    }
    const resolverFn = (...args) => {
      if (!isAborted) {
        browser$2.nextTick(() => callback.apply(stream, args));
      }
    };
    PromisePrototypeThen$2(stream[kIsClosedPromise].promise, resolverFn, resolverFn);
    return nop$2
  }
  function finished$2(stream, opts) {
    var _opts;
    let autoCleanup = false;
    if (opts === null) {
      opts = kEmptyObject;
    }
    if ((_opts = opts) !== null && _opts !== undefined && _opts.cleanup) {
      validateBoolean(opts.cleanup, 'cleanup');
      autoCleanup = opts.cleanup;
    }
    return new Promise$5((resolve, reject) => {
      const cleanup = eos(stream, opts, (err) => {
        if (autoCleanup) {
          cleanup();
        }
        if (err) {
          reject(err);
        } else {
          resolve();
        }
      });
    })
  }
  var endOfStream = eos;
  var finished_1 = finished$2;
  endOfStream.finished = finished_1;

  /* replacement start */



  /* replacement end */

  const {
    aggregateTwoErrors: aggregateTwoErrors$2,
    codes: { ERR_MULTIPLE_CALLBACK: ERR_MULTIPLE_CALLBACK$1 },
    AbortError: AbortError$5
  } = errors;
  const { Symbol: Symbol$5 } = primordials;
  const { kIsDestroyed, isDestroyed, isFinished, isServerRequest } = utils;
  const kDestroy$1 = Symbol$5('kDestroy');
  const kConstruct = Symbol$5('kConstruct');
  function checkError(err, w, r) {
    if (err) {
      // Avoid V8 leak, https://github.com/nodejs/node/pull/34103#issuecomment-652002364
      err.stack; // eslint-disable-line no-unused-expressions

      if (w && !w.errored) {
        w.errored = err;
      }
      if (r && !r.errored) {
        r.errored = err;
      }
    }
  }

  // Backwards compat. cb() is undocumented and unused in core but
  // unfortunately might be used by modules.
  function destroy$1(err, cb) {
    const r = this._readableState;
    const w = this._writableState;
    // With duplex streams we use the writable side for state.
    const s = w || r;
    if ((w !== null && w !== undefined && w.destroyed) || (r !== null && r !== undefined && r.destroyed)) {
      if (typeof cb === 'function') {
        cb();
      }
      return this
    }

    // We set destroyed to true before firing error callbacks in order
    // to make it re-entrance safe in case destroy() is called within callbacks
    checkError(err, w, r);
    if (w) {
      w.destroyed = true;
    }
    if (r) {
      r.destroyed = true;
    }

    // If still constructing then defer calling _destroy.
    if (!s.constructed) {
      this.once(kDestroy$1, function (er) {
        _destroy(this, aggregateTwoErrors$2(er, err), cb);
      });
    } else {
      _destroy(this, err, cb);
    }
    return this
  }
  function _destroy(self, err, cb) {
    let called = false;
    function onDestroy(err) {
      if (called) {
        return
      }
      called = true;
      const r = self._readableState;
      const w = self._writableState;
      checkError(err, w, r);
      if (w) {
        w.closed = true;
      }
      if (r) {
        r.closed = true;
      }
      if (typeof cb === 'function') {
        cb(err);
      }
      if (err) {
        browser$2.nextTick(emitErrorCloseNT, self, err);
      } else {
        browser$2.nextTick(emitCloseNT, self);
      }
    }
    try {
      self._destroy(err || null, onDestroy);
    } catch (err) {
      onDestroy(err);
    }
  }
  function emitErrorCloseNT(self, err) {
    emitErrorNT(self, err);
    emitCloseNT(self);
  }
  function emitCloseNT(self) {
    const r = self._readableState;
    const w = self._writableState;
    if (w) {
      w.closeEmitted = true;
    }
    if (r) {
      r.closeEmitted = true;
    }
    if ((w !== null && w !== undefined && w.emitClose) || (r !== null && r !== undefined && r.emitClose)) {
      self.emit('close');
    }
  }
  function emitErrorNT(self, err) {
    const r = self._readableState;
    const w = self._writableState;
    if ((w !== null && w !== undefined && w.errorEmitted) || (r !== null && r !== undefined && r.errorEmitted)) {
      return
    }
    if (w) {
      w.errorEmitted = true;
    }
    if (r) {
      r.errorEmitted = true;
    }
    self.emit('error', err);
  }
  function undestroy() {
    const r = this._readableState;
    const w = this._writableState;
    if (r) {
      r.constructed = true;
      r.closed = false;
      r.closeEmitted = false;
      r.destroyed = false;
      r.errored = null;
      r.errorEmitted = false;
      r.reading = false;
      r.ended = r.readable === false;
      r.endEmitted = r.readable === false;
    }
    if (w) {
      w.constructed = true;
      w.destroyed = false;
      w.closed = false;
      w.closeEmitted = false;
      w.errored = null;
      w.errorEmitted = false;
      w.finalCalled = false;
      w.prefinished = false;
      w.ended = w.writable === false;
      w.ending = w.writable === false;
      w.finished = w.writable === false;
    }
  }
  function errorOrDestroy$2(stream, err, sync) {
    // We have tests that rely on errors being emitted
    // in the same tick, so changing this is semver major.
    // For now when you opt-in to autoDestroy we allow
    // the error to be emitted nextTick. In a future
    // semver major update we should change the default to this.

    const r = stream._readableState;
    const w = stream._writableState;
    if ((w !== null && w !== undefined && w.destroyed) || (r !== null && r !== undefined && r.destroyed)) {
      return this
    }
    if ((r !== null && r !== undefined && r.autoDestroy) || (w !== null && w !== undefined && w.autoDestroy))
      stream.destroy(err);
    else if (err) {
      // Avoid V8 leak, https://github.com/nodejs/node/pull/34103#issuecomment-652002364
      err.stack; // eslint-disable-line no-unused-expressions

      if (w && !w.errored) {
        w.errored = err;
      }
      if (r && !r.errored) {
        r.errored = err;
      }
      if (sync) {
        browser$2.nextTick(emitErrorNT, stream, err);
      } else {
        emitErrorNT(stream, err);
      }
    }
  }
  function construct(stream, cb) {
    if (typeof stream._construct !== 'function') {
      return
    }
    const r = stream._readableState;
    const w = stream._writableState;
    if (r) {
      r.constructed = false;
    }
    if (w) {
      w.constructed = false;
    }
    stream.once(kConstruct, cb);
    if (stream.listenerCount(kConstruct) > 1) {
      // Duplex
      return
    }
    browser$2.nextTick(constructNT, stream);
  }
  function constructNT(stream) {
    let called = false;
    function onConstruct(err) {
      if (called) {
        errorOrDestroy$2(stream, err !== null && err !== undefined ? err : new ERR_MULTIPLE_CALLBACK$1());
        return
      }
      called = true;
      const r = stream._readableState;
      const w = stream._writableState;
      const s = w || r;
      if (r) {
        r.constructed = true;
      }
      if (w) {
        w.constructed = true;
      }
      if (s.destroyed) {
        stream.emit(kDestroy$1, err);
      } else if (err) {
        errorOrDestroy$2(stream, err, true);
      } else {
        browser$2.nextTick(emitConstructNT, stream);
      }
    }
    try {
      stream._construct((err) => {
        browser$2.nextTick(onConstruct, err);
      });
    } catch (err) {
      browser$2.nextTick(onConstruct, err);
    }
  }
  function emitConstructNT(stream) {
    stream.emit(kConstruct);
  }
  function isRequest(stream) {
    return (stream === null || stream === undefined ? undefined : stream.setHeader) && typeof stream.abort === 'function'
  }
  function emitCloseLegacy(stream) {
    stream.emit('close');
  }
  function emitErrorCloseLegacy(stream, err) {
    stream.emit('error', err);
    browser$2.nextTick(emitCloseLegacy, stream);
  }

  // Normalize destroy for legacy.
  function destroyer$3(stream, err) {
    if (!stream || isDestroyed(stream)) {
      return
    }
    if (!err && !isFinished(stream)) {
      err = new AbortError$5();
    }

    // TODO: Remove isRequest branches.
    if (isServerRequest(stream)) {
      stream.socket = null;
      stream.destroy(err);
    } else if (isRequest(stream)) {
      stream.abort();
    } else if (isRequest(stream.req)) {
      stream.req.abort();
    } else if (typeof stream.destroy === 'function') {
      stream.destroy(err);
    } else if (typeof stream.close === 'function') {
      // TODO: Don't lose err?
      stream.close();
    } else if (err) {
      browser$2.nextTick(emitErrorCloseLegacy, stream, err);
    } else {
      browser$2.nextTick(emitCloseLegacy, stream);
    }
    if (!stream.destroyed) {
      stream[kIsDestroyed] = true;
    }
  }
  var destroy_1 = {
    construct,
    destroyer: destroyer$3,
    destroy: destroy$1,
    undestroy,
    errorOrDestroy: errorOrDestroy$2
  };

  const { ArrayIsArray: ArrayIsArray$1, ObjectSetPrototypeOf: ObjectSetPrototypeOf$5 } = primordials;
  const { EventEmitter: EE$2 } = events;
  function Stream$2(opts) {
    EE$2.call(this, opts);
  }
  ObjectSetPrototypeOf$5(Stream$2.prototype, EE$2.prototype);
  ObjectSetPrototypeOf$5(Stream$2, EE$2);
  Stream$2.prototype.pipe = function (dest, options) {
    const source = this;
    function ondata(chunk) {
      if (dest.writable && dest.write(chunk) === false && source.pause) {
        source.pause();
      }
    }
    source.on('data', ondata);
    function ondrain() {
      if (source.readable && source.resume) {
        source.resume();
      }
    }
    dest.on('drain', ondrain);

    // If the 'end' option is not supplied, dest.end() will be called when
    // source gets the 'end' or 'close' events.  Only dest.end() once.
    if (!dest._isStdio && (!options || options.end !== false)) {
      source.on('end', onend);
      source.on('close', onclose);
    }
    let didOnEnd = false;
    function onend() {
      if (didOnEnd) return
      didOnEnd = true;
      dest.end();
    }
    function onclose() {
      if (didOnEnd) return
      didOnEnd = true;
      if (typeof dest.destroy === 'function') dest.destroy();
    }

    // Don't leave dangling pipes when there are errors.
    function onerror(er) {
      cleanup();
      if (EE$2.listenerCount(this, 'error') === 0) {
        this.emit('error', er);
      }
    }
    prependListener$1(source, 'error', onerror);
    prependListener$1(dest, 'error', onerror);

    // Remove all the event listeners that were added.
    function cleanup() {
      source.removeListener('data', ondata);
      dest.removeListener('drain', ondrain);
      source.removeListener('end', onend);
      source.removeListener('close', onclose);
      source.removeListener('error', onerror);
      dest.removeListener('error', onerror);
      source.removeListener('end', cleanup);
      source.removeListener('close', cleanup);
      dest.removeListener('close', cleanup);
    }
    source.on('end', cleanup);
    source.on('close', cleanup);
    dest.on('close', cleanup);
    dest.emit('pipe', source);

    // Allow for unix-like usage: A.pipe(B).pipe(C)
    return dest
  };
  function prependListener$1(emitter, event, fn) {
    // Sadly this is not cacheable as some libraries bundle their own
    // event emitter implementation with them.
    if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn)

    // This is a hack to make sure that our error handler is attached before any
    // userland ones.  NEVER DO THIS. This is here only because this code needs
    // to continue to work with older versions of Node.js that do not include
    // the prependListener() method. The goal is to eventually remove this hack.
    if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);
    else if (ArrayIsArray$1(emitter._events[event])) emitter._events[event].unshift(fn);
    else emitter._events[event] = [fn, emitter._events[event]];
  }
  var legacy = {
    Stream: Stream$2,
    prependListener: prependListener$1
  };

  var addAbortSignal$2 = createCommonjsModule(function (module) {

  const { SymbolDispose } = primordials;
  const { AbortError, codes } = errors;
  const { isNodeStream, isWebStream, kControllerErrorFunction } = utils;

  const { ERR_INVALID_ARG_TYPE } = codes;
  let addAbortListener;

  // This method is inlined here for readable-stream
  // It also does not allow for signal to not exist on the stream
  // https://github.com/nodejs/node/pull/36061#discussion_r533718029
  const validateAbortSignal = (signal, name) => {
    if (typeof signal !== 'object' || !('aborted' in signal)) {
      throw new ERR_INVALID_ARG_TYPE(name, 'AbortSignal', signal)
    }
  };
  module.exports.addAbortSignal = function addAbortSignal(signal, stream) {
    validateAbortSignal(signal, 'signal');
    if (!isNodeStream(stream) && !isWebStream(stream)) {
      throw new ERR_INVALID_ARG_TYPE('stream', ['ReadableStream', 'WritableStream', 'Stream'], stream)
    }
    return module.exports.addAbortSignalNoValidate(signal, stream)
  };
  module.exports.addAbortSignalNoValidate = function (signal, stream) {
    if (typeof signal !== 'object' || !('aborted' in signal)) {
      return stream
    }
    const onAbort = isNodeStream(stream)
      ? () => {
          stream.destroy(
            new AbortError(undefined, {
              cause: signal.reason
            })
          );
        }
      : () => {
          stream[kControllerErrorFunction](
            new AbortError(undefined, {
              cause: signal.reason
            })
          );
        };
    if (signal.aborted) {
      onAbort();
    } else {
      addAbortListener = addAbortListener || util.addAbortListener;
      const disposable = addAbortListener(signal, onAbort);
      endOfStream(stream, disposable[SymbolDispose]);
    }
    return stream
  };
  });

  const { StringPrototypeSlice, SymbolIterator: SymbolIterator$1, TypedArrayPrototypeSet, Uint8Array: Uint8Array$1 } = primordials;
  const { Buffer: Buffer$4 } = buffer$1;
  const { inspect } = util;
  var buffer_list = class BufferList {
    constructor() {
      this.head = null;
      this.tail = null;
      this.length = 0;
    }
    push(v) {
      const entry = {
        data: v,
        next: null
      };
      if (this.length > 0) this.tail.next = entry;
      else this.head = entry;
      this.tail = entry;
      ++this.length;
    }
    unshift(v) {
      const entry = {
        data: v,
        next: this.head
      };
      if (this.length === 0) this.tail = entry;
      this.head = entry;
      ++this.length;
    }
    shift() {
      if (this.length === 0) return
      const ret = this.head.data;
      if (this.length === 1) this.head = this.tail = null;
      else this.head = this.head.next;
      --this.length;
      return ret
    }
    clear() {
      this.head = this.tail = null;
      this.length = 0;
    }
    join(s) {
      if (this.length === 0) return ''
      let p = this.head;
      let ret = '' + p.data;
      while ((p = p.next) !== null) ret += s + p.data;
      return ret
    }
    concat(n) {
      if (this.length === 0) return Buffer$4.alloc(0)
      const ret = Buffer$4.allocUnsafe(n >>> 0);
      let p = this.head;
      let i = 0;
      while (p) {
        TypedArrayPrototypeSet(ret, p.data, i);
        i += p.data.length;
        p = p.next;
      }
      return ret
    }

    // Consumes a specified amount of bytes or characters from the buffered data.
    consume(n, hasStrings) {
      const data = this.head.data;
      if (n < data.length) {
        // `slice` is the same for buffers and strings.
        const slice = data.slice(0, n);
        this.head.data = data.slice(n);
        return slice
      }
      if (n === data.length) {
        // First chunk is a perfect match.
        return this.shift()
      }
      // Result spans more than one buffer.
      return hasStrings ? this._getString(n) : this._getBuffer(n)
    }
    first() {
      return this.head.data
    }
    *[SymbolIterator$1]() {
      for (let p = this.head; p; p = p.next) {
        yield p.data;
      }
    }

    // Consumes a specified amount of characters from the buffered data.
    _getString(n) {
      let ret = '';
      let p = this.head;
      let c = 0;
      do {
        const str = p.data;
        if (n > str.length) {
          ret += str;
          n -= str.length;
        } else {
          if (n === str.length) {
            ret += str;
            ++c;
            if (p.next) this.head = p.next;
            else this.head = this.tail = null;
          } else {
            ret += StringPrototypeSlice(str, 0, n);
            this.head = p;
            p.data = StringPrototypeSlice(str, n);
          }
          break
        }
        ++c;
      } while ((p = p.next) !== null)
      this.length -= c;
      return ret
    }

    // Consumes a specified amount of bytes from the buffered data.
    _getBuffer(n) {
      const ret = Buffer$4.allocUnsafe(n);
      const retLen = n;
      let p = this.head;
      let c = 0;
      do {
        const buf = p.data;
        if (n > buf.length) {
          TypedArrayPrototypeSet(ret, buf, retLen - n);
          n -= buf.length;
        } else {
          if (n === buf.length) {
            TypedArrayPrototypeSet(ret, buf, retLen - n);
            ++c;
            if (p.next) this.head = p.next;
            else this.head = this.tail = null;
          } else {
            TypedArrayPrototypeSet(ret, new Uint8Array$1(buf.buffer, buf.byteOffset, n), retLen - n);
            this.head = p;
            p.data = buf.slice(n);
          }
          break
        }
        ++c;
      } while ((p = p.next) !== null)
      this.length -= c;
      return ret
    }

    // Make sure the linked list only shows the minimal necessary information.
    [Symbol.for('nodejs.util.inspect.custom')](_, options) {
      return inspect(this, {
        ...options,
        // Only inspect one level.
        depth: 0,
        // It should not recurse.
        customInspect: false
      })
    }
  };

  const { MathFloor: MathFloor$1, NumberIsInteger: NumberIsInteger$1 } = primordials;
  const { validateInteger: validateInteger$1 } = validators;
  const { ERR_INVALID_ARG_VALUE: ERR_INVALID_ARG_VALUE$2 } = errors.codes;
  let defaultHighWaterMarkBytes = 16 * 1024;
  let defaultHighWaterMarkObjectMode = 16;
  function highWaterMarkFrom(options, isDuplex, duplexKey) {
    return options.highWaterMark != null ? options.highWaterMark : isDuplex ? options[duplexKey] : null
  }
  function getDefaultHighWaterMark$2(objectMode) {
    return objectMode ? defaultHighWaterMarkObjectMode : defaultHighWaterMarkBytes
  }
  function setDefaultHighWaterMark(objectMode, value) {
    validateInteger$1(value, 'value', 0);
    if (objectMode) {
      defaultHighWaterMarkObjectMode = value;
    } else {
      defaultHighWaterMarkBytes = value;
    }
  }
  function getHighWaterMark$3(state, options, duplexKey, isDuplex) {
    const hwm = highWaterMarkFrom(options, isDuplex, duplexKey);
    if (hwm != null) {
      if (!NumberIsInteger$1(hwm) || hwm < 0) {
        const name = isDuplex ? `options.${duplexKey}` : 'options.highWaterMark';
        throw new ERR_INVALID_ARG_VALUE$2(name, hwm)
      }
      return MathFloor$1(hwm)
    }

    // Default value
    return getDefaultHighWaterMark$2(state.objectMode)
  }
  var state = {
    getHighWaterMark: getHighWaterMark$3,
    getDefaultHighWaterMark: getDefaultHighWaterMark$2,
    setDefaultHighWaterMark
  };

  var safeBuffer = createCommonjsModule(function (module, exports) {
  /*! safe-buffer. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> */
  /* eslint-disable node/no-deprecated-api */

  var Buffer = buffer$1.Buffer;

  // alternative to using Object.keys for old browsers
  function copyProps (src, dst) {
    for (var key in src) {
      dst[key] = src[key];
    }
  }
  if (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {
    module.exports = buffer$1;
  } else {
    // Copy properties from require('buffer')
    copyProps(buffer$1, exports);
    exports.Buffer = SafeBuffer;
  }

  function SafeBuffer (arg, encodingOrOffset, length) {
    return Buffer(arg, encodingOrOffset, length)
  }

  SafeBuffer.prototype = Object.create(Buffer.prototype);

  // Copy static methods from Buffer
  copyProps(Buffer, SafeBuffer);

  SafeBuffer.from = function (arg, encodingOrOffset, length) {
    if (typeof arg === 'number') {
      throw new TypeError('Argument must not be a number')
    }
    return Buffer(arg, encodingOrOffset, length)
  };

  SafeBuffer.alloc = function (size, fill, encoding) {
    if (typeof size !== 'number') {
      throw new TypeError('Argument must be a number')
    }
    var buf = Buffer(size);
    if (fill !== undefined) {
      if (typeof encoding === 'string') {
        buf.fill(fill, encoding);
      } else {
        buf.fill(fill);
      }
    } else {
      buf.fill(0);
    }
    return buf
  };

  SafeBuffer.allocUnsafe = function (size) {
    if (typeof size !== 'number') {
      throw new TypeError('Argument must be a number')
    }
    return Buffer(size)
  };

  SafeBuffer.allocUnsafeSlow = function (size) {
    if (typeof size !== 'number') {
      throw new TypeError('Argument must be a number')
    }
    return buffer$1.SlowBuffer(size)
  };
  });

  /*<replacement>*/

  var Buffer$3 = safeBuffer.Buffer;
  /*</replacement>*/

  var isEncoding = Buffer$3.isEncoding || function (encoding) {
    encoding = '' + encoding;
    switch (encoding && encoding.toLowerCase()) {
      case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':
        return true;
      default:
        return false;
    }
  };

  function _normalizeEncoding(enc) {
    if (!enc) return 'utf8';
    var retried;
    while (true) {
      switch (enc) {
        case 'utf8':
        case 'utf-8':
          return 'utf8';
        case 'ucs2':
        case 'ucs-2':
        case 'utf16le':
        case 'utf-16le':
          return 'utf16le';
        case 'latin1':
        case 'binary':
          return 'latin1';
        case 'base64':
        case 'ascii':
        case 'hex':
          return enc;
        default:
          if (retried) return; // undefined
          enc = ('' + enc).toLowerCase();
          retried = true;
      }
    }
  }
  // Do not cache `Buffer.isEncoding` when checking encoding names as some
  // modules monkey-patch it to support additional encodings
  function normalizeEncoding(enc) {
    var nenc = _normalizeEncoding(enc);
    if (typeof nenc !== 'string' && (Buffer$3.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);
    return nenc || enc;
  }

  // StringDecoder provides an interface for efficiently splitting a series of
  // buffers into a series of JS strings without breaking apart multi-byte
  // characters.
  var StringDecoder_1 = StringDecoder$1;
  function StringDecoder$1(encoding) {
    this.encoding = normalizeEncoding(encoding);
    var nb;
    switch (this.encoding) {
      case 'utf16le':
        this.text = utf16Text;
        this.end = utf16End;
        nb = 4;
        break;
      case 'utf8':
        this.fillLast = utf8FillLast;
        nb = 4;
        break;
      case 'base64':
        this.text = base64Text;
        this.end = base64End;
        nb = 3;
        break;
      default:
        this.write = simpleWrite;
        this.end = simpleEnd;
        return;
    }
    this.lastNeed = 0;
    this.lastTotal = 0;
    this.lastChar = Buffer$3.allocUnsafe(nb);
  }

  StringDecoder$1.prototype.write = function (buf) {
    if (buf.length === 0) return '';
    var r;
    var i;
    if (this.lastNeed) {
      r = this.fillLast(buf);
      if (r === undefined) return '';
      i = this.lastNeed;
      this.lastNeed = 0;
    } else {
      i = 0;
    }
    if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);
    return r || '';
  };

  StringDecoder$1.prototype.end = utf8End;

  // Returns only complete characters in a Buffer
  StringDecoder$1.prototype.text = utf8Text;

  // Attempts to complete a partial non-UTF-8 character using bytes from a Buffer
  StringDecoder$1.prototype.fillLast = function (buf) {
    if (this.lastNeed <= buf.length) {
      buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);
      return this.lastChar.toString(this.encoding, 0, this.lastTotal);
    }
    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);
    this.lastNeed -= buf.length;
  };

  // Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a
  // continuation byte. If an invalid byte is detected, -2 is returned.
  function utf8CheckByte(byte) {
    if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;
    return byte >> 6 === 0x02 ? -1 : -2;
  }

  // Checks at most 3 bytes at the end of a Buffer in order to detect an
  // incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)
  // needed to complete the UTF-8 character (if applicable) are returned.
  function utf8CheckIncomplete(self, buf, i) {
    var j = buf.length - 1;
    if (j < i) return 0;
    var nb = utf8CheckByte(buf[j]);
    if (nb >= 0) {
      if (nb > 0) self.lastNeed = nb - 1;
      return nb;
    }
    if (--j < i || nb === -2) return 0;
    nb = utf8CheckByte(buf[j]);
    if (nb >= 0) {
      if (nb > 0) self.lastNeed = nb - 2;
      return nb;
    }
    if (--j < i || nb === -2) return 0;
    nb = utf8CheckByte(buf[j]);
    if (nb >= 0) {
      if (nb > 0) {
        if (nb === 2) nb = 0;else self.lastNeed = nb - 3;
      }
      return nb;
    }
    return 0;
  }

  // Validates as many continuation bytes for a multi-byte UTF-8 character as
  // needed or are available. If we see a non-continuation byte where we expect
  // one, we "replace" the validated continuation bytes we've seen so far with
  // a single UTF-8 replacement character ('\ufffd'), to match v8's UTF-8 decoding
  // behavior. The continuation byte check is included three times in the case
  // where all of the continuation bytes for a character exist in the same buffer.
  // It is also done this way as a slight performance increase instead of using a
  // loop.
  function utf8CheckExtraBytes(self, buf, p) {
    if ((buf[0] & 0xC0) !== 0x80) {
      self.lastNeed = 0;
      return '\ufffd';
    }
    if (self.lastNeed > 1 && buf.length > 1) {
      if ((buf[1] & 0xC0) !== 0x80) {
        self.lastNeed = 1;
        return '\ufffd';
      }
      if (self.lastNeed > 2 && buf.length > 2) {
        if ((buf[2] & 0xC0) !== 0x80) {
          self.lastNeed = 2;
          return '\ufffd';
        }
      }
    }
  }

  // Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.
  function utf8FillLast(buf) {
    var p = this.lastTotal - this.lastNeed;
    var r = utf8CheckExtraBytes(this, buf);
    if (r !== undefined) return r;
    if (this.lastNeed <= buf.length) {
      buf.copy(this.lastChar, p, 0, this.lastNeed);
      return this.lastChar.toString(this.encoding, 0, this.lastTotal);
    }
    buf.copy(this.lastChar, p, 0, buf.length);
    this.lastNeed -= buf.length;
  }

  // Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a
  // partial character, the character's bytes are buffered until the required
  // number of bytes are available.
  function utf8Text(buf, i) {
    var total = utf8CheckIncomplete(this, buf, i);
    if (!this.lastNeed) return buf.toString('utf8', i);
    this.lastTotal = total;
    var end = buf.length - (total - this.lastNeed);
    buf.copy(this.lastChar, 0, end);
    return buf.toString('utf8', i, end);
  }

  // For UTF-8, a replacement character is added when ending on a partial
  // character.
  function utf8End(buf) {
    var r = buf && buf.length ? this.write(buf) : '';
    if (this.lastNeed) return r + '\ufffd';
    return r;
  }

  // UTF-16LE typically needs two bytes per character, but even if we have an even
  // number of bytes available, we need to check if we end on a leading/high
  // surrogate. In that case, we need to wait for the next two bytes in order to
  // decode the last character properly.
  function utf16Text(buf, i) {
    if ((buf.length - i) % 2 === 0) {
      var r = buf.toString('utf16le', i);
      if (r) {
        var c = r.charCodeAt(r.length - 1);
        if (c >= 0xD800 && c <= 0xDBFF) {
          this.lastNeed = 2;
          this.lastTotal = 4;
          this.lastChar[0] = buf[buf.length - 2];
          this.lastChar[1] = buf[buf.length - 1];
          return r.slice(0, -1);
        }
      }
      return r;
    }
    this.lastNeed = 1;
    this.lastTotal = 2;
    this.lastChar[0] = buf[buf.length - 1];
    return buf.toString('utf16le', i, buf.length - 1);
  }

  // For UTF-16LE we do not explicitly append special replacement characters if we
  // end on a partial character, we simply let v8 handle that.
  function utf16End(buf) {
    var r = buf && buf.length ? this.write(buf) : '';
    if (this.lastNeed) {
      var end = this.lastTotal - this.lastNeed;
      return r + this.lastChar.toString('utf16le', 0, end);
    }
    return r;
  }

  function base64Text(buf, i) {
    var n = (buf.length - i) % 3;
    if (n === 0) return buf.toString('base64', i);
    this.lastNeed = 3 - n;
    this.lastTotal = 3;
    if (n === 1) {
      this.lastChar[0] = buf[buf.length - 1];
    } else {
      this.lastChar[0] = buf[buf.length - 2];
      this.lastChar[1] = buf[buf.length - 1];
    }
    return buf.toString('base64', i, buf.length - n);
  }

  function base64End(buf) {
    var r = buf && buf.length ? this.write(buf) : '';
    if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);
    return r;
  }

  // Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)
  function simpleWrite(buf) {
    return buf.toString(this.encoding);
  }

  function simpleEnd(buf) {
    return buf && buf.length ? this.write(buf) : '';
  }

  var string_decoder = {
  	StringDecoder: StringDecoder_1
  };

  /* replacement start */



  /* replacement end */

  const { PromisePrototypeThen: PromisePrototypeThen$1, SymbolAsyncIterator: SymbolAsyncIterator$2, SymbolIterator } = primordials;
  const { Buffer: Buffer$2 } = buffer$1;
  const { ERR_INVALID_ARG_TYPE: ERR_INVALID_ARG_TYPE$5, ERR_STREAM_NULL_VALUES: ERR_STREAM_NULL_VALUES$1 } = errors.codes;
  function from(Readable, iterable, opts) {
    let iterator;
    if (typeof iterable === 'string' || iterable instanceof Buffer$2) {
      return new Readable({
        objectMode: true,
        ...opts,
        read() {
          this.push(iterable);
          this.push(null);
        }
      })
    }
    let isAsync;
    if (iterable && iterable[SymbolAsyncIterator$2]) {
      isAsync = true;
      iterator = iterable[SymbolAsyncIterator$2]();
    } else if (iterable && iterable[SymbolIterator]) {
      isAsync = false;
      iterator = iterable[SymbolIterator]();
    } else {
      throw new ERR_INVALID_ARG_TYPE$5('iterable', ['Iterable'], iterable)
    }
    const readable = new Readable({
      objectMode: true,
      highWaterMark: 1,
      // TODO(ronag): What options should be allowed?
      ...opts
    });

    // Flag to protect against _read
    // being called before last iteration completion.
    let reading = false;
    readable._read = function () {
      if (!reading) {
        reading = true;
        next();
      }
    };
    readable._destroy = function (error, cb) {
      PromisePrototypeThen$1(
        close(error),
        () => browser$2.nextTick(cb, error),
        // nextTick is here in case cb throws
        (e) => browser$2.nextTick(cb, e || error)
      );
    };
    async function close(error) {
      const hadError = error !== undefined && error !== null;
      const hasThrow = typeof iterator.throw === 'function';
      if (hadError && hasThrow) {
        const { value, done } = await iterator.throw(error);
        await value;
        if (done) {
          return
        }
      }
      if (typeof iterator.return === 'function') {
        const { value } = await iterator.return();
        await value;
      }
    }
    async function next() {
      for (;;) {
        try {
          const { value, done } = isAsync ? await iterator.next() : iterator.next();
          if (done) {
            readable.push(null);
          } else {
            const res = value && typeof value.then === 'function' ? await value : value;
            if (res === null) {
              reading = false;
              throw new ERR_STREAM_NULL_VALUES$1()
            } else if (readable.push(res)) {
              continue
            } else {
              reading = false;
            }
          }
        } catch (err) {
          readable.destroy(err);
        }
        break
      }
    }
    return readable
  }
  var from_1 = from;

  var require$$11 = duplex;

  /* replacement start */



  /* replacement end */

  const {
    ArrayPrototypeIndexOf,
    NumberIsInteger,
    NumberIsNaN: NumberIsNaN$1,
    NumberParseInt,
    ObjectDefineProperties: ObjectDefineProperties$2,
    ObjectKeys: ObjectKeys$1,
    ObjectSetPrototypeOf: ObjectSetPrototypeOf$4,
    Promise: Promise$4,
    SafeSet,
    SymbolAsyncDispose,
    SymbolAsyncIterator: SymbolAsyncIterator$1,
    Symbol: Symbol$4
  } = primordials;
  var readable = Readable$2;
  Readable$2.ReadableState = ReadableState;
  const { EventEmitter: EE$1 } = events;
  const { Stream: Stream$1, prependListener } = legacy;
  const { Buffer: Buffer$1 } = buffer$1;
  const { addAbortSignal: addAbortSignal$1 } = addAbortSignal$2;

  let debug = util.debuglog('stream', (fn) => {
    debug = fn;
  });


  const { getHighWaterMark: getHighWaterMark$2, getDefaultHighWaterMark: getDefaultHighWaterMark$1 } = state;
  const {
    aggregateTwoErrors: aggregateTwoErrors$1,
    codes: {
      ERR_INVALID_ARG_TYPE: ERR_INVALID_ARG_TYPE$4,
      ERR_METHOD_NOT_IMPLEMENTED: ERR_METHOD_NOT_IMPLEMENTED$2,
      ERR_OUT_OF_RANGE: ERR_OUT_OF_RANGE$1,
      ERR_STREAM_PUSH_AFTER_EOF,
      ERR_STREAM_UNSHIFT_AFTER_END_EVENT
    },
    AbortError: AbortError$4
  } = errors;
  const { validateObject: validateObject$1 } = validators;
  const kPaused = Symbol$4('kPaused');
  const { StringDecoder } = string_decoder;

  ObjectSetPrototypeOf$4(Readable$2.prototype, Stream$1.prototype);
  ObjectSetPrototypeOf$4(Readable$2, Stream$1);
  const nop$1 = () => {};
  const { errorOrDestroy: errorOrDestroy$1 } = destroy_1;
  const kObjectMode = 1 << 0;
  const kEnded = 1 << 1;
  const kEndEmitted = 1 << 2;
  const kReading = 1 << 3;
  const kConstructed = 1 << 4;
  const kSync = 1 << 5;
  const kNeedReadable = 1 << 6;
  const kEmittedReadable = 1 << 7;
  const kReadableListening = 1 << 8;
  const kResumeScheduled = 1 << 9;
  const kErrorEmitted = 1 << 10;
  const kEmitClose = 1 << 11;
  const kAutoDestroy = 1 << 12;
  const kDestroyed = 1 << 13;
  const kClosed = 1 << 14;
  const kCloseEmitted = 1 << 15;
  const kMultiAwaitDrain = 1 << 16;
  const kReadingMore = 1 << 17;
  const kDataEmitted = 1 << 18;

  // TODO(benjamingr) it is likely slower to do it this way than with free functions
  function makeBitMapDescriptor(bit) {
    return {
      enumerable: false,
      get() {
        return (this.state & bit) !== 0
      },
      set(value) {
        if (value) this.state |= bit;
        else this.state &= ~bit;
      }
    }
  }
  ObjectDefineProperties$2(ReadableState.prototype, {
    objectMode: makeBitMapDescriptor(kObjectMode),
    ended: makeBitMapDescriptor(kEnded),
    endEmitted: makeBitMapDescriptor(kEndEmitted),
    reading: makeBitMapDescriptor(kReading),
    // Stream is still being constructed and cannot be
    // destroyed until construction finished or failed.
    // Async construction is opt in, therefore we start as
    // constructed.
    constructed: makeBitMapDescriptor(kConstructed),
    // A flag to be able to tell if the event 'readable'/'data' is emitted
    // immediately, or on a later tick.  We set this to true at first, because
    // any actions that shouldn't happen until "later" should generally also
    // not happen before the first read call.
    sync: makeBitMapDescriptor(kSync),
    // Whenever we return null, then we set a flag to say
    // that we're awaiting a 'readable' event emission.
    needReadable: makeBitMapDescriptor(kNeedReadable),
    emittedReadable: makeBitMapDescriptor(kEmittedReadable),
    readableListening: makeBitMapDescriptor(kReadableListening),
    resumeScheduled: makeBitMapDescriptor(kResumeScheduled),
    // True if the error was already emitted and should not be thrown again.
    errorEmitted: makeBitMapDescriptor(kErrorEmitted),
    emitClose: makeBitMapDescriptor(kEmitClose),
    autoDestroy: makeBitMapDescriptor(kAutoDestroy),
    // Has it been destroyed.
    destroyed: makeBitMapDescriptor(kDestroyed),
    // Indicates whether the stream has finished destroying.
    closed: makeBitMapDescriptor(kClosed),
    // True if close has been emitted or would have been emitted
    // depending on emitClose.
    closeEmitted: makeBitMapDescriptor(kCloseEmitted),
    multiAwaitDrain: makeBitMapDescriptor(kMultiAwaitDrain),
    // If true, a maybeReadMore has been scheduled.
    readingMore: makeBitMapDescriptor(kReadingMore),
    dataEmitted: makeBitMapDescriptor(kDataEmitted)
  });
  function ReadableState(options, stream, isDuplex) {
    // Duplex streams are both readable and writable, but share
    // the same options object.
    // However, some cases require setting options to different
    // values for the readable and the writable sides of the duplex stream.
    // These options can be provided separately as readableXXX and writableXXX.
    if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof require$$11;

    // Bit map field to store ReadableState more effciently with 1 bit per field
    // instead of a V8 slot per field.
    this.state = kEmitClose | kAutoDestroy | kConstructed | kSync;
    // Object stream flag. Used to make read(n) ignore n and to
    // make all the buffer merging and length checks go away.
    if (options && options.objectMode) this.state |= kObjectMode;
    if (isDuplex && options && options.readableObjectMode) this.state |= kObjectMode;

    // The point at which it stops calling _read() to fill the buffer
    // Note: 0 is a valid value, means "don't call _read preemptively ever"
    this.highWaterMark = options
      ? getHighWaterMark$2(this, options, 'readableHighWaterMark', isDuplex)
      : getDefaultHighWaterMark$1(false);

    // A linked list is used to store data chunks instead of an array because the
    // linked list can remove elements from the beginning faster than
    // array.shift().
    this.buffer = new buffer_list();
    this.length = 0;
    this.pipes = [];
    this.flowing = null;
    this[kPaused] = null;

    // Should close be emitted on destroy. Defaults to true.
    if (options && options.emitClose === false) this.state &= ~kEmitClose;

    // Should .destroy() be called after 'end' (and potentially 'finish').
    if (options && options.autoDestroy === false) this.state &= ~kAutoDestroy;

    // Indicates whether the stream has errored. When true no further
    // _read calls, 'data' or 'readable' events should occur. This is needed
    // since when autoDestroy is disabled we need a way to tell whether the
    // stream has failed.
    this.errored = null;

    // Crypto is kind of old and crusty.  Historically, its default string
    // encoding is 'binary' so we have to make this configurable.
    // Everything else in the universe uses 'utf8', though.
    this.defaultEncoding = (options && options.defaultEncoding) || 'utf8';

    // Ref the piped dest which we need a drain event on it
    // type: null | Writable | Set<Writable>.
    this.awaitDrainWriters = null;
    this.decoder = null;
    this.encoding = null;
    if (options && options.encoding) {
      this.decoder = new StringDecoder(options.encoding);
      this.encoding = options.encoding;
    }
  }
  function Readable$2(options) {
    if (!(this instanceof Readable$2)) return new Readable$2(options)

    // Checking for a Stream.Duplex instance is faster here instead of inside
    // the ReadableState constructor, at least with V8 6.5.
    const isDuplex = this instanceof require$$11;
    this._readableState = new ReadableState(options, this, isDuplex);
    if (options) {
      if (typeof options.read === 'function') this._read = options.read;
      if (typeof options.destroy === 'function') this._destroy = options.destroy;
      if (typeof options.construct === 'function') this._construct = options.construct;
      if (options.signal && !isDuplex) addAbortSignal$1(options.signal, this);
    }
    Stream$1.call(this, options);
    destroy_1.construct(this, () => {
      if (this._readableState.needReadable) {
        maybeReadMore(this, this._readableState);
      }
    });
  }
  Readable$2.prototype.destroy = destroy_1.destroy;
  Readable$2.prototype._undestroy = destroy_1.undestroy;
  Readable$2.prototype._destroy = function (err, cb) {
    cb(err);
  };
  Readable$2.prototype[EE$1.captureRejectionSymbol] = function (err) {
    this.destroy(err);
  };
  Readable$2.prototype[SymbolAsyncDispose] = function () {
    let error;
    if (!this.destroyed) {
      error = this.readableEnded ? null : new AbortError$4();
      this.destroy(error);
    }
    return new Promise$4((resolve, reject) => endOfStream(this, (err) => (err && err !== error ? reject(err) : resolve(null))))
  };

  // Manually shove something into the read() buffer.
  // This returns true if the highWaterMark has not been hit yet,
  // similar to how Writable.write() returns true if you should
  // write() some more.
  Readable$2.prototype.push = function (chunk, encoding) {
    return readableAddChunk(this, chunk, encoding, false)
  };

  // Unshift should *always* be something directly out of read().
  Readable$2.prototype.unshift = function (chunk, encoding) {
    return readableAddChunk(this, chunk, encoding, true)
  };
  function readableAddChunk(stream, chunk, encoding, addToFront) {
    debug('readableAddChunk', chunk);
    const state = stream._readableState;
    let err;
    if ((state.state & kObjectMode) === 0) {
      if (typeof chunk === 'string') {
        encoding = encoding || state.defaultEncoding;
        if (state.encoding !== encoding) {
          if (addToFront && state.encoding) {
            // When unshifting, if state.encoding is set, we have to save
            // the string in the BufferList with the state encoding.
            chunk = Buffer$1.from(chunk, encoding).toString(state.encoding);
          } else {
            chunk = Buffer$1.from(chunk, encoding);
            encoding = '';
          }
        }
      } else if (chunk instanceof Buffer$1) {
        encoding = '';
      } else if (Stream$1._isUint8Array(chunk)) {
        chunk = Stream$1._uint8ArrayToBuffer(chunk);
        encoding = '';
      } else if (chunk != null) {
        err = new ERR_INVALID_ARG_TYPE$4('chunk', ['string', 'Buffer', 'Uint8Array'], chunk);
      }
    }
    if (err) {
      errorOrDestroy$1(stream, err);
    } else if (chunk === null) {
      state.state &= ~kReading;
      onEofChunk(stream, state);
    } else if ((state.state & kObjectMode) !== 0 || (chunk && chunk.length > 0)) {
      if (addToFront) {
        if ((state.state & kEndEmitted) !== 0) errorOrDestroy$1(stream, new ERR_STREAM_UNSHIFT_AFTER_END_EVENT());
        else if (state.destroyed || state.errored) return false
        else addChunk(stream, state, chunk, true);
      } else if (state.ended) {
        errorOrDestroy$1(stream, new ERR_STREAM_PUSH_AFTER_EOF());
      } else if (state.destroyed || state.errored) {
        return false
      } else {
        state.state &= ~kReading;
        if (state.decoder && !encoding) {
          chunk = state.decoder.write(chunk);
          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);
          else maybeReadMore(stream, state);
        } else {
          addChunk(stream, state, chunk, false);
        }
      }
    } else if (!addToFront) {
      state.state &= ~kReading;
      maybeReadMore(stream, state);
    }

    // We can push more data if we are below the highWaterMark.
    // Also, if we have no data yet, we can stand some more bytes.
    // This is to work around cases where hwm=0, such as the repl.
    return !state.ended && (state.length < state.highWaterMark || state.length === 0)
  }
  function addChunk(stream, state, chunk, addToFront) {
    if (state.flowing && state.length === 0 && !state.sync && stream.listenerCount('data') > 0) {
      // Use the guard to avoid creating `Set()` repeatedly
      // when we have multiple pipes.
      if ((state.state & kMultiAwaitDrain) !== 0) {
        state.awaitDrainWriters.clear();
      } else {
        state.awaitDrainWriters = null;
      }
      state.dataEmitted = true;
      stream.emit('data', chunk);
    } else {
      // Update the buffer info.
      state.length += state.objectMode ? 1 : chunk.length;
      if (addToFront) state.buffer.unshift(chunk);
      else state.buffer.push(chunk);
      if ((state.state & kNeedReadable) !== 0) emitReadable(stream);
    }
    maybeReadMore(stream, state);
  }
  Readable$2.prototype.isPaused = function () {
    const state = this._readableState;
    return state[kPaused] === true || state.flowing === false
  };

  // Backwards compatibility.
  Readable$2.prototype.setEncoding = function (enc) {
    const decoder = new StringDecoder(enc);
    this._readableState.decoder = decoder;
    // If setEncoding(null), decoder.encoding equals utf8.
    this._readableState.encoding = this._readableState.decoder.encoding;
    const buffer = this._readableState.buffer;
    // Iterate over current buffer to convert already stored Buffers:
    let content = '';
    for (const data of buffer) {
      content += decoder.write(data);
    }
    buffer.clear();
    if (content !== '') buffer.push(content);
    this._readableState.length = content.length;
    return this
  };

  // Don't raise the hwm > 1GB.
  const MAX_HWM = 0x40000000;
  function computeNewHighWaterMark(n) {
    if (n > MAX_HWM) {
      throw new ERR_OUT_OF_RANGE$1('size', '<= 1GiB', n)
    } else {
      // Get the next highest power of 2 to prevent increasing hwm excessively in
      // tiny amounts.
      n--;
      n |= n >>> 1;
      n |= n >>> 2;
      n |= n >>> 4;
      n |= n >>> 8;
      n |= n >>> 16;
      n++;
    }
    return n
  }

  // This function is designed to be inlinable, so please take care when making
  // changes to the function body.
  function howMuchToRead(n, state) {
    if (n <= 0 || (state.length === 0 && state.ended)) return 0
    if ((state.state & kObjectMode) !== 0) return 1
    if (NumberIsNaN$1(n)) {
      // Only flow one buffer at a time.
      if (state.flowing && state.length) return state.buffer.first().length
      return state.length
    }
    if (n <= state.length) return n
    return state.ended ? state.length : 0
  }

  // You can override either this method, or the async _read(n) below.
  Readable$2.prototype.read = function (n) {
    debug('read', n);
    // Same as parseInt(undefined, 10), however V8 7.3 performance regressed
    // in this scenario, so we are doing it manually.
    if (n === undefined) {
      n = NaN;
    } else if (!NumberIsInteger(n)) {
      n = NumberParseInt(n, 10);
    }
    const state = this._readableState;
    const nOrig = n;

    // If we're asking for more than the current hwm, then raise the hwm.
    if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);
    if (n !== 0) state.state &= ~kEmittedReadable;

    // If we're doing read(0) to trigger a readable event, but we
    // already have a bunch of data in the buffer, then just trigger
    // the 'readable' event and move on.
    if (
      n === 0 &&
      state.needReadable &&
      ((state.highWaterMark !== 0 ? state.length >= state.highWaterMark : state.length > 0) || state.ended)
    ) {
      debug('read: emitReadable', state.length, state.ended);
      if (state.length === 0 && state.ended) endReadable(this);
      else emitReadable(this);
      return null
    }
    n = howMuchToRead(n, state);

    // If we've ended, and we're now clear, then finish it up.
    if (n === 0 && state.ended) {
      if (state.length === 0) endReadable(this);
      return null
    }

    // All the actual chunk generation logic needs to be
    // *below* the call to _read.  The reason is that in certain
    // synthetic stream cases, such as passthrough streams, _read
    // may be a completely synchronous operation which may change
    // the state of the read buffer, providing enough data when
    // before there was *not* enough.
    //
    // So, the steps are:
    // 1. Figure out what the state of things will be after we do
    // a read from the buffer.
    //
    // 2. If that resulting state will trigger a _read, then call _read.
    // Note that this may be asynchronous, or synchronous.  Yes, it is
    // deeply ugly to write APIs this way, but that still doesn't mean
    // that the Readable class should behave improperly, as streams are
    // designed to be sync/async agnostic.
    // Take note if the _read call is sync or async (ie, if the read call
    // has returned yet), so that we know whether or not it's safe to emit
    // 'readable' etc.
    //
    // 3. Actually pull the requested chunks out of the buffer and return.

    // if we need a readable event, then we need to do some reading.
    let doRead = (state.state & kNeedReadable) !== 0;
    debug('need readable', doRead);

    // If we currently have less than the highWaterMark, then also read some.
    if (state.length === 0 || state.length - n < state.highWaterMark) {
      doRead = true;
      debug('length less than watermark', doRead);
    }

    // However, if we've ended, then there's no point, if we're already
    // reading, then it's unnecessary, if we're constructing we have to wait,
    // and if we're destroyed or errored, then it's not allowed,
    if (state.ended || state.reading || state.destroyed || state.errored || !state.constructed) {
      doRead = false;
      debug('reading, ended or constructing', doRead);
    } else if (doRead) {
      debug('do read');
      state.state |= kReading | kSync;
      // If the length is currently zero, then we *need* a readable event.
      if (state.length === 0) state.state |= kNeedReadable;

      // Call internal read method
      try {
        this._read(state.highWaterMark);
      } catch (err) {
        errorOrDestroy$1(this, err);
      }
      state.state &= ~kSync;

      // If _read pushed data synchronously, then `reading` will be false,
      // and we need to re-evaluate how much data we can return to the user.
      if (!state.reading) n = howMuchToRead(nOrig, state);
    }
    let ret;
    if (n > 0) ret = fromList(n, state);
    else ret = null;
    if (ret === null) {
      state.needReadable = state.length <= state.highWaterMark;
      n = 0;
    } else {
      state.length -= n;
      if (state.multiAwaitDrain) {
        state.awaitDrainWriters.clear();
      } else {
        state.awaitDrainWriters = null;
      }
    }
    if (state.length === 0) {
      // If we have nothing in the buffer, then we want to know
      // as soon as we *do* get something into the buffer.
      if (!state.ended) state.needReadable = true;

      // If we tried to read() past the EOF, then emit end on the next tick.
      if (nOrig !== n && state.ended) endReadable(this);
    }
    if (ret !== null && !state.errorEmitted && !state.closeEmitted) {
      state.dataEmitted = true;
      this.emit('data', ret);
    }
    return ret
  };
  function onEofChunk(stream, state) {
    debug('onEofChunk');
    if (state.ended) return
    if (state.decoder) {
      const chunk = state.decoder.end();
      if (chunk && chunk.length) {
        state.buffer.push(chunk);
        state.length += state.objectMode ? 1 : chunk.length;
      }
    }
    state.ended = true;
    if (state.sync) {
      // If we are sync, wait until next tick to emit the data.
      // Otherwise we risk emitting data in the flow()
      // the readable code triggers during a read() call.
      emitReadable(stream);
    } else {
      // Emit 'readable' now to make sure it gets picked up.
      state.needReadable = false;
      state.emittedReadable = true;
      // We have to emit readable now that we are EOF. Modules
      // in the ecosystem (e.g. dicer) rely on this event being sync.
      emitReadable_(stream);
    }
  }

  // Don't emit readable right away in sync mode, because this can trigger
  // another read() call => stack overflow.  This way, it might trigger
  // a nextTick recursion warning, but that's not so bad.
  function emitReadable(stream) {
    const state = stream._readableState;
    debug('emitReadable', state.needReadable, state.emittedReadable);
    state.needReadable = false;
    if (!state.emittedReadable) {
      debug('emitReadable', state.flowing);
      state.emittedReadable = true;
      browser$2.nextTick(emitReadable_, stream);
    }
  }
  function emitReadable_(stream) {
    const state = stream._readableState;
    debug('emitReadable_', state.destroyed, state.length, state.ended);
    if (!state.destroyed && !state.errored && (state.length || state.ended)) {
      stream.emit('readable');
      state.emittedReadable = false;
    }

    // The stream needs another readable event if:
    // 1. It is not flowing, as the flow mechanism will take
    //    care of it.
    // 2. It is not ended.
    // 3. It is below the highWaterMark, so we can schedule
    //    another readable later.
    state.needReadable = !state.flowing && !state.ended && state.length <= state.highWaterMark;
    flow(stream);
  }

  // At this point, the user has presumably seen the 'readable' event,
  // and called read() to consume some data.  that may have triggered
  // in turn another _read(n) call, in which case reading = true if
  // it's in progress.
  // However, if we're not ended, or reading, and the length < hwm,
  // then go ahead and try to read some more preemptively.
  function maybeReadMore(stream, state) {
    if (!state.readingMore && state.constructed) {
      state.readingMore = true;
      browser$2.nextTick(maybeReadMore_, stream, state);
    }
  }
  function maybeReadMore_(stream, state) {
    // Attempt to read more data if we should.
    //
    // The conditions for reading more data are (one of):
    // - Not enough data buffered (state.length < state.highWaterMark). The loop
    //   is responsible for filling the buffer with enough data if such data
    //   is available. If highWaterMark is 0 and we are not in the flowing mode
    //   we should _not_ attempt to buffer any extra data. We'll get more data
    //   when the stream consumer calls read() instead.
    // - No data in the buffer, and the stream is in flowing mode. In this mode
    //   the loop below is responsible for ensuring read() is called. Failing to
    //   call read here would abort the flow and there's no other mechanism for
    //   continuing the flow if the stream consumer has just subscribed to the
    //   'data' event.
    //
    // In addition to the above conditions to keep reading data, the following
    // conditions prevent the data from being read:
    // - The stream has ended (state.ended).
    // - There is already a pending 'read' operation (state.reading). This is a
    //   case where the stream has called the implementation defined _read()
    //   method, but they are processing the call asynchronously and have _not_
    //   called push() with new data. In this case we skip performing more
    //   read()s. The execution ends in this method again after the _read() ends
    //   up calling push() with more data.
    while (
      !state.reading &&
      !state.ended &&
      (state.length < state.highWaterMark || (state.flowing && state.length === 0))
    ) {
      const len = state.length;
      debug('maybeReadMore read 0');
      stream.read(0);
      if (len === state.length)
        // Didn't get any data, stop spinning.
        break
    }
    state.readingMore = false;
  }

  // Abstract method.  to be overridden in specific implementation classes.
  // call cb(er, data) where data is <= n in length.
  // for virtual (non-string, non-buffer) streams, "length" is somewhat
  // arbitrary, and perhaps not very meaningful.
  Readable$2.prototype._read = function (n) {
    throw new ERR_METHOD_NOT_IMPLEMENTED$2('_read()')
  };
  Readable$2.prototype.pipe = function (dest, pipeOpts) {
    const src = this;
    const state = this._readableState;
    if (state.pipes.length === 1) {
      if (!state.multiAwaitDrain) {
        state.multiAwaitDrain = true;
        state.awaitDrainWriters = new SafeSet(state.awaitDrainWriters ? [state.awaitDrainWriters] : []);
      }
    }
    state.pipes.push(dest);
    debug('pipe count=%d opts=%j', state.pipes.length, pipeOpts);
    const doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== browser$2.stdout && dest !== browser$2.stderr;
    const endFn = doEnd ? onend : unpipe;
    if (state.endEmitted) browser$2.nextTick(endFn);
    else src.once('end', endFn);
    dest.on('unpipe', onunpipe);
    function onunpipe(readable, unpipeInfo) {
      debug('onunpipe');
      if (readable === src) {
        if (unpipeInfo && unpipeInfo.hasUnpiped === false) {
          unpipeInfo.hasUnpiped = true;
          cleanup();
        }
      }
    }
    function onend() {
      debug('onend');
      dest.end();
    }
    let ondrain;
    let cleanedUp = false;
    function cleanup() {
      debug('cleanup');
      // Cleanup event handlers once the pipe is broken.
      dest.removeListener('close', onclose);
      dest.removeListener('finish', onfinish);
      if (ondrain) {
        dest.removeListener('drain', ondrain);
      }
      dest.removeListener('error', onerror);
      dest.removeListener('unpipe', onunpipe);
      src.removeListener('end', onend);
      src.removeListener('end', unpipe);
      src.removeListener('data', ondata);
      cleanedUp = true;

      // If the reader is waiting for a drain event from this
      // specific writer, then it would cause it to never start
      // flowing again.
      // So, if this is awaiting a drain, then we just call it now.
      // If we don't know, then assume that we are waiting for one.
      if (ondrain && state.awaitDrainWriters && (!dest._writableState || dest._writableState.needDrain)) ondrain();
    }
    function pause() {
      // If the user unpiped during `dest.write()`, it is possible
      // to get stuck in a permanently paused state if that write
      // also returned false.
      // => Check whether `dest` is still a piping destination.
      if (!cleanedUp) {
        if (state.pipes.length === 1 && state.pipes[0] === dest) {
          debug('false write response, pause', 0);
          state.awaitDrainWriters = dest;
          state.multiAwaitDrain = false;
        } else if (state.pipes.length > 1 && state.pipes.includes(dest)) {
          debug('false write response, pause', state.awaitDrainWriters.size);
          state.awaitDrainWriters.add(dest);
        }
        src.pause();
      }
      if (!ondrain) {
        // When the dest drains, it reduces the awaitDrain counter
        // on the source.  This would be more elegant with a .once()
        // handler in flow(), but adding and removing repeatedly is
        // too slow.
        ondrain = pipeOnDrain(src, dest);
        dest.on('drain', ondrain);
      }
    }
    src.on('data', ondata);
    function ondata(chunk) {
      debug('ondata');
      const ret = dest.write(chunk);
      debug('dest.write', ret);
      if (ret === false) {
        pause();
      }
    }

    // If the dest has an error, then stop piping into it.
    // However, don't suppress the throwing behavior for this.
    function onerror(er) {
      debug('onerror', er);
      unpipe();
      dest.removeListener('error', onerror);
      if (dest.listenerCount('error') === 0) {
        const s = dest._writableState || dest._readableState;
        if (s && !s.errorEmitted) {
          // User incorrectly emitted 'error' directly on the stream.
          errorOrDestroy$1(dest, er);
        } else {
          dest.emit('error', er);
        }
      }
    }

    // Make sure our error handler is attached before userland ones.
    prependListener(dest, 'error', onerror);

    // Both close and finish should trigger unpipe, but only once.
    function onclose() {
      dest.removeListener('finish', onfinish);
      unpipe();
    }
    dest.once('close', onclose);
    function onfinish() {
      debug('onfinish');
      dest.removeListener('close', onclose);
      unpipe();
    }
    dest.once('finish', onfinish);
    function unpipe() {
      debug('unpipe');
      src.unpipe(dest);
    }

    // Tell the dest that it's being piped to.
    dest.emit('pipe', src);

    // Start the flow if it hasn't been started already.

    if (dest.writableNeedDrain === true) {
      pause();
    } else if (!state.flowing) {
      debug('pipe resume');
      src.resume();
    }
    return dest
  };
  function pipeOnDrain(src, dest) {
    return function pipeOnDrainFunctionResult() {
      const state = src._readableState;

      // `ondrain` will call directly,
      // `this` maybe not a reference to dest,
      // so we use the real dest here.
      if (state.awaitDrainWriters === dest) {
        debug('pipeOnDrain', 1);
        state.awaitDrainWriters = null;
      } else if (state.multiAwaitDrain) {
        debug('pipeOnDrain', state.awaitDrainWriters.size);
        state.awaitDrainWriters.delete(dest);
      }
      if ((!state.awaitDrainWriters || state.awaitDrainWriters.size === 0) && src.listenerCount('data')) {
        src.resume();
      }
    }
  }
  Readable$2.prototype.unpipe = function (dest) {
    const state = this._readableState;
    const unpipeInfo = {
      hasUnpiped: false
    };

    // If we're not piping anywhere, then do nothing.
    if (state.pipes.length === 0) return this
    if (!dest) {
      // remove all.
      const dests = state.pipes;
      state.pipes = [];
      this.pause();
      for (let i = 0; i < dests.length; i++)
        dests[i].emit('unpipe', this, {
          hasUnpiped: false
        });
      return this
    }

    // Try to find the right one.
    const index = ArrayPrototypeIndexOf(state.pipes, dest);
    if (index === -1) return this
    state.pipes.splice(index, 1);
    if (state.pipes.length === 0) this.pause();
    dest.emit('unpipe', this, unpipeInfo);
    return this
  };

  // Set up data events if they are asked for
  // Ensure readable listeners eventually get something.
  Readable$2.prototype.on = function (ev, fn) {
    const res = Stream$1.prototype.on.call(this, ev, fn);
    const state = this._readableState;
    if (ev === 'data') {
      // Update readableListening so that resume() may be a no-op
      // a few lines down. This is needed to support once('readable').
      state.readableListening = this.listenerCount('readable') > 0;

      // Try start flowing on next tick if stream isn't explicitly paused.
      if (state.flowing !== false) this.resume();
    } else if (ev === 'readable') {
      if (!state.endEmitted && !state.readableListening) {
        state.readableListening = state.needReadable = true;
        state.flowing = false;
        state.emittedReadable = false;
        debug('on readable', state.length, state.reading);
        if (state.length) {
          emitReadable(this);
        } else if (!state.reading) {
          browser$2.nextTick(nReadingNextTick, this);
        }
      }
    }
    return res
  };
  Readable$2.prototype.addListener = Readable$2.prototype.on;
  Readable$2.prototype.removeListener = function (ev, fn) {
    const res = Stream$1.prototype.removeListener.call(this, ev, fn);
    if (ev === 'readable') {
      // We need to check if there is someone still listening to
      // readable and reset the state. However this needs to happen
      // after readable has been emitted but before I/O (nextTick) to
      // support once('readable', fn) cycles. This means that calling
      // resume within the same tick will have no
      // effect.
      browser$2.nextTick(updateReadableListening, this);
    }
    return res
  };
  Readable$2.prototype.off = Readable$2.prototype.removeListener;
  Readable$2.prototype.removeAllListeners = function (ev) {
    const res = Stream$1.prototype.removeAllListeners.apply(this, arguments);
    if (ev === 'readable' || ev === undefined) {
      // We need to check if there is someone still listening to
      // readable and reset the state. However this needs to happen
      // after readable has been emitted but before I/O (nextTick) to
      // support once('readable', fn) cycles. This means that calling
      // resume within the same tick will have no
      // effect.
      browser$2.nextTick(updateReadableListening, this);
    }
    return res
  };
  function updateReadableListening(self) {
    const state = self._readableState;
    state.readableListening = self.listenerCount('readable') > 0;
    if (state.resumeScheduled && state[kPaused] === false) {
      // Flowing needs to be set to true now, otherwise
      // the upcoming resume will not flow.
      state.flowing = true;

      // Crude way to check if we should resume.
    } else if (self.listenerCount('data') > 0) {
      self.resume();
    } else if (!state.readableListening) {
      state.flowing = null;
    }
  }
  function nReadingNextTick(self) {
    debug('readable nexttick read 0');
    self.read(0);
  }

  // pause() and resume() are remnants of the legacy readable stream API
  // If the user uses them, then switch into old mode.
  Readable$2.prototype.resume = function () {
    const state = this._readableState;
    if (!state.flowing) {
      debug('resume');
      // We flow only if there is no one listening
      // for readable, but we still have to call
      // resume().
      state.flowing = !state.readableListening;
      resume(this, state);
    }
    state[kPaused] = false;
    return this
  };
  function resume(stream, state) {
    if (!state.resumeScheduled) {
      state.resumeScheduled = true;
      browser$2.nextTick(resume_, stream, state);
    }
  }
  function resume_(stream, state) {
    debug('resume', state.reading);
    if (!state.reading) {
      stream.read(0);
    }
    state.resumeScheduled = false;
    stream.emit('resume');
    flow(stream);
    if (state.flowing && !state.reading) stream.read(0);
  }
  Readable$2.prototype.pause = function () {
    debug('call pause flowing=%j', this._readableState.flowing);
    if (this._readableState.flowing !== false) {
      debug('pause');
      this._readableState.flowing = false;
      this.emit('pause');
    }
    this._readableState[kPaused] = true;
    return this
  };
  function flow(stream) {
    const state = stream._readableState;
    debug('flow', state.flowing);
    while (state.flowing && stream.read() !== null);
  }

  // Wrap an old-style stream as the async data source.
  // This is *not* part of the readable stream interface.
  // It is an ugly unfortunate mess of history.
  Readable$2.prototype.wrap = function (stream) {
    let paused = false;

    // TODO (ronag): Should this.destroy(err) emit
    // 'error' on the wrapped stream? Would require
    // a static factory method, e.g. Readable.wrap(stream).

    stream.on('data', (chunk) => {
      if (!this.push(chunk) && stream.pause) {
        paused = true;
        stream.pause();
      }
    });
    stream.on('end', () => {
      this.push(null);
    });
    stream.on('error', (err) => {
      errorOrDestroy$1(this, err);
    });
    stream.on('close', () => {
      this.destroy();
    });
    stream.on('destroy', () => {
      this.destroy();
    });
    this._read = () => {
      if (paused && stream.resume) {
        paused = false;
        stream.resume();
      }
    };

    // Proxy all the other methods. Important when wrapping filters and duplexes.
    const streamKeys = ObjectKeys$1(stream);
    for (let j = 1; j < streamKeys.length; j++) {
      const i = streamKeys[j];
      if (this[i] === undefined && typeof stream[i] === 'function') {
        this[i] = stream[i].bind(stream);
      }
    }
    return this
  };
  Readable$2.prototype[SymbolAsyncIterator$1] = function () {
    return streamToAsyncIterator(this)
  };
  Readable$2.prototype.iterator = function (options) {
    if (options !== undefined) {
      validateObject$1(options, 'options');
    }
    return streamToAsyncIterator(this, options)
  };
  function streamToAsyncIterator(stream, options) {
    if (typeof stream.read !== 'function') {
      stream = Readable$2.wrap(stream, {
        objectMode: true
      });
    }
    const iter = createAsyncIterator(stream, options);
    iter.stream = stream;
    return iter
  }
  async function* createAsyncIterator(stream, options) {
    let callback = nop$1;
    function next(resolve) {
      if (this === stream) {
        callback();
        callback = nop$1;
      } else {
        callback = resolve;
      }
    }
    stream.on('readable', next);
    let error;
    const cleanup = endOfStream(
      stream,
      {
        writable: false
      },
      (err) => {
        error = err ? aggregateTwoErrors$1(error, err) : null;
        callback();
        callback = nop$1;
      }
    );
    try {
      while (true) {
        const chunk = stream.destroyed ? null : stream.read();
        if (chunk !== null) {
          yield chunk;
        } else if (error) {
          throw error
        } else if (error === null) {
          return
        } else {
          await new Promise$4(next);
        }
      }
    } catch (err) {
      error = aggregateTwoErrors$1(error, err);
      throw error
    } finally {
      if (
        (error || (options === null || options === undefined ? undefined : options.destroyOnReturn) !== false) &&
        (error === undefined || stream._readableState.autoDestroy)
      ) {
        destroy_1.destroyer(stream, null);
      } else {
        stream.off('readable', next);
        cleanup();
      }
    }
  }

  // Making it explicit these properties are not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail.
  ObjectDefineProperties$2(Readable$2.prototype, {
    readable: {
      __proto__: null,
      get() {
        const r = this._readableState;
        // r.readable === false means that this is part of a Duplex stream
        // where the readable side was disabled upon construction.
        // Compat. The user might manually disable readable side through
        // deprecated setter.
        return !!r && r.readable !== false && !r.destroyed && !r.errorEmitted && !r.endEmitted
      },
      set(val) {
        // Backwards compat.
        if (this._readableState) {
          this._readableState.readable = !!val;
        }
      }
    },
    readableDidRead: {
      __proto__: null,
      enumerable: false,
      get: function () {
        return this._readableState.dataEmitted
      }
    },
    readableAborted: {
      __proto__: null,
      enumerable: false,
      get: function () {
        return !!(
          this._readableState.readable !== false &&
          (this._readableState.destroyed || this._readableState.errored) &&
          !this._readableState.endEmitted
        )
      }
    },
    readableHighWaterMark: {
      __proto__: null,
      enumerable: false,
      get: function () {
        return this._readableState.highWaterMark
      }
    },
    readableBuffer: {
      __proto__: null,
      enumerable: false,
      get: function () {
        return this._readableState && this._readableState.buffer
      }
    },
    readableFlowing: {
      __proto__: null,
      enumerable: false,
      get: function () {
        return this._readableState.flowing
      },
      set: function (state) {
        if (this._readableState) {
          this._readableState.flowing = state;
        }
      }
    },
    readableLength: {
      __proto__: null,
      enumerable: false,
      get() {
        return this._readableState.length
      }
    },
    readableObjectMode: {
      __proto__: null,
      enumerable: false,
      get() {
        return this._readableState ? this._readableState.objectMode : false
      }
    },
    readableEncoding: {
      __proto__: null,
      enumerable: false,
      get() {
        return this._readableState ? this._readableState.encoding : null
      }
    },
    errored: {
      __proto__: null,
      enumerable: false,
      get() {
        return this._readableState ? this._readableState.errored : null
      }
    },
    closed: {
      __proto__: null,
      get() {
        return this._readableState ? this._readableState.closed : false
      }
    },
    destroyed: {
      __proto__: null,
      enumerable: false,
      get() {
        return this._readableState ? this._readableState.destroyed : false
      },
      set(value) {
        // We ignore the value if the stream
        // has not been initialized yet.
        if (!this._readableState) {
          return
        }

        // Backward compatibility, the user is explicitly
        // managing destroyed.
        this._readableState.destroyed = value;
      }
    },
    readableEnded: {
      __proto__: null,
      enumerable: false,
      get() {
        return this._readableState ? this._readableState.endEmitted : false
      }
    }
  });
  ObjectDefineProperties$2(ReadableState.prototype, {
    // Legacy getter for `pipesCount`.
    pipesCount: {
      __proto__: null,
      get() {
        return this.pipes.length
      }
    },
    // Legacy property for `paused`.
    paused: {
      __proto__: null,
      get() {
        return this[kPaused] !== false
      },
      set(value) {
        this[kPaused] = !!value;
      }
    }
  });

  // Exposed for testing purposes only.
  Readable$2._fromList = fromList;

  // Pluck off n bytes from an array of buffers.
  // Length is the combined lengths of all the buffers in the list.
  // This function is designed to be inlinable, so please take care when making
  // changes to the function body.
  function fromList(n, state) {
    // nothing buffered.
    if (state.length === 0) return null
    let ret;
    if (state.objectMode) ret = state.buffer.shift();
    else if (!n || n >= state.length) {
      // Read it all, truncate the list.
      if (state.decoder) ret = state.buffer.join('');
      else if (state.buffer.length === 1) ret = state.buffer.first();
      else ret = state.buffer.concat(state.length);
      state.buffer.clear();
    } else {
      // read part of list.
      ret = state.buffer.consume(n, state.decoder);
    }
    return ret
  }
  function endReadable(stream) {
    const state = stream._readableState;
    debug('endReadable', state.endEmitted);
    if (!state.endEmitted) {
      state.ended = true;
      browser$2.nextTick(endReadableNT, state, stream);
    }
  }
  function endReadableNT(state, stream) {
    debug('endReadableNT', state.endEmitted, state.length);

    // Check that we didn't get one last unshift.
    if (!state.errored && !state.closeEmitted && !state.endEmitted && state.length === 0) {
      state.endEmitted = true;
      stream.emit('end');
      if (stream.writable && stream.allowHalfOpen === false) {
        browser$2.nextTick(endWritableNT, stream);
      } else if (state.autoDestroy) {
        // In case of duplex streams we need a way to detect
        // if the writable side is ready for autoDestroy as well.
        const wState = stream._writableState;
        const autoDestroy =
          !wState ||
          (wState.autoDestroy &&
            // We don't expect the writable to ever 'finish'
            // if writable is explicitly set to false.
            (wState.finished || wState.writable === false));
        if (autoDestroy) {
          stream.destroy();
        }
      }
    }
  }
  function endWritableNT(stream) {
    const writable = stream.writable && !stream.writableEnded && !stream.destroyed;
    if (writable) {
      stream.end();
    }
  }
  Readable$2.from = function (iterable, opts) {
    return from_1(Readable$2, iterable, opts)
  };
  let webStreamsAdapters$2;

  // Lazy to avoid circular references
  function lazyWebStreams$2() {
    if (webStreamsAdapters$2 === undefined) webStreamsAdapters$2 = {};
    return webStreamsAdapters$2
  }
  Readable$2.fromWeb = function (readableStream, options) {
    return lazyWebStreams$2().newStreamReadableFromReadableStream(readableStream, options)
  };
  Readable$2.toWeb = function (streamReadable, options) {
    return lazyWebStreams$2().newReadableStreamFromStreamReadable(streamReadable, options)
  };
  Readable$2.wrap = function (src, options) {
    var _ref, _src$readableObjectMo;
    return new Readable$2({
      objectMode:
        (_ref =
          (_src$readableObjectMo = src.readableObjectMode) !== null && _src$readableObjectMo !== undefined
            ? _src$readableObjectMo
            : src.objectMode) !== null && _ref !== undefined
          ? _ref
          : true,
      ...options,
      destroy(err, callback) {
        destroy_1.destroyer(src, err);
        callback(err);
      }
    }).wrap(src)
  };

  /* replacement start */



  /* replacement end */

  const {
    ArrayPrototypeSlice,
    Error: Error$1,
    FunctionPrototypeSymbolHasInstance,
    ObjectDefineProperty,
    ObjectDefineProperties: ObjectDefineProperties$1,
    ObjectSetPrototypeOf: ObjectSetPrototypeOf$3,
    StringPrototypeToLowerCase,
    Symbol: Symbol$3,
    SymbolHasInstance
  } = primordials;
  var writable = Writable;
  Writable.WritableState = WritableState;
  const { EventEmitter: EE } = events;
  const Stream = legacy.Stream;
  const { Buffer } = buffer$1;

  const { addAbortSignal } = addAbortSignal$2;
  const { getHighWaterMark: getHighWaterMark$1, getDefaultHighWaterMark } = state;
  const {
    ERR_INVALID_ARG_TYPE: ERR_INVALID_ARG_TYPE$3,
    ERR_METHOD_NOT_IMPLEMENTED: ERR_METHOD_NOT_IMPLEMENTED$1,
    ERR_MULTIPLE_CALLBACK,
    ERR_STREAM_CANNOT_PIPE,
    ERR_STREAM_DESTROYED: ERR_STREAM_DESTROYED$1,
    ERR_STREAM_ALREADY_FINISHED,
    ERR_STREAM_NULL_VALUES,
    ERR_STREAM_WRITE_AFTER_END,
    ERR_UNKNOWN_ENCODING
  } = errors.codes;
  const { errorOrDestroy } = destroy_1;
  ObjectSetPrototypeOf$3(Writable.prototype, Stream.prototype);
  ObjectSetPrototypeOf$3(Writable, Stream);
  function nop() {}
  const kOnFinished = Symbol$3('kOnFinished');
  function WritableState(options, stream, isDuplex) {
    // Duplex streams are both readable and writable, but share
    // the same options object.
    // However, some cases require setting options to different
    // values for the readable and the writable sides of the duplex stream,
    // e.g. options.readableObjectMode vs. options.writableObjectMode, etc.
    if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof require$$11;

    // Object stream flag to indicate whether or not this stream
    // contains buffers or objects.
    this.objectMode = !!(options && options.objectMode);
    if (isDuplex) this.objectMode = this.objectMode || !!(options && options.writableObjectMode);

    // The point at which write() starts returning false
    // Note: 0 is a valid value, means that we always return false if
    // the entire buffer is not flushed immediately on write().
    this.highWaterMark = options
      ? getHighWaterMark$1(this, options, 'writableHighWaterMark', isDuplex)
      : getDefaultHighWaterMark(false);

    // if _final has been called.
    this.finalCalled = false;

    // drain event flag.
    this.needDrain = false;
    // At the start of calling end()
    this.ending = false;
    // When end() has been called, and returned.
    this.ended = false;
    // When 'finish' is emitted.
    this.finished = false;

    // Has it been destroyed
    this.destroyed = false;

    // Should we decode strings into buffers before passing to _write?
    // this is here so that some node-core streams can optimize string
    // handling at a lower level.
    const noDecode = !!(options && options.decodeStrings === false);
    this.decodeStrings = !noDecode;

    // Crypto is kind of old and crusty.  Historically, its default string
    // encoding is 'binary' so we have to make this configurable.
    // Everything else in the universe uses 'utf8', though.
    this.defaultEncoding = (options && options.defaultEncoding) || 'utf8';

    // Not an actual buffer we keep track of, but a measurement
    // of how much we're waiting to get pushed to some underlying
    // socket or file.
    this.length = 0;

    // A flag to see when we're in the middle of a write.
    this.writing = false;

    // When true all writes will be buffered until .uncork() call.
    this.corked = 0;

    // A flag to be able to tell if the onwrite cb is called immediately,
    // or on a later tick.  We set this to true at first, because any
    // actions that shouldn't happen until "later" should generally also
    // not happen before the first write call.
    this.sync = true;

    // A flag to know if we're processing previously buffered items, which
    // may call the _write() callback in the same tick, so that we don't
    // end up in an overlapped onwrite situation.
    this.bufferProcessing = false;

    // The callback that's passed to _write(chunk, cb).
    this.onwrite = onwrite.bind(undefined, stream);

    // The callback that the user supplies to write(chunk, encoding, cb).
    this.writecb = null;

    // The amount that is being written when _write is called.
    this.writelen = 0;

    // Storage for data passed to the afterWrite() callback in case of
    // synchronous _write() completion.
    this.afterWriteTickInfo = null;
    resetBuffer(this);

    // Number of pending user-supplied write callbacks
    // this must be 0 before 'finish' can be emitted.
    this.pendingcb = 0;

    // Stream is still being constructed and cannot be
    // destroyed until construction finished or failed.
    // Async construction is opt in, therefore we start as
    // constructed.
    this.constructed = true;

    // Emit prefinish if the only thing we're waiting for is _write cbs
    // This is relevant for synchronous Transform streams.
    this.prefinished = false;

    // True if the error was already emitted and should not be thrown again.
    this.errorEmitted = false;

    // Should close be emitted on destroy. Defaults to true.
    this.emitClose = !options || options.emitClose !== false;

    // Should .destroy() be called after 'finish' (and potentially 'end').
    this.autoDestroy = !options || options.autoDestroy !== false;

    // Indicates whether the stream has errored. When true all write() calls
    // should return false. This is needed since when autoDestroy
    // is disabled we need a way to tell whether the stream has failed.
    this.errored = null;

    // Indicates whether the stream has finished destroying.
    this.closed = false;

    // True if close has been emitted or would have been emitted
    // depending on emitClose.
    this.closeEmitted = false;
    this[kOnFinished] = [];
  }
  function resetBuffer(state) {
    state.buffered = [];
    state.bufferedIndex = 0;
    state.allBuffers = true;
    state.allNoop = true;
  }
  WritableState.prototype.getBuffer = function getBuffer() {
    return ArrayPrototypeSlice(this.buffered, this.bufferedIndex)
  };
  ObjectDefineProperty(WritableState.prototype, 'bufferedRequestCount', {
    __proto__: null,
    get() {
      return this.buffered.length - this.bufferedIndex
    }
  });
  function Writable(options) {
    // Writable ctor is applied to Duplexes, too.
    // `realHasInstance` is necessary because using plain `instanceof`
    // would return false, as no `_writableState` property is attached.

    // Trying to use the custom `instanceof` for Writable here will also break the
    // Node.js LazyTransform implementation, which has a non-trivial getter for
    // `_writableState` that would lead to infinite recursion.

    // Checking for a Stream.Duplex instance is faster here instead of inside
    // the WritableState constructor, at least with V8 6.5.
    const isDuplex = this instanceof require$$11;
    if (!isDuplex && !FunctionPrototypeSymbolHasInstance(Writable, this)) return new Writable(options)
    this._writableState = new WritableState(options, this, isDuplex);
    if (options) {
      if (typeof options.write === 'function') this._write = options.write;
      if (typeof options.writev === 'function') this._writev = options.writev;
      if (typeof options.destroy === 'function') this._destroy = options.destroy;
      if (typeof options.final === 'function') this._final = options.final;
      if (typeof options.construct === 'function') this._construct = options.construct;
      if (options.signal) addAbortSignal(options.signal, this);
    }
    Stream.call(this, options);
    destroy_1.construct(this, () => {
      const state = this._writableState;
      if (!state.writing) {
        clearBuffer(this, state);
      }
      finishMaybe(this, state);
    });
  }
  ObjectDefineProperty(Writable, SymbolHasInstance, {
    __proto__: null,
    value: function (object) {
      if (FunctionPrototypeSymbolHasInstance(this, object)) return true
      if (this !== Writable) return false
      return object && object._writableState instanceof WritableState
    }
  });

  // Otherwise people can pipe Writable streams, which is just wrong.
  Writable.prototype.pipe = function () {
    errorOrDestroy(this, new ERR_STREAM_CANNOT_PIPE());
  };
  function _write(stream, chunk, encoding, cb) {
    const state = stream._writableState;
    if (typeof encoding === 'function') {
      cb = encoding;
      encoding = state.defaultEncoding;
    } else {
      if (!encoding) encoding = state.defaultEncoding;
      else if (encoding !== 'buffer' && !Buffer.isEncoding(encoding)) throw new ERR_UNKNOWN_ENCODING(encoding)
      if (typeof cb !== 'function') cb = nop;
    }
    if (chunk === null) {
      throw new ERR_STREAM_NULL_VALUES()
    } else if (!state.objectMode) {
      if (typeof chunk === 'string') {
        if (state.decodeStrings !== false) {
          chunk = Buffer.from(chunk, encoding);
          encoding = 'buffer';
        }
      } else if (chunk instanceof Buffer) {
        encoding = 'buffer';
      } else if (Stream._isUint8Array(chunk)) {
        chunk = Stream._uint8ArrayToBuffer(chunk);
        encoding = 'buffer';
      } else {
        throw new ERR_INVALID_ARG_TYPE$3('chunk', ['string', 'Buffer', 'Uint8Array'], chunk)
      }
    }
    let err;
    if (state.ending) {
      err = new ERR_STREAM_WRITE_AFTER_END();
    } else if (state.destroyed) {
      err = new ERR_STREAM_DESTROYED$1('write');
    }
    if (err) {
      browser$2.nextTick(cb, err);
      errorOrDestroy(stream, err, true);
      return err
    }
    state.pendingcb++;
    return writeOrBuffer(stream, state, chunk, encoding, cb)
  }
  Writable.prototype.write = function (chunk, encoding, cb) {
    return _write(this, chunk, encoding, cb) === true
  };
  Writable.prototype.cork = function () {
    this._writableState.corked++;
  };
  Writable.prototype.uncork = function () {
    const state = this._writableState;
    if (state.corked) {
      state.corked--;
      if (!state.writing) clearBuffer(this, state);
    }
  };
  Writable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {
    // node::ParseEncoding() requires lower case.
    if (typeof encoding === 'string') encoding = StringPrototypeToLowerCase(encoding);
    if (!Buffer.isEncoding(encoding)) throw new ERR_UNKNOWN_ENCODING(encoding)
    this._writableState.defaultEncoding = encoding;
    return this
  };

  // If we're already writing something, then just put this
  // in the queue, and wait our turn.  Otherwise, call _write
  // If we return false, then we need a drain event, so set that flag.
  function writeOrBuffer(stream, state, chunk, encoding, callback) {
    const len = state.objectMode ? 1 : chunk.length;
    state.length += len;

    // stream._write resets state.length
    const ret = state.length < state.highWaterMark;
    // We must ensure that previous needDrain will not be reset to false.
    if (!ret) state.needDrain = true;
    if (state.writing || state.corked || state.errored || !state.constructed) {
      state.buffered.push({
        chunk,
        encoding,
        callback
      });
      if (state.allBuffers && encoding !== 'buffer') {
        state.allBuffers = false;
      }
      if (state.allNoop && callback !== nop) {
        state.allNoop = false;
      }
    } else {
      state.writelen = len;
      state.writecb = callback;
      state.writing = true;
      state.sync = true;
      stream._write(chunk, encoding, state.onwrite);
      state.sync = false;
    }

    // Return false if errored or destroyed in order to break
    // any synchronous while(stream.write(data)) loops.
    return ret && !state.errored && !state.destroyed
  }
  function doWrite(stream, state, writev, len, chunk, encoding, cb) {
    state.writelen = len;
    state.writecb = cb;
    state.writing = true;
    state.sync = true;
    if (state.destroyed) state.onwrite(new ERR_STREAM_DESTROYED$1('write'));
    else if (writev) stream._writev(chunk, state.onwrite);
    else stream._write(chunk, encoding, state.onwrite);
    state.sync = false;
  }
  function onwriteError(stream, state, er, cb) {
    --state.pendingcb;
    cb(er);
    // Ensure callbacks are invoked even when autoDestroy is
    // not enabled. Passing `er` here doesn't make sense since
    // it's related to one specific write, not to the buffered
    // writes.
    errorBuffer(state);
    // This can emit error, but error must always follow cb.
    errorOrDestroy(stream, er);
  }
  function onwrite(stream, er) {
    const state = stream._writableState;
    const sync = state.sync;
    const cb = state.writecb;
    if (typeof cb !== 'function') {
      errorOrDestroy(stream, new ERR_MULTIPLE_CALLBACK());
      return
    }
    state.writing = false;
    state.writecb = null;
    state.length -= state.writelen;
    state.writelen = 0;
    if (er) {
      // Avoid V8 leak, https://github.com/nodejs/node/pull/34103#issuecomment-652002364
      er.stack; // eslint-disable-line no-unused-expressions

      if (!state.errored) {
        state.errored = er;
      }

      // In case of duplex streams we need to notify the readable side of the
      // error.
      if (stream._readableState && !stream._readableState.errored) {
        stream._readableState.errored = er;
      }
      if (sync) {
        browser$2.nextTick(onwriteError, stream, state, er, cb);
      } else {
        onwriteError(stream, state, er, cb);
      }
    } else {
      if (state.buffered.length > state.bufferedIndex) {
        clearBuffer(stream, state);
      }
      if (sync) {
        // It is a common case that the callback passed to .write() is always
        // the same. In that case, we do not schedule a new nextTick(), but
        // rather just increase a counter, to improve performance and avoid
        // memory allocations.
        if (state.afterWriteTickInfo !== null && state.afterWriteTickInfo.cb === cb) {
          state.afterWriteTickInfo.count++;
        } else {
          state.afterWriteTickInfo = {
            count: 1,
            cb,
            stream,
            state
          };
          browser$2.nextTick(afterWriteTick, state.afterWriteTickInfo);
        }
      } else {
        afterWrite(stream, state, 1, cb);
      }
    }
  }
  function afterWriteTick({ stream, state, count, cb }) {
    state.afterWriteTickInfo = null;
    return afterWrite(stream, state, count, cb)
  }
  function afterWrite(stream, state, count, cb) {
    const needDrain = !state.ending && !stream.destroyed && state.length === 0 && state.needDrain;
    if (needDrain) {
      state.needDrain = false;
      stream.emit('drain');
    }
    while (count-- > 0) {
      state.pendingcb--;
      cb();
    }
    if (state.destroyed) {
      errorBuffer(state);
    }
    finishMaybe(stream, state);
  }

  // If there's something in the buffer waiting, then invoke callbacks.
  function errorBuffer(state) {
    if (state.writing) {
      return
    }
    for (let n = state.bufferedIndex; n < state.buffered.length; ++n) {
      var _state$errored;
      const { chunk, callback } = state.buffered[n];
      const len = state.objectMode ? 1 : chunk.length;
      state.length -= len;
      callback(
        (_state$errored = state.errored) !== null && _state$errored !== undefined
          ? _state$errored
          : new ERR_STREAM_DESTROYED$1('write')
      );
    }
    const onfinishCallbacks = state[kOnFinished].splice(0);
    for (let i = 0; i < onfinishCallbacks.length; i++) {
      var _state$errored2;
      onfinishCallbacks[i](
        (_state$errored2 = state.errored) !== null && _state$errored2 !== undefined
          ? _state$errored2
          : new ERR_STREAM_DESTROYED$1('end')
      );
    }
    resetBuffer(state);
  }

  // If there's something in the buffer waiting, then process it.
  function clearBuffer(stream, state) {
    if (state.corked || state.bufferProcessing || state.destroyed || !state.constructed) {
      return
    }
    const { buffered, bufferedIndex, objectMode } = state;
    const bufferedLength = buffered.length - bufferedIndex;
    if (!bufferedLength) {
      return
    }
    let i = bufferedIndex;
    state.bufferProcessing = true;
    if (bufferedLength > 1 && stream._writev) {
      state.pendingcb -= bufferedLength - 1;
      const callback = state.allNoop
        ? nop
        : (err) => {
            for (let n = i; n < buffered.length; ++n) {
              buffered[n].callback(err);
            }
          };
      // Make a copy of `buffered` if it's going to be used by `callback` above,
      // since `doWrite` will mutate the array.
      const chunks = state.allNoop && i === 0 ? buffered : ArrayPrototypeSlice(buffered, i);
      chunks.allBuffers = state.allBuffers;
      doWrite(stream, state, true, state.length, chunks, '', callback);
      resetBuffer(state);
    } else {
      do {
        const { chunk, encoding, callback } = buffered[i];
        buffered[i++] = null;
        const len = objectMode ? 1 : chunk.length;
        doWrite(stream, state, false, len, chunk, encoding, callback);
      } while (i < buffered.length && !state.writing)
      if (i === buffered.length) {
        resetBuffer(state);
      } else if (i > 256) {
        buffered.splice(0, i);
        state.bufferedIndex = 0;
      } else {
        state.bufferedIndex = i;
      }
    }
    state.bufferProcessing = false;
  }
  Writable.prototype._write = function (chunk, encoding, cb) {
    if (this._writev) {
      this._writev(
        [
          {
            chunk,
            encoding
          }
        ],
        cb
      );
    } else {
      throw new ERR_METHOD_NOT_IMPLEMENTED$1('_write()')
    }
  };
  Writable.prototype._writev = null;
  Writable.prototype.end = function (chunk, encoding, cb) {
    const state = this._writableState;
    if (typeof chunk === 'function') {
      cb = chunk;
      chunk = null;
      encoding = null;
    } else if (typeof encoding === 'function') {
      cb = encoding;
      encoding = null;
    }
    let err;
    if (chunk !== null && chunk !== undefined) {
      const ret = _write(this, chunk, encoding);
      if (ret instanceof Error$1) {
        err = ret;
      }
    }

    // .end() fully uncorks.
    if (state.corked) {
      state.corked = 1;
      this.uncork();
    }
    if (err) ; else if (!state.errored && !state.ending) {
      // This is forgiving in terms of unnecessary calls to end() and can hide
      // logic errors. However, usually such errors are harmless and causing a
      // hard error can be disproportionately destructive. It is not always
      // trivial for the user to determine whether end() needs to be called
      // or not.

      state.ending = true;
      finishMaybe(this, state, true);
      state.ended = true;
    } else if (state.finished) {
      err = new ERR_STREAM_ALREADY_FINISHED('end');
    } else if (state.destroyed) {
      err = new ERR_STREAM_DESTROYED$1('end');
    }
    if (typeof cb === 'function') {
      if (err || state.finished) {
        browser$2.nextTick(cb, err);
      } else {
        state[kOnFinished].push(cb);
      }
    }
    return this
  };
  function needFinish(state) {
    return (
      state.ending &&
      !state.destroyed &&
      state.constructed &&
      state.length === 0 &&
      !state.errored &&
      state.buffered.length === 0 &&
      !state.finished &&
      !state.writing &&
      !state.errorEmitted &&
      !state.closeEmitted
    )
  }
  function callFinal(stream, state) {
    let called = false;
    function onFinish(err) {
      if (called) {
        errorOrDestroy(stream, err !== null && err !== undefined ? err : ERR_MULTIPLE_CALLBACK());
        return
      }
      called = true;
      state.pendingcb--;
      if (err) {
        const onfinishCallbacks = state[kOnFinished].splice(0);
        for (let i = 0; i < onfinishCallbacks.length; i++) {
          onfinishCallbacks[i](err);
        }
        errorOrDestroy(stream, err, state.sync);
      } else if (needFinish(state)) {
        state.prefinished = true;
        stream.emit('prefinish');
        // Backwards compat. Don't check state.sync here.
        // Some streams assume 'finish' will be emitted
        // asynchronously relative to _final callback.
        state.pendingcb++;
        browser$2.nextTick(finish, stream, state);
      }
    }
    state.sync = true;
    state.pendingcb++;
    try {
      stream._final(onFinish);
    } catch (err) {
      onFinish(err);
    }
    state.sync = false;
  }
  function prefinish$1(stream, state) {
    if (!state.prefinished && !state.finalCalled) {
      if (typeof stream._final === 'function' && !state.destroyed) {
        state.finalCalled = true;
        callFinal(stream, state);
      } else {
        state.prefinished = true;
        stream.emit('prefinish');
      }
    }
  }
  function finishMaybe(stream, state, sync) {
    if (needFinish(state)) {
      prefinish$1(stream, state);
      if (state.pendingcb === 0) {
        if (sync) {
          state.pendingcb++;
          browser$2.nextTick(
            (stream, state) => {
              if (needFinish(state)) {
                finish(stream, state);
              } else {
                state.pendingcb--;
              }
            },
            stream,
            state
          );
        } else if (needFinish(state)) {
          state.pendingcb++;
          finish(stream, state);
        }
      }
    }
  }
  function finish(stream, state) {
    state.pendingcb--;
    state.finished = true;
    const onfinishCallbacks = state[kOnFinished].splice(0);
    for (let i = 0; i < onfinishCallbacks.length; i++) {
      onfinishCallbacks[i]();
    }
    stream.emit('finish');
    if (state.autoDestroy) {
      // In case of duplex streams we need a way to detect
      // if the readable side is ready for autoDestroy as well.
      const rState = stream._readableState;
      const autoDestroy =
        !rState ||
        (rState.autoDestroy &&
          // We don't expect the readable to ever 'end'
          // if readable is explicitly set to false.
          (rState.endEmitted || rState.readable === false));
      if (autoDestroy) {
        stream.destroy();
      }
    }
  }
  ObjectDefineProperties$1(Writable.prototype, {
    closed: {
      __proto__: null,
      get() {
        return this._writableState ? this._writableState.closed : false
      }
    },
    destroyed: {
      __proto__: null,
      get() {
        return this._writableState ? this._writableState.destroyed : false
      },
      set(value) {
        // Backward compatibility, the user is explicitly managing destroyed.
        if (this._writableState) {
          this._writableState.destroyed = value;
        }
      }
    },
    writable: {
      __proto__: null,
      get() {
        const w = this._writableState;
        // w.writable === false means that this is part of a Duplex stream
        // where the writable side was disabled upon construction.
        // Compat. The user might manually disable writable side through
        // deprecated setter.
        return !!w && w.writable !== false && !w.destroyed && !w.errored && !w.ending && !w.ended
      },
      set(val) {
        // Backwards compatible.
        if (this._writableState) {
          this._writableState.writable = !!val;
        }
      }
    },
    writableFinished: {
      __proto__: null,
      get() {
        return this._writableState ? this._writableState.finished : false
      }
    },
    writableObjectMode: {
      __proto__: null,
      get() {
        return this._writableState ? this._writableState.objectMode : false
      }
    },
    writableBuffer: {
      __proto__: null,
      get() {
        return this._writableState && this._writableState.getBuffer()
      }
    },
    writableEnded: {
      __proto__: null,
      get() {
        return this._writableState ? this._writableState.ending : false
      }
    },
    writableNeedDrain: {
      __proto__: null,
      get() {
        const wState = this._writableState;
        if (!wState) return false
        return !wState.destroyed && !wState.ending && wState.needDrain
      }
    },
    writableHighWaterMark: {
      __proto__: null,
      get() {
        return this._writableState && this._writableState.highWaterMark
      }
    },
    writableCorked: {
      __proto__: null,
      get() {
        return this._writableState ? this._writableState.corked : 0
      }
    },
    writableLength: {
      __proto__: null,
      get() {
        return this._writableState && this._writableState.length
      }
    },
    errored: {
      __proto__: null,
      enumerable: false,
      get() {
        return this._writableState ? this._writableState.errored : null
      }
    },
    writableAborted: {
      __proto__: null,
      enumerable: false,
      get: function () {
        return !!(
          this._writableState.writable !== false &&
          (this._writableState.destroyed || this._writableState.errored) &&
          !this._writableState.finished
        )
      }
    }
  });
  const destroy = destroy_1.destroy;
  Writable.prototype.destroy = function (err, cb) {
    const state = this._writableState;

    // Invoke pending callbacks.
    if (!state.destroyed && (state.bufferedIndex < state.buffered.length || state[kOnFinished].length)) {
      browser$2.nextTick(errorBuffer, state);
    }
    destroy.call(this, err, cb);
    return this
  };
  Writable.prototype._undestroy = destroy_1.undestroy;
  Writable.prototype._destroy = function (err, cb) {
    cb(err);
  };
  Writable.prototype[EE.captureRejectionSymbol] = function (err) {
    this.destroy(err);
  };
  let webStreamsAdapters$1;

  // Lazy to avoid circular references
  function lazyWebStreams$1() {
    if (webStreamsAdapters$1 === undefined) webStreamsAdapters$1 = {};
    return webStreamsAdapters$1
  }
  Writable.fromWeb = function (writableStream, options) {
    return lazyWebStreams$1().newStreamWritableFromWritableStream(writableStream, options)
  };
  Writable.toWeb = function (streamWritable) {
    return lazyWebStreams$1().newWritableStreamFromStreamWritable(streamWritable)
  };

  const {
    isReadable: isReadable$2,
    isWritable: isWritable$2,
    isIterable: isIterable$2,
    isNodeStream: isNodeStream$4,
    isReadableNodeStream: isReadableNodeStream$1,
    isWritableNodeStream,
    isDuplexNodeStream,
    isReadableStream: isReadableStream$2,
    isWritableStream: isWritableStream$1
  } = utils;

  const {
    AbortError: AbortError$3,
    codes: { ERR_INVALID_ARG_TYPE: ERR_INVALID_ARG_TYPE$2, ERR_INVALID_RETURN_VALUE: ERR_INVALID_RETURN_VALUE$1 }
  } = errors;
  const { destroyer: destroyer$2 } = destroy_1;



  const { createDeferredPromise } = util;

  const Blob = globalThis.Blob || buffer$1.Blob;
  const isBlob =
    typeof Blob !== 'undefined'
      ? function isBlob(b) {
          return b instanceof Blob
        }
      : function isBlob(b) {
          return false
        };
  const AbortController$2 = globalThis.AbortController || browser$1.AbortController;
  const { FunctionPrototypeCall } = primordials;

  // This is needed for pre node 17.
  class Duplexify extends require$$11 {
    constructor(options) {
      super(options);

      // https://github.com/nodejs/node/pull/34385

      if ((options === null || options === undefined ? undefined : options.readable) === false) {
        this._readableState.readable = false;
        this._readableState.ended = true;
        this._readableState.endEmitted = true;
      }
      if ((options === null || options === undefined ? undefined : options.writable) === false) {
        this._writableState.writable = false;
        this._writableState.ending = true;
        this._writableState.ended = true;
        this._writableState.finished = true;
      }
    }
  }
  var duplexify$1 = function duplexify(body, name) {
    if (isDuplexNodeStream(body)) {
      return body
    }
    if (isReadableNodeStream$1(body)) {
      return _duplexify({
        readable: body
      })
    }
    if (isWritableNodeStream(body)) {
      return _duplexify({
        writable: body
      })
    }
    if (isNodeStream$4(body)) {
      return _duplexify({
        writable: false,
        readable: false
      })
    }
    if (isReadableStream$2(body)) {
      return _duplexify({
        readable: readable.fromWeb(body)
      })
    }
    if (isWritableStream$1(body)) {
      return _duplexify({
        writable: writable.fromWeb(body)
      })
    }
    if (typeof body === 'function') {
      const { value, write, final, destroy } = fromAsyncGen(body);
      if (isIterable$2(value)) {
        return from_1(Duplexify, value, {
          // TODO (ronag): highWaterMark?
          objectMode: true,
          write,
          final,
          destroy
        })
      }
      const then = value === null || value === undefined ? undefined : value.then;
      if (typeof then === 'function') {
        let d;
        const promise = FunctionPrototypeCall(
          then,
          value,
          (val) => {
            if (val != null) {
              throw new ERR_INVALID_RETURN_VALUE$1('nully', 'body', val)
            }
          },
          (err) => {
            destroyer$2(d, err);
          }
        );
        return (d = new Duplexify({
          // TODO (ronag): highWaterMark?
          objectMode: true,
          readable: false,
          write,
          final(cb) {
            final(async () => {
              try {
                await promise;
                browser$2.nextTick(cb, null);
              } catch (err) {
                browser$2.nextTick(cb, err);
              }
            });
          },
          destroy
        }))
      }
      throw new ERR_INVALID_RETURN_VALUE$1('Iterable, AsyncIterable or AsyncFunction', name, value)
    }
    if (isBlob(body)) {
      return duplexify(body.arrayBuffer())
    }
    if (isIterable$2(body)) {
      return from_1(Duplexify, body, {
        // TODO (ronag): highWaterMark?
        objectMode: true,
        writable: false
      })
    }
    if (
      isReadableStream$2(body === null || body === undefined ? undefined : body.readable) &&
      isWritableStream$1(body === null || body === undefined ? undefined : body.writable)
    ) {
      return Duplexify.fromWeb(body)
    }
    if (
      typeof (body === null || body === undefined ? undefined : body.writable) === 'object' ||
      typeof (body === null || body === undefined ? undefined : body.readable) === 'object'
    ) {
      const readable =
        body !== null && body !== undefined && body.readable
          ? isReadableNodeStream$1(body === null || body === undefined ? undefined : body.readable)
            ? body === null || body === undefined
              ? undefined
              : body.readable
            : duplexify(body.readable)
          : undefined;
      const writable =
        body !== null && body !== undefined && body.writable
          ? isWritableNodeStream(body === null || body === undefined ? undefined : body.writable)
            ? body === null || body === undefined
              ? undefined
              : body.writable
            : duplexify(body.writable)
          : undefined;
      return _duplexify({
        readable,
        writable
      })
    }
    const then = body === null || body === undefined ? undefined : body.then;
    if (typeof then === 'function') {
      let d;
      FunctionPrototypeCall(
        then,
        body,
        (val) => {
          if (val != null) {
            d.push(val);
          }
          d.push(null);
        },
        (err) => {
          destroyer$2(d, err);
        }
      );
      return (d = new Duplexify({
        objectMode: true,
        writable: false,
        read() {}
      }))
    }
    throw new ERR_INVALID_ARG_TYPE$2(
      name,
      [
        'Blob',
        'ReadableStream',
        'WritableStream',
        'Stream',
        'Iterable',
        'AsyncIterable',
        'Function',
        '{ readable, writable } pair',
        'Promise'
      ],
      body
    )
  };
  function fromAsyncGen(fn) {
    let { promise, resolve } = createDeferredPromise();
    const ac = new AbortController$2();
    const signal = ac.signal;
    const value = fn(
      (async function* () {
        while (true) {
          const _promise = promise;
          promise = null;
          const { chunk, done, cb } = await _promise;
          browser$2.nextTick(cb);
          if (done) return
          if (signal.aborted)
            throw new AbortError$3(undefined, {
              cause: signal.reason
            })
          ;({ promise, resolve } = createDeferredPromise());
          yield chunk;
        }
      })(),
      {
        signal
      }
    );
    return {
      value,
      write(chunk, encoding, cb) {
        const _resolve = resolve;
        resolve = null;
        _resolve({
          chunk,
          done: false,
          cb
        });
      },
      final(cb) {
        const _resolve = resolve;
        resolve = null;
        _resolve({
          done: true,
          cb
        });
      },
      destroy(err, cb) {
        ac.abort();
        cb(err);
      }
    }
  }
  function _duplexify(pair) {
    const r = pair.readable && typeof pair.readable.read !== 'function' ? readable.wrap(pair.readable) : pair.readable;
    const w = pair.writable;
    let readable$1 = !!isReadable$2(r);
    let writable = !!isWritable$2(w);
    let ondrain;
    let onfinish;
    let onreadable;
    let onclose;
    let d;
    function onfinished(err) {
      const cb = onclose;
      onclose = null;
      if (cb) {
        cb(err);
      } else if (err) {
        d.destroy(err);
      }
    }

    // TODO(ronag): Avoid double buffering.
    // Implement Writable/Readable/Duplex traits.
    // See, https://github.com/nodejs/node/pull/33515.
    d = new Duplexify({
      // TODO (ronag): highWaterMark?
      readableObjectMode: !!(r !== null && r !== undefined && r.readableObjectMode),
      writableObjectMode: !!(w !== null && w !== undefined && w.writableObjectMode),
      readable: readable$1,
      writable
    });
    if (writable) {
      endOfStream(w, (err) => {
        writable = false;
        if (err) {
          destroyer$2(r, err);
        }
        onfinished(err);
      });
      d._write = function (chunk, encoding, callback) {
        if (w.write(chunk, encoding)) {
          callback();
        } else {
          ondrain = callback;
        }
      };
      d._final = function (callback) {
        w.end();
        onfinish = callback;
      };
      w.on('drain', function () {
        if (ondrain) {
          const cb = ondrain;
          ondrain = null;
          cb();
        }
      });
      w.on('finish', function () {
        if (onfinish) {
          const cb = onfinish;
          onfinish = null;
          cb();
        }
      });
    }
    if (readable$1) {
      endOfStream(r, (err) => {
        readable$1 = false;
        if (err) {
          destroyer$2(r, err);
        }
        onfinished(err);
      });
      r.on('readable', function () {
        if (onreadable) {
          const cb = onreadable;
          onreadable = null;
          cb();
        }
      });
      r.on('end', function () {
        d.push(null);
      });
      d._read = function () {
        while (true) {
          const buf = r.read();
          if (buf === null) {
            onreadable = d._read;
            return
          }
          if (!d.push(buf)) {
            return
          }
        }
      };
    }
    d._destroy = function (err, callback) {
      if (!err && onclose !== null) {
        err = new AbortError$3();
      }
      onreadable = null;
      ondrain = null;
      onfinish = null;
      if (onclose === null) {
        callback(err);
      } else {
        onclose = callback;
        destroyer$2(w, err);
        destroyer$2(r, err);
      }
    };
    return d
  }

  const {
    ObjectDefineProperties,
    ObjectGetOwnPropertyDescriptor,
    ObjectKeys,
    ObjectSetPrototypeOf: ObjectSetPrototypeOf$2
  } = primordials;
  var duplex = Duplex;


  ObjectSetPrototypeOf$2(Duplex.prototype, readable.prototype);
  ObjectSetPrototypeOf$2(Duplex, readable);
  {
    const keys = ObjectKeys(writable.prototype);
    // Allow the keys array to be GC'ed.
    for (let i = 0; i < keys.length; i++) {
      const method = keys[i];
      if (!Duplex.prototype[method]) Duplex.prototype[method] = writable.prototype[method];
    }
  }
  function Duplex(options) {
    if (!(this instanceof Duplex)) return new Duplex(options)
    readable.call(this, options);
    writable.call(this, options);
    if (options) {
      this.allowHalfOpen = options.allowHalfOpen !== false;
      if (options.readable === false) {
        this._readableState.readable = false;
        this._readableState.ended = true;
        this._readableState.endEmitted = true;
      }
      if (options.writable === false) {
        this._writableState.writable = false;
        this._writableState.ending = true;
        this._writableState.ended = true;
        this._writableState.finished = true;
      }
    } else {
      this.allowHalfOpen = true;
    }
  }
  ObjectDefineProperties(Duplex.prototype, {
    writable: {
      __proto__: null,
      ...ObjectGetOwnPropertyDescriptor(writable.prototype, 'writable')
    },
    writableHighWaterMark: {
      __proto__: null,
      ...ObjectGetOwnPropertyDescriptor(writable.prototype, 'writableHighWaterMark')
    },
    writableObjectMode: {
      __proto__: null,
      ...ObjectGetOwnPropertyDescriptor(writable.prototype, 'writableObjectMode')
    },
    writableBuffer: {
      __proto__: null,
      ...ObjectGetOwnPropertyDescriptor(writable.prototype, 'writableBuffer')
    },
    writableLength: {
      __proto__: null,
      ...ObjectGetOwnPropertyDescriptor(writable.prototype, 'writableLength')
    },
    writableFinished: {
      __proto__: null,
      ...ObjectGetOwnPropertyDescriptor(writable.prototype, 'writableFinished')
    },
    writableCorked: {
      __proto__: null,
      ...ObjectGetOwnPropertyDescriptor(writable.prototype, 'writableCorked')
    },
    writableEnded: {
      __proto__: null,
      ...ObjectGetOwnPropertyDescriptor(writable.prototype, 'writableEnded')
    },
    writableNeedDrain: {
      __proto__: null,
      ...ObjectGetOwnPropertyDescriptor(writable.prototype, 'writableNeedDrain')
    },
    destroyed: {
      __proto__: null,
      get() {
        if (this._readableState === undefined || this._writableState === undefined) {
          return false
        }
        return this._readableState.destroyed && this._writableState.destroyed
      },
      set(value) {
        // Backward compatibility, the user is explicitly
        // managing destroyed.
        if (this._readableState && this._writableState) {
          this._readableState.destroyed = value;
          this._writableState.destroyed = value;
        }
      }
    }
  });
  let webStreamsAdapters;

  // Lazy to avoid circular references
  function lazyWebStreams() {
    if (webStreamsAdapters === undefined) webStreamsAdapters = {};
    return webStreamsAdapters
  }
  Duplex.fromWeb = function (pair, options) {
    return lazyWebStreams().newStreamDuplexFromReadableWritablePair(pair, options)
  };
  Duplex.toWeb = function (duplex) {
    return lazyWebStreams().newReadableWritablePairFromDuplex(duplex)
  };
  let duplexify;
  Duplex.from = function (body) {
    if (!duplexify) {
      duplexify = duplexify$1;
    }
    return duplexify(body, 'body')
  };

  const { ObjectSetPrototypeOf: ObjectSetPrototypeOf$1, Symbol: Symbol$2 } = primordials;
  var transform = Transform;
  const { ERR_METHOD_NOT_IMPLEMENTED } = errors.codes;

  const { getHighWaterMark } = state;
  ObjectSetPrototypeOf$1(Transform.prototype, require$$11.prototype);
  ObjectSetPrototypeOf$1(Transform, require$$11);
  const kCallback = Symbol$2('kCallback');
  function Transform(options) {
    if (!(this instanceof Transform)) return new Transform(options)

    // TODO (ronag): This should preferably always be
    // applied but would be semver-major. Or even better;
    // make Transform a Readable with the Writable interface.
    const readableHighWaterMark = options ? getHighWaterMark(this, options, 'readableHighWaterMark', true) : null;
    if (readableHighWaterMark === 0) {
      // A Duplex will buffer both on the writable and readable side while
      // a Transform just wants to buffer hwm number of elements. To avoid
      // buffering twice we disable buffering on the writable side.
      options = {
        ...options,
        highWaterMark: null,
        readableHighWaterMark,
        // TODO (ronag): 0 is not optimal since we have
        // a "bug" where we check needDrain before calling _write and not after.
        // Refs: https://github.com/nodejs/node/pull/32887
        // Refs: https://github.com/nodejs/node/pull/35941
        writableHighWaterMark: options.writableHighWaterMark || 0
      };
    }
    require$$11.call(this, options);

    // We have implemented the _read method, and done the other things
    // that Readable wants before the first _read call, so unset the
    // sync guard flag.
    this._readableState.sync = false;
    this[kCallback] = null;
    if (options) {
      if (typeof options.transform === 'function') this._transform = options.transform;
      if (typeof options.flush === 'function') this._flush = options.flush;
    }

    // When the writable side finishes, then flush out anything remaining.
    // Backwards compat. Some Transform streams incorrectly implement _final
    // instead of or in addition to _flush. By using 'prefinish' instead of
    // implementing _final we continue supporting this unfortunate use case.
    this.on('prefinish', prefinish);
  }
  function final(cb) {
    if (typeof this._flush === 'function' && !this.destroyed) {
      this._flush((er, data) => {
        if (er) {
          if (cb) {
            cb(er);
          } else {
            this.destroy(er);
          }
          return
        }
        if (data != null) {
          this.push(data);
        }
        this.push(null);
        if (cb) {
          cb();
        }
      });
    } else {
      this.push(null);
      if (cb) {
        cb();
      }
    }
  }
  function prefinish() {
    if (this._final !== final) {
      final.call(this);
    }
  }
  Transform.prototype._final = final;
  Transform.prototype._transform = function (chunk, encoding, callback) {
    throw new ERR_METHOD_NOT_IMPLEMENTED('_transform()')
  };
  Transform.prototype._write = function (chunk, encoding, callback) {
    const rState = this._readableState;
    const wState = this._writableState;
    const length = rState.length;
    this._transform(chunk, encoding, (err, val) => {
      if (err) {
        callback(err);
        return
      }
      if (val != null) {
        this.push(val);
      }
      if (
        wState.ended ||
        // Backwards compat.
        length === rState.length ||
        // Backwards compat.
        rState.length < rState.highWaterMark
      ) {
        callback();
      } else {
        this[kCallback] = callback;
      }
    });
  };
  Transform.prototype._read = function () {
    if (this[kCallback]) {
      const callback = this[kCallback];
      this[kCallback] = null;
      callback();
    }
  };

  const { ObjectSetPrototypeOf } = primordials;
  var passthrough = PassThrough$1;

  ObjectSetPrototypeOf(PassThrough$1.prototype, transform.prototype);
  ObjectSetPrototypeOf(PassThrough$1, transform);
  function PassThrough$1(options) {
    if (!(this instanceof PassThrough$1)) return new PassThrough$1(options)
    transform.call(this, options);
  }
  PassThrough$1.prototype._transform = function (chunk, encoding, cb) {
    cb(null, chunk);
  };

  const { ArrayIsArray, Promise: Promise$3, SymbolAsyncIterator, SymbolDispose } = primordials;

  const { once } = util;


  const {
    aggregateTwoErrors,
    codes: {
      ERR_INVALID_ARG_TYPE: ERR_INVALID_ARG_TYPE$1,
      ERR_INVALID_RETURN_VALUE,
      ERR_MISSING_ARGS: ERR_MISSING_ARGS$2,
      ERR_STREAM_DESTROYED,
      ERR_STREAM_PREMATURE_CLOSE
    },
    AbortError: AbortError$2
  } = errors;
  const { validateFunction, validateAbortSignal: validateAbortSignal$1 } = validators;
  const {
    isIterable: isIterable$1,
    isReadable: isReadable$1,
    isReadableNodeStream,
    isNodeStream: isNodeStream$3,
    isTransformStream: isTransformStream$1,
    isWebStream: isWebStream$2,
    isReadableStream: isReadableStream$1,
    isReadableFinished
  } = utils;
  const AbortController$1 = globalThis.AbortController || browser$1.AbortController;
  let PassThrough;
  let Readable$1;
  let addAbortListener;
  function destroyer$1(stream, reading, writing) {
    let finished = false;
    stream.on('close', () => {
      finished = true;
    });
    const cleanup = endOfStream(
      stream,
      {
        readable: reading,
        writable: writing
      },
      (err) => {
        finished = !err;
      }
    );
    return {
      destroy: (err) => {
        if (finished) return
        finished = true;
        destroy_1.destroyer(stream, err || new ERR_STREAM_DESTROYED('pipe'));
      },
      cleanup
    }
  }
  function popCallback(streams) {
    // Streams should never be an empty array. It should always contain at least
    // a single stream. Therefore optimize for the average case instead of
    // checking for length === 0 as well.
    validateFunction(streams[streams.length - 1], 'streams[stream.length - 1]');
    return streams.pop()
  }
  function makeAsyncIterable(val) {
    if (isIterable$1(val)) {
      return val
    } else if (isReadableNodeStream(val)) {
      // Legacy streams are not Iterable.
      return fromReadable(val)
    }
    throw new ERR_INVALID_ARG_TYPE$1('val', ['Readable', 'Iterable', 'AsyncIterable'], val)
  }
  async function* fromReadable(val) {
    if (!Readable$1) {
      Readable$1 = readable;
    }
    yield* Readable$1.prototype[SymbolAsyncIterator].call(val);
  }
  async function pumpToNode(iterable, writable, finish, { end }) {
    let error;
    let onresolve = null;
    const resume = (err) => {
      if (err) {
        error = err;
      }
      if (onresolve) {
        const callback = onresolve;
        onresolve = null;
        callback();
      }
    };
    const wait = () =>
      new Promise$3((resolve, reject) => {
        if (error) {
          reject(error);
        } else {
          onresolve = () => {
            if (error) {
              reject(error);
            } else {
              resolve();
            }
          };
        }
      });
    writable.on('drain', resume);
    const cleanup = endOfStream(
      writable,
      {
        readable: false
      },
      resume
    );
    try {
      if (writable.writableNeedDrain) {
        await wait();
      }
      for await (const chunk of iterable) {
        if (!writable.write(chunk)) {
          await wait();
        }
      }
      if (end) {
        writable.end();
        await wait();
      }
      finish();
    } catch (err) {
      finish(error !== err ? aggregateTwoErrors(error, err) : err);
    } finally {
      cleanup();
      writable.off('drain', resume);
    }
  }
  async function pumpToWeb(readable, writable, finish, { end }) {
    if (isTransformStream$1(writable)) {
      writable = writable.writable;
    }
    // https://streams.spec.whatwg.org/#example-manual-write-with-backpressure
    const writer = writable.getWriter();
    try {
      for await (const chunk of readable) {
        await writer.ready;
        writer.write(chunk).catch(() => {});
      }
      await writer.ready;
      if (end) {
        await writer.close();
      }
      finish();
    } catch (err) {
      try {
        await writer.abort(err);
        finish(err);
      } catch (err) {
        finish(err);
      }
    }
  }
  function pipeline$2(...streams) {
    return pipelineImpl(streams, once(popCallback(streams)))
  }
  function pipelineImpl(streams, callback, opts) {
    if (streams.length === 1 && ArrayIsArray(streams[0])) {
      streams = streams[0];
    }
    if (streams.length < 2) {
      throw new ERR_MISSING_ARGS$2('streams')
    }
    const ac = new AbortController$1();
    const signal = ac.signal;
    const outerSignal = opts === null || opts === undefined ? undefined : opts.signal;

    // Need to cleanup event listeners if last stream is readable
    // https://github.com/nodejs/node/issues/35452
    const lastStreamCleanup = [];
    validateAbortSignal$1(outerSignal, 'options.signal');
    function abort() {
      finishImpl(new AbortError$2());
    }
    addAbortListener = addAbortListener || util.addAbortListener;
    let disposable;
    if (outerSignal) {
      disposable = addAbortListener(outerSignal, abort);
    }
    let error;
    let value;
    const destroys = [];
    let finishCount = 0;
    function finish(err) {
      finishImpl(err, --finishCount === 0);
    }
    function finishImpl(err, final) {
      var _disposable;
      if (err && (!error || error.code === 'ERR_STREAM_PREMATURE_CLOSE')) {
        error = err;
      }
      if (!error && !final) {
        return
      }
      while (destroys.length) {
        destroys.shift()(error);
      }
  (_disposable = disposable) === null || _disposable === undefined ? undefined : _disposable[SymbolDispose]();
      ac.abort();
      if (final) {
        if (!error) {
          lastStreamCleanup.forEach((fn) => fn());
        }
        browser$2.nextTick(callback, error, value);
      }
    }
    let ret;
    for (let i = 0; i < streams.length; i++) {
      const stream = streams[i];
      const reading = i < streams.length - 1;
      const writing = i > 0;
      const end = reading || (opts === null || opts === undefined ? undefined : opts.end) !== false;
      const isLastStream = i === streams.length - 1;
      if (isNodeStream$3(stream)) {
        if (end) {
          const { destroy, cleanup } = destroyer$1(stream, reading, writing);
          destroys.push(destroy);
          if (isReadable$1(stream) && isLastStream) {
            lastStreamCleanup.push(cleanup);
          }
        }

        // Catch stream errors that occur after pipe/pump has completed.
        function onError(err) {
          if (err && err.name !== 'AbortError' && err.code !== 'ERR_STREAM_PREMATURE_CLOSE') {
            finish(err);
          }
        }
        stream.on('error', onError);
        if (isReadable$1(stream) && isLastStream) {
          lastStreamCleanup.push(() => {
            stream.removeListener('error', onError);
          });
        }
      }
      if (i === 0) {
        if (typeof stream === 'function') {
          ret = stream({
            signal
          });
          if (!isIterable$1(ret)) {
            throw new ERR_INVALID_RETURN_VALUE('Iterable, AsyncIterable or Stream', 'source', ret)
          }
        } else if (isIterable$1(stream) || isReadableNodeStream(stream) || isTransformStream$1(stream)) {
          ret = stream;
        } else {
          ret = require$$11.from(stream);
        }
      } else if (typeof stream === 'function') {
        if (isTransformStream$1(ret)) {
          var _ret;
          ret = makeAsyncIterable((_ret = ret) === null || _ret === undefined ? undefined : _ret.readable);
        } else {
          ret = makeAsyncIterable(ret);
        }
        ret = stream(ret, {
          signal
        });
        if (reading) {
          if (!isIterable$1(ret, true)) {
            throw new ERR_INVALID_RETURN_VALUE('AsyncIterable', `transform[${i - 1}]`, ret)
          }
        } else {
          var _ret2;
          if (!PassThrough) {
            PassThrough = passthrough;
          }

          // If the last argument to pipeline is not a stream
          // we must create a proxy stream so that pipeline(...)
          // always returns a stream which can be further
          // composed through `.pipe(stream)`.

          const pt = new PassThrough({
            objectMode: true
          });

          // Handle Promises/A+ spec, `then` could be a getter that throws on
          // second use.
          const then = (_ret2 = ret) === null || _ret2 === undefined ? undefined : _ret2.then;
          if (typeof then === 'function') {
            finishCount++;
            then.call(
              ret,
              (val) => {
                value = val;
                if (val != null) {
                  pt.write(val);
                }
                if (end) {
                  pt.end();
                }
                browser$2.nextTick(finish);
              },
              (err) => {
                pt.destroy(err);
                browser$2.nextTick(finish, err);
              }
            );
          } else if (isIterable$1(ret, true)) {
            finishCount++;
            pumpToNode(ret, pt, finish, {
              end
            });
          } else if (isReadableStream$1(ret) || isTransformStream$1(ret)) {
            const toRead = ret.readable || ret;
            finishCount++;
            pumpToNode(toRead, pt, finish, {
              end
            });
          } else {
            throw new ERR_INVALID_RETURN_VALUE('AsyncIterable or Promise', 'destination', ret)
          }
          ret = pt;
          const { destroy, cleanup } = destroyer$1(ret, false, true);
          destroys.push(destroy);
          if (isLastStream) {
            lastStreamCleanup.push(cleanup);
          }
        }
      } else if (isNodeStream$3(stream)) {
        if (isReadableNodeStream(ret)) {
          finishCount += 2;
          const cleanup = pipe(ret, stream, finish, {
            end
          });
          if (isReadable$1(stream) && isLastStream) {
            lastStreamCleanup.push(cleanup);
          }
        } else if (isTransformStream$1(ret) || isReadableStream$1(ret)) {
          const toRead = ret.readable || ret;
          finishCount++;
          pumpToNode(toRead, stream, finish, {
            end
          });
        } else if (isIterable$1(ret)) {
          finishCount++;
          pumpToNode(ret, stream, finish, {
            end
          });
        } else {
          throw new ERR_INVALID_ARG_TYPE$1(
            'val',
            ['Readable', 'Iterable', 'AsyncIterable', 'ReadableStream', 'TransformStream'],
            ret
          )
        }
        ret = stream;
      } else if (isWebStream$2(stream)) {
        if (isReadableNodeStream(ret)) {
          finishCount++;
          pumpToWeb(makeAsyncIterable(ret), stream, finish, {
            end
          });
        } else if (isReadableStream$1(ret) || isIterable$1(ret)) {
          finishCount++;
          pumpToWeb(ret, stream, finish, {
            end
          });
        } else if (isTransformStream$1(ret)) {
          finishCount++;
          pumpToWeb(ret.readable, stream, finish, {
            end
          });
        } else {
          throw new ERR_INVALID_ARG_TYPE$1(
            'val',
            ['Readable', 'Iterable', 'AsyncIterable', 'ReadableStream', 'TransformStream'],
            ret
          )
        }
        ret = stream;
      } else {
        ret = require$$11.from(stream);
      }
    }
    if (
      (signal !== null && signal !== undefined && signal.aborted) ||
      (outerSignal !== null && outerSignal !== undefined && outerSignal.aborted)
    ) {
      browser$2.nextTick(abort);
    }
    return ret
  }
  function pipe(src, dst, finish, { end }) {
    let ended = false;
    dst.on('close', () => {
      if (!ended) {
        // Finish if the destination closes before the source has completed.
        finish(new ERR_STREAM_PREMATURE_CLOSE());
      }
    });
    src.pipe(dst, {
      end: false
    }); // If end is true we already will have a listener to end dst.

    if (end) {
      // Compat. Before node v10.12.0 stdio used to throw an error so
      // pipe() did/does not end() stdio destinations.
      // Now they allow it but "secretly" don't close the underlying fd.

      function endFn() {
        ended = true;
        dst.end();
      }
      if (isReadableFinished(src)) {
        // End the destination if the source has already ended.
        browser$2.nextTick(endFn);
      } else {
        src.once('end', endFn);
      }
    } else {
      finish();
    }
    endOfStream(
      src,
      {
        readable: true,
        writable: false
      },
      (err) => {
        const rState = src._readableState;
        if (
          err &&
          err.code === 'ERR_STREAM_PREMATURE_CLOSE' &&
          rState &&
          rState.ended &&
          !rState.errored &&
          !rState.errorEmitted
        ) {
          // Some readable streams will emit 'close' before 'end'. However, since
          // this is on the readable side 'end' should still be emitted if the
          // stream has been ended and no error emitted. This should be allowed in
          // favor of backwards compatibility. Since the stream is piped to a
          // destination this should not result in any observable difference.
          // We don't need to check if this is a writable premature close since
          // eos will only fail with premature close on the reading side for
          // duplex streams.
          src.once('end', finish).once('error', finish);
        } else {
          finish(err);
        }
      }
    );
    return endOfStream(
      dst,
      {
        readable: false,
        writable: true
      },
      finish
    )
  }
  var pipeline_1 = {
    pipelineImpl,
    pipeline: pipeline$2
  };

  const { pipeline: pipeline$1 } = pipeline_1;

  const { destroyer } = destroy_1;
  const {
    isNodeStream: isNodeStream$2,
    isReadable,
    isWritable: isWritable$1,
    isWebStream: isWebStream$1,
    isTransformStream,
    isWritableStream,
    isReadableStream
  } = utils;
  const {
    AbortError: AbortError$1,
    codes: { ERR_INVALID_ARG_VALUE: ERR_INVALID_ARG_VALUE$1, ERR_MISSING_ARGS: ERR_MISSING_ARGS$1 }
  } = errors;

  var compose$1 = function compose(...streams) {
    if (streams.length === 0) {
      throw new ERR_MISSING_ARGS$1('streams')
    }
    if (streams.length === 1) {
      return require$$11.from(streams[0])
    }
    const orgStreams = [...streams];
    if (typeof streams[0] === 'function') {
      streams[0] = require$$11.from(streams[0]);
    }
    if (typeof streams[streams.length - 1] === 'function') {
      const idx = streams.length - 1;
      streams[idx] = require$$11.from(streams[idx]);
    }
    for (let n = 0; n < streams.length; ++n) {
      if (!isNodeStream$2(streams[n]) && !isWebStream$1(streams[n])) {
        // TODO(ronag): Add checks for non streams.
        continue
      }
      if (
        n < streams.length - 1 &&
        !(isReadable(streams[n]) || isReadableStream(streams[n]) || isTransformStream(streams[n]))
      ) {
        throw new ERR_INVALID_ARG_VALUE$1(`streams[${n}]`, orgStreams[n], 'must be readable')
      }
      if (n > 0 && !(isWritable$1(streams[n]) || isWritableStream(streams[n]) || isTransformStream(streams[n]))) {
        throw new ERR_INVALID_ARG_VALUE$1(`streams[${n}]`, orgStreams[n], 'must be writable')
      }
    }
    let ondrain;
    let onfinish;
    let onreadable;
    let onclose;
    let d;
    function onfinished(err) {
      const cb = onclose;
      onclose = null;
      if (cb) {
        cb(err);
      } else if (err) {
        d.destroy(err);
      } else if (!readable && !writable) {
        d.destroy();
      }
    }
    const head = streams[0];
    const tail = pipeline$1(streams, onfinished);
    const writable = !!(isWritable$1(head) || isWritableStream(head) || isTransformStream(head));
    const readable = !!(isReadable(tail) || isReadableStream(tail) || isTransformStream(tail));

    // TODO(ronag): Avoid double buffering.
    // Implement Writable/Readable/Duplex traits.
    // See, https://github.com/nodejs/node/pull/33515.
    d = new require$$11({
      // TODO (ronag): highWaterMark?
      writableObjectMode: !!(head !== null && head !== undefined && head.writableObjectMode),
      readableObjectMode: !!(tail !== null && tail !== undefined && tail.readableObjectMode),
      writable,
      readable
    });
    if (writable) {
      if (isNodeStream$2(head)) {
        d._write = function (chunk, encoding, callback) {
          if (head.write(chunk, encoding)) {
            callback();
          } else {
            ondrain = callback;
          }
        };
        d._final = function (callback) {
          head.end();
          onfinish = callback;
        };
        head.on('drain', function () {
          if (ondrain) {
            const cb = ondrain;
            ondrain = null;
            cb();
          }
        });
      } else if (isWebStream$1(head)) {
        const writable = isTransformStream(head) ? head.writable : head;
        const writer = writable.getWriter();
        d._write = async function (chunk, encoding, callback) {
          try {
            await writer.ready;
            writer.write(chunk).catch(() => {});
            callback();
          } catch (err) {
            callback(err);
          }
        };
        d._final = async function (callback) {
          try {
            await writer.ready;
            writer.close().catch(() => {});
            onfinish = callback;
          } catch (err) {
            callback(err);
          }
        };
      }
      const toRead = isTransformStream(tail) ? tail.readable : tail;
      endOfStream(toRead, () => {
        if (onfinish) {
          const cb = onfinish;
          onfinish = null;
          cb();
        }
      });
    }
    if (readable) {
      if (isNodeStream$2(tail)) {
        tail.on('readable', function () {
          if (onreadable) {
            const cb = onreadable;
            onreadable = null;
            cb();
          }
        });
        tail.on('end', function () {
          d.push(null);
        });
        d._read = function () {
          while (true) {
            const buf = tail.read();
            if (buf === null) {
              onreadable = d._read;
              return
            }
            if (!d.push(buf)) {
              return
            }
          }
        };
      } else if (isWebStream$1(tail)) {
        const readable = isTransformStream(tail) ? tail.readable : tail;
        const reader = readable.getReader();
        d._read = async function () {
          while (true) {
            try {
              const { value, done } = await reader.read();
              if (!d.push(value)) {
                return
              }
              if (done) {
                d.push(null);
                return
              }
            } catch {
              return
            }
          }
        };
      }
    }
    d._destroy = function (err, callback) {
      if (!err && onclose !== null) {
        err = new AbortError$1();
      }
      onreadable = null;
      ondrain = null;
      onfinish = null;
      if (onclose === null) {
        callback(err);
      } else {
        onclose = callback;
        if (isNodeStream$2(tail)) {
          destroyer(tail, err);
        }
      }
    };
    return d
  };

  const AbortController = globalThis.AbortController || browser$1.AbortController;
  const {
    codes: { ERR_INVALID_ARG_VALUE, ERR_INVALID_ARG_TYPE, ERR_MISSING_ARGS, ERR_OUT_OF_RANGE },
    AbortError
  } = errors;
  const { validateAbortSignal, validateInteger, validateObject } = validators;
  const kWeakHandler = primordials.Symbol('kWeak');
  const kResistStopPropagation = primordials.Symbol('kResistStopPropagation');
  const { finished: finished$1 } = endOfStream;

  const { addAbortSignalNoValidate } = addAbortSignal$2;
  const { isWritable, isNodeStream: isNodeStream$1 } = utils;
  const { deprecate } = util;
  const {
    ArrayPrototypePush,
    Boolean: Boolean$1,
    MathFloor,
    Number: Number$1,
    NumberIsNaN,
    Promise: Promise$2,
    PromiseReject,
    PromiseResolve,
    PromisePrototypeThen,
    Symbol: Symbol$1
  } = primordials;
  const kEmpty = Symbol$1('kEmpty');
  const kEof = Symbol$1('kEof');
  function compose(stream, options) {
    if (options != null) {
      validateObject(options, 'options');
    }
    if ((options === null || options === undefined ? undefined : options.signal) != null) {
      validateAbortSignal(options.signal, 'options.signal');
    }
    if (isNodeStream$1(stream) && !isWritable(stream)) {
      throw new ERR_INVALID_ARG_VALUE('stream', stream, 'must be writable')
    }
    const composedStream = compose$1(this, stream);
    if (options !== null && options !== undefined && options.signal) {
      // Not validating as we already validated before
      addAbortSignalNoValidate(options.signal, composedStream);
    }
    return composedStream
  }
  function map(fn, options) {
    if (typeof fn !== 'function') {
      throw new ERR_INVALID_ARG_TYPE('fn', ['Function', 'AsyncFunction'], fn)
    }
    if (options != null) {
      validateObject(options, 'options');
    }
    if ((options === null || options === undefined ? undefined : options.signal) != null) {
      validateAbortSignal(options.signal, 'options.signal');
    }
    let concurrency = 1;
    if ((options === null || options === undefined ? undefined : options.concurrency) != null) {
      concurrency = MathFloor(options.concurrency);
    }
    let highWaterMark = concurrency - 1;
    if ((options === null || options === undefined ? undefined : options.highWaterMark) != null) {
      highWaterMark = MathFloor(options.highWaterMark);
    }
    validateInteger(concurrency, 'options.concurrency', 1);
    validateInteger(highWaterMark, 'options.highWaterMark', 0);
    highWaterMark += concurrency;
    return async function* map() {
      const signal = util.AbortSignalAny(
        [options === null || options === undefined ? undefined : options.signal].filter(Boolean$1)
      );
      const stream = this;
      const queue = [];
      const signalOpt = {
        signal
      };
      let next;
      let resume;
      let done = false;
      let cnt = 0;
      function onCatch() {
        done = true;
        afterItemProcessed();
      }
      function afterItemProcessed() {
        cnt -= 1;
        maybeResume();
      }
      function maybeResume() {
        if (resume && !done && cnt < concurrency && queue.length < highWaterMark) {
          resume();
          resume = null;
        }
      }
      async function pump() {
        try {
          for await (let val of stream) {
            if (done) {
              return
            }
            if (signal.aborted) {
              throw new AbortError()
            }
            try {
              val = fn(val, signalOpt);
              if (val === kEmpty) {
                continue
              }
              val = PromiseResolve(val);
            } catch (err) {
              val = PromiseReject(err);
            }
            cnt += 1;
            PromisePrototypeThen(val, afterItemProcessed, onCatch);
            queue.push(val);
            if (next) {
              next();
              next = null;
            }
            if (!done && (queue.length >= highWaterMark || cnt >= concurrency)) {
              await new Promise$2((resolve) => {
                resume = resolve;
              });
            }
          }
          queue.push(kEof);
        } catch (err) {
          const val = PromiseReject(err);
          PromisePrototypeThen(val, afterItemProcessed, onCatch);
          queue.push(val);
        } finally {
          done = true;
          if (next) {
            next();
            next = null;
          }
        }
      }
      pump();
      try {
        while (true) {
          while (queue.length > 0) {
            const val = await queue[0];
            if (val === kEof) {
              return
            }
            if (signal.aborted) {
              throw new AbortError()
            }
            if (val !== kEmpty) {
              yield val;
            }
            queue.shift();
            maybeResume();
          }
          await new Promise$2((resolve) => {
            next = resolve;
          });
        }
      } finally {
        done = true;
        if (resume) {
          resume();
          resume = null;
        }
      }
    }.call(this)
  }
  function asIndexedPairs(options = undefined) {
    if (options != null) {
      validateObject(options, 'options');
    }
    if ((options === null || options === undefined ? undefined : options.signal) != null) {
      validateAbortSignal(options.signal, 'options.signal');
    }
    return async function* asIndexedPairs() {
      let index = 0;
      for await (const val of this) {
        var _options$signal;
        if (
          options !== null &&
          options !== undefined &&
          (_options$signal = options.signal) !== null &&
          _options$signal !== undefined &&
          _options$signal.aborted
        ) {
          throw new AbortError({
            cause: options.signal.reason
          })
        }
        yield [index++, val];
      }
    }.call(this)
  }
  async function some(fn, options = undefined) {
    for await (const unused of filter.call(this, fn, options)) {
      return true
    }
    return false
  }
  async function every(fn, options = undefined) {
    if (typeof fn !== 'function') {
      throw new ERR_INVALID_ARG_TYPE('fn', ['Function', 'AsyncFunction'], fn)
    }
    // https://en.wikipedia.org/wiki/De_Morgan%27s_laws
    return !(await some.call(
      this,
      async (...args) => {
        return !(await fn(...args))
      },
      options
    ))
  }
  async function find(fn, options) {
    for await (const result of filter.call(this, fn, options)) {
      return result
    }
    return undefined
  }
  async function forEach(fn, options) {
    if (typeof fn !== 'function') {
      throw new ERR_INVALID_ARG_TYPE('fn', ['Function', 'AsyncFunction'], fn)
    }
    async function forEachFn(value, options) {
      await fn(value, options);
      return kEmpty
    }
    // eslint-disable-next-line no-unused-vars
    for await (const unused of map.call(this, forEachFn, options));
  }
  function filter(fn, options) {
    if (typeof fn !== 'function') {
      throw new ERR_INVALID_ARG_TYPE('fn', ['Function', 'AsyncFunction'], fn)
    }
    async function filterFn(value, options) {
      if (await fn(value, options)) {
        return value
      }
      return kEmpty
    }
    return map.call(this, filterFn, options)
  }

  // Specific to provide better error to reduce since the argument is only
  // missing if the stream has no items in it - but the code is still appropriate
  class ReduceAwareErrMissingArgs extends ERR_MISSING_ARGS {
    constructor() {
      super('reduce');
      this.message = 'Reduce of an empty stream requires an initial value';
    }
  }
  async function reduce(reducer, initialValue, options) {
    var _options$signal2;
    if (typeof reducer !== 'function') {
      throw new ERR_INVALID_ARG_TYPE('reducer', ['Function', 'AsyncFunction'], reducer)
    }
    if (options != null) {
      validateObject(options, 'options');
    }
    if ((options === null || options === undefined ? undefined : options.signal) != null) {
      validateAbortSignal(options.signal, 'options.signal');
    }
    let hasInitialValue = arguments.length > 1;
    if (
      options !== null &&
      options !== undefined &&
      (_options$signal2 = options.signal) !== null &&
      _options$signal2 !== undefined &&
      _options$signal2.aborted
    ) {
      const err = new AbortError(undefined, {
        cause: options.signal.reason
      });
      this.once('error', () => {}); // The error is already propagated
      await finished$1(this.destroy(err));
      throw err
    }
    const ac = new AbortController();
    const signal = ac.signal;
    if (options !== null && options !== undefined && options.signal) {
      const opts = {
        once: true,
        [kWeakHandler]: this,
        [kResistStopPropagation]: true
      };
      options.signal.addEventListener('abort', () => ac.abort(), opts);
    }
    let gotAnyItemFromStream = false;
    try {
      for await (const value of this) {
        var _options$signal3;
        gotAnyItemFromStream = true;
        if (
          options !== null &&
          options !== undefined &&
          (_options$signal3 = options.signal) !== null &&
          _options$signal3 !== undefined &&
          _options$signal3.aborted
        ) {
          throw new AbortError()
        }
        if (!hasInitialValue) {
          initialValue = value;
          hasInitialValue = true;
        } else {
          initialValue = await reducer(initialValue, value, {
            signal
          });
        }
      }
      if (!gotAnyItemFromStream && !hasInitialValue) {
        throw new ReduceAwareErrMissingArgs()
      }
    } finally {
      ac.abort();
    }
    return initialValue
  }
  async function toArray(options) {
    if (options != null) {
      validateObject(options, 'options');
    }
    if ((options === null || options === undefined ? undefined : options.signal) != null) {
      validateAbortSignal(options.signal, 'options.signal');
    }
    const result = [];
    for await (const val of this) {
      var _options$signal4;
      if (
        options !== null &&
        options !== undefined &&
        (_options$signal4 = options.signal) !== null &&
        _options$signal4 !== undefined &&
        _options$signal4.aborted
      ) {
        throw new AbortError(undefined, {
          cause: options.signal.reason
        })
      }
      ArrayPrototypePush(result, val);
    }
    return result
  }
  function flatMap(fn, options) {
    const values = map.call(this, fn, options);
    return async function* flatMap() {
      for await (const val of values) {
        yield* val;
      }
    }.call(this)
  }
  function toIntegerOrInfinity(number) {
    // We coerce here to align with the spec
    // https://github.com/tc39/proposal-iterator-helpers/issues/169
    number = Number$1(number);
    if (NumberIsNaN(number)) {
      return 0
    }
    if (number < 0) {
      throw new ERR_OUT_OF_RANGE('number', '>= 0', number)
    }
    return number
  }
  function drop(number, options = undefined) {
    if (options != null) {
      validateObject(options, 'options');
    }
    if ((options === null || options === undefined ? undefined : options.signal) != null) {
      validateAbortSignal(options.signal, 'options.signal');
    }
    number = toIntegerOrInfinity(number);
    return async function* drop() {
      var _options$signal5;
      if (
        options !== null &&
        options !== undefined &&
        (_options$signal5 = options.signal) !== null &&
        _options$signal5 !== undefined &&
        _options$signal5.aborted
      ) {
        throw new AbortError()
      }
      for await (const val of this) {
        var _options$signal6;
        if (
          options !== null &&
          options !== undefined &&
          (_options$signal6 = options.signal) !== null &&
          _options$signal6 !== undefined &&
          _options$signal6.aborted
        ) {
          throw new AbortError()
        }
        if (number-- <= 0) {
          yield val;
        }
      }
    }.call(this)
  }
  function take(number, options = undefined) {
    if (options != null) {
      validateObject(options, 'options');
    }
    if ((options === null || options === undefined ? undefined : options.signal) != null) {
      validateAbortSignal(options.signal, 'options.signal');
    }
    number = toIntegerOrInfinity(number);
    return async function* take() {
      var _options$signal7;
      if (
        options !== null &&
        options !== undefined &&
        (_options$signal7 = options.signal) !== null &&
        _options$signal7 !== undefined &&
        _options$signal7.aborted
      ) {
        throw new AbortError()
      }
      for await (const val of this) {
        var _options$signal8;
        if (
          options !== null &&
          options !== undefined &&
          (_options$signal8 = options.signal) !== null &&
          _options$signal8 !== undefined &&
          _options$signal8.aborted
        ) {
          throw new AbortError()
        }
        if (number-- > 0) {
          yield val;
        }

        // Don't get another item from iterator in case we reached the end
        if (number <= 0) {
          return
        }
      }
    }.call(this)
  }
  var streamReturningOperators = {
    asIndexedPairs: deprecate(asIndexedPairs, 'readable.asIndexedPairs will be removed in a future version.'),
    drop,
    filter,
    flatMap,
    map,
    take,
    compose
  };
  var promiseReturningOperators = {
    every,
    forEach,
    reduce,
    toArray,
    some,
    find
  };

  var operators = {
  	streamReturningOperators: streamReturningOperators,
  	promiseReturningOperators: promiseReturningOperators
  };

  var CustomStream = stream;

  const { ArrayPrototypePop, Promise: Promise$1 } = primordials;
  const { isIterable, isNodeStream, isWebStream } = utils;
  const { pipelineImpl: pl } = pipeline_1;
  const { finished } = endOfStream;

  function pipeline(...streams) {
    return new Promise$1((resolve, reject) => {
      let signal;
      let end;
      const lastArg = streams[streams.length - 1];
      if (
        lastArg &&
        typeof lastArg === 'object' &&
        !isNodeStream(lastArg) &&
        !isIterable(lastArg) &&
        !isWebStream(lastArg)
      ) {
        const options = ArrayPrototypePop(streams);
        signal = options.signal;
        end = options.end;
      }
      pl(
        streams,
        (err, value) => {
          if (err) {
            reject(err);
          } else {
            resolve(value);
          }
        },
        {
          signal,
          end
        }
      );
    })
  }
  var promises = {
    finished,
    pipeline
  };

  var stream = createCommonjsModule(function (module) {

  /* replacement start */

  const { Buffer } = buffer$1;

  /* replacement end */

  const { ObjectDefineProperty, ObjectKeys, ReflectApply } = primordials;
  const {
    promisify: { custom: customPromisify }
  } = util;
  const { streamReturningOperators, promiseReturningOperators } = operators;
  const {
    codes: { ERR_ILLEGAL_CONSTRUCTOR }
  } = errors;

  const { setDefaultHighWaterMark, getDefaultHighWaterMark } = state;
  const { pipeline } = pipeline_1;
  const { destroyer } = destroy_1;


  const Stream = (module.exports = legacy.Stream);
  Stream.isDestroyed = utils.isDestroyed;
  Stream.isDisturbed = utils.isDisturbed;
  Stream.isErrored = utils.isErrored;
  Stream.isReadable = utils.isReadable;
  Stream.isWritable = utils.isWritable;
  Stream.Readable = readable;
  for (const key of ObjectKeys(streamReturningOperators)) {
    const op = streamReturningOperators[key];
    function fn(...args) {
      if (new.target) {
        throw ERR_ILLEGAL_CONSTRUCTOR()
      }
      return Stream.Readable.from(ReflectApply(op, this, args))
    }
    ObjectDefineProperty(fn, 'name', {
      __proto__: null,
      value: op.name
    });
    ObjectDefineProperty(fn, 'length', {
      __proto__: null,
      value: op.length
    });
    ObjectDefineProperty(Stream.Readable.prototype, key, {
      __proto__: null,
      value: fn,
      enumerable: false,
      configurable: true,
      writable: true
    });
  }
  for (const key of ObjectKeys(promiseReturningOperators)) {
    const op = promiseReturningOperators[key];
    function fn(...args) {
      if (new.target) {
        throw ERR_ILLEGAL_CONSTRUCTOR()
      }
      return ReflectApply(op, this, args)
    }
    ObjectDefineProperty(fn, 'name', {
      __proto__: null,
      value: op.name
    });
    ObjectDefineProperty(fn, 'length', {
      __proto__: null,
      value: op.length
    });
    ObjectDefineProperty(Stream.Readable.prototype, key, {
      __proto__: null,
      value: fn,
      enumerable: false,
      configurable: true,
      writable: true
    });
  }
  Stream.Writable = writable;
  Stream.Duplex = require$$11;
  Stream.Transform = transform;
  Stream.PassThrough = passthrough;
  Stream.pipeline = pipeline;
  const { addAbortSignal } = addAbortSignal$2;
  Stream.addAbortSignal = addAbortSignal;
  Stream.finished = endOfStream;
  Stream.destroy = destroyer;
  Stream.compose = compose$1;
  Stream.setDefaultHighWaterMark = setDefaultHighWaterMark;
  Stream.getDefaultHighWaterMark = getDefaultHighWaterMark;
  ObjectDefineProperty(Stream, 'promises', {
    __proto__: null,
    configurable: true,
    enumerable: true,
    get() {
      return promises
    }
  });
  ObjectDefineProperty(pipeline, customPromisify, {
    __proto__: null,
    enumerable: true,
    get() {
      return promises.pipeline
    }
  });
  ObjectDefineProperty(endOfStream, customPromisify, {
    __proto__: null,
    enumerable: true,
    get() {
      return promises.finished
    }
  });

  // Backwards-compat with node 0.4.x
  Stream.Stream = Stream;
  Stream._isUint8Array = function isUint8Array(value) {
    return value instanceof Uint8Array
  };
  Stream._uint8ArrayToBuffer = function _uint8ArrayToBuffer(chunk) {
    return Buffer.from(chunk.buffer, chunk.byteOffset, chunk.byteLength)
  };
  });

  var browser = createCommonjsModule(function (module) {



  const originalDestroy = CustomStream.Readable.destroy;
  module.exports = CustomStream.Readable;

  // Explicit export naming is needed for ESM
  module.exports._uint8ArrayToBuffer = CustomStream._uint8ArrayToBuffer;
  module.exports._isUint8Array = CustomStream._isUint8Array;
  module.exports.isDisturbed = CustomStream.isDisturbed;
  module.exports.isErrored = CustomStream.isErrored;
  module.exports.isReadable = CustomStream.isReadable;
  module.exports.Readable = CustomStream.Readable;
  module.exports.Writable = CustomStream.Writable;
  module.exports.Duplex = CustomStream.Duplex;
  module.exports.Transform = CustomStream.Transform;
  module.exports.PassThrough = CustomStream.PassThrough;
  module.exports.addAbortSignal = CustomStream.addAbortSignal;
  module.exports.finished = CustomStream.finished;
  module.exports.destroy = CustomStream.destroy;
  module.exports.destroy = originalDestroy;
  module.exports.pipeline = CustomStream.pipeline;
  module.exports.compose = CustomStream.compose;
  Object.defineProperty(CustomStream, 'promises', {
    configurable: true,
    enumerable: true,
    get() {
      return promises
    }
  });
  module.exports.Stream = CustomStream.Stream;

  // Allow default importing
  module.exports.default = module.exports;
  });

  const { Readable } = browser;

  const kIterator = Symbol('iterator');
  const kNextv = Symbol('nextv');
  const kNextvLegacy = Symbol('nextvLegacy');
  const kDestroy = Symbol('destroy');

  class LevelReadStream extends Readable {
    constructor (db, method, options) {
      const { highWaterMark, ...rest } = options || {};

      super({
        objectMode: true,
        autoDestroy: true,
        highWaterMark: highWaterMark || 1000
      });

      this[kIterator] = db[method](rest);
      this[kNextv] = this[kNextv].bind(this);
      this[kNextvLegacy] = this[kNextvLegacy].bind(this);
      this[kDestroy] = this.destroy.bind(this);
    }

    get db () {
      return this[kIterator].db
    }

    _read (size) {
      if (this.destroyed) return

      this[kIterator].nextv(size).then(
        this[kNextv],
        this[kDestroy]
      );
    }

    [kNextvLegacy] (err, items) {
      if (this.destroyed) return
      if (err) return this.destroy(err)

      if (items.length === 0) {
        this.push(null);
      } else {
        for (const item of items) {
          this.push(item);
        }
      }
    }

    [kNextv] (items) {
      if (this.destroyed) return

      if (items.length === 0) {
        this.push(null);
      } else {
        for (const item of items) {
          this.push(item);
        }
      }
    }

    _destroy (err, callback) {
      this[kIterator].close().then(
        err ? () => callback(err) : callback,
        callback
      );
    }
  }

  class EntryStream extends LevelReadStream {
    constructor (db, options) {
      super(db, 'iterator', { ...options, keys: true, values: true });
    }

    [kNextvLegacy] (err, entries) {
      if (this.destroyed) return
      if (err) return this.destroy(err)

      if (entries.length === 0) {
        this.push(null);
      } else {
        for (const [key, value] of entries) {
          this.push({ key, value });
        }
      }
    }

    [kNextv] (entries) {
      if (this.destroyed) return

      if (entries.length === 0) {
        this.push(null);
      } else {
        for (const [key, value] of entries) {
          this.push({ key, value });
        }
      }
    }
  }

  class KeyStream extends LevelReadStream {
    constructor (db, options) {
      super(db, 'keys', options);
    }
  }

  class ValueStream extends LevelReadStream {
    constructor (db, options) {
      super(db, 'values', options);
    }
  }

  var EntryStream_1 = EntryStream;
  var KeyStream_1 = KeyStream;
  var ValueStream_1 = ValueStream;

  const PREFERRED_TRIM_SIZE = 500;

  const YEncodingString = 0;
  const YEncodingUint32 = 1;

  /**
   * @typedef {import('abstract-level').AbstractLevel<any, Array<String|number>, Uint8Array>} AbstractLevel
   */
  /**
   * @typedef {['v1', string, 'update', number] | ['v1', string, 'meta', string] | ['v1_sv', number]} DocKey
   */

  const valueEncoding = {
    buffer: true,
    type: 'y-value',
    encode: /** @param {any} data */ data => data,
    decode: /** @param {any} data */ data => data
  };

  /**
   * Write two bytes as an unsigned integer in big endian order.
   * (most significant byte first)
   *
   * @function
   * @param {encoding.Encoder} encoder
   * @param {number} num The number that is to be encoded.
   */
  const writeUint32BigEndian = (encoder, num) => {
    for (let i = 3; i >= 0; i--) {
      write$1(encoder, (num >>> (8 * i)) & BITS8);
    }
  };

  /**
   * Read 4 bytes as unsigned integer in big endian order.
   * (most significant byte first)
   *
   * @todo use lib0/decoding instead
   *
   * @function
   * @param {decoding.Decoder} decoder
   * @return {number} An unsigned integer.
   */
  const readUint32BigEndian = decoder => {
    const uint =
      (decoder.arr[decoder.pos + 3] +
      (decoder.arr[decoder.pos + 2] << 8) +
      (decoder.arr[decoder.pos + 1] << 16) +
      (decoder.arr[decoder.pos] << 24)) >>> 0;
    decoder.pos += 4;
    return uint
  };

  const keyEncoding = {
    buffer: true,
    type: 'y-keys',
    /* istanbul ignore next */
    encode: /** @param {Array<string|number>} arr */  arr => {
      const encoder = createEncoder();
      for (let i = 0; i < arr.length; i++) {
        const v = arr[i];
        if (typeof v === 'string') {
          writeUint8(encoder, YEncodingString);
          writeVarString(encoder, v);
        } else /* istanbul ignore else */ if (typeof v === 'number') {
          writeUint8(encoder, YEncodingUint32);
          writeUint32BigEndian(encoder, v);
        } else {
          throw new Error('Unexpected key value')
        }
      }
      return buffer$1.Buffer.from(toUint8Array(encoder))
    },
    decode: /** @param {Uint8Array} buf */ buf => {
      const decoder = createDecoder(buf);
      const key = [];
      while (hasContent(decoder)) {
        switch (readUint8(decoder)) {
          case YEncodingString:
            key.push(readVarString(decoder));
            break
          case YEncodingUint32:
            key.push(readUint32BigEndian(decoder));
            break
        }
      }
      return key
    }
  };

  /**
   * level returns an error if a value is not found.
   *
   * This helper method for level returns `null` instead if the key is not found.
   *
   * @param {AbstractLevel} db
   * @param {any} key
   * @return {Promise<Uint8Array | undefined>}
   */
  const levelGet = async (db, key) => {
    let res;
    try {
      res = await db.get(key);
    } catch (err) {
      /* istanbul ignore else */
      if (/** @type {any} */ (err).notFound) {
        return
      } else {
        throw err
      }
    }
    return res
  };

  /**
   * Level expects a Buffer, but in Yjs we typically work with Uint8Arrays.
   *
   * Since Level thinks that these are two entirely different things,
   * we transform the Uint8array to a Buffer before storing it.
   *
   * @param {any} db
   * @param {any} key
   * @param {Uint8Array} val
   */
  const levelPut = async (db, key, val) => db.put(key, buffer$1.Buffer.from(val));

  /**
   * A "bulkier" implementation of level streams. Returns the result in one flush.
   *
   * @param {AbstractLevel} db
   * @param {import('abstract-level').AbstractIteratorOptions<any, Uint8Array>} opts
   * @return {Promise<Array<{ key: DocKey, value: Uint8Array }>>}
   */
  const getLevelBulkEntries = (db, opts) => create$3((resolve, reject) => {
    /**
     * @type {Array<any>} result
     */
    const result = [];
    new EntryStream_1(db, opts).on('data', data => {
      result.push(data);
    }).on('end', () => {
      resolve(result);
    }).on('error', reject);
  });

  /**
   * A "bulkier" implementation of level streams. Returns the result in one flush.
   *
   * @param {AbstractLevel} db
   * @param {import('abstract-level').AbstractIteratorOptions<any, Uint8Array>} opts
   * @return {Promise<Array<DocKey>>}
   */
  const getLevelBulkKeys = (db, opts) => create$3((resolve, reject) => {
    /**
     * @type {Array<any>} result
     */
    const result = [];
    new KeyStream_1(db, opts).on('data', data => {
      result.push(data);
    }).on('end', () => {
      resolve(result);
    }).on('error', reject);
  });

  /**
   * A "bulkier" implementation of level streams. Returns the result in one flush.
   *
   * @param {AbstractLevel} db
   * @param {import('abstract-level').AbstractIteratorOptions<DocKey, Uint8Array>} opts
   * @return {Promise<Array<Uint8Array>>}
   */
  const getLevelBulkValues = (db, opts) => create$3((resolve, reject) => {
    /**
     * @type {Array<any>} result
     */
    const result = [];
    new ValueStream_1(db, opts).on('data', data => {
      result.push(data);
    }).on('end', () => {
      resolve(result);
    }).on('error', reject);
  });

  /**
   * Get all document updates for a specific document.
   *
   * @param {any} db
   * @param {string} docName
   * @param {any} [opts]
   * @return {Promise<Array<Uint8Array>>}
   */
  const getLevelUpdates = (db, docName, opts = {}) => getLevelBulkValues(db, {
    gte: createDocumentUpdateKey(docName, 0),
    lt: createDocumentUpdateKey(docName, BITS32),
    ...opts
  });

  /**
   * Get all document updates for a specific document.
   *
   * @param {any} db
   * @param {string} docName
   * @param {any} [opts]
   * @return {Promise<Array<{key: DocKey, value: Uint8Array }>>}
   */
  const getLevelUpdatesEntries = (db, docName, opts = {}) => getLevelBulkEntries(db, {
    gte: createDocumentUpdateKey(docName, 0),
    lt: createDocumentUpdateKey(docName, BITS32),
    ...opts
  });

  /**
   * Get all document updates for a specific document.
   *
   * @param {any} db
   * @param {string} docName
   * @param {any} opts
   * @return {Promise<Array<DocKey>>}
   */
  /* istanbul ignore next */
  const getLevelUpdatesKeys = (db, docName, opts = {}) => getLevelBulkKeys(db, {
    gte: createDocumentUpdateKey(docName, 0),
    lt: createDocumentUpdateKey(docName, BITS32),
    ...opts
  });

  /**
   * Get all document updates for a specific document.
   *
   * @param {AbstractLevel} db
   */
  const getAllDocsKeys = (db) => getLevelBulkKeys(db, {
    gte: ['v1_sv'],
    lt: ['v1_sw']
  });

  /**
   * Get all document updates for a specific document.
   *
   * @param {AbstractLevel} db
   */
  const getAllDocs = (db) => getLevelBulkEntries(db, {
    gte: ['v1_sv'],
    lt: ['v1_sw']
  });

  /**
   * @param {any} db
   * @param {string} docName
   * @return {Promise<number>} Returns -1 if this document doesn't exist yet
   */
  const getCurrentUpdateClock = (db, docName) => getLevelUpdatesKeys(db, docName, { reverse: true, limit: 1 }).then(entries => {
    if (entries.length === 0) {
      return -1
    } else {
      return /** @type {number} */ (entries[0][3])
    }
  });

  /**
   * @param {any} db
   * @param {Array<string|number>} gte Greater than or equal
   * @param {Array<string|number>} lt lower than (not equal)
   * @return {Promise<void>}
   */
  const clearRange = async (db, gte, lt) => {
    /* istanbul ignore else */
    if (db.supports.clear) {
      await db.clear({ gte, lt });
    } else {
      const keys = await getLevelBulkKeys(db, { gte, lt });
      const ops = keys.map(key => ({ type: 'del', key }));
      await db.batch(ops);
    }
  };

  /**
   * @param {any} db
   * @param {string} docName
   * @param {number} from Greater than or equal
   * @param {number} to lower than (not equal)
   * @return {Promise<void>}
   */
  const clearUpdatesRange = async (db, docName, from, to) => clearRange(db, createDocumentUpdateKey(docName, from), createDocumentUpdateKey(docName, to));

  /**
   * Create a unique key for a update message.
   * We encode the result using `keyEncoding` which expects an array.
   *
   * @param {string} docName
   * @param {number} clock must be unique
   * @return {DocKey}
   */
  const createDocumentUpdateKey = (docName, clock) => ['v1', docName, 'update', clock];

  /**
   * @param {string} docName
   * @param {string} metaKey
   * @return {any}
   */
  const createDocumentMetaKey = (docName, metaKey) => ['v1', docName, 'meta', metaKey];

  /**
   * @param {string} docName
   * @return {any}
   */
  const createDocumentMetaEndKey = (docName) => ['v1', docName, 'metb']; // simple trick

  /**
   * We have a separate state vector key so we can iterate efficiently over all documents
   * @param {string} docName
   */
  const createDocumentStateVectorKey = (docName) => ['v1_sv', docName];

  /**
   * @param {string} docName
   */
  const createDocumentFirstKey = (docName) => ['v1', docName];

  /**
   * We use this key as the upper limit of all keys that can be written.
   * Make sure that all document keys are smaller! Strings are encoded using varLength string encoding,
   * so we need to make sure that this key has the biggest size!
   *
   * @param {string} docName
   */
  const createDocumentLastKey = (docName) => ['v1', docName, 'zzzzzzz'];

  // const emptyStateVector = (() => Y.encodeStateVector(new Y.Doc()))()

  /**
   * For now this is a helper method that creates a Y.Doc and then re-encodes a document update.
   * In the future this will be handled by Yjs without creating a Y.Doc (constant memory consumption).
   *
   * @param {Array<Uint8Array>} updates
   * @return {{update:Uint8Array, sv: Uint8Array}}
   */
  const mergeUpdates = (updates) => {
    const ydoc = new Doc();
    ydoc.transact(() => {
      for (let i = 0; i < updates.length; i++) {
        applyUpdate(ydoc, updates[i]);
      }
    });
    return { update: encodeStateAsUpdate(ydoc), sv: encodeStateVector(ydoc) }
  };

  /**
   * @param {any} db
   * @param {string} docName
   * @param {Uint8Array} sv state vector
   * @param {number} clock current clock of the document so we can determine when this statevector was created
   */
  const writeStateVector = async (db, docName, sv, clock) => {
    const encoder = createEncoder();
    writeVarUint(encoder, clock);
    writeVarUint8Array(encoder, sv);
    await levelPut(db, createDocumentStateVectorKey(docName), toUint8Array(encoder));
  };

  /**
   * @param {Uint8Array} buf
   * @return {{ sv: Uint8Array, clock: number }}
   */
  const decodeLeveldbStateVector = buf => {
    const decoder = createDecoder(buf);
    const clock = readVarUint(decoder);
    const sv = readVarUint8Array(decoder);
    return { sv, clock }
  };

  /**
   * @param {any} db
   * @param {string} docName
   */
  const readStateVector$1 = async (db, docName) => {
    const buf = await levelGet(db, createDocumentStateVectorKey(docName));
    if (buf == null) {
      // no state vector created yet or no document exists
      return { sv: null, clock: -1 }
    }
    return decodeLeveldbStateVector(buf)
  };

  /**
   * @param {any} db
   * @param {string} docName
   * @param {Uint8Array} stateAsUpdate
   * @param {Uint8Array} stateVector
   * @return {Promise<number>} returns the clock of the flushed doc
   */
  const flushDocument = async (db, docName, stateAsUpdate, stateVector) => {
    const clock = await storeUpdate(db, docName, stateAsUpdate);
    await writeStateVector(db, docName, stateVector, clock);
    await clearUpdatesRange(db, docName, 0, clock); // intentionally not waiting for the promise to resolve!
    return clock
  };

  /**
   * @param {any} db
   * @param {string} docName
   * @param {Uint8Array} update
   * @return {Promise<number>} Returns the clock of the stored update
   */
  const storeUpdate = async (db, docName, update) => {
    const clock = await getCurrentUpdateClock(db, docName);
    if (clock === -1) {
      // make sure that a state vector is aways written, so we can search for available documents
      const ydoc = new Doc();
      applyUpdate(ydoc, update);
      const sv = encodeStateVector(ydoc);
      await writeStateVector(db, docName, sv, 0);
    }
    await levelPut(db, createDocumentUpdateKey(docName, clock + 1), update);
    return clock + 1
  };

  class LeveldbPersistence {
    /**
     * @param {string} location
     * @param {object} opts
     * @param {any} [opts.Level] Level-compatible adapter. E.g. leveldown, level-rem, level-indexeddb. Defaults to `level`
     * @param {object} [opts.levelOptions] Options that are passed down to the level instance
     */
    constructor (location, /* istanbul ignore next */ { Level: Level$1 = Level, levelOptions = {} } = {}) {
      /**
       * @type {import('abstract-level').AbstractLevel<any>}
       */
      const db = new Level$1(location, { ...levelOptions, valueEncoding, keyEncoding });
      this.tr = resolve();
      /**
       * Execute an transaction on a database. This will ensure that other processes are currently not writing.
       *
       * This is a private method and might change in the future.
       *
       * @todo only transact on the same room-name. Allow for concurrency of different rooms.
       *
       * @template T
       *
       * @param {function(any):Promise<T>} f A transaction that receives the db object
       * @return {Promise<T>}
       */
      this._transact = f => {
        const currTr = this.tr;
        this.tr = (async () => {
          await currTr;
          let res = /** @type {any} */ (null);
          try {
            res = await f(db);
          } catch (err) {
            /* istanbul ignore next */
            console.warn('Error during y-leveldb transaction', err);
          }
          return res
        })();
        return this.tr
      };
    }

    /**
     * @param {string} docName
     */
    flushDocument (docName) {
      return this._transact(async db => {
        const updates = await getLevelUpdates(db, docName);
        const { update, sv } = mergeUpdates(updates);
        await flushDocument(db, docName, update, sv);
      })
    }

    /**
     * @param {string} docName
     * @return {Promise<Y.Doc>}
     */
    getYDoc (docName) {
      return this._transact(async db => {
        const updates = await getLevelUpdates(db, docName);
        const ydoc = new Doc();
        ydoc.transact(() => {
          for (let i = 0; i < updates.length; i++) {
            applyUpdate(ydoc, updates[i]);
          }
        });
        if (updates.length > PREFERRED_TRIM_SIZE) {
          await flushDocument(db, docName, encodeStateAsUpdate(ydoc), encodeStateVector(ydoc));
        }
        return ydoc
      })
    }

    /**
     * @param {string} docName
     * @return {Promise<Uint8Array>}
     */
    getStateVector (docName) {
      return this._transact(async db => {
        const { clock, sv } = await readStateVector$1(db, docName);
        let curClock = -1;
        if (sv !== null) {
          curClock = await getCurrentUpdateClock(db, docName);
        }
        if (sv !== null && clock === curClock) {
          return sv
        } else {
          // current state vector is outdated
          const updates = await getLevelUpdates(db, docName);
          const { update, sv } = mergeUpdates(updates);
          await flushDocument(db, docName, update, sv);
          return sv
        }
      })
    }

    /**
     * @param {string} docName
     * @param {Uint8Array} update
     * @return {Promise<number>} Returns the clock of the stored update
     */
    storeUpdate (docName, update) {
      return this._transact(db => storeUpdate(db, docName, update))
    }

    /**
     * @param {string} docName
     * @param {Uint8Array} stateVector
     */
    async getDiff (docName, stateVector) {
      const ydoc = await this.getYDoc(docName);
      return encodeStateAsUpdate(ydoc, stateVector)
    }

    /**
     * @param {string} docName
     * @return {Promise<void>}
     */
    clearDocument (docName) {
      return this._transact(async db => {
        await db.del(createDocumentStateVectorKey(docName));
        await clearRange(db, createDocumentFirstKey(docName), createDocumentLastKey(docName));
      })
    }

    /**
     * @param {string} docName
     * @param {string} metaKey
     * @param {any} value
     * @return {Promise<void>}
     */
    setMeta (docName, metaKey, value) {
      return this._transact(db => levelPut(db, createDocumentMetaKey(docName, metaKey), encodeAny(value)))
    }

    /**
     * @param {string} docName
     * @param {string} metaKey
     * @return {Promise<any>}
     */
    delMeta (docName, metaKey) {
      return this._transact(db => db.del(createDocumentMetaKey(docName, metaKey)))
    }

    /**
     * @param {string} docName
     * @param {string} metaKey
     * @return {Promise<any>}
     */
    getMeta (docName, metaKey) {
      return this._transact(async db => {
        const res = await levelGet(db, createDocumentMetaKey(docName, metaKey));
        if (res == null) {
          return
        }
        return decodeAny(res)
      })
    }

    /**
     * @return {Promise<Array<string>>}
     */
    getAllDocNames () {
      return this._transact(async db => {
        const docKeys = await getAllDocsKeys(db);
        return docKeys.map(key => /** @type {string} */ (key[1]))
      })
    }

    /**
     * @return {Promise<Array<{ name: string, sv: Uint8Array, clock: number }>>}
     */
    getAllDocStateVectors () {
      return this._transact(async db => {
        const docs = await getAllDocs(db);
        return docs.map(doc => {
          const { sv, clock } = decodeLeveldbStateVector(doc.value);
          return { name: /** @type {string} */ (doc.key[1]), sv, clock }
        })
      })
    }

    /**
     * @param {string} docName
     * @return {Promise<Map<string, any>>}
     */
    getMetas (docName) {
      return this._transact(async db => {
        const data = await getLevelBulkEntries(db, {
          gte: createDocumentMetaKey(docName, ''),
          lt: createDocumentMetaEndKey(docName),
          keys: true,
          values: true
        });
        const metas = new Map();
        data.forEach(v => { metas.set(v.key[3], decodeAny(v.value)); });
        return metas
      })
    }

    /**
     * Close connection to a leveldb database and discard all state and bindings
     *
     * @return {Promise<void>}
     */
    destroy () {
      return this._transact(db => db.close())
    }

    /**
     * Delete all data in database.
     */
    clearAll () {
      return this._transact(async db => db.clear())
    }
  }

  /**
   * @module prng
   */

  /**
   * Xorshift32 is a very simple but elegang PRNG with a period of `2^32-1`.
   */
  class Xorshift32 {
    /**
     * @param {number} seed Unsigned 32 bit number
     */
    constructor (seed) {
      this.seed = seed;
      /**
       * @type {number}
       */
      this._state = seed;
    }

    /**
     * Generate a random signed integer.
     *
     * @return {Number} A 32 bit signed integer.
     */
    next () {
      let x = this._state;
      x ^= x << 13;
      x ^= x >> 17;
      x ^= x << 5;
      this._state = x;
      return (x >>> 0) / (BITS32 + 1)
    }
  }

  /**
   * @module prng
   */

  /**
   * This is a variant of xoroshiro128plus - the fastest full-period generator passing BigCrush without systematic failures.
   *
   * This implementation follows the idea of the original xoroshiro128plus implementation,
   * but is optimized for the JavaScript runtime. I.e.
   * * The operations are performed on 32bit integers (the original implementation works with 64bit values).
   * * The initial 128bit state is computed based on a 32bit seed and Xorshift32.
   * * This implementation returns two 32bit values based on the 64bit value that is computed by xoroshiro128plus.
   *   Caution: The last addition step works slightly different than in the original implementation - the add carry of the
   *   first 32bit addition is not carried over to the last 32bit.
   *
   * [Reference implementation](http://vigna.di.unimi.it/xorshift/xoroshiro128plus.c)
   */
  class Xoroshiro128plus {
    /**
     * @param {number} seed Unsigned 32 bit number
     */
    constructor (seed) {
      this.seed = seed;
      // This is a variant of Xoroshiro128plus to fill the initial state
      const xorshift32 = new Xorshift32(seed);
      this.state = new Uint32Array(4);
      for (let i = 0; i < 4; i++) {
        this.state[i] = xorshift32.next() * BITS32;
      }
      this._fresh = true;
    }

    /**
     * @return {number} Float/Double in [0,1)
     */
    next () {
      const state = this.state;
      if (this._fresh) {
        this._fresh = false;
        return ((state[0] + state[2]) >>> 0) / (BITS32 + 1)
      } else {
        this._fresh = true;
        const s0 = state[0];
        const s1 = state[1];
        const s2 = state[2] ^ s0;
        const s3 = state[3] ^ s1;
        // function js_rotl (x, k) {
        //   k = k - 32
        //   const x1 = x[0]
        //   const x2 = x[1]
        //   x[0] = x2 << k | x1 >>> (32 - k)
        //   x[1] = x1 << k | x2 >>> (32 - k)
        // }
        // rotl(s0, 55) // k = 23 = 55 - 32; j = 9 =  32 - 23
        state[0] = (s1 << 23 | s0 >>> 9) ^ s2 ^ (s2 << 14 | s3 >>> 18);
        state[1] = (s0 << 23 | s1 >>> 9) ^ s3 ^ (s3 << 14);
        // rol(s1, 36) // k = 4 = 36 - 32; j = 23 = 32 - 9
        state[2] = s3 << 4 | s2 >>> 28;
        state[3] = s2 << 4 | s3 >>> 28;
        return (((state[1] + state[3]) >>> 0) / (BITS32 + 1))
      }
    }
  }

  /*
  // Reference implementation
  // Source: http://vigna.di.unimi.it/xorshift/xoroshiro128plus.c
  // By David Blackman and Sebastiano Vigna
  // Who published the reference implementation under Public Domain (CC0)

  #include <stdint.h>
  #include <stdio.h>

  uint64_t s[2];

  static inline uint64_t rotl(const uint64_t x, int k) {
      return (x << k) | (x >> (64 - k));
  }

  uint64_t next(void) {
      const uint64_t s0 = s[0];
      uint64_t s1 = s[1];
      s1 ^= s0;
      s[0] = rotl(s0, 55) ^ s1 ^ (s1 << 14); // a, b
      s[1] = rotl(s1, 36); // c
      return (s[0] + s[1]) & 0xFFFFFFFF;
  }

  int main(void)
  {
      int i;
      s[0] = 1111 | (1337ul << 32);
      s[1] = 1234 | (9999ul << 32);

      printf("1000 outputs of genrand_int31()\n");
      for (i=0; i<100; i++) {
          printf("%10lu ", i);
          printf("%10lu ", next());
          printf("- %10lu ", s[0] >> 32);
          printf("%10lu ", (s[0] << 32) >> 32);
          printf("%10lu ", s[1] >> 32);
          printf("%10lu ", (s[1] << 32) >> 32);
          printf("\n");
          // if (i%5==4) printf("\n");
      }
      return 0;
  }
  */

  /**
   * Fast Pseudo Random Number Generators.
   *
   * Given a seed a PRNG generates a sequence of numbers that cannot be reasonably predicted.
   * Two PRNGs must generate the same random sequence of numbers if  given the same seed.
   *
   * @module prng
   */

  /**
   * Description of the function
   *  @callback generatorNext
   *  @return {number} A random float in the cange of [0,1)
   */

  /**
   * A random type generator.
   *
   * @typedef {Object} PRNG
   * @property {generatorNext} next Generate new number
   */
  const DefaultPRNG = Xoroshiro128plus;

  /**
   * Create a Xoroshiro128plus Pseudo-Random-Number-Generator.
   * This is the fastest full-period generator passing BigCrush without systematic failures.
   * But there are more PRNGs available in ./PRNG/.
   *
   * @param {number} seed A positive 32bit integer. Do not use negative numbers.
   * @return {PRNG}
   */
  const create = seed => new DefaultPRNG(seed);
  /* c8 ignore stop */

  /**
   * Utility helpers for generating statistics.
   *
   * @module statistics
   */

  /**
   * @param {Array<number>} arr Array of values
   * @return {number} Returns null if the array is empty
   */
  const median = arr => arr.length === 0 ? NaN : (arr.length % 2 === 1 ? arr[(arr.length - 1) / 2] : (arr[floor((arr.length - 1) / 2)] + arr[ceil((arr.length - 1) / 2)]) / 2);

  /**
   * @param {Array<number>} arr
   * @return {number}
   */
  const average = arr => arr.reduce(add, 0) / arr.length;

  /* eslint-env browser */

  const measure = performance.measure.bind(performance);
  const now = performance.now.bind(performance);
  const mark = performance.mark.bind(performance);

  /**
   * Testing framework with support for generating tests.
   *
   * ```js
   * // test.js template for creating a test executable
   * import { runTests } from 'lib0/testing'
   * import * as log from 'lib0/logging'
   * import * as mod1 from './mod1.test.js'
   * import * as mod2 from './mod2.test.js'

   * import { isBrowser, isNode } from 'lib0/environment.js'
   *
   * if (isBrowser) {
   *   // optional: if this is ran in the browser, attach a virtual console to the dom
   *   log.createVConsole(document.body)
   * }
   *
   * runTests({
   *  mod1,
   *  mod2,
   * }).then(success => {
   *   if (isNode) {
   *     process.exit(success ? 0 : 1)
   *   }
   * })
   * ```
   *
   * ```js
   * // mod1.test.js
   * /**
   *  * runTests automatically tests all exported functions that start with "test".
   *  * The name of the function should be in camelCase and is used for the logging output.
   *  *
   *  * @param {t.TestCase} tc
   *  *\/
   * export const testMyFirstTest = tc => {
   *   t.compare({ a: 4 }, { a: 4 }, 'objects are equal')
   * }
   * ```
   *
   * Now you can simply run `node test.js` to run your test or run test.js in the browser.
   *
   * @module testing
   */

  hasConf('extensive');

  /* c8 ignore next */
  const envSeed = hasParam('--seed') ? Number.parseInt(getParam('--seed', '0')) : null;

  class TestCase {
    /**
     * @param {string} moduleName
     * @param {string} testName
     */
    constructor (moduleName, testName) {
      /**
       * @type {string}
       */
      this.moduleName = moduleName;
      /**
       * @type {string}
       */
      this.testName = testName;
      /**
       * This type can store custom information related to the TestCase
       *
       * @type {Map<string,any>}
       */
      this.meta = new Map();
      this._seed = null;
      this._prng = null;
    }

    resetSeed () {
      this._seed = null;
      this._prng = null;
    }

    /**
     * @type {number}
     */
    /* c8 ignore next */
    get seed () {
      /* c8 ignore else */
      if (this._seed === null) {
        /* c8 ignore next */
        this._seed = envSeed === null ? uint32() : envSeed;
      }
      return this._seed
    }

    /**
     * A PRNG for this test case. Use only this PRNG for randomness to make the test case reproducible.
     *
     * @type {prng.PRNG}
     */
    get prng () {
      /* c8 ignore else */
      if (this._prng === null) {
        this._prng = create(this.seed);
      }
      return this._prng
    }
  }

  const repetitionTime = Number(getParam('--repetition-time', '50'));
  /* c8 ignore next */
  const testFilter = hasParam('--filter') ? getParam('--filter', '') : null;

  /* c8 ignore next */
  const testFilterRegExp = testFilter !== null ? new RegExp(testFilter) : /.*/;

  const repeatTestRegex = /^(repeat|repeating)\s/;

  /**
   * @param {string} moduleName
   * @param {string} name
   * @param {function(TestCase):void|Promise<any>} f
   * @param {number} i
   * @param {number} numberOfTests
   */
  const run = async (moduleName, name, f, i, numberOfTests) => {
    const uncamelized = fromCamelCase(name.slice(4), ' ');
    const filtered = !testFilterRegExp.test(`[${i + 1}/${numberOfTests}] ${moduleName}: ${uncamelized}`);
    /* c8 ignore next 3 */
    if (filtered) {
      return true
    }
    const tc = new TestCase(moduleName, name);
    const repeat = repeatTestRegex.test(uncamelized);
    const groupArgs = [GREY, `[${i + 1}/${numberOfTests}] `, PURPLE, `${moduleName}: `, BLUE, uncamelized];
    /* c8 ignore next 5 */
    if (testFilter === null) {
      groupCollapsed(...groupArgs);
    } else {
      group(...groupArgs);
    }
    const times = [];
    const start = now();
    let lastTime = start;
    /**
     * @type {any}
     */
    let err = null;
    mark(`${name}-start`);
    do {
      try {
        const p = f(tc);
        if (isPromise(p)) {
          await p;
        }
      } catch (_err) {
        err = _err;
      }
      const currTime = now();
      times.push(currTime - lastTime);
      lastTime = currTime;
      if (repeat && err === null && (lastTime - start) < repetitionTime) {
        tc.resetSeed();
      } else {
        break
      }
    } while (err === null && (lastTime - start) < repetitionTime)
    mark(`${name}-end`);
    /* c8 ignore next 3 */
    if (err !== null && err.constructor !== SkipError) {
      printError(err);
    }
    measure(name, `${name}-start`, `${name}-end`);
    groupEnd();
    const duration = lastTime - start;
    let success = true;
    times.sort((a, b) => a - b);
    /* c8 ignore next 3 */
    const againMessage = isBrowser
      ? `     - ${window.location.host + window.location.pathname}?filter=\\[${i + 1}/${tc._seed === null ? '' : `&seed=${tc._seed}`}`
      : `\nrepeat: npm run test -- --filter "\\[${i + 1}/" ${tc._seed === null ? '' : `--seed ${tc._seed}`}`;
    const timeInfo = (repeat && err === null)
      ? ` - ${times.length} repetitions in ${humanizeDuration(duration)} (best: ${humanizeDuration(times[0])}, worst: ${humanizeDuration(last(times))}, median: ${humanizeDuration(median(times))}, average: ${humanizeDuration(average(times))})`
      : ` in ${humanizeDuration(duration)}`;
    if (err !== null) {
      /* c8 ignore start */
      if (err.constructor === SkipError) {
        print(GREY, BOLD, 'Skipped: ', UNBOLD, uncamelized);
      } else {
        success = false;
        print(RED, BOLD, 'Failure: ', UNBOLD, UNCOLOR, uncamelized, GREY, timeInfo, againMessage);
      }
      /* c8 ignore stop */
    } else {
      print(GREEN, BOLD, 'Success: ', UNBOLD, UNCOLOR, uncamelized, GREY, timeInfo, againMessage);
    }
    return success
  };

  /**
   * @template T
   * @param {Array<T>} as
   * @param {Array<T>} bs
   * @param {string} [m]
   * @return {boolean}
   */
  const compareArrays = (as, bs, m = 'Arrays match') => {
    if (as.length !== bs.length) {
      fail(m);
    }
    for (let i = 0; i < as.length; i++) {
      if (as[i] !== bs[i]) {
        fail(m);
      }
    }
    return true
  };

  /**
   * @param {any} _constructor
   * @param {any} a
   * @param {any} b
   * @param {string} path
   * @throws {TestError}
   */
  const compareValues = (_constructor, a, b, path) => {
    if (a !== b) {
      fail(`Values ${stringify(a)} and ${stringify(b)} don't match (${path})`);
    }
    return true
  };

  /**
   * @param {string?} message
   * @param {string} reason
   * @param {string} path
   * @throws {TestError}
   */
  const _failMessage = (message, reason, path) => fail(
    message === null
      ? `${reason} ${path}`
      : `${message} (${reason}) ${path}`
  );

  /**
   * @param {any} a
   * @param {any} b
   * @param {string} path
   * @param {string?} message
   * @param {function(any,any,any,string,any):boolean} customCompare
   */
  const _compare = (a, b, path, message, customCompare) => {
    // we don't use assert here because we want to test all branches (istanbul errors if one branch is not tested)
    if (a == null || b == null) {
      return compareValues(null, a, b, path)
    }
    if (a.constructor !== b.constructor) {
      _failMessage(message, 'Constructors don\'t match', path);
    }
    let success = true;
    switch (a.constructor) {
      case ArrayBuffer:
        a = new Uint8Array(a);
        b = new Uint8Array(b);
      // eslint-disable-next-line no-fallthrough
      case Uint8Array: {
        if (a.byteLength !== b.byteLength) {
          _failMessage(message, 'ArrayBuffer lengths match', path);
        }
        for (let i = 0; success && i < a.length; i++) {
          success = success && a[i] === b[i];
        }
        break
      }
      case Set: {
        if (a.size !== b.size) {
          _failMessage(message, 'Sets have different number of attributes', path);
        }
        // @ts-ignore
        a.forEach(value => {
          if (!b.has(value)) {
            _failMessage(message, `b.${path} does have ${value}`, path);
          }
        });
        break
      }
      case Map: {
        if (a.size !== b.size) {
          _failMessage(message, 'Maps have different number of attributes', path);
        }
        // @ts-ignore
        a.forEach((value, key) => {
          if (!b.has(key)) {
            _failMessage(message, `Property ${path}["${key}"] does not exist on second argument`, path);
          }
          _compare(value, b.get(key), `${path}["${key}"]`, message, customCompare);
        });
        break
      }
      case undefined: // undefined is often set as a constructor for objects
      case Object:
        if (length(a) !== length(b)) {
          _failMessage(message, 'Objects have a different number of attributes', path);
        }
        forEach$2(a, (value, key) => {
          if (!hasProperty(b, key)) {
            _failMessage(message, `Property ${path} does not exist on second argument`, path);
          }
          _compare(value, b[key], `${path}["${key}"]`, message, customCompare);
        });
        break
      case Array:
        if (a.length !== b.length) {
          _failMessage(message, 'Arrays have a different number of attributes', path);
        }
        // @ts-ignore
        a.forEach((value, i) => _compare(value, b[i], `${path}[${i}]`, message, customCompare));
        break
      /* c8 ignore next 4 */
      default:
        if (!customCompare(a.constructor, a, b, path, compareValues)) {
          _failMessage(message, `Values ${stringify(a)} and ${stringify(b)} don't match`, path);
        }
    }
    assert(success, message);
    return true
  };

  /**
   * @template T
   * @param {T} a
   * @param {T} b
   * @param {string?} [message]
   * @param {function(any,T,T,string,any):boolean} [customCompare]
   */
  const compare = (a, b, message = null, customCompare = compareValues) => _compare(a, b, 'obj', message, customCompare);

  /**
   * @template T
   * @param {T} property
   * @param {string?} [message]
   * @return {asserts property is NonNullable<T>}
   * @throws {TestError}
   */
  /* c8 ignore next */
  const assert = (property, message = null) => { property || fail(`Assertion failed${message !== null ? `: ${message}` : ''}`); };

  /**
   * @param {Object<string, Object<string, function(TestCase):void|Promise<any>>>} tests
   */
  const runTests = async tests => {
    /**
     * @param {string} testname
     */
    const filterTest = testname => testname.startsWith('test') || testname.startsWith('benchmark');
    const numberOfTests = map$1(tests, mod => map$1(mod, (f, fname) => /* c8 ignore next */ f && filterTest(fname) ? 1 : 0).reduce(add, 0)).reduce(add, 0);
    let successfulTests = 0;
    let testnumber = 0;
    const start = now();
    for (const modName in tests) {
      const mod = tests[modName];
      for (const fname in mod) {
        const f = mod[fname];
        /* c8 ignore else */
        if (f && filterTest(fname)) {
          const repeatEachTest = 1;
          let success = true;
          for (let i = 0; success && i < repeatEachTest; i++) {
            success = await run(modName, fname, f, testnumber, numberOfTests);
          }
          testnumber++;
          /* c8 ignore else */
          if (success) {
            successfulTests++;
          }
        }
      }
    }
    const end = now();
    print('');
    const success = successfulTests === numberOfTests;
    /* c8 ignore start */
    if (success) {
      print(GREEN, BOLD, 'All tests successful!', GREY, UNBOLD, ` in ${humanizeDuration(end - start)}`);
      printImgBase64(nyanCatImage, 50);
    } else {
      const failedTests = numberOfTests - successfulTests;
      print(RED, BOLD, `> ${failedTests} test${failedTests > 1 ? 's' : ''} failed`);
    }
    /* c8 ignore stop */
    return success
  };

  class TestError extends Error {}

  /**
   * @param {string} reason
   * @throws {TestError}
   */
  const fail = reason => {
    print(RED, BOLD, 'X ', UNBOLD, reason);
    throw new TestError('Test Failed')
  };

  class SkipError extends Error {}

  // eslint-disable-next-line
  const nyanCatImage = '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';

  // When changing this, also make sure to change the file in gitignore
  const storageName = 'tmp-leveldb-storage';

  /**
   * Read state vector from Decoder and return as Map. This is a helper method that will be exported by Yjs directly.
   *
   * @param {decoding.Decoder} decoder
   * @return {Map<number,number>} Maps `client` to the number next expected `clock` from that client.
   *
   * @function
   */
  const readStateVector = decoder => {
    const ss = new Map();
    const ssLength = readVarUint(decoder);
    for (let i = 0; i < ssLength; i++) {
      const client = readVarUint(decoder);
      const clock = readVarUint(decoder);
      ss.set(client, clock);
    }
    return ss
  };

  /**
   * Read decodedState and return State as Map.
   *
   * @param {Uint8Array} decodedState
   * @return {Map<number,number>} Maps `client` to the number next expected `clock` from that client.
   *
   * @function
   */
  const decodeStateVector = decodedState => readStateVector(createDecoder(decodedState));

  /**
   * Flushes all updates to ldb and delets items from updates array.
   *
   * @param {LeveldbPersistence} ldb
   * @param {string} docName
   * @param {Array<Uint8Array>} updates
   */
  const flushUpdatesHelper = (ldb, docName, updates) =>
    Promise.all(updates.splice(0).map(update => ldb.storeUpdate(docName, update)));

  /**
   * @param {t.TestCase} tc
   */
  const testLeveldbUpdateStorage = async tc => {
    const docName = tc.testName;
    const ydoc1 = new Doc();
    ydoc1.clientID = 0; // so we can check the state vector
    const leveldbPersistence = new LeveldbPersistence(storageName);
    // clear all data, so we can check allData later
    await leveldbPersistence._transact(async db => db.clear());
    compareArrays([], await leveldbPersistence.getAllDocNames());

    /**
     * @type {Array<Uint8Array>}
     */
    const updates = [];

    ydoc1.on('update', update => {
      updates.push(update);
    });

    ydoc1.getArray('arr').insert(0, [1]);
    ydoc1.getArray('arr').insert(0, [2]);

    await flushUpdatesHelper(leveldbPersistence, docName, updates);

    const encodedSv = await leveldbPersistence.getStateVector(docName);
    const sv = decodeStateVector(encodedSv);
    assert(sv.size === 1);
    assert(sv.get(0) === 2);

    const ydoc2 = await leveldbPersistence.getYDoc(docName);
    compareArrays(ydoc2.getArray('arr').toArray(), [2, 1]);

    const allData = await leveldbPersistence._transact(async db => getLevelBulkEntries(db, { gte: ['v1'], lt: ['v2'] }));
    assert(allData.length > 0, 'some data exists');

    compareArrays([docName], await leveldbPersistence.getAllDocNames());
    await leveldbPersistence.clearDocument(docName);
    compareArrays([], await leveldbPersistence.getAllDocNames());
    const allData2 = await leveldbPersistence._transact(async db => getLevelBulkEntries(db, { gte: ['v1'], lt: ['v2'] }));
    console.log(allData2);
    assert(allData2.length === 0, 'really deleted all data');

    await leveldbPersistence.destroy();
  };

  /**
   * @param {t.TestCase} tc
   */
  const testEncodeManyUpdates = async tc => {
    const N = PREFERRED_TRIM_SIZE * 7;
    const docName = tc.testName;
    const ydoc1 = new Doc();
    ydoc1.clientID = 0; // so we can check the state vector
    const leveldbPersistence = new LeveldbPersistence(storageName);
    await leveldbPersistence.clearDocument(docName);

    /**
     * @type {Array<Uint8Array>}
     */
    const updates = [];

    ydoc1.on('update', update => {
      updates.push(update);
    });
    await flushUpdatesHelper(leveldbPersistence, docName, updates);

    const keys = await leveldbPersistence._transact(db => getLevelUpdatesEntries(db, docName));

    for (let i = 0; i < keys.length; i++) {
      assert(keys[i].key[3] === i);
    }

    const yarray = ydoc1.getArray('arr');
    for (let i = 0; i < N; i++) {
      yarray.insert(0, [i]);
    }
    await flushUpdatesHelper(leveldbPersistence, docName, updates);

    const ydoc2 = await leveldbPersistence.getYDoc(docName);
    assert(ydoc2.getArray('arr').length === N);

    await leveldbPersistence.flushDocument(docName);
    const mergedKeys = await leveldbPersistence._transact(db => getLevelUpdatesEntries(db, docName));
    assert(mergedKeys.length === 1);

    // getYDoc still works after flush/merge
    const ydoc3 = await leveldbPersistence.getYDoc(docName);
    assert(ydoc3.getArray('arr').length === N);

    // test if state vector is properly generated
    compare(encodeStateVector(ydoc1), await leveldbPersistence.getStateVector(docName));
    // add new update so that sv needs to be updated
    ydoc1.getArray('arr').insert(0, ['new']);
    await flushUpdatesHelper(leveldbPersistence, docName, updates);
    compare(encodeStateVector(ydoc1), await leveldbPersistence.getStateVector(docName));

    await leveldbPersistence.destroy();
  };

  /**
   * @param {t.TestCase} tc
   */
  const testDiff = async tc => {
    const N = PREFERRED_TRIM_SIZE * 2; // primes are awesome - ensure that the document is at least flushed once
    const docName = tc.testName;
    const ydoc1 = new Doc();
    ydoc1.clientID = 0; // so we can check the state vector
    const leveldbPersistence = new LeveldbPersistence(storageName);
    await leveldbPersistence.clearDocument(docName);

    /**
     * @type {Array<Uint8Array>}
     */
    const updates = [];
    ydoc1.on('update', update => {
      updates.push(update);
    });

    const yarray = ydoc1.getArray('arr');
    // create N changes
    for (let i = 0; i < N; i++) {
      yarray.insert(0, [i]);
    }
    await flushUpdatesHelper(leveldbPersistence, docName, updates);

    // create partially merged doc
    const ydoc2 = await leveldbPersistence.getYDoc(docName);

    // another N updates
    for (let i = 0; i < N; i++) {
      yarray.insert(0, [i]);
    }
    await flushUpdatesHelper(leveldbPersistence, docName, updates);

    // apply diff to doc
    const diffUpdate = await leveldbPersistence.getDiff(docName, encodeStateVector(ydoc2));
    applyUpdate(ydoc2, diffUpdate);

    assert(ydoc2.getArray('arr').length === ydoc1.getArray('arr').length);
    assert(ydoc2.getArray('arr').length === N * 2);

    await leveldbPersistence.destroy();
  };

  /**
   * @param {t.TestCase} tc
   */
  const testMetas = async tc => {
    const docName = tc.testName;
    const leveldbPersistence = new LeveldbPersistence(storageName);
    await leveldbPersistence.clearDocument(docName);

    await leveldbPersistence.setMeta(docName, 'a', 4);
    await leveldbPersistence.setMeta(docName, 'a', 5);
    await leveldbPersistence.setMeta(docName, 'b', 4);
    const a = await leveldbPersistence.getMeta(docName, 'a');
    const b = await leveldbPersistence.getMeta(docName, 'b');
    assert(a === 5);
    assert(b === 4);
    const metas = await leveldbPersistence.getMetas(docName);
    assert(metas.size === 2);
    assert(metas.get('a') === 5);
    assert(metas.get('b') === 4);
    await leveldbPersistence.delMeta(docName, 'a');
    const c = await leveldbPersistence.getMeta(docName, 'a');
    assert(c === undefined);
    await leveldbPersistence.clearDocument(docName);
    const metasEmpty = await leveldbPersistence.getMetas(docName);
    assert(metasEmpty.size === 0);

    await leveldbPersistence.destroy();
  };

  /**
   * @param {t.TestCase} tc
   */
  const testDeleteEmptySv = async tc => {
    const docName = tc.testName;
    const leveldbPersistence = new LeveldbPersistence(storageName);
    await leveldbPersistence.clearAll();

    const ydoc = new Doc();
    ydoc.clientID = 0;
    ydoc.getArray('arr').insert(0, [1]);
    const singleUpdate = encodeStateAsUpdate(ydoc);

    compareArrays([], await leveldbPersistence.getAllDocNames());
    await leveldbPersistence.storeUpdate(docName, singleUpdate);
    compareArrays([docName], await leveldbPersistence.getAllDocNames());
    const docSvs = await leveldbPersistence.getAllDocStateVectors();
    assert(docSvs.length === 1);
    compare([{ name: docName, clock: 0, sv: encodeStateVector(ydoc) }], docSvs);

    await leveldbPersistence.clearDocument(docName);
    compareArrays([], await leveldbPersistence.getAllDocNames());
    await leveldbPersistence.destroy();
  };

  /**
   * @param {t.TestCase} tc
   */
  const testMisc = async tc => {
    const docName = tc.testName;
    const leveldbPersistence = new LeveldbPersistence(storageName);
    await leveldbPersistence.clearDocument(docName);

    const sv = await leveldbPersistence.getStateVector('does not exist');
    assert(sv.byteLength === 1);

    await leveldbPersistence.destroy();
  };

  var leveldb = /*#__PURE__*/Object.freeze({
    __proto__: null,
    testLeveldbUpdateStorage: testLeveldbUpdateStorage,
    testEncodeManyUpdates: testEncodeManyUpdates,
    testDiff: testDiff,
    testMetas: testMetas,
    testDeleteEmptySv: testDeleteEmptySv,
    testMisc: testMisc
  });

  if (isBrowser) {
    createVConsole(document.body);
  }
  runTests({
    leveldb
  }).then(success => {
    /* istanbul ignore next */
    if (isNode) {
      process.exit(success ? 0 : 1);
    }
  });

})();
//# sourceMappingURL=test.js.map
